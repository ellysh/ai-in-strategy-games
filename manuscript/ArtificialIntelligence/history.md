## 2.1 История

Искусственный интеллект (ИИ) как направление исследований появился на стыке нескольких дисциплин. Он перенял некоторые теории, идеи и методы из других наук. Эти науки приводит таблица 2-1.

{caption: "Таблица 2-1. Науки, оказавшие влияние на ИИ", width: "100%"}
| Наука | Применяемая в ИИ теория, идея или метод |
| --- | --- |
| Нейрофизиология | Модель искусственного нейрона и нейронной сети |
|  | |
| Математика | Правила формальной логики и логического вывода |
|  | Статистические методы |
|  | Теория вероятностей |
|  | Теория принятия решений |
|  | |
| Информатика | Языки программирования |
|  | Теория вычислительной сложности |
|  | Высокопроизводительные компьютеры |
|  | |
| Кибернетика | Теория управления сложных систем |

Проследим путь развития ИИ и разберёмся, почему именно эти науки оказали на него влияние.

### 2.1.1 Появление новой науки 1943 – 1956

#### 2.1.1.1 Нейронная сеть

##### 2.1.1.1.1 Искусственный нейрон

Первая исследовательская работа в области ИИ связана с нейрофизиологией и математикой. Её выполнили американские учёные [Уоррен Мак-Каллок](https://ru.wikipedia.org/wiki/Мак-Каллок,_Уоррен) и [Уолтер Питтс](https://ru.wikipedia.org/wiki/Питтс,_Уолтер), когда изучали мозг человека.

Уоррен Мак-Каллок был известным нейрофизиком. Он изучал медицину в колледже врачей и хирургов Колумбийского университета в Нью-Йорке, где в 1927 году получил степень доктора медицины. После этого он занимался медицинской практикой до 1937 года. Закончив её, Мак-Каллок работал в лаборатории нейрофизиологии Йельского университета. В 1941 году он переехал в Чикаго и поступил на кафедру психиатрии Иллинойского университета в Чикаго, где был профессором психиатрии.

Уолтер Питтс был самоучкой из бедной семьи. В 1935 году в возрасте 12 лет Питтс прочитал "Основания математики" Бертрана Рассела. Он нашёл в книге несколько ошибок и написал о них автору. Благодаря этой переписке с известным английским математиком, Уолтер Питтс смог получить образование в Иллинойсском университете в Чикаго. Его специальностью была математическая логика.

Уоррен Мак-Каллок и Уолтер Питтс познакомились Иллинойсском университете. Они решили объединить свои знания и усилия, чтобы найти логические закономерности работы мозга. Вместе учёные разработали математическую модель связанных между собой [**искусственных нейронов**](https://ru.wikipedia.org/wiki/Искусственный_нейрон). Эта модель впоследствии стала известна как **бинарный пороговый нейрон** ([binary threshold neuron](https://www.youtube.com/watch?v=iKKfoP-naN8)).

[**Нейрон**](https://ru.wikipedia.org/wiki/Нейрон) — это узкоспециализированная электрически возбудимая клетка. В организме человека и животных нейроны соединяются друг с другом в [**нервную сеть**](https://ru.wikipedia.org/wiki/Нервная_сеть). По этой сети проходят электрические и химические сигналы. С их помощью передаётся информация между узлами нервной системы.

Бинарный пороговый нейрон представляет собой упрощённую модель биологического нейрона. Эта модель имеет два состояния: возбуждённое и невозбуждённое. На вход нейрон получает сигналы от других нейронов. Их обрабатывает [**функция активации**](https://ru.wikipedia.org/wiki/Функция_активации). Результат функции передаётся на выход нейрона, который связан со входами других нейронов.

Функция активации бинарного порогового нейрона называется **ступенчатой** ([step function](https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Activation_Functions#Step_Function)). Её формула выглядит следующим образом:
{width: "50%"}
![](images/ArtificialIntelligence/step-function-formula.png)

В этой формуле используются следующие обозначения:

* f(x) — результат функции
* m — число входных сигналов нейрона
* x~i~ — значение i-ого входного сигнала
* θ — пороговое значение для входных сигналов.

Иллюстрация 2-1 демонстрирует график ступенчатой функции активации. Результат функции f(x) отображается на оси Y, а сумма входных сигналов — на оси X. Пока эта сумма меньше θ, нейрон находится в невозбуждённом состоянии. Его выходной сигнал равен нулю. Когда сумма входных сигналов превышает θ, нейрон возбуждается. Его выходной сигнал становится равен единице.

{caption: "Иллюстрация 2-1. Ступенчатая функция активации бинарного порогового нейрона", height: "30%"}
![Ступенчатая функция активации бинарного порогового нейрона](images/ArtificialIntelligence/step-function-graph.png)

Мак-Каллок и Питтс попробовали связать между собой несколько искусственных нейронов. При этом выходы одних нейронов соединялись со входами других. Такая структура получила название [**нейронная сеть**](https://ru.wikipedia.org/wiki/Нейронная_сеть).

Мак-Каллок и Питтс доказали, что нейронная сеть способна выполнять числовые и логические операции. Кроме того они предположили, что сети с особенной архитектурой способны обучаться. В 1943 году учёные опубликовали свои результаты в статье "Логическое исчисление идей, присущих нервной деятельности" (A Logical Calculus of Ideas Immanent in Nervous Activity).

Модель нейронной сети Мак-Каллока и Питтса была только теоретической. Учёные подтверждали свои гипотезы только математическими выкладками. На тот момент не существовало программы или устройства, которое работало как нейронная сеть. Поэтому нельзя было проверить работоспособность модели на практике.

##### 2.1.1.1.2 Обучение нейронной сети

Модель Мак-Каллока и Питтса показала вычислительный потенциал нейронных сетей. В своей статье учёные рассмотрели, как сети работают с логическими выражениями. Таким образом новая модель является вычислительным механизмом. Но чтобы решать с его помощью реальные задачи, нужны средства управления. Для универсальных компьютеров такими средствами управления стали программы. Это же решение не подходит для нейронных сетей. Для них нужен принципиально иной подход.

Прототип средств управления нейронной сетью разработал канадский нейропсихолог [Дональд Хебб](https://ru.wikipedia.org/wiki/Хебб,_Дональд). Он изучал влияние хирургии и травм головного мозга человека на его функции. Также учёный проводил эксперименты на животных. Он пытался выяснить, как обучение в детском возрасте влияет на поведение взрослых животных. Результаты своих исследований и их трактовку Дональд Хебб привёл в книге "Организация поведения: нейропсихологическая теория" (The Organization of Behavior: A Neuropsychological Theory). Она была опубликована в 1949 году.

Книга посвящена не искусственным нейронным сетям, а нейробиологии. На момент её написания существовало несколько теорий поведения человека: [**бихевиоризм**](https://ru.wikipedia.org/wiki/Бихевиоризм), [**гештальтпсихология**](https://ru.wikipedia.org/wiki/Гештальтпсихология) и другие. Каждая из теорий хорошо объясняла некоторые психические функции, но имела трудности с другими. Дональд Хебб объединил существующие данные о поведении и мозге в единую теорию. Она связала биологические функции мозга как органа с высшими функциями разума.

Центральная идея книги — зависимость поведения человека от способа обработки информации мозгом. Учёный ввёл понятие **сборка клеток** (cell assembly), которое означает взаимосвязанные нейроны. Дональд Хебб утверждает, что обучение и память основаны на формировании сборок клеток. Входящие в одну сборку нейроны активируются вместе в результате обучения. Именно такие взаимосвязанные нейроны являются основными единицами мышления. Их организация определяет поведение человека.

Согласно Дональду Хеббу, поведение человека определяется двумя фундаментальными процессами: физиологическими процессами мозга и переживаниями. Учёный предположил, что эти два фактора неразрывно связаны. Мозг постоянно приспосабливается к окружающей среде. Для этого между нейронами образуются новые связи.

Предложенная Дональдом Хеббом теория обучения нейронов человеческого мозга получила название **обучение Хебба**. Основное правило этой теории учёный сформулировал так:

> Пусть аксон клетки А находится достаточно близко, чтобы возбуждать клетку B. Он неоднократно или постоянно принимает участие в ее возбуждении. Тогда наблюдается процесс роста или метаболических изменений в одной или обеих клетках. Этот процесс увеличивает эффективность А, как одной из клеток возбуждающих В

I> **Аксон** — это длинный цилиндрический отросток нервной клетки, по которому нервные импульсы идут от её тела к органам и другим нервным клеткам.

Этот постулат известен как [**правило Хебба**](https://habr.com/ru/articles/102305/). Оно объясняет, как связи между нейронами меняются в зависимости от их активности. Простыми словами его можно переформулировать так:

> Если за активацией нейрона А последовательно следует активация нейрона Б, связь между ними усиливается. С другой стороны, если за активацией нейрона А не следует активация нейрона Б, связь ослабевает.

Правило Хебба заложило основу теории обучения искусственных нейронных сетей. Именно разработанные в рамках этой теории алгоритмы и стали средствами управления для нейронных сетей.

#### 2.1.1.2 Статьи Тьюринга

##### 2.1.1.2.1 Статья "Умная машинерия"

Известный английский математик и криптограф [Алан Тьюринг](https://ru.wikipedia.org/wiki/Тьюринг,_Алан) посвятил две статьи теме искусственного интеллекта. В них он рассуждает о том, возможно ли в принципе создать машину с интеллектом уровня человека.

Первую статью учёный написал в 1948 году. Она получила название ["Умная машинерия"](https://weightagnostic.github.io/papers/turing1948.pdf) (Intelligent Machinery). Статья представляла собой отчёт Алана Тьюринга для Национальной физической лаборатории Великобритании (National Physical Laboratory или NPL). Отчёт был засекречен и долгое время нигде не публиковался. Только спустя 40 лет он стал доступен для широкой публики.

Отчёт "Умная машинерия" написан формальным языком, как и другие научные работы Алана Тьюринга. Статья начинается с вопроса: "способны ли машины демонстрировать разумное поведение?". В конце 1950-х годов большинство учёных отвечали на него отрицательно. Поэтому автор подробно разбирает несколько распространённых возражений.

Далее Алан Тьюринг рассуждает о "машинерии". Так он называет существующие и гипотетические устройства, которые теоретически могли бы демонстрировать разумное поведение. Автор рассматривает следующие из них:

* **Логические вычислительные машины** (logical computing machines) — например, модель абстрактного вычислителя [**машина Тьюринга**](https://ru.wikipedia.org/wiki/Машина_Тьюринга).

* **Реальные вычислительные машины** (practical computing machines) — например существующие на тот момент универсальные цифровые компьютеры [ENIAC](https://ru.wikipedia.org/wiki/ЭНИАК) и [ACE](https://ru.wikipedia.org/wiki/ACE).

* **Бумажные машины** (paper machine) — когда человек с бумагой и ручкой исполняет набор формальных правил для решения поставленной задачи.

* **Частично случайные машины** (partially random machines) — это гипотетические компьютеры, в которых могут выполняться несколько альтернативных операций одновременно. Некоторый случайный процесс выбирает один из результатов этих операций в качестве окончательного.

* **Неорганизованные машины** (unorganized machines) — машины собранные из неких стандартных компонентов, конструкция которых изначально не предполагает конкретной цели.

Из этого списка Алан Тьюринг выбирает неорганизованные машины, как наиболее перспективные. Автор предлагает некоторый процесс обучения, который меняет состояние неорганизованной машины. В результате обучения она становится пригодной для решения конкретных задач.

В своих рассуждения Алан Тьюринг неоднократно проводит параллели между неорганизованной машиной и корой головного мозга человека. Так же он сравнивает процессы обучения машины и человека. Между ними автор находит аналогии.

Далее учёный говорит о двух подходах к созданию машины, демонстрирующей разумное поведение. Первый подход автор называет **прямым методом** (direct method). Он заключается в программировании реальной вычислительной машины. Этот подход основан на следующем предположении:

> Если машина будет следовать небольшому набору общих принципов, она буде демонстрировать разумное поведение.

Второй подход — это обучение неорганизованной машины. Результатом такого обучения станет разумное поведение. Именно этим двум направлениям следовало развитие ИИ в будущем.

В конце статьи Алан Тьюринг размышляет о критериях разумного поведения. Он предлагает тест для трёх участников:

1. Шахматист A.
2. Шахматист С.
3. Оператор B, работающий на бумажной машине.

Участники должны сыграть друг с другом в шахматы, находясь в разных комнатах. В результате игры участник C должен определить, кто из оппонентов — шахматист A, а кто — оператор машины B. Если C не может верно ответить, значит машина B демонстрирует разумное поведение.

В отчёте "Умная машинерия" Алан Тьюринг впервые высказал идею о том, чтобы применить процесс обучения к машинам особого типа. Исследователи ИИ реализовали её на практике только спустя десять лет. Если бы отчёт не был засекречен, это могло бы произойти намного раньше.

##### 2.1.1.2.2 Статья "Вычислительные машины и разум"

Спустя два года Алан Тьюринг написал вторую статью с названием ["Вычислительные машины и разум"](https://ru.wikipedia.org/wiki/Вычислительные_машины_и_разум) (Computing Machinery and Intelligence). Её опубликовал английский журнал Mind в 1950 году. Этот журнал издаётся небольшим тиражом Оксфордским университетом. Он посвящён психологии и философии.

Статья Тьюринга стала широко известна в 1956 году после того, как попала в сборник "Мир Математики" (The Worlds of Mathematics). Его составил американский математик [Джеймс Ньюмен](https://ru.wikipedia.org/wiki/Ньюмен,_Джеймс_(математик)). В этом же году появился термин "искусственный интеллект". Возможно, это совпадение и авторитет Тьюринга возвело статью в культ.

В статье "Вычислительные машины и разум" Алан Тьюринг неформальным языком пересказывает свои мысли из засекреченного отчёта "Умная машинерия". Главная тема отчёта техническая: устройство и свойства различных машин, а также возможность их обучения. Статья же носит более философский характер.

Учёный начинает статью с определения терминов "машина" и "думать". Он признаёт, что любое их однозначное определение вызовет критику. Поэтому автор подменяет вопрос "может ли машина думать?" на "может ли машина имитировать разумное поведение"?

Чтобы объективно оценить возможности машины, Алан Тьюринг предлагает **игру в имитацию**. Это продолжение идеи шахматного теста из отчёта "Умная машинерия". Суть игры в том, что человек и машина обмениваются с судьёй текстовыми сообщениями. Все три участника находятся в разных комнатах и не видят друг друга. После переписки судья должен определить, кто из собеседников является машиной. Если судья не может этого сделать, выигрывает машина.

Игра в имитацию получила известность как [**тест Тьюринга**](https://ru.wikipedia.org/wiki/Тест_Тьюринга). Его смысл учёный формулирует так:

> Прошедшая тест машина должна считаться разумной в том же смысле, что и человек.

Далее Алан Тьюринг рассматривает объекты, которые можно отнести к категории "машина". Он предлагает ограничиться только **цифровыми компьютерами**, которые оперируют числами 0 и 1. Эти компьютеры должны быть универсальны в том смысле, что с помощью программирования их можно настроить на решение любой задачи. Возможно, из соображений секретности Тьюринг даёт крайне общее описание машин такого типа. Хотя он сам участвовал в военных проектах по их созданию.

После определения терминов Алан Тьюринг рассматривает девять возражений против идеи о том, что машины могут мыслить. Эту же тему он поднимал в отчёте, но на этот раз останавливается на ней подробнее. Среди возражений есть теологическое: машины не могут обладать духовными качествами и сознанием. Так же — математическое: машины ограничены формальными правилами и не могут выйти за их пределы. Рассмотрев аргументы против, Алан Тьюринг утверждает, что все они основаны на предвзятых представлениях. Возражения не дают окончательных доказательств того, что машинный интеллект невозможен в принципе.

В заключении статьи Алан Тьюринг утверждает, что машина может пройти игру в имитацию. Он предлагает модель обучающейся машины, которая теоретически на это способна. Опять же это неформальный пересказ идей из отчёта "Умная машинерия". Тьюринг описывает базовые принципы машинного обучения и генетических алгоритмов. Эти идеи намного опередили своё время. Только спустя годы исследователи ИИ смогут применить их на практике.

Статья Алана Тьюринга оказала огромное влияние на первых исследователей в области искусственного интеллекта. Она предлагает простую цель. Её достижение означает создание разумной машины. Многие учёные последовали за этой целью. Но были и те, кто критиковал идеи Тьюринга.

Есть мнение, что статья "Вычислительные машины и разум" — это мистификация или даже розыгрыш. Его сторонники указывают на шутливый тон автора и отсутствие строгих математических выкладок, характерных для других работ Алана Тьюринга.

Мне кажется более правдоподобной другая точка зрения. Алан Тьюринг задумал статью, чтобы спровоцировать широкую дискуссию о разумности машин. И этой цели он достиг: статья вызывала горячие споры на протяжении последующих десятилетий. Не имея возможности опубликовать секретный отчёт, Алан Тьюринг был вынужден завуалировано его пересказать. В то же время неформальная подача сделала мысли автора доступными для не математиков. Учёные из смежных областей тоже приняли участие в дискуссиях на тему ИИ и внесли свой вклад в развитие этой области.

Так или иначе несколько интеллектуальных систем уже успешно прошли тест Тьюринга. Однако никто не считает их разумными в каком-либо смысле этого слова. Современные исследователи отказались как от самого теста в качестве критерия оценки, так и от идеи мыслящей как человек машины. Несмотря на это, высказанные Тьюрингом идеи машинного обучения успешно применяются в большинстве современных ИИ систем.

#### 2.1.1.3 Logic Theorist

Первую интеллектуальную систему в виде компьютерной программы разработала группа американских учёных в 1956 году. Система получила название [Logic Theorist](https://en.wikipedia.org/wiki/Logic_Theorist). Её авторы работали на корпорацию [RAND](https://ru.wikipedia.org/wiki/RAND_(корпорация)), которая с 1948 года занималась стратегическими исследованиями для правительства США. Их было трое:

* [Герберт Саймон](https://ru.wikipedia.org/wiki/Саймон,_Герберт_Александер) — учёный в области экономических, социальных и политических наук. Одна из его работа посвящена принятию решений в правительственных учреждениях и компаниях. В своих исследованиях он использовал методы теории принятия решений.

* [Аллен Ньюэлл](https://ru.wikipedia.org/wiki/Ньюэлл,_Аллен) — учёный в области логистики и [теории организаций](https://ru.wikipedia.org/wiki/Теория_организаций). Это теория из области социологии, которая исследует взаимодействия людей в политических и коммерческих организациях.

* [Клиффорд Шоу](https://en.wikipedia.org/wiki/Cliff_Shaw) — опытный программист корпорации RAND, который реализовал замыслы Саймона и Ньюэлла.

Идею системы предложил Аллен Ньюэлл. Он утверждал, что простое программируемое устройство, вроде компьютера, способно на сложное поведение. Чтобы проверить эту гипотезу Ньюэлл и Саймон решили разработать систему для [**доказательства математических теорем**](https://en.wikipedia.org/wiki/Automated_theorem_proving) (automated theorem proving). Тогда к проекту присоединился Клиффорд Шоу, чтобы помочь с программированием.

Система Logic Theorist смогла доказать 38 теорем из книги ["Начала математики"](https://ru.wikipedia.org/wiki/Principia_Mathematica) Бертрана Рассела. Учёные посчитали, что это подтверждает гипотезу Аллена Ньюэлла. По их мнению универсальный компьютер, доказывающий математические теоремы, демонстрирует способность к разумному поведению.

В середине 1950-х годов считалось, что цифровые компьютеры могут оперировать только числами. Вопреки этому мнению, система Logic Theorist работала с символами. Её разработчики утверждали, что создали программу, способную мыслить в нечисловых терминах. Операции над символами позволили перейти от математических вычислений к логическим высказываниям. Этот подход стал доминирующим в области ИИ в течение следующих 30 лет.

Разработчики Logic Theorist впервые применили следующие концепций:

* **Рассуждение как поиск**. Logic Theorist представляет доказательство гипотезы как поиск по дереву. Корень дерева соответствует начальной гипотезе. Исходящие из корня ветви — это логические операции над начальной гипотезой. Каждая ветвь приводит к определённому выводу. Один из этих выводов является целью рассуждения. Именно его и ищет система.

* [**Эвристика**](https://ru.wikipedia.org/wiki/Эвристика) — это дополнительное правило, которое исключает из рассмотрения некоторые ветви дерева поиска. Эвристика позволяет предсказать без проверки, что какая-то ветвь не приведёт к решению. Удаление таких ветвей значительно сокращает время поиска.

* **Обработка списков**. Чтобы написать программу Logic Theorist, был разработан специальный язык программирования [IPL](https://en.wikipedia.org/wiki/Information_Processing_Language). Для него Клиффорд Шоу впервые применил структуру данных под названием [**связанный список**](https://ru.wikipedia.org/wiki/Связный_список). Она хранит список символов в эффективном формате. Позднее на основе IPL и списков Джон Маккарти разработает язык Lisp, который станет одним из основных для исследователей ИИ.

Новаторские идеи, заложенные в Logic Theorist, во многом определили дальнейшее развитие области ИИ.

#### 2.1.1.4 Дартмутский семинар

В начале 1950-х годов учёные проводили первые исследования в области искусственного интеллекта. Однако, самого этого термина не существовало до лета 1956 года. Поэтому свою работу учёные относили к сложной обработке информации, кибернетике или теории автоматов. Название зависело от подхода, выбранного в каждом конкретном проекте.

В 1955 году американский математик Джон Маккарти решил организовать [семинар](https://ru.wikipedia.org/wiki/Дартмутский_семинар), посвящённый "думающим машинам". Он собирался пригласить исследователей, которые уже занимались этой темой. Участники семинара должны были представить свои результаты и в ходе открытого обсуждения обменяться опытом. На тот момент Джон Маккарти работал в Дартмутском колледже в Хановере (штат Нью-Гэмпшир). Поэтому это мероприятие стало известно как **Дартмутский семинар**.

При подготовке семинара и поиска средств на его проведение сформировалась группа организаторов. В неё входили:

* Джон Маккарти
* Клод Шеннон
* Марвин Мински
* Натаниэль Рочестер

Спонсором мероприятия стал благотворительный фонд Рокфеллера (Rockefeller Foundation).

[Заявка на проведение семинара](http://raysolomonoff.com/dartmouth/boxa/dart564props.pdf) начиналась так:

> Мы предлагаем провести двухмесячное исследование искусственного интеллекта с участием 10 человек летом 1956 года в Дартмутском колледже в Хановере, штат Нью-Гэмпшир. Исследование основано на предположении, что каждый аспект обучения или любое другое свойство интеллекта можно в принципе описать столь точно, что возможно создать машину, которая сможет его симулировать. Мы попытаемся понять, как заставить машины использовать язык, формировать абстракции и концепции, решать задачи, доступные сейчас только людям, и улучшать самих себя. Мы считаем, что существенное продвижение в одной или более из этих проблем вполне возможно, если специально подобранная группа учёных будет работать над ними в течение лета.

Далее документ предлагает следующие темы для обсуждения на семинаре:

1. Компьютеры и их возможности.
2. Обработка естественного языка.
3. Искусственные нейронные сети.
4. Теория вычислений.
5. Самосовершенствование машин.
6. Формирование абстракций машиной.
7. Случайность и творчество в работе машин.

Именно заявка на проведение семинара стала первым официальным документом, в котором употребляется термин "искусственный интеллект". До этого его никто нигде не использовал. Организаторы придумали новый термин, чтобы предотвратить возможные споры относительно подходов. Если бы они выбрали любое уже существующее название научной области, это сфокусировало бы обсуждения только на конкретном подходе. Целью же семинара был [**мозговой штурм**](https://ru.wikipedia.org/wiki/Метод_мозгового_штурма), то есть разработка совершенно новых идей.

В семинаре приняли участие ведущие учёные из следующих областей:

* Теория управления
* Теория автоматов
* Нейрофизиология
* Теорией игр
* Когнитивная психология

Самыми обсуждаемыми темами стали: обработка естественных языков, ориентированные на прикладные области системы (ранние экспертные системы), дедуктивные и индуктивные системы логического вывода. С другой стороны, искусственные нейронные сети и машинное обучение не получили должного внимания.

Затронутые на семинаре темы было решено объединить в единое научное направление под названием "искусственный интеллект". Это решение оказало огромное влияние на последующие исследования. Во-первых, доминирующими направлениями стали именно те, которые активно обсуждались на семинаре. Во-вторых, учёные получили возможность свободно экспериментировать и искать новые подходы к построению интеллектуальных машин. Их больше не ограничивали аналоговые вычисления кибернетики и математический аппарат теории автоматов. Новое научное направление началось как экспериментальная дисциплина.

### 2.1.2 Формирование основных направлений ИИ 1956 – 1974

Дартмутский семинар дал мощный толчок для развития области ИИ. Он задал несколько перспективных направлений для исследований и определил их методологию. После семинара его участники смогли найти поддержку в правительственных кругах. Таким образом они получили финансирование для своей работы.

Правительство США выделило огромные средства, которые пошли на создание лабораторий на базе известных учебных заведений. Руководящие роли в этих лабораториях заняли некоторые из участников семинара. Они перечислены в таблице 2-2.

{caption: "Таблица 2-2. Лаборатории по исследованию ИИ", width: "100%"}
| Учебное заведение | Основатели лаборатории ИИ |
| --- | --- |
| [Университет Карнеги — Меллона](https://ru.wikipedia.org/wiki/Университет_Карнеги_—_Меллона) | Аллен Ньюэлл и Герберт Саймон |
|  | |
| [Стэнфордский университет](https://ru.wikipedia.org/wiki/Стэнфордский_университет) | Джон Маккарти |
|  | |
| [Массачусетский](https://ru.wikipedia.org/wiki/Массачусетский_технологический_институт) |  Марвин Минский |
| технологический институт (МТИ) | Джон Маккарти (впоследствии покинул МТИ) |

Новые лаборатории специализировались на исследованиях в области вычислительной техники и ИИ. Каждая из них разрабатывала собственные подходы для создания интеллектуальных систем.

Некоторые из подходов оказались особенно успешными. На них стали ориентироваться все дальнейшие исследования. Таблица 2-3 демонстрирует три основных направления исследований.

{caption: "Таблица 2-3. Направления в ИИ", width: "100%"}
| Название | Идея | Основоположники |
| --- | --- | --- |
| [Символьный](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | Задача решается | Аллен Ньюэлл |
| [подход](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | через действия над понятными человеку символическими обозначениями. | Герберт Саймон |
|  | | |
| [Логическое программирование](https://ru.wikipedia.org/wiki/Логическое_программирование) | Задача решается методами формальной логики. | Джон Маккарти |
|  | | |
| [Коннекционизм](https://ru.wikipedia.org/wiki/Коннекционизм) | Задача решается | Уоррен Мак-Каллок |
| | сетью из связанных между собой простых элементов (нейронной сетью). | Уолтер Питтс |

Эти направления сформировались в период становления области ИИ в конце 1950-х годов. Их популярность менялась в зависимости от успехов и неудач в исследованиях. Сегодня самым многообещающим подходом считается машинное обучение. Оно появилось в результате развития идей коннекционизма.

Рассмотрим подробнее каждое из направлений ИИ.

#### 2.1.2.1 Символьный подход

Система Logic Theorist произвела впечатление на участников Дартмутского семинара. Она была единственным работающим решением, среди всех представленных проектов. Остальные исследования находились только на этапе теоретических моделей.

Аллен Ньюэлл, Герберт Саймон и Клиффорд Шоу продолжили работать с операциями над символами. Их следующим проектом стала универсальная система для решения задач. Она получила название [General Problem Solver](https://ru.wikipedia.org/wiki/Универсальный_решатель_задач) (GPS). В отличие от Logic Theorist её область применения не ограничивалась математическими задачами. GPS была намного мощнее. Авторы утверждали, что для решения различных задач она моделирует процесс принятия решений человеком.

Система GPS была готова в 1959 году. Для решения поставленной задачи она использовала новую технику поиска под названием [**анализ средств и результатов**](https://en.wikipedia.org/wiki/Means–ends_analysis) (means–ends analysis или MEA). Эта техника стала развитием концепции "рассуждение как поиск", на которой был построен Logic Theorist.

Алгоритм анализа средств и результатов выглядит так:

1. Оценить текущее состояние системы. Если поставлена задача, необходимы действия для её решения.

2. Определить конечную цель. Она выражается в некотором состоянии системы, которое надо достигнуть. Достижение этого состояние означает решение поставленной задачи.

3. Разделить конечную цель на составные части, называемые подцелями. Если подцели остаются сложными, они так же делятся на составные части.

4. Составить список действий, выполнение которых приведёт к конечной цели. Достижение этой цели означает решение поставленной задачи.

5. Связать каждую из подцелей с соответствующим ей действием из списка.

6. Выполнить все действия из списка.

7. Сравнить полученное состояние системы с тем, которое надо достигнуть для решения поставленной задачи. Если эти состояния отличаются, повторить алгоритм начиная со второго шага.

Система GPS успешно доказывала теоремы [евклидовой геометрии](https://ru.wikipedia.org/wiki/Евклидова_геометрия) и логики предикатов. Также она могла решать шахматные задачи.

Эксперимент с системой GPS дал Аллену Ньюэллу и Герберту Саймону полезный опыт. Опираясь на него, учёные сформулировали [**гипотезу о физической символьной системе**](https://ru.wikipedia.org/wiki/Гипотеза_Ньюэлла_—_Саймона) в 1976 году. Она звучит так:

> Физическая символьная система обладает необходимыми и достаточными средствами для разумного поведения.

Учёные обосновали свою гипотезу следующими рассуждениями:

1. Без символьной системы невозможно разумное поведение.

2. Следовательно, мышление человека основано на символьной системе и заключается в манипулировании символами.

3. Универсальный компьютер также может манипулировать символами.

4. Следовательно, он теоретически способен на разумное поведение.

Исследования Аллена Ньюэлла и Герберта Саймона заложили основу **символьного подхода** (symbolic approach). Его последователи предлагают создавать системы, работа которых основана на манипулировании символами. Символы могут быть абстрактными, но должны быть понятны человеку. Саму систему надо программировать вручную, как и любую другую компьютерную программу. Это именно тот самый "прямой метод" (direct method) создания "думающих машин", о котором писал Алан Тьюринг в отчёте "Умная машинерия".

Символьный подход, как идея и метод, доминировал в области ИИ с середины 1950-х до конца 1980-х годов.

#### 2.1.2.2 Логическое программирование

В 1958 году Джон Маккарти разработал модель системы под названием [Advice Taker](https://en.wikipedia.org/wiki/Advice_taker). Принцип её работы учёный описал в статье "Программы со здравым смыслом" (["Programs with Common Sense"](http://www-formal.stanford.edu/jmc/mcc59.pdf)). Advice Taker, так же как Logic Theorist, использовал поиск по дереву для вывода результатов. Главное различие между ними в том, что новая система работала с логическими высказываниями, а не с абстрактными символами.

На вход система Advice Taker получала от пользователя условия задачи. Эти условия представляли собой логические утверждения на некотором формальном языке. Далее система искала решение поставленной задачи путём логических рассуждений. В основе этих рассуждений был поиск.

Джон Маккарти выдвинул следующую гипотезу: 

> Система станет универсальной, если сообщить ей достаточно общей информации об окружающем мире.

Если эта гипотеза верна, то Advice Taker смог бы самостоятельно делать выводы обо всём, что ему сообщают и что он уже знает. Это означало бы, что система рассуждает с позиции [здравого смысла](https://ru.wikipedia.org/wiki/Здравый_смысл).

Разработчики Logic Theorist делали ставку на продвинутые алгоритмы поиска по множеству высказываний. Джон Маккарти предложил другой путь улучшения работы системы. Advice Taker использовал [**формальную**](https://ru.wikipedia.org/wiki/Формальная_логика) и [**математическую**](https://ru.wikipedia.org/wiki/Математическая_логика) логику. По мнению учёного, это более точный подход для моделирования интеллектуальных систем. Главное его преимущество в том, что работоспособность системы можно формально доказать.

I> **Формальная логика** — это раздел логики, в котором применяется формальный язык и строгие правила для операций над высказываниями. **Математическая логика** — это направление формальной логики, в которой активно применяется математический аппарат.

Джон Маккарти предложил новый способ представления знаний для Advice Taker. Система Logic Theorist хранила все знания и эвристики в коде самой программы. Из-за этого их было сложно редактировать. Чтобы добавить новое утверждение или исправить существующее, приходилось исправлять программный код на языке IPL.

В системе Advice Taker знания и механизм рассуждений чётко разделялись. Знания хранились в виде правил на некотором формальном языке. Эти правила помещались в списки. В результате их стало проще редактировать. Теперь с этой задачей мог справиться оператор без навыков программирования.

Для логического вывода Advice Taker выполнял поиск по спискам. Джон Маккарти искал способ вынести алгоритм поиска из кода самой системы. Учёный решил сделать поиск одним из механизмов языка программирования. Тогда на таком языке стало бы значительно проще и быстрее создавать новые специализированные интеллектуальные системы.

Джон Маккарти начал работать над новым языком программирования. Он рассматривал это как первый шаг для реализации Advice Taker. Так появился язык LISt Processing более известный как [Lisp](https://ru.wikipedia.org/wiki/Лисп). Учёный описал Lisp в статье для журнала Communications of the ACM в 1960 году. Первый работающий интерпретатор языка появился в 1958 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704).

Некоторые идеи языка Lisp Джон Маккарти высказал ещё в статье "Программы со здравым смыслом". В ней учёный рассуждал над преимуществами декларативных и императивных инструкций. **Декларативные инструкции** описывают свойства результата, который должна выдать программа. **Императивные инструкции** — задают чёткий алгоритм вычисления результата. Джон Маккарти утверждал, что декларативные инструкции лучше подходят для разработки интеллектуальных систем и упрощают работу с логическими правилами.

Главный механизм Lisp — это операции над списками. В отличие от других языков Lisp не различает данные и код программы. Вся программа записывается в виде списков, заключенных в круглые скобки. Такие структуры в терминологии языка называются **S-выражениями** (s-expressions).

Изначально Джон Маккарти задумывал Lisp как чисто декларативный язык. Но в процессе реализации учёный добавил такие конструкции императивного языка как циклы и переменные. Благодаря им, Lisp стал универсальным языком. Он подходит для широкого круга задач, которые не относятся к ИИ. Сегодня его [продолжают применять](https://habr.com/ru/companies/typeable/articles/581488/) в различных прикладных областях.

Lisp оказал влияние на следующее поколение специализированных языков программирования. Одним из них стал [Prolog](https://ru.wikipedia.org/wiki/Пролог_(язык_программирования)). Его разработал французский учёный Ален Колмероэ в 1972 году.

Prolog — это чисто декларативный язык, основанный на математической логике. Программа на нём представляет собой набор логических утверждений и правил вывода. Prolog стал первым и самым известным языком логического программирования. Исследователи ИИ долгое время сохраняли к нему интерес.

Система Advice Taker так никогда и не была реализована. Она потеряла актуальность к тому времени, когда Джон Маккарти довел язык Lisp до стабильного состояния. Тем не менее Advice Taker оказалась полезна как модель типичной интеллектуальной системы. Она помогла учёному лучше понять нужды разработчиков. Благодаря этому, Джон Маккарти создал язык, который стал основным инструментом для исследователей ИИ на протяжении десятилетий.

#### 2.1.2.3 Коннекционизм

Модель бинарного порогового нейрона Уоррена Мак-Каллока и Уолтера Питтса, а также теория обучения Дональда Хебба заложили основу коннекционизма. **Коннекционизм** (connectionism) — это подход к пониманию разума и когнитивных процессов. Главная роль в этом подходе отводится математическим моделям, которые представляют собой искусственные нейронные сети.

Коннекционизм считается направлением искусственного интеллекта. Но также этот подход успешно применяется в других науках: когнитивистике, нейробиологии, теории познания и когнитивной психологии.

После исследований Дональда Хебба следующим значительным шагом в развитии коннекционизма стала модель под названием перцептрон.

##### 2.1.2.3.1 Перцептрон

В середине 1950-х годов американский психолог и нейрофизиолог [Фрэнк Розенблатт](https://ru.wikipedia.org/wiki/Розенблатт,_Фрэнк) изучал организацию памяти в биологических системах. Он пришел к выводу, что механизм памяти неразрывно связан с процессом восприятия. Тогда учёный сменил направление исследований и начал изучать этот процесс.

В конце 1950-х годов Фрэнк Розенблатт разработал модель восприятия информации мозгом человека. Она получила название [**перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон). Позднее модель такого типа стала называться [**двоичным классификатором**](https://ru.wikipedia.org/wiki/Двоичная_классификация) ([binary classifier](https://www.youtube.com/watch?v=mI6jTc-8sUY)).

Термин "перцептрон" часто вызывает путаницу. Причина в том, что им обозначают следующие понятия:

1. Алгоритм обучения с учителем для двоичных классификаторов.

2. Модель отдельного нейрона.

3. Модель однослойной нейронной сети.

4. Модель многослойной нейронной сети.

I> С алгоритмами обучения мы познакомимся в разделе "2.6 Машинное обучение".

Для начала рассмотрим модель отдельного нейрона под названием перцептрон. Такой нейрон получает на вход несколько сигналов. Каждый входной сигнал имеет свой вес. **Вес** — это вещественное число, которое пропорционально важности сигнала. Чем важнее сигнал, тем больше вес и наоборот. Вес нужен для расчёта **взвешенной суммы входных сигналов**. Она рассчитывается по следующей формуле:
{height: "10%"}
![](images/ArtificialIntelligence/perceptron-dot-product.png)

В этой формуле используются следующие обозначения:

* Y — взвешенная сумма входных сигналов
* m — число входных сигналов перцептрона
* w~i~ — вес i-ого входного сигнала
* x~i~ — значение i-ого входного сигнала.

Иногда к взвешенной сумме входных сигналов прибавляют константу. Она называется **смещением** (bias). Благодаря ей, результат функции активации смещается в область положительных или отрицательных значений. Это решает некоторые проблемы при обучении нейронных сетей.

Обозначим смещение буквой b. Тогда функция активации перцептрона выглядит так:
{height: "10%"}
![](images/ArtificialIntelligence/perceptron-activation-function.png)

Здесь f(x) означает результат функции активации. Функция равна 1, если взвешенная сумма входных сигналов плюс смещение больше нуля. В противном случае, она равна 0. Функция активации определяет величину выходного сигнала перцептрона.

Функция активации перцептрона, как и бинарного порогового нейрона, является ступенчатой. Её график демонстрирует иллюстрация 2-2. Единственное отличие этого графика от иллюстрации 2-1 — это смещение перехода функции от 0 к 1 в начало оси X.

{caption: "Иллюстрация 2-2. Ступенчатая функция активации перцептрона", height: "30%"}
![Ступенчатая функция активации перцептрона](images/ArtificialIntelligence/perceptron-step-function-graph.png)

Функция активации перцептрона f(x) отображается на оси Y, а взвешенная сумма входных сигналов — на оси X. Пока эта сумма меньше 0, перцептрон находится в невозбуждённом состоянии. Когда сумма превышает 0, перцептрон возбуждается. Его выходной сигнал становится равен единице.

Чтобы понять особенности перцептрона, сравним его с бинарным пороговым нейроном. Вот их ключевые различия:

1. Бинарный пороговый нейрон получает на вход сигналы, которые представляются двоичными числами (0 или 1). Входные сигналы перцептрона представляются вещественными числами.

2. В отличие от бинарного порогового нейрона, каждый входной сигнал перцептрона имеет вес.

3. Функция активации бинарного порогового нейрона рассчитывает сумму всех входных сигналов. Функция активации перцептрона рассчитывает взвешенную сумму входных сигналов.

4. Бинарный пороговый нейрон не предусматривает алгоритма обучения. В отличие от него перцептрон может обучаться. Этот процесс заключается в автоматическом подборе значений весов для каждого входного сигнала. Алгоритм обучения перцептрона основан на теории Дональда Хебба.

5. Бинарный пороговый нейрон был только теоретической моделью. Он не решал какую-то практическую задачу. Перцептрон разрабатывался как инструмент для распознавания изображений.

I> [**Распознавание образов**](https://en.wikipedia.org/wiki/Pattern_recognition) (pattern recognition) в общем смысле — это задача обнаружения шаблонов и закономерностей во входных данных. Если говорить об обработке изображений, то распознавание образов означает обнаружение определённых объектов (например, лиц людей). Такая частная задача называется **распознавание изображений** (image recognition).

Теперь рассмотрим модель [однослойной нейронной сети под названием перцептрон](https://en.wikipedia.org/wiki/Feedforward_neural_network#Single-layer_perceptron). Впоследствии этот класс моделей стал называться [**нейронные сети с прямой связью**](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью) (feedforward neural network или FNN).

Фрэнк Розенблатт разработал модель нейрона, чтобы изучить процессы восприятия в биологических системах. Чтобы проверить её достоверность на практике, учёный обратился к задаче распознавания образов. Для решения этой задачи отдельному нейрону не хватало вычислительных возможностей. Поэтому Фрэнк Розенблатт объединил несколько перцептронов в нейронную сеть. Это увеличило вычислительную мощность проверяемой модели.

В 1957 году Фрэнк Розенблатт смоделировал работу нейронной сети в виде программы для универсального компьютера IBM 704. Годом позже учёный сконструировал первый [**нейрокомпьютер**](https://ru.wikipedia.org/wiki/Нейрокомпьютер) под названием [Mark I Perceptron](https://ru.wikipedia.org/wiki/Марк-1). 

Mark I представлял собой однослойную нейронную сеть. Она работала по тому же принципу, что и отдельный перцептрон. Компьютер состоял только из аналоговых компонентов. Входное изображение поступало на матрицу из фотодетекторов размером 20x20. Сигналы с неё передавались на электромеханические устройства, моделирующие нейроны. Чтобы регулировать веса входных сигналов, применялись потенциометры. В процессе обучения их настройки менялись автоматически с помощью электромоторов.

Mark I должен был распознавать все буквы английского алфавита. Но финальная версия компьютера научилась распознавать только некоторые буквы.

Работа с аналоговым компьютером была очень трудоёмкой. Его компоненты были ненадёжны и часто выходили из строя. Чтобы поддерживать Mark I в рабочем состоянии, нужен был специалист оператор. Он должен был следить за компьютером и заменять отказавшие компоненты.

Иллюстрация 2-3 демонстрирует архитектуру однослойной нейронной сети под названием перцептрон.

{caption: "Иллюстрация 2-3. Архитектура нейронной сети под названием перцептрон", height: "30%"}
![Архитектура нейронной сети перцептрон](images/ArtificialIntelligence/perceptron.png)

Сеть состоит из элементов трёх типов:

1. S-элементы (сенсорные)
2. A-элементы (ассоциативные)
3. R-элементы (реагирующие)

I> Несмотря на три слоя элементов, перцептрон на иллюстрации 2-3 называется однослойным. Причина в том, что у него только один скрытый слой A-элементов. **Скрытым** называется слой, не содержащий входных и выходных нейронов сети.

Проведём аналогию между работой нейронной сети и мозгом. Пример обработки сигнала мозгом — реакция человека на зрительную информацию. Если человек видит опасность, физиологическим ответом на неё будет активация [двигательных нейронов](https://ru.wikipedia.org/wiki/Мотонейрон). Эти нейроны отвечают за мышечную активность. Похожим образом перцептрон обрабатывает входные сигналы. Реагирующие нейроны R возбуждаются в ответ на импульсы сенсорных нейронов S, согласно ассоциациям A.

Кратко работу перцептрона можно описать так:

> Перцептрон создаёт набор ассоциаций (A-элементы) между входными сигналами (S-элементы) и реакцией на них (R-элементы).

Первая версия нейронной сети имела только один R-элемент. Из-за этого она могла различать только два класса объектов. Отсюда происходит название модели: двоичный классификатор. В более поздних моделях Фрэнк Розенблатт экспериментировал с несколькими R-элементами. Так ему удалось добиться распознавания нескольких классов. Каждый класс соответствовал одной из букв английского алфавита.

В конце 1950-х годов ещё не существовало общепринятой терминологии для нейронных сетей. Фрэнк Розенблатт вводил новые понятия, которые позднее вышли из употребления. Это часто приводит к ошибкам при обсуждении идей учёного.

В 1962 году Фрэнк Розенблатт опубликовал книгу "Принципы нейродинамики" (Principles of Neurodynamics). В ней учёный описал различные архитектуры перцептронов, в том числе и многослойные. Также в книге доказана [теорема сходимости перцептрона](https://ru.wikipedia.org/wiki/Теорема_сходимости_перцептрона). Согласно ей, перцептрон можно обучить за конечное число шагов. После такого обучения он сможет решить поставленную задачу.

Книга "Принципы нейродинамики" оказала большое влияние на развитие коннекционизма. Последователи этого направления использовали теорему сходимости перцептрона в своих исследованиях. С помощью теоремы и её выводов, они сформулировали общие требования к архитектурам нейронных сетей и методам их обучения.

#### 2.1.2.4 Экспериментальный подход

Исследователи из лаборатории ИИ Массачусетского технологического института следовали подходу, который в 1970-е годы получил название [**scruffy**](https://en.wikipedia.org/wiki/Neats_and_scruffies). Дословно переводится как "неряшливый". Его также можно назвать экспериментальным. Идея подхода была следующей: разрабатывать прототипы интеллектуальных систем для небольших задач из разных областей. Затем скомбинировать и усовершенствовать полученные системы. Так исследователи надеялись прийти к решению реальных сложных задачи.

Противоположный подход получил название **neat**. Дословно переводится как "аккуратный". Его идею хорошо передаёт слово "теоретический". Этот подход предлагает использовать [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы) для разработки интеллектуальных систем. Эти методы основаны на математике и логике. Они дают более надёжный и научно обоснованный результат. Этого подхода придерживались исследователи из университетов Карнеги — Меллона и Стэнфордского.

В первые годы развития ИИ экспериментальный подход казался весьма плодотворным. Исследователи из МТИ разработали и продемонстрировали ряд систем для решения небольших прикладных задач. Эти системы произвели впечатление на научные и политические круги, а также на инвесторов. Рассмотрим самые известные из этих разработок.

##### 2.1.2.4.1 Обработка естественного языка

Первой системой обработки естественного языка считается программа [STUDENT](https://en.wikipedia.org/wiki/STUDENT_(computer_program)). Её написал Даниэль Бобров в рамках свой докторской работы в 1964 году. Руководил этим проектом Марвин Минский.

I> **Естественным** называется любой язык, который естественным образом возник в каком-то человеческом сообществе. Такой язык никто сознательно не планировал и не создавал. Примеры: английский, французский и т.д.

Программа STUDENT решала задачи из школьного учебника по алгебре. Их описание система принимала на вход в виде текста на английском языке. На выходе она печатала решение задачи в виде одного числа.

STUDENT была написана на языке Lisp и использовала его новые возможности. В исходном предложении на английском языке программа искала типовые шаблоны. Далее она последовательно преобразовывала шаблоны в более простые предложения, а затем в математические выражения. Для трансформации предложений программа использовала базу данных с правилами. Для работы с формулами STUDENT использовала запрограммированные вручную правила и механизм логического вывода.

Другой известной системой обработки естественного языка была [ELIZA](https://ru.wikipedia.org/wiki/Элиза_(программа)). Её разработал профессор МТИ [Джозеф Вейценбаум](https://ru.wikipedia.org/wiki/Вейценбаум,_Джозеф) в 1966 году.

ELIZA представляла собой [виртуального собеседника](https://ru.wikipedia.org/wiki/Виртуальный_собеседник). Она обменивалась сообщениями с пользователем на английском языке. Направление разговора задавали специальные сценарии. Самым популярным сценарием был DOCTOR. Согласно ему, программа парадировала психотерапевта и строила вопросы на основе прошлых сообщений от пользователя.

ELIZA по-настоящему не понимала сути разговора. Она находила во входной фразе ключевые слова и подставляла их в шаблонные фразы. Эти фразы и были ответами системы. Для поиска ключевых слов программа использовала закодированные вручную синтаксические правила построения предложений.

ELIZA считается первой реальной программой, которая пыталась пройти тест Тьюринга. Но ей это не удалось.

##### 2.1.2.4.2 Микромиры

В конце 1960-х годов Марвин Минский и его коллега Сеймур Пейперт предложили сфокусировать исследования на упрощённых проблемных областях. Такие области получили название **микромиры**. Учёные утверждали, что разработанные для микромиров системы смогут решать и реальные задачи.

Разработка интеллектуальной системы для одного из микромиров стала типичной дипломной работой для студентов МТИ. Самым популярным у студентов был [**мир блоков**](https://en.wikipedia.org/wiki/Blocks_world). Он представлял собой плоскую поверхность (table), на которой можно было размещать объекты. Изначально эти объекты находились в коробке (box). Сами объекты представляли собой геометрические фигуры различных цветов, размеров и форм (шары, конусы, кубы и т.д).

Программа [SHRDLU](https://ru.wikipedia.org/wiki/SHRDLU) стала наиболее известным проектом для мира блоков. Её разработал [Терри Виноград](https://ru.wikipedia.org/wiki/Виноград,_Терри) в 1970 году. Программа работала на компьютере DEC PDP-6 с графическим терминалом. Терминал отрисовывал полную 3D картину текущего состояния мира блоков.

SHRDLU принимала на вход команды от пользователя. Эти команды были обычными предложениями на английском языке. Программа понимала команды следующих типов:

1. Указание к действию. Например: "положи красный шар на синий блок".

2. Вопрос о состоянии мира блоков. Например: "сколько объектов находится на плоскости?".

3. Вопрос о выполненных ранее командах. Например: "перемещался ли красный куб?".

4. Вопрос о возможности выполнения действия. Например: "можно ли поставить красную пирамиду на синий куб?"

Программа правильно выполняла команды и отвечала на заданные ей вопросы. Пользователи считали, что SHRDLU хорошо их понимает. Причиной такого понимания была простота мира блоков. Для его полного описания хватало порядка 50 слов: существительных (названия объектов), глаголов (описание действий) и прилагательных (описание объектов). Комбинации этих слов были элементарны. Программа использовала простые правила синтаксического разбора, чтобы выделить из предложений ключевые слова. Эти правила были закодированы вручную.

SHRDLU имела специальную область памяти, в которой сохранялось каждое выполненное действие. Благодаря этому, программа следила за состоянием мира блоков. Также в коде SHRDLU имелись простейшие правила физики твёрдых тел. Они позволяли делать выводы о выполнимости команд пользователя.

В лаборатории МТИ для мира блоков разрабатывали не только программы, но и роботов. Было создано несколько версий руки манипулятора для передвижения блоков:

* [Робота MH-1](https://www.csail.mit.edu/node/6674) спроектировал Генри Эрнст в 1961 году. Робот [подключался к компьютеру TX-0](https://www.semanticscholar.org/paper/MH-1%2C-a-computer-operated-mechanical-hand-Ernst/06600e1ca9451d81e89d078a924184683ace9196), через который пользователь вводил команды. MH-1 пытался выполнить введённую команду. Для обратной связи у него было несколько датчиков. MH-1 служил прототипом для изучения автономной работы подобных механизмов. Его демонстрирует иллюстрация 2-4.

* [Робота Минского-Беннета](https://cyberneticzoo.com/underwater-robotics/1968-minsky-bennett-arm-marvin-minsky-and-bill-bennett-american/) спроектировали Марвин Минский и Вильям Беннет в 1968 году. Он [управлялся с помощью джойстика и компьютера DEC PDP-6](https://commodorez.tumblr.com/post/710801395944767488).

* Робота ["Серебряная рука"](https://www.computerhistory.org/timeline/1974/#169ebbe2ad45559efbc6eb35720d99bc) (Silver Arm) спроектировал [Дэвид Сильвер](https://en.wikipedia.org/wiki/David_Silver_(roboticist)) в 1974 году. Робот мог работать с мелкими деталями благодаря датчикам прикосновения и давления. Его демонстрирует иллюстрация 2-5.

{caption: "Иллюстрация 2-4. Рука манипулятор MH-1", height: "30%"}
![Рука-манипулятор MH-1](images/ArtificialIntelligence/mh-1-arm-robot.jpg)

{caption: "Иллюстрация 2-5. Робот Серебряная рука", height: "30%"}
![Робот Серебряная рука](images/ArtificialIntelligence/the-silver-arm.jpeg)

### 2.1.3 Первая зима ИИ 1974 – 1980

К концу 1950-х и началу 1960-х годов исследователи ИИ добились некоторых успехов. Они демонстрировали рабочие прототипы систем, которые решали небольшие задачи. При этом учёные делали очень смелые заявления. Они утверждали, что в ближайшем будущем машины возьмут на себя задачи, с которыми раньше справлялись только люди.

Заявления о скором прогрессе ИИ попали в прессу. В результате этими исследованиями заинтересовались лица, принимающие решения о финансировании. Это были правительственные чиновники, военные, инвесторы, руководители частных и государственных организаций.

Скоро вокруг темы ИИ возник ажиотаж, который продолжался до середины 1970-х годов. Вслед за ним пришло разочарование в достигнутых результатах. На какое-то время общество и инвесторы потеряли интерес к ИИ. Этот период получил название "первая зима ИИ". Рассмотрим её причины.

#### 2.1.3.1 Проект машинного перевода

В 1957 году СССР запустил первый искусственный спутник земли. После этого [Национальный научно-исследовательский совет США](https://ru.wikipedia.org/wiki/Национальные_академии_наук,_инженерии_и_медицины) (National Research Council или NRC) стал внимательно следить за советскими научными статьями. Чтобы ускорить их перевод на английский язык, совет решил создать специальную интеллектуальную систему. Её разрабатывала компания IBM совместно с университетом Вашингтона в Сент-Луисе.

В начале проекта разработчики считали, что для машинного перевода достаточно простых синтаксических преобразований и замены слов по словарю. Они закодировали правила грамматики русского и английского языков, а также составили словарь. Оказалось, что качество перевода такой системы просто неприемлемо.

Главной проблемой были неоднозначности. Большинство слов русского языка имеет несколько вариантов перевода на английский. То же справедливо и в обратную сторону. Чтобы выбрать правильное английское слово, надо учитывать контекст и смысл предложения. На это система перевода была неспособна. Позже это затруднение стало называться [**проблемой здравого смысла**](https://en.wikipedia.org/wiki/Commonsense_knowledge_(artificial_intelligence)).

Суть проблемы здравого смысла в следующем. Есть очевидные всем людям факты. Например, что зима — холодное время года. Во время общения друг с другом люди предполагают, что собеседнику эти факты известны. Поэтому когда человек формулирует свои мысли на естественном языке, он опускает очевидные вещи. Но если в интеллектуальную систему целенаправленно не заложить общие знания, она ничего не знает об очевидных людям фактах. В результате система не понимает смысл многих предложений на естественном языке.

К 1964 году NRC вложил в проект машинного перевода около 20 миллионов долларов. Но почти десять лет разработки не дали заметного прогресса. Тогда NRC сформировал комитет. Ему поставили задачу: выяснить текущий статус и актуальные проблемы системы перевода.

В 1966 году комитет подготовил отчёт с результатами своей работы. Главная мысль отчёта в том, что машинный перевод дороже, менее точен и медленнее, чем выполненный человеком. После такого вывода правительство США прекратило финансирование проекта, а направление машинного перевода долгое время считалось бесперспективным.

#### 2.1.3.2 Финансирование ARPA

В 1958 году министерство обороны США организовало [управление перспективных исследовательских проектов](https://ru.wikipedia.org/wiki/Управление_перспективных_исследовательских_проектов_Министерства_обороны_США) (Advanced Research Projects Agency или ARPA). Эта организация искала и финансировала научные исследования, которые могли бы применяться в военных целях.

Благодаря общему ажиотажу вокруг темы ИИ, этими исследованиями заинтересовались специалисты ARPA. Они посчитали, что открытия в новой области науки принесут военным пользу. Это решение привело к тому, что на протяжении 1960-х годов лаборатории ИИ в МТИ, университетах Карнеги — Меллона и Стэнфордском получали гранты в размере нескольких миллионов долларов ежегодно. Эти деньги выделялись не на конкретные проекты с жёсткими сроками. Лаборатории получали их на фундаментальные исследования, часто не имевшие практического применения.

В то время решения, связанные с компьютерными технологиями, в ARPA принимал известный американский учёный
[Джозеф Ликлайдер](https://en.wikipedia.org/wiki/J._C._R._Licklider). Он верил в успех финансирования "людей, а не проектов". Но Джозеф Ликлайдер ошибся. Отсутствие результатов и провал одного из крупных проектов под названием SUR заставил ARPA изменить политику финансирования.

SUR был проектом голосового управления для военных пилотов. Над ним работала команда из университета Карнеги — Меллона. Исследователи разработали систему распознавания речи, но она оказалась очень ограниченной. Например, порядок произнесения слов был строго определён. Реальные возможности системы оказались очень далеки от обещанных. В результате ARPA прекратила финансирование этого проекта в 1974 году.

На раздутый бюджет военных исследований обратил внимание сенат США. Это привело к принятию поправки Мэнсфилда в 1969 году. Она требовала от ARPA финансировать только целевые исследования. Теперь учёные были обязаны доказать, что их работа связана с военными технологиями. Их заявки на финансирование рассматривались по очень строгим стандартам. Это привело к значительному сокращению бюджета лабораторий ИИ по всей стране.

#### 2.1.3.3 Отчёт Лайтхилла

В 1965 году английский учёный [Дональд Мичи](https://en.wikipedia.org/wiki/Donald_Michie) организовал лабораторию ИИ в [Эдинбургском университете](https://ru.wikipedia.org/wiki/Эдинбургский_университет). Позднее подобные лаборатории открылись в университетах Сассекс и Эссекс. В конце 1960-х и начале 1970-х они получали значительные гранты от правительства Англии.

Распределением грантов занимался [совет по научным и инженерным исследованиям](https://en.wikipedia.org/wiki/Science_and_Engineering_Research_Council) (Science and Engineering Research Council или SERC). В конце 1970-х годов совет решил проверить достигнутые успехи в области ИИ. В то время учёные часто обещали, что вот-вот создадут разумные машины. Но научная основа таких заявлений была неясна. SERC хотел проверить их достоверность. Кроме этого совет хотел убедиться, что значительные инвестиции на исследования были оправданы.

В 1973 году SERC поручил [Джеймсу Лайтхиллу](https://ru.wikipedia.org/wiki/Лайтхилл,_Джеймс) оценить текущее состояние исследований в области ИИ. Джеймс Лайтхилл был профессором в области прикладной математики и физики, который работал ректором в Имперском колледже Лондона. Он был известен своим критическим анализом научных и математических проблем. Поэтому его посчитали подходящим кандидатом.

Джеймс Лайтхилл провёл всестороннее исследование: он изучил доступные материалы, побеседовал с наиболее известными экспертами в области ИИ из США и Европы, а затем классифицировал полученные данные. Результаты своей работы он опубликовал в статье под названием "Искусственный интеллект: общий обзор" ([Artificial Intelligence: A General Survey](www.chilton-computing.org.uk/inf/literature/reports/lighthill_report/p001.htm)). Позднее она стала широко известна как [отчёт Лайтхилла](https://ru.wikipedia.org/wiki/Отчёт_Лайтхилла).

Отчёт Лайтхилла даёт непредвзятое и объективное мнение о состоянии области ИИ на 1973 год. Поэтому нам имеет смысл кратко познакомиться с его содержанием.

В первой части отчёта Джеймс Лайтхилл описывает три основных направления исследований ИИ того времени:

* A — Advanced Automation (продвинутая автоматизация). К этой области автор относит разработку систем, которые могут заменить людей для решения прикладных задач. Такие системы он подразделяет на два типа. Первый — для решения промышленных и военных задач. Второй — для математической и научной работы.

* C — Computer-based CNS research (исследование центральной нервной системы человека с помощью компьютера). К этому направлению относятся все теоретические исследования в области нейрофизиологии и психологии. Джеймс Лайтхилл подчёркивает, что эти исследования занимаются моделированием работы мозга с помощью компьютера.

* B — Building Robots (создание роботов). Это направление связывает A и C для создания автоматических устройств, которые имитируют определённый набор человеческих функций.

Во второй части отчёта автор разбирает ожидания и реальные достижения каждого из трёх направлений. Джеймс Лайтхилл признаёт, что исследования в областях A и C имели некоторые успехи. Но для направления B ни одна из заявленных целей так и не была достигнута.

Джеймс Лайтхилл оценивает достижения в Advanced Automation (A) с помощью сравнения. Он оценивает уже существующими коммерческие системы автоматизированного управления. Такие системы уже применялись в авиации и космической индустрии. Они оказались значительно сложнее и эффективнее, чем существующие проекты в области ИИ. Также автор замечает, что многие такие проекты закончились провалом. Например, система машинного перевода для NRC.

Далее Джеймс Лайтхилл оценивает направление Computer-based CNS research (C). Учёный рассматривает его только как дополнение для фундаментальных исследований в области психологии. Автор утверждает, что затраты вычислительных мощностей и труда для моделирования процессов нервной системы неоправданно высоки. Основную проблему этого направления Джеймс Лайтхилл видит в ограничениях современной компьютерной техники. Доступные учёным вычислительные мощности просто недостаточны для качественного моделирования нейронных сетей.

Проблемы последнего направления Building Robots (B) Джеймс Лайтхилл связывает с неудачами направлений A и C. Без надёжных систем распознавания образов, речи и логического рассуждения нет никакой возможности построить роботов. Даже узкоспециализированные машины с интеллектом близким человеческому оказываются недостижимой целью.

В заключении статьи Джеймс Лайтхилл очень сдержанно оценивает возможные достижения области ИИ в следующие 25 лет.

Отчёт Лайтхилла стал причиной, по которой SERC прекратил финансирование большинства исследований ИИ в университетах. Это решение привлекло к себе внимание всех европейских стран. В итоге финансирование разработок в новой области сократилось по всей Европе.

#### 2.1.3.4 Ограничения систем ИИ

Проблемы с финансированием исследований ИИ в середине 1970-х возникли по вине самих учёных. Они недооценили сложность задач, которые им предстояло решить. Поэтому прогнозы и сроки выполнения проектов оказались слишком оптимистичными. Это привело к необоснованно высоким ожиданиям инвесторов.

Крупные инвестиции в область ИИ начались в середине 1960-х годов. К началу 1970-х стали ясны результаты разработок, на которые ушли несколько лет. Эти результаты оказались неудовлетворительными. Возможности созданных интеллектуальных систем были очень ограниченны.

Есть мнение, что учёные умышленно вводили в заблуждение инвесторов. Так они стремились получить финансирование. Вполне возможно, что некоторые из них действительно так поступали. Но как объяснить следующее? Ошибочными оказались абсолютно все прогнозы о перспективах развития ИИ, сделанные в начале 1960-х годов. Разберёмся, почему это произошло.

##### 2.1.3.4.1 Производительность компьютеров

В конце 1950-х годов сменилась технология производства компьютеров. Раньше их рабочими элементами были [**электровакуумные лампы**](https://ru.wikipedia.org/wiki/Электронная_лампа). В 1958-м году компания IBM выпустила первый компьютер, который работал на [**транзисторах**](https://ru.wikipedia.org/wiki/Транзистор). Они превосходили лампы по компактности, надёжности и скорости работы.

Переход на транзисторы увеличил быстродействие компьютеров. Но конструкция самих транзисторов [продолжала развиваться](https://en.wikipedia.org/wiki/MOSFET#Commercialization) на протяжении 1960-х годов. Только в начале 1970-х годов она достигла уровня, который позволил дальше наращивать производительность компьютеров. Тогда начал действовать [**закон Мура**](https://ru.wikipedia.org/wiki/Закон_Мура). Он говорит о том, что число транзисторов на [**интегральной схеме**](https://ru.wikipedia.org/wiki/Интегральная_схема) удваивается примерно каждые два года. Соответственно растёт скорость вычислений и объём памяти.

Исследователи ИИ разрабатывали прототипы своих систем для компьютеров 1960-х годов. Они имели слабую вычислительную мощность и ограниченную память. Эти прототипы справлялись с относительно простыми задачами. Такие тесты позволили учёным сравнить эффективность разных подходов и методов. Но оценить масштабируемость прототипов было невозможно. Запуск на более мощном компьютере дал бы необходимую информацию. К сожалению, на тот момент таких компьютеров просто не существовало.

I> [**Масштабируемость**](https://ru.wikipedia.org/wiki/Масштабируемость) означает повышение производительности системы при увеличении доступных ей аппаратных ресурсов.

Вот один из примеров. Прототип системы машинного перевода обрабатывал небольшие специально подготовленные тексты. Памяти компьютера 1960-ого года хватало только на несколько десятков слов. Поэтому система могла переводить только маленькие тексты. Чтобы проверить насколько она универсальна, нужен был компьютер с намного большим объёмом памяти. Учёные были уверены, что более мощное оборудование решит все проблемы. В начале 1970-х годов они его получили и попытались переводить реальные тексты. Тогда учёные столкнулись с проблемой здравого смысла.

Ограничением была не только память, но и быстродействие компьютеров. В 1976 году учёный [Ханс Моравек](https://ru.wikipedia.org/wiki/Моравек,_Ханс) из университета Карнеги — Меллона дал следующую оценку. Чтобы распознавать грани объектов и движение в реальном времени, система ИИ должна работать на компьютере с производительностью 10^9^ [операций в секунду](https://ru.wikipedia.org/wiki/IPS_(быстродействие)) (1000 мегаинструкций в секунду или MIPS). Однако, самый быстрый суперкомпьютер 1976 года [Cray-1](https://ru.wikipedia.org/wiki/Cray-1) выполнял всего 160 MIPS.

В 1960-е годы исследователи ИИ не смогли правильно оценить вычислительные мощности, которые нужны для работы их систем. Многие принципиальные проблемы обнаружились только при тестировании прототипов на более мощных компьютерах начала 1970-х годов. Решение этих проблем требовало новых исследований и времени, но инвесторы уже ждали готовых результатов.

##### 2.1.3.4.2 Комбинаторный взрыв

Джеймс Лайтхилл в своём отчёте упоминает проблему комбинаторного взрыва. [**Комбинаторный взрыв**](https://ru.wikipedia.org/wiki/Комбинаторный_взрыв) (combinatorial explosion) — это быстрый рост сложности задачи при увеличении размера входных данных. Именно он стал одной из причин, помешавших развитию направления Advanced Automation. Разберёмся, в чём суть этой проблемы.

Одну и ту же вычислительную задачу можно решить разными алгоритмами. Некоторые из них окажутся эффективнее, чем другие. Для выбора подходящего алгоритма, нужен надёжный способ сравнения.

Самое простое решение — замерить время работы каждого алгоритма на конкретном наборе входных данных. К сожалению, такой прямолинейный подход ненадёжен. Какой-то алгоритм может быстрее других работать на большом наборе входных данных (например, обрабатывать длинные строки), но на малых наборах (коротки строки) он будет уступать другим.

Для достоверной оценки алгоритма надо учитывать зависимость его показателей от размера входных данных. Поэтому сегодня применяют две основных оценки:

* [**Временная сложность**](https://ru.wikipedia.org/wiki/Временная_сложность_алгоритма) (time complexity) — это зависимость количества итераций алгоритма от размера входных данных. Другими словами, на сколько шагов увеличится алгоритм при увеличении входных данных.

* **Пространственная сложность** (space complexity) — это зависимость количества используемой алгоритмом памяти от размера входных данных.

Джеймс Лайтхилл демонстрирует проблему комбинаторного взрыва на примере интеллектуальных системах для доказательства теорем. Такие системы следуют подходу "рассуждение как поиск". То есть они делают логические выводы из доступной информации с помощью алгоритма поиска.

Чтобы применить подход "рассуждение как поиск", надо представить информацию в структурированном формате. Примеры таких форматов: граф или дерево. Вершинами могут быть некоторые факты, а рёбрами отношения "предпосылка -> вывод". Тогда система с помощью алгоритма поиска может обойти построенный граф. Так она найдёт путь для доказательства какого-то факта из всего доступного набора возможных предпосылок.

Такие системы хорошо справляются с небольшими формальными задачами. Например, с теоремами из книги "Начала математики". Если построить дерево поиска с исходной информацией для доказательства теоремы, оно окажется небольшим. Если же перейти к реальным прикладным задачам, дерево поиска увеличится на несколько порядков.

В конце 1950-х и начале 1960-х годов алгоритмы поиска были малоэффективны. У них была высокая временная и пространственная сложность. Это приводило к тому, что интеллектуальная система исчерпывала ресурсы компьютера задолго до решения задачи. Именно в этом и состояла проблема комбинаторного взрыва. В реальной прикладной задаче объем информации для обработки быстро увеличивается при незначительном увеличении размера входных данных. Существующие алгоритмы поиска были просто к этому не готовы.

В своих рассуждениях Джеймс Лайтхилл ссылается на [**теорию вычислительной сложности**](https://ru.wikipedia.org/wiki/Теория_сложности_вычислений). Она стала отдельным направлением информатики в 1965 году. В 1970-е годы эта теория активно развивалась. Согласно её выводам, некоторые классы задач в принципе не имеют эффективных решений. Это значит, что не существует алгоритмов для их решения за приемлемое время. Такие задачи называются [**трудноразрешимыми**](https://www.slideshare.net/mkurnosov/12-34608847).

Концепция трудноразрешимых задач устанавливает строгие ограничения для возможностей интеллектуальных систем. Эти системы способны решать только те задачи, для которых существуют эффективные алгоритмы решения.

#### 2.1.3.5 Проблемы коннекционизма

В начале 1960-х годов модель перцептрона Фрэнка Розенблатта выглядела многообещающей. Группы учёных из разных университетов изучали её свойства. Они пришли к выводу, что перцептрон хорошо справляется только с простыми задачами. Его возможностей оказалось недостаточно для реальных прикладных задач.

Фрэнк Розенблатт тоже понимал ограничения своей модели. В книге "Принципы нейродинамики" он указал следующие недостатки однослойных перцептронов:

1. Чтобы решать сложные задачи, нейронной сети нужно очень большое количество элементов.

2. В некоторых случаях обучение занимает неприемлемо много времени.

3. Качество обучения сильно зависит от оценок системы во время обучения.

4. Перцептрон плохо справляется с задачей обобщения.

5. Перцептрон плохо выделяет существенные элементы в сложных входных сигналах.

Первый и второй пункт говорят о высоких требованиях перцептрона к памяти и производительности компьютера, на котором он моделируется. Реальная сложная задача требует большой нейронной сети. Каждый элемент сети хранится в памяти компьютера. Поэтому памяти должно быть много. Чтобы модель с большим числом элементов обучить, нужна высокая вычислительная мощность.

Третий пункт говорит о том, что обучение нейронной сети — итеративный процесс. Его результат нельзя предсказать наверняка. Если обучение не дало нужной точности работы модели, его нужно повторить снова.

Четвёртый пункт означает следующее: перцептрон правильно обрабатывает только те входные данные, на которых он учился. Если условия задачи похожи на учебный пример, но полностью с ним не совпадают, перцептрон скорее всего не сможет её решить.

Пятый пункт приводит к тому, что перцептрон плохо справляется со сложными задачами. Наиболее эффективный метод их решения — разделить на простые подзадачи. Но перцептрон не способен на такое разделение. Он анализирует задачу целиком как есть.

Фрэнк Розенблатт надеялся, что многослойные перцептроны смогут преодолеть некоторые из ограничений однослойных моделей. Он начал рассматривать архитектуры таких нейронных сетей в своей книге. Но эта теория осталась недоработанной.

Исследовать многослойные перцептроны на практике в 1960-х годах было сложно. Моделирование их работы на универсальных компьютерах требовало больше памяти и времени обучения, чем для однослойных перцептронов. Часто модель сети не помещалась в память компьютера или для её обучения требовалось слишком много времени.

Моделировать многослойные перцептроны на специальных компьютерах (таких как Марк-1) было технически невозможно. В 1960-х годах ещё не появились надёжные и дешёвые электронные компоненты, подходящие для сборки нейрокомпьютера. Поэтому архитектура Марк-1 не масштабировалась. Добавление новых компонентов настолько усложнило бы компьютер, что он бы перестал работать из-за постоянных отказов. Эту проблему признал сам Фрэнк Розенблатт.

К середине 1960-х годов работы с моделью перцептрона зашли в тупик. Фрэнк Розенблатт тоже оставил эту тему, как малоперспективную. Продолжать исследования можно было только развивая математические модели, но на практике их нельзя было проверить. Главным ограничением стала недостаточная мощность компьютеров того времени.

Начиная с 1965 года Марвин Минский и Сеймур Пейперт провели ряд экспериментов над перцептронами. Свои результаты они привели в книге ["Перцептроны"](https://ru.wikipedia.org/wiki/Перцептроны_(книга)) (Perceptrons: an introduction to computational geometry), опубликованной в 1969 году.

В книге авторы подробно рассматривают ряд типовых задач по распознаванию образов, с которыми не справляется однослойный перцептрон. Все эти задачи связаны с **инвариантным представлением** образов. Примеры такого представления: поворот объекта, его перенос, растяжение и сжатие. После таких действий над исходным образом перцептрон не может его распознать. Причина этого в неспособности модели к обобщению.

Из своих результатов Марвин Минский и Сеймур Пейперт сделали смелые выводы. Они заявили, что рассмотренные ими ограничения справедливы для любых параллельных вычислений. Именно к этому типу вычислений относятся нейронные сети. При этом авторы утверждали, что последовательные вычисления справляются с проблемой инвариантного представления. Другими словами они заявляли превосходство своего символьного подхода над коннекционизмом.

Есть мнение, что Марвин Минский и Сеймур Пейперт стремились не столько дать объективную оценку возможностям перцептрона, сколько очернить конкурирующее направление ИИ. Это вполне возможно. Особенно после того, как ARPA урезала финансирование и в среде учёных началась жёсткая конкуренция за гранты.

Так или иначе, но выводы книги "Перцептроны" оказались неверными для многослойных нейронных сетей. К сожалению, такими моделями мало кто занимался в конце 1960-х годов. Поэтому ошибки авторов обнаружили намного позже.

Наверняка неизвестно, как именно книга повлияла на отношение к коннекционизму в научных кругах. К моменту её выхода в 1969 году параллельные вычисления уже считались малоперспективным направлением. Большинство лабораторий ИИ сконцентрировало свою работу на символьных интеллектуальных системах.

На развитие коннекционизма также повлияла поправка Мэнсфилда. Исследователи рассматривали нейронные сети как теоретическую модель для изучения мозга человека. Практические результаты от таких проектов ожидались редко. Поэтому ARPA перестало спонсировать проекты в рамках коннекционизма. Не имея финансирования, учёные были вынуждены переключаться на другие направления ИИ.

### 2.1.4 Развитие ИИ 1980 – 1987

#### 2.1.4.1 Экспертные системы

Отличительная особенность ранних символьных интеллектуальных систем 1950-х годов — их универсальность. Главным элементом такой системы считался алгоритм поиска решений. Он работал с любыми знаниями и фактами. Сами знания рассматривались как нечто второстепенное. Разработчики полагали, что универсальные системы смогут решать задачи из разных прикладных областей. Но этот подход не сработал на практике из-за проблемы комбинаторного взрыва.

В середине 1960-х годов [Эдвард Фейгенбаум](https://ru.wikipedia.org/wiki/Фейгенбаум,_Эдвард_Альберт) и его коллеги из Стэнфордского университета предложили новый подход. Они отказались от идеи универсальной системы. Вместо этого учёные выбрали одну конкретную прикладную задачу и разработали узкоспециализированную систему для её решения.

Новый тип программы получил название [**экспертная система**](https://en.wikipedia.org/wiki/Expert_system) (expert system). Она имитировала процесс принятия решений человеком-экспертом в конкретной прикладной области. Для этого общие знания об окружающем мире не нужны. Достаточно только знаний человека-эксперта и правил логического вывода для работы с ними.

Экспертная система состоит из двух частей: базы знаний и механизма вывода. Такое разделений данных и кода впервые предложил Джон Маккарти для своей гипотетической системы Advice Taker. Это решение значительно упростило разработку и обслуживание систем нового типа. Их главным элементом была база знаний. Человек-эксперт мог работать с ней, не имея навыков программирования.

[**База знаний**](https://ru.wikipedia.org/wiki/База_знаний) содержит информацию об опыте и знаниях человека-эксперта в некоторой предметной области, а также правила логического вывода. Информация представлена иерархически в строго определённом форме. Такая форма называется онтологией. [**Онтология**](https://ru.wikipedia.org/wiki/Онтология_(информатика)) показывает свойства предметной области и их связи. Для этого она определяет понятия и категории, которые представляют сам предмет.

[**Механизм вывода**](https://ru.wikipedia.org/wiki/Машина_вывода) применяет логические правила к информации из базы знаний. Таким образом он выводит новые знания, необходимые для решения поставленной задачи. Этот процесс работает итеративно. Полученное новое знание может запустить выполнение дополнительного правила в механизме вывода. Есть два режима его работы: прямой вывод и обратный. **Прямой вывод** начинается с известных фактов и доказывает новые факты. **Обратный вывод** начинает с целей. Он определяет, какие факты надо доказать для достижения этих целей.

Экспертные системы решили проблему комбинаторного взрыва. Ранние символьные системы выполняли алгоритм поиска по дереву элементарных общих фактов об окружающем мире. Для решения реальной прикладной задачи этих фактов оказывалось слишком много. Обработать их за приемлемое время было невозможно.

Экспертная система работает более целенаправленно. У неё есть только факты, необходимые для решения поставленной задачи, и логические правила для их обработки. Вместо поиска по огромному массиву данных система последовательно применяет заданные ей правила к конкретным фактам. Таким образом она быстро решает поставленную задачу.

Рассмотрим первые экспертные системы и их возможности.

##### 2.1.4.1.1 Dendral

В 1965 году учёные из Стэнфордского университета начали разработку первой экспертной системы. Она получила название Dendritic Algorithm или сокращённо [Dendral](https://ru.wikipedia.org/wiki/Dendral). Над ней работали [Эдвард Фейгенбаум](https://ru.wikipedia.org/wiki/Фейгенбаум,_Эдвард_Альберт), [Джошуа Ледерберг](https://ru.wikipedia.org/wiki/Ледерберг,_Джошуа), Брюс Бьюкенен и [Карл Джерасси](https://ru.wikipedia.org/wiki/Джерасси,_Карл).

Всё началось с того, что Джошуа Ледерберг занимался исследованиями в области [астробиологии](https://ru.wikipedia.org/wiki/Астробиология). Эта наука изучает жизнь на других планетах. Учёный задался вопросом: может ли компьютер помочь ему с анализом незнакомых органических соединений? Джошуа Ледерберг обратился за советом к химику Карлу Джерасси и специалисту в области информатики Эдварду Фейгенбауму. Вместе они спроектировали первую версию системы Dendral. Позже к проекту присоединился программист Брюс Бьюкенен.

Система Dendral должна была определять структуру неизвестных молекул по картине их масс-спектра. Чтобы решить поставленную задачу, Джошуа Ледерберг и Гарольд Браун разработали вспомогательный алгоритм. Он [генерировал](https://en.wikipedia.org/wiki/Chemical_graph_generator) все возможные химические соединения по заданным параметрам. Каждое соединение представлялось в виде графа. Для генерации использовались картины масс-спектров известных молекул, общие знания по химии и теории графов.

I> **Масс-спектрометрия** измеряет отношение массы фрагментов молекулы к их заряду.

Для каждого сгенерированного химического соединения экспертная система вычисляла ожидаемую картину масс-спектра. Далее Dendral сравнивала её с картиной заданной неизвестной молекулы. Если масс-спектры совпадали, система делала вывод, что сгенерирована именно заданная молекула.

Dendral решала задачу, которую в общем виде можно сформулировать так:

> Разработать решение с учётом данного набора ограничений.

Именно в задачах такого типа оказались сильны экспертные системы.

Dendral была готова к использованию в 1969 году. Её применяли химики в своих исследованиях на протяжении 1970-х и 1980-х годов. Это был первый случай, когда символьная интеллектуальная система смогла решать реальные задачи из прикладной области.

##### 2.1.4.1.2 Mycin

Успех Dendral доказал, что экспертные системы способны решать прикладные задачи. Поэтому учёные из Стэнфордского университета продолжили исследования в этом направлении.

В начале 1970-х годов Эдвард Фейгенбаум, [Эдвард Шортлифф](https://en.wikipedia.org/wiki/Edward_H._Shortliffe), Брюс Бьюкенен и генетик [Стэнли Коэн](https://ru.wikipedia.org/wiki/Коэн,_Стэнли_Норман) разработали экспертную систему [Mycin](https://ru.wikipedia.org/wiki/MYCIN). Она анализировала симптомы пациента с тяжелым инфекционным заболеванием. По симптомам система могла определить болезнетворные бактерии. Исходя из этой информации, система рекомендовала антибиотики и дозировку для лечения, в зависимости от веса больного.

Mycin имела несколько принципиальных отличий от системы Dendral. Во-первых, пользователь работал с Mycin интерактивно. Система задавала длинную серию вопросов о симптомах пациента. Вопросы были двух типов: с простым ответом да/нет, с развёрнутым ответом в виде текста. Mycin ставила диагноз, ориентируясь на полученную от пользователя информацию.

Второе отличие системы Mycin — это характер знаний, с которыми она работала. В медицине нет такой строгой теоретической модели как в химии. Поэтому Mycin не могла точно вычислить диагноз пациента. Результат работы системы выглядел как список возможных бактерий, вызвавших заболевание. Этот список был отсортирован по убыванию вероятности диагноза. В каждой строке списка Mycin указывала рекомендуемый курс антибиотиков.

Третье отличие системы Mycin от Dendral было в механизме вывода. У Dendral был механизм генерации химических соединений. С его помощью система сама генерировала гипотезы, которые затем проверяла по правилам вычисления масс-спектра.

Mycin имела базу знаний примерно из 600 правил. Каждое правило описывало некоторый симптом заболевания и **вес доказательства** (weight of evidence) того, что пациент заражён конкретной бактерией. Большее значение веса означало большую вероятность. Получив все ответы пользователя, система подставляла в формулу веса для каждого заболевания. Эта формула вычисляла вероятность, которая выводилась в списке с результатами.

Разработчики системы Mycin провели эксперимент, чтобы оценить точность её диагнозов. Для этого они подготовили данные по нескольким пациентам с симптомами заболеваний и уже известными диагнозами. Симптомы проанализировала Mycin и пять преподавателей медицинского факультета Стэнфорда. Система поставила правильный диагноз в 65% случаев. Точность диагнозов у каждого преподавателя была разной: от 42.5% до 62.5%.

Несмотря на многообещающие результаты, Mycin осталась исследовательской разработкой. Она никогда не применялась в больницах. На это было несколько причин.

Во-первых, работа с интерфейсом системы оказалась слишком трудоёмкой. В 1970-х годах больницы не имели электронного документооборота. Вся информация о пациентах хранилась в бумажном виде. Поэтому врач должен был проходить через весь список вопросов для каждого пациента. Один сеанс работы с Mycin мог длиться до получаса. Для врачей такие потери времени были неприемлемы.

Вторая проблема заключалась в высокой стоимости вычислительного времени. Mycin работала на компьютере PDP-10 от компании DEC по цене от 500000$ до 1000000$ долларов. Чтобы окупить приобретение такого компьютера, каждая минута расчётов на нём должна приносить прибыль. Система Mycin использовала вычислительное время очень неэффективно. Большую часть сеанса работы она ожидала ответ пользователя на заданный ему вопрос.

Третья причина была юридическая. Система ставила неверный диагноз примерно с 35% вероятностью. В этом случае было неясно, кто несёт ответственность: разработчики или врачи, которые использовали систему в качестве советчика.

Mycin ещё раз подтвердила эффективность экспертных систем в решении практических задач. В то же время она обозначила будущие проблемы нового подхода. Разработчики обратили внимание на то, что сбор и занесение в систему экспертных знаний — это очень трудоёмкая задача.

##### 2.1.4.1.3 XCON

Американская компания Digital Equipment Corporation (DEC) первой применила экспертную систему для автоматизации своих бизнес-процессов.

В 1970-е годы DEC занимала второе место после IBM по производству компьютеров. Она была известна своими машинами серии PDP и VAX. Именно на компьютерах PDP разрабатывались первые интеллектуальные системы. DEC была главным поставщиком оборудования для лабораторий ИИ и поддерживала хорошие контакты с исследователями. Инженеры компании знали о последних разработках в сфере ИИ.

У компании была проблема. Компьютеры DEC имели много комплектующих и кабелей соединения. Поэтому при оформлении заказов часто происходили ошибки. Покупатели получали несовместимое между собой оборудование или им не хватало кабелей для подключения. Такие ошибки приводили к лишним расходам. Инженеры DEC неоднократно пытались решить эту проблему с помощью автоматизации, но безуспешно.

В конце 1970-х годов Джон Макдермотт работал научным сотрудником в университете Карнеги — Меллона. Он предположил, что экспертная система может решить проблему DEC с конфигурированием оборудования. Вместе со своими коллегами он спроектировал её прототип. Для составления базы знаний Джон Макдермотт консультировался с инженерами DEC. Так он собрал необходимые правила для конфигурации компьютеров. Компания DEC поддерживала и полностью финансировала этот проект.

В 1980-ом году DEC получила прототип системы, получивший название [R1](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/460/396&usg=AOvVaw0VSwYr6eysX2PsWS3AykcU&opi=89978449). Эта версия содержала около 750 правил и могла конфигурировать некоторые вводимые в неё заказы. Но для реального применения отделом продаж DEC систему надо было доработать. Этим занялся новый специально созданный отдел компании. Его задачами стали поддержка существующих и разработка новых экспертных систем для внутренних нужд.

После доработки система конфигурации заказов R1 получила название XCON. Она постоянно дополнялась новыми правилами и механизмами вывода. База знаний системы насчитывала около 2500 правил к концу срока её эксплуатации. За всё это время она обработала около 80000 заказов. Специалисты DEC оценивали точность её работы на уровне 95%. Благодаря XCON, компания DEC экономила до 25 миллионов долларов ежегодно.

Коммерческий успех системы XCON вызвал ажиотаж. Корпорации по всему миру начали внедрять экспертные системы для внутреннего использования. Для этого создавались новые отделы и обучались технические специалисты. В курсе многих университетов появилась новая программа по разработке экспертных систем. Вокруг этой технологии выросла целая индустрия.

Команда Джона Макдермотта разработала прототип системы R1 на языке OPS-4. Его применяли исследователи университета Карнеги — Меллона. За пределами учебного заведения язык никто не знал. Это стало проблемой для инженеров DEC, которые поддерживали систему XCON. Им пришлось изучать OPS-4 с нуля.

Более ранние экспертные системы Dendral и Mycin были написаны на языке Lisp. Он был широко известен и распространён. Его возможности отлично подходили для разработки экспертных систем. Поэтому именно Lisp, а не OPS-4 стал стандартом для новой области программного обеспечения.

В середине 1980-х годов рынок экспертных систем активно рос. Появились специальные компьютеры под названием [**Lisp-машины**](https://ru.wikipedia.org/wiki/Лисп-машина). Их аппаратная архитектура была оптимизирована для запуска программ, написанных на языке Lisp. Производство таких компьютеров приносило огромные прибыли, а спрос на них безостановочно рос до 1987 года.

#### 2.1.4.2 Успехи коннекционизма

В 1970-е и 1980-е годы исследования в рамках коннекционизма проводили учёные не связанные с областью ИИ. Тем не менее их работа внесла важный вклад в развитие коннекционизма. Рассмотрим эти проекты.

##### 2.1.4.2.1 Сеть Хопфилда

В 1972 году японский математик Шуничи Амари занимался [**моделью Изинга**](https://ru.wikipedia.org/wiki/Модель_Изинга). Это модель из статистической физики. Она описывает процесс намагничивания материала. Её разработали для изучения спиновых стёкол. **Спиновые стёкла** — это сплавы немагнитных материалов с магнитными примесями. Их поведение намного сложнее чем у обычных магнитов. Шуничи Амари первым применил модель Изинга для обучения нейронных сетей.

Идеи Шуничи Амари продолжил развивать Уильям Литтл из Стэнфордского университета. В своей статье 1974 года ["Существование устойчивых состояний в мозгу"](https://www.sciencedirect.com/science/article/abs/pii/0025556474900315?via%3Dihub) (The existence of persistent states in the brain) он рассматривает возможность математического моделирования деятельности мозга. В следующей статье 1980 года ["Модель Изинга для нейронных сетей"](https://link.springer.com/chapter/10.1007/978-3-642-61850-5_18) (An Ising Model of a Neural Network) Уильям Литтл подробно разбирает, как применить модель Изинга для нейронных сетей.

Следующий шаг сделал американский физик [Джон Хопфилд](https://ru.wikipedia.org/wiki/Хопфилд,_Джон). Он изучал свойства хранения данных в нейронной сети. Для описания такой сети учёный применил модель Изинга и наработки Уильяма Литтла. В результате Джон Хопфилд разработал новую архитектуру нейронной сети, которая была названа в его честь.

[**Сеть Хопфилда**](https://ru.wikipedia.org/wiki/Нейронная_сеть_Хопфилда) стала моделью для изучения человеческой памяти. Она получала на вход новый образец данных и искала ближайший похожий образец из уже известных. Таким образом сеть выполняла функцию ассоциативной памяти. Кроме этого сеть могла решать следующие задачи:

 1. Распознавать образы.

 2. Восстанавливать повреждённые изображения.
 
 3. Решать [комбинаторные задачи оптимизации](https://ru.wikipedia.org/wiki/Комбинаторная_оптимизация).

Джон Хопфилд подробно описал свои идеи в статье 1982 года под названием ["Нейронные сети и физические системы с возникающими коллективными вычислительными способностями"](https://www.pnas.org/doi/10.1073/pnas.79.8.2554) (Neural networks and physical systems with emergent collective computational abilities).

Сеть Хопфилда была полезна как новая модель с перспективными возможностями. Но намного важнее была стоящая за ней идея: применить хорошо проработанный математический аппарат модели Изинга к нейронным сетям. Именно эта идея подтолкнула дальнейшие исследования в рамках коннекционизма.

##### 2.1.4.2.2 Машина Больцмана

Развивать идеи Джона Хопфилда продолжили другие учёные. Они искали альтернативные математические модели для создания новых архитектур нейронных сетей. Одной из таких моделей стала [**машина Больцмана**](https://ru.wikipedia.org/wiki/Машина_Больцмана). Её разработала группа учёных: психолог [Джеффри Хинтон](https://ru.wikipedia.org/wiki/Хинтон,_Джеффри), математик Дэвид Окли и биолог Терри Сейновски. В 1985 году они описали устройство новой модели в статье "Обучающий алгоритм для машины Больцмана" (A Learning Algorithm for Boltzmann Machines).

Учёные представили машину Больцмана как модель нейронного компьютера, выполняющего параллельные вычисления. Такой компьютер состоит из процессоров, соединённых в сеть. На эту идею учёных подтолкнуло развитие технологии транзисторов и сверхбольших интегральных схем (СБИС) в начале 1980-х.

Машина Больцмана строится на одном из вариантов модели Изинга, который известен как стохастический. Применительно к нейронным сетям, стохастический означает, что функция активации нейронов недетерминирована. Нейроны такой сети находятся в состоянии "включено" или "выключено" с некоторой вероятностью. Это одно из основных отличий машины Больцмана от детерминированной сети Хопфилда.

Создатели машина Больцмана предложили применять её для следующих задач:

1. Генерация данных (в том числе изображений). Машина способна производить данные похожие на те, что применялись в процессе обучения.

2. Дополнение неполных входных данных по обучающим примерам.

3. Обнаружение во входных данных общих признаков и шаблонов.

Над созданием надёжных нейрокомпьютеров на СБИС продолжили работать Карвер Мид и Мохаммед Исмаил. В 1989 году они опубликовали книгу "Аналоговая реализация нейронных сетей на сверхбольших интегральных схемах" (Analog VLSI Implementation of Neural Systems). В ней они описали возможную архитектуру нейрокомпьютера.

##### 2.1.4.2.3 Метод обратного распространения ошибки

В 1962 году Фрэнк Розенблатт впервые ввёл термин **исправление ошибки обратным распространением** (back-propagating error correction). Так он назвал способ обучения сети перцептрон, при котором корректируются веса соединений нейронов. В начале 1960-х годов этот способ оставался только теоретической идеей. Фрэнк Розенблатт не смог реализовать его на практике.

В 1970 году финский математик Сеппо Линнайнмаа защитил магистерскую диссертацию. В ней он описал, как эффективно применить [**метод обратного распространения ошибки**](https://en.wikipedia.org/wiki/Backpropagation) (backpropagation) к сетям произвольной архитектуры, которые похожи на нейронные. В диссертации нейронные сети не упоминаются явно. Но разработанный Сеппо Линнайнмаа математический аппарат применяется в современных алгоритмах обучения практически без изменений.

Американский учёный Пол Вербос был первым, кто подробно описал обучение именно нейронной сети методом обратного распространения ошибки. Это стало темой его диссертации в 1974 году. К сожалению, сообщество исследователей ИИ не обратило внимание на работу молодого учёного.

В 1982 году Пол Вербос опубликовал статью "Применение достижений в нелинейном анализе чувствительности" (Applications of advances in nonlinear sensitivity analysis). В ней он применил метод обратного распространения ошибки к многослойным сетям с прямой связью.

Спустя четыре года эту же тему подняли Джеффри Хинтон и психолог [Дэвид Румельхарт](https://ru.wikipedia.org/wiki/Румельхарт,_Дэвид). В 1986 году они опубликовали статью "Изучение представлений путем обратного распространения ошибок" (Learning representations by back-propagating errors). Статья описывает обучение [**многослойного перцептрона Румельхарта**](https://ru.wikipedia.org/wiki/Многослойный_перцептрон_Румельхарта) методом обратного распространения ошибки. Эта нейронная сеть является частным случаем перцептрона Розенблатта.

Алгоритм обратного распространения ошибки выглядит так:

1. **Инициализация**. Весам всех соединений нейронной сети присваиваются случайные числа.

2. **Прямой проход**. Нейронная сеть получает на вход обучающий пример. Сигналы распространяются по сети от входных нейронов к выходам. Каждый нейрон вычисляет взвешенную функцию своих входов и с помощью функции активации рассчитывает свой выходной сигнал.

3. **Ошибка вычисления**. После прямого прохода выход сети сравнивался с желаемым результатом. Разница между ними представляла собой ошибку вычисления.

4. **Обратный проход**. При обратном проходе ошибка распространяется по сети в направлении от выходов к входам. Начиная с выходного слоя, алгоритм вычисляет вклад каждого веса в общую ошибку вычисления.

5. **Обновление веса**. Алгоритм обучения обновляет все веса сети, используя вклад каждого веса в общую ошибку. Веса корректируются в направлении, которое минимизирует ошибку. Для этого применяется алгоритм оптимизации, например **градиентный спуск**.

6. **Повторение процесса**. Шаги со второго по пятый повторяются для каждого обучающего примера. Алгоритм продолжает корректировать веса сети итеративно. Тем самым он постепенно уменьшает ошибку вычисления.

7. **Критерий остановки** Процесс обучения продолжает до тех пор, пока не выполнен критерий остановки. Это может быть максимально допустимое число итераций. Другой вариант — ошибка вычисления падает ниже заданного значения.

В 1986 году Дэвид Румельхарт и [Джеймс Макклелланд](https://ru.wikipedia.org/wiki/Макклелланд,_Джеймс) опубликовали цикл статей под названием "Параллельная распределенная обработка" (Parallel Distributed Processing). В нём авторы продемонстрировали области применения метода обратного распространения ошибки в компьютерных науках и психологии. Благодаря статьям Джеффри Хинтона, Дэвида Румельхарта и Джеймса Макклелланда, исследователи ИИ снова заинтересовались коннекционизмом.

### 2.1.5 Вторая зима ИИ 1987 — 1993

В 1984 году состоялась ежегодная встреча Американской ассоциации искусственного интеллекта (AAAI). На одном из обсуждений Марвин Минский и Роджер Шэнк обратились к предпринимателям. Они предупредили, что ожидания от ИИ необоснованно завышены. Именно на их выступлении впервые прозвучал термин "зима ИИ". Так Марвин Минский и Роджер Шэнк назвали период разочарования и сокращения финансирования исследований в 1974 – 1980 годах.

После успеха XCON в начале 1980-х компании ежегодно увеличивали инвестиции в разработку экспертных систем. К 1985 году корпорации по всему миру потратили на это в сумме свыше миллиарда долларов. Большая часть средств пошла на развитие внутренних отделов искусственного интеллекта.

Внедрение экспертных систем в больших масштабах создало спрос на связанные с ними услуги. На рынке появлялись новые компании. Они предлагали программные и аппаратные решения для экспертных систем.

Несмотря на бурный рост, в 1987 году рынок экспертных систем рухнул по сценарию [экономического пузыря](https://ru.wikipedia.org/wiki/Экономический_пузырь). Это стало результатом сразу нескольких неудачных для области ИИ событий. Но главной причиной был именно необоснованный энтузиазм, о котором говорили Марвин Минский и Роджер Шэнк.

Инвесторы ожидали от области ИИ высоких прибылей, которые в реальности были невозможны. Обслуживающие экспертные системы компании давали слишком оптимистичные сроки поставки своих продуктов. Эти сроки неоднократно проваливались. В результате многие проекты были закрыты, а контракты на поддержку расторгнуты.

Такой поворот разочаровал инвесторов. Появились сомнения в том, что разработки интеллектуальных систем и специального оборудования для них вообще могут приносить прибыль.

#### 2.1.5.1 Банкротство производителей Lisp-машин

В конце 1970-х сотрудники лаборатории ИИ Массачусетского технологического института начали работать над специальным компьютером. Он должен был максимально эффективно выполнять код экспертных систем. Язык Lisp стал стандартом для разработки таких систем. Поэтому новый компьютер был нацелен на исполнение только Lisp-программ. Он получил название **Lisp-машина**.

В 1979 году разработчики Lisp-машины создали компанию на базе своего института. Она получила название [Lisp Machines](https://en.wikipedia.org/wiki/Lisp_Machines). Первым клиентом стала [Control Data Corporation](https://ru.wikipedia.org/wiki/Control_Data_Corporation) (CDC) — крупный производитель компьютерной периферии и суперкомпьютеров. Именно благодаря заказам и поддержки со стороны CDC, компания Lisp Machines смогла начать свою деятельность.

В феврале 1979 года между сотрудниками Lisp Machines возникли разногласия. Вопрос касался источников финансирования. Часть сотрудников хотела сохранить контроль над компанией, другая — настаивала на привлечении инвесторов. В результате группа, заинтересованная в привлечении инвестиций, покинула Lisp Machines и организовала новую компанию [Symbolics](https://en.wikipedia.org/wiki/Symbolics).

Позднее к производству Lisp-машин подключились крупные производители электроники: [Texas Instruments](https://ru.wikipedia.org/wiki/Texas_Instruments) и [Xerox](https://ru.wikipedia.org/wiki/Xerox). Рынок специализированных компьютеров выглядел перспективно и обещал долгосрочный рост. Инвестиции в разработки Lisp-машин достигли полумиллиарда долларов.

Спрос на Lisp-машины рос до 1987 года. Затем рынок неожиданно рухнул. Специализированные компьютеры стали никому не нужны. Это произошло из-за появления рабочих станций от компании Sun Microsystems. Рабочие станции оказались более выгодным решением, чем Lisp-машины.

I> [**Рабочая станция**](https://en.wikipedia.org/wiki/Workstation) отличается от персонального компьютера (ПК) более высокой ценой и производительностью. Её аппаратное обеспечение оптимизировано для задач визуализации, 3D моделирования и математических расчётов. При этом рабочая станция остаётся [**компьютером общего назначения**](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения).

Рабочие станции от Sun Microsystems имели высокую для своего времени производительность. Она была выше, чем у специализированных Lisp-машин. Несмотря на очевидные преимущества, корпорации отказывались переходить на рабочие станции. Проблема была в том, что они не поддерживали программы на языке Lisp. Это означало, что экспертные системы на них не запускались.

В 1987 году компания [Lucid](https://en.wikipedia.org/wiki/Lucid_Inc.) разработала интерпретатор языка Lisp для операционной системы Unix. Именно эта система устанавливалась на компьютеры Sun Microsystems.

У интерпретатора от компании Lucid были альтернативы. Одну из них разработали в университете Беркли в 1980-м году. Этот интерпретатор назывался [Franz Lisp](https://en.wikipedia.org/wiki/Franz_Lisp). Изначально целью проекта был запуск университетской системы компьютерной алгебры Macsyma на новом оборудовании. В 1982 году Franz Lisp портировали на рабочие станции Sun Microsystems. Позднее сотрудники Беркли организовали компанию Franz Inc., которая занималась развитием и поддержкой интерпретатора.

Благодаря усилиям компаний Lucid и Franz Inc., у Lisp-машин появился сильный конкурент в лице компьютеров от Sun Microsystems. Цена обоих решений была соизмерима, но рабочие станции были мощнее и предлагали больше возможностей.

К концу 1980-х годов относительно недорогие ПК от компаний Apple и IBM достигли производительности Lisp-машин. В 1987-м году на них уже запускались популярные интерпретаторы языка Lisp.

Пользователям экспертных систем не осталось причин переплачивать за специальное оборудование. Корпорации стали массово отказываться от Lisp-машин в пользу дешёвых и универсальных компьютеров с поддержкой языка Lisp.

#### 2.1.5.2 Проблемы экспертных систем

К началу 1990-х годов компании накопили достаточно опыта в использовании и сопровождении экспертных систем. Этот опыт показал, что обслуживать их слишком дорого.

Проблема возникала каждый раз при добавлении новой информации в базу знаний. Сама экспертная система не имеет функции обучения. Поэтому специалисты вносят необходимые изменения вручную. После этого всю базу знаний надо проверить на согласованность. [**Согласованность**](https://ru.wikipedia.org/wiki/Согласованность_данных) означает, что в базе нет противоречащих друг другу правил. Такая проверка и исправление найденных ошибок требует много времени и сил.

К 1990-м годам научные круги потеряли интерес к экспертным системам. В те годы многих учёных занимала тема универсального ИИ. Создать его на основе экспертной системы было невозможно. Универсальному ИИ нужны общие знания о реальном мире. Но исследования в области архитектуры базы знаний показали, что представление общих знаний — трудновыполнимая задача. Как следствие, учёные перестали развивать технологию экспертных систем. Поэтому обнаруженные в этой технологии принципиальные проблемы так и остались без решения.

Американский учёный [Дуглас Ленат](https://ru.wikipedia.org/wiki/Ленат,_Дуглас) всё-таки попытался построить универсальный ИИ на основе экспертной системы. Для этого он организовал проект [Cyc](https://ru.wikipedia.org/wiki/Cyc). Его идея в том, чтобы представить общие знания о мире в виде огромной базы знаний. Этот проект неоднократно подвергался критике со стороны научного сообщества. Многие учёные считают его бесполезным.

Экспертные системы доказали свою эффективность в некоторых узкоспециализированных прикладных областях. Но из-за коммерческих неудач инвесторы потеряли интерес к этому направлению. Без финансирования и поддержки со стороны научного сообщества активная разработка экспертных систем прекратилась.

#### 2.1.5.3 Провал проекта компьютера пятого поколения

В 1982 году правительство Японии запустило проект [компьютера пятого поколения](https://ru.wikipedia.org/wiki/Компьютеры_пятого_поколения). В рамках проекта планировалось разработать производительный суперкомпьютер и запустить его в серийное производство. На всю работу отводилось 10 лет.

До 1970-х годов Япония отставала в производстве компьютеров. Самыми передовыми технологиями в этой области владели США и Англия. Поэтому в середине 1970-х министерство международной торговли и промышленности Японии (MITI) начало исследовать перспективные компьютерные технологии. Эту задачу поручили Японскому центру развития обработки информации (JIPDEC).

Центр JIPDEC определил следующие перспективные направления:

* Технологии логического вывода для обработки знаний.
* Технологии для обработки баз знаний большого масштаба.
* Высокопроизводительные рабочие станции.
* [Параллельные вычисления](https://ru.wikipedia.org/wiki/Параллельные_вычисления).
* Суперкомпьютеры для научных вычислений.

Министерство MITI решило объединить работу по этим направлениям в одном проекте.

Чтобы достичь высокой производительности, участники проекта решили применить многопроцессорную архитектуру. Большинство компьютеров того времени имели один процессор. Поэтому в любой момент времени они могли выполнять только одну программу. Многопроцессорная архитектура позволяла решать несколько задач одновременно или разбивать одну задачу на подзадачи и выполнять их разом. В этом заключается суть параллельных вычислений.

Именно многопроцессорной архитектуре проект и обязан своему названию. Новый суперкомпьютер отнесли к пятому поколению. Почему? Поколения компьютеров принято различать по рабочим элементам, которые выполняют элементарные вычисления. Таблица 2-4 демонстрирует четыре общепризнанных поколения компьютеров и соответствующие им рабочие элементы.

{caption: "Таблица 2-4. Поколения компьютеров", width: "100%"}
| Поколение | Рабочий элемент |
| --- | --- |
| Первое | [Электровакуумная лампа](https://ru.wikipedia.org/wiki/Электронная_лампа) |
|  | |
| Второе | [Транзистор](https://ru.wikipedia.org/wiki/Транзистор) |
|  | |
| Третье | [Интегральная схема](https://ru.wikipedia.org/wiki/Интегральная_схема) |
|  | |
| Четвёртое | [Микропроцессор](https://ru.wikipedia.org/wiki/Микропроцессор) |

Пятым поколением японские специалисты назвали многопроцессорный компьютер. Впоследствии это название так и не прижилось.

Парадигмой разработки программ для нового компьютера стало логическое программирование. Центр JIPDEC высоко оценил его перспективы. Главным языком программирования для всего проекта стал Prolog, а не более универсальный Lisp.

На логическое программирование возлагались большие надежды. Ожидалось, что эта концепция хорошо сочетается с параллельными вычислениями. С её помощью разработчики планировали реализовать следующие функции ИИ для суперкомпьютера:

* Распознавание речи и автоматический набор текста.
* Машинный перевод.
* Анализ печатного текста и его категоризация.
* Распознавание образов.
* Саморазвитие системы.

Другие страны не могли игнорировать амбициозные планы Японии. В 1984 году правительство Великобритании запустило программу [Alvey](https://en.wikipedia.org/wiki/Alvey). Целью программы стали исследования по следующим направлениям:

* Сверхбольшие интегральные схемы (VLSI).
* Системы ИИ, основанные на знаниях.
* Разработка программ.
* Интерфейс взаимодействия человека и машины.

Группа американских компаний объединилась и создала [корпорацию MCC](https://en.wikipedia.org/wiki/Microelectronics_and_Computer_Technology_Corporation), также известную как Консорциум Микроэлектроники и Компьютеров. Эта корпорация должна была спонсировать фундаментальные исследования в области ИИ и информационных технологий. В то же время управление министерства обороны США ARPA утроило финансирование в области ИИ.

К 1991 году проект компьютера пятого поколения не достиг поставленных целей. В рамках проекта инженеры собрали несколько рабочих станций. На них запускались следующие [демонстрационные приложения](https://instadeq.com/blog/posts/japans-fifth-generation-computer-systems-success-or-failure/):

* Распределённая система управления данными Kappa.
* [Правовая экспертная система](https://ru.wikipedia.org/wiki/Правовая_экспертная_система) HELIC-II.
* Система для доказательства теорем MGTP.
* Система для обработки естественного языка Laputa.

Эти результаты оказались далеки от ожиданий министерства MITI. В проект были инвестированы огромные средства и усилия. Но несмотря на это, рабочие станции не пошли в серийное производство и не попали на рынок. У этой неудачи было несколько причин.

Во-первых, когда прототипы рабочих станций были готовы, они уже оказались устаревшими. Проект длился 10 лет. В момент его запуска исследователи предполагали, что однопроцессорные компьютеры достигли предела производительности. Специалисты пришли к выводу, что параллельные вычисления — это единственный способ увеличить мощность компьютера. Этот прогноз оказался неверным. Число транзисторов на интегральной схеме продолжало увеличиваться, согласно закону Мура. В результате к 1991 году недорогие однопроцессорные ПК, собранные на стандартных компонентах, превзошли по производительности рабочие станции пятого поколения.

Во-вторых, рабочие станции устарели не только из-за низкой производительности. Вместе с микропроцессорами развивались и информационные технологии. В 1984 году компания Apple разработала графический интерфейс для своих ПК. В начале 1990-х появился Internet. Рабочие станции пятого поколения не поддерживали эти передовые технологии. Поэтому они были неинтересны пользователям.

Другая проблема компьютера пятого поколения связана с его программами. Разработчики выбрали парадигму логического программирования и язык Prolog. Но оказалось, что эта парадигма плохо совместима с параллельными вычислениями. Сам язык Prolog не имеет встроенных средств для выполнения программы на нескольких процессорах. Все попытки добавить такие средства в язык провалились.

Последняя проблема связана с тем, что запланированные возможности ИИ оказались очень требовательными и к аппаратному и к программному обеспечению. Производительности рабочих станций пятого поколения для них не хватало. Средств логического программирования — тоже. Нужна была принципиально другая платформа для разработки возможностей ИИ.

Провал проекта компьютера пятого поколения повлиял на развитие информационных технологий в целом. Во-первых, проект подорвал веру разработчиков программ и учёных в логическое программирование. Недостатки этого подхода считались одной из главных причин неудачи проекта. Крупные исследования в рамках этого направления ИИ и его финансирование прекратились.

Во-вторых, правительства США и Англии сократили инвестиции в компьютерные технологии и исследования ИИ. Эти страны остались лидерами в обеих областях. Япония прекратила попытки их догнать.

### 2.1.6 Развитие ИИ в 1993–2011

#### 2.1.6.1 Байесовская сеть

В начале 1990-х годов в исследованиях ИИ начал доминировать подход теоретиков (neat). Этому способствовали достижения коннекционизма в 1980-е годы. Оказалось, что существующие математические модели могут стать отправной точкой для разработки новых архитектур нейронных сетей.

Появились новые статистические и математические подходы к разработке ИИ. Одним из них стала [**математическая оптимизация**](https://ru.wikipedia.org/wiki/Оптимизация_(математика)). Идея этого подхода в поиске наилучшего решения с заданными критериями между несколькими альтернативами.

В 1988 году учёный в области информатики Джудиа Перл опубликовал книгу "Вероятностное рассуждение в интеллектуальных системах" (Probabilistic Reasoning in Intelligent Systems). В ней автор предлагает теоретические основы и вычислительные методы для создания интеллектуальных систем, которые принимают решения в условиях неопределённости. Книга получила признание среди специалистов. Она убедила многих в том, что теория вероятности и теория принятия решений применимы в области ИИ.

Используя математический аппарат теории вероятностей, Джудиа Перл разработал модель [**байесовской сети**](https://ru.wikipedia.org/wiki/Байесовская_сеть). Эта модель отражает связи между множеством переменных и их вероятностными зависимостями по теореме Байеса. Эта теорема определяет вероятность события при условии, что произошло другое статистически взаимозависимое с ним событие.

Байесовская сеть представляет собой ориентированный ациклический граф. Его узлы — это некоторые переменные. Ребра графа соответствуют вероятностным взаимосвязям между узлами. Для примера допустим, что система медицинской диагностики построена на Байесовской сети. Тогда узлы графа — это симптомы и вызвавшие их заболевания. Ребра графа показывают причинно-следственную связь между ними.

Для каждого ребра определяется условная вероятность. Она отражает вероятность переменной в данном узле с учётом его родителей. Родитель — это узел из которого выходит ребро, входящее в данный узел. В медицинской системе диагностики условная вероятность определяется экспертами, клиническими испытаниями и статистическими данными.

Готовая байесовская сеть получает на вход данные. Для системы диагностики данные — это симптомы пациента. По ним сеть выдаёт наиболее вероятный диагноз.

Мы рассмотрели **причинно-следственную байесовскую сеть** (causal bayesian network). Кроме неё есть и другие виды байесовских сетей:

1. **Статическая** (Static Bayesian Network) — в ней отношения между переменными фиксированы и не меняются.

2. **Динамическая** (Dynamic Bayesian Network) — может моделировать временные зависимости и изменения во времени. Используется, когда моделируемая система подвержена динамическим процессам.

3. **Гибридная** (Hybrid Bayesian Network) — объединяет разные типы переменных: дискретные и непрерывные. Используется, когда переменные имеют разные типы данных.

4. **Временные** (Temporal Bayesian Network) — обобщённая версия динамической сети. Может обрабатывать данные временных рядов. [**Временной ряд**](https://ru.wikipedia.org/wiki/Временной_ряд) — это замеры каких-либо параметров в разные моменты времени.

5. **Скрытая марковская модель** (Hidden Markov Model или HMM) — особый вид динамической сети, который используют для моделирования последовательностей наблюдаемых событий со скрытыми состояниями. HMM решает задачи распознавания речи, обработки естественного языка и последовательного анализа данных.

6. **Диаграмма влияния** (Influence Diagram) — представляют собой единую графическую модель, которая включает неопределённость и данные для принятия решений. Используются в задачах анализа решений и оптимизации.

7. **Полидеревья и цепные графы** (Polytrees and Chain Graphs). Байесовская сеть представляет собой направленный ациклический граф. Полидеревья и цепные графы ослабляют это ограничение. Полидеревья допускают не более одного цикла. Цепные графы могут содержать как ориентированные, так и неориентированные ребра.

Алгоритмы машинного обучения применимы ко всем видам байесовских сетей. Структура и параметры этих сетей зависят от конкретной задачи. Их выбирают исходя из обучающих данных.

#### 2.1.6.2 Интеллектуальные агенты

В 1995 году Стюарт Рассел и Питер Норвиг опубликовали книгу "Искусственный интеллект: современный подход". В ней авторы предложили концепцию интеллектуального агента. Она заимствована из экономики и теории принятия решений. В этих науках есть понятие рационального агента. **Интеллектуальный агент** — это тот же рациональный агент только в контексте ИИ. В экономике рациональный агент стремится максимизировать свою прибыль. Точно так же интеллектуальный агент пытается максимизировать свою эффективность при решении поставленной задачи.

Большинство исследователей согласилось с концепцией интеллектуального агента. Она разрешила несколько философских проблем в области ИИ. Первой проблемой были разногласия учёных о том, что именно считать интеллектом. Тест Тьюринга подразумевает сравнение с человеческим интеллектом. Понятие рационального агента устранило это сравнение. Любое поведение агента считается интеллектуальным, если оно приводит к эффективному достижению цели.

Вторая философская проблема заключалась в вопросе: может ли машина обладать сознанием и настоящим пониманием? Учёные давали разные ответы на этот вопрос. В зависимости от своей точки зрения, они выбирали соответствующее направление исследований. Для интеллектуального агента сознание и понимание оказались совершенно неважны. Новая концепция ставит на первое место эффективность решения. Метод поиска решения может быть любым.

Теперь исследователи могли сконцентрироваться на решении конкретных практических задач. Им больше не надо было защищать свои методы с философской точки зрения. Достаточно было математически доказать их эффективность.

Концепция интеллектуального агента помогла исследователям не только с философской точки зрения, но и на практике. Она дала надёжный способ сравнивать системы, основанные на разных подходах. Принцип их работы отошёл на второй план. Теперь главным показателем стала **функция полезности** (value function). Если агент лучше максимизирует эту функцию, он лучше справляется с поставленной задачей. Благодаря новому методу оценки, учёные стали быстрее добиваться практических результатов.

Раньше каждый исследователь работал в рамках только одного подхода (например, коннекционизма). Когда приоритетом стала измеряемая эффективность, учёные начали совмещать разные подходы в одной системе. В некоторых случаях такие эксперименты давали положительные результаты.

Формальные методы оценки результатов дали исследователям ИИ средство для общения с другими научными направлениями. Математическая оптимизация, теория вероятностей и теория принятия решений внесли свой вклад в развитие ИИ. Использование общего математического аппарата ускорило обмен идеями со смежными науками.

#### 2.1.6.3 Восстановление репутации ИИ

Многие инвесторы разочаровались в области ИИ после краха рынка Lisp-машин, проблем с экспертными системами и провала проекта компьютера пятого поколения. Правительства стран и компании потеряли деньги, когда пузырь экспертных систем лопнул. Они больше не хотели вкладываться в исследования ИИ.

На протяжении 1990-х годов учёные избегали термина "искусственный интеллект". Он ассоциировался с невыполнимыми обещаниями и отпугивал инвесторов. Вместо этого исследователи ИИ называли свою работу информатикой, когнитивными системами или вычислительным интеллектом. Это привело к двум долгосрочным последствиям:

1. [Алгоритмы и концепции](https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence#Historical_contributions), разработанные в рамках исследований ИИ, начали интегрировать в обычные компьютерные системы. Как следствие, эти достижения ошибочно считаются результатом развития информатики, а не ИИ.

2. Область ИИ оказалась раздробленной. Достижения учёных 1990-х годов приписывались новым, выдуманным им направлениям. На самом деле все эти достижения относятся к ИИ.

В конце 1990-х и 2000-х годах несколько интеллектуальных систем достигли впечатляющих успехов. Они широко освещались в СМИ и привлекли общественное внимание. Благодаря этому, испорченная репутация науки об ИИ была частично восстановлена.

Вот некоторые из самых известных интеллектуальных систем того времени:

* В 1997 году суперкомпьютер [DeepBlue](https://ru.wikipedia.org/wiki/Deep_Blue) от IBM обыграл чемпиона мира по шахматам Гарри Каспарова.

* В 2005 году робот, разработанный в Стэнфордском университете, победил в гонках [DARPA Grand Challenge](https://ru.wikipedia.org/wiki/DARPA_Grand_Challenge). Автономно управляемая машина смогла проехать весь маршрут в 211 километров по пустыне Мохаве. На это у робота ушло почти семь часов.

* В 2011 году ИИ система [Watson](https://ru.wikipedia.org/wiki/IBM_Watson) от компании IBM обыграла двух лучших игроков в телевизионной игре-викторине Jeopardy!. В этой игре участники отвечают на вопросы из области общих знаний.

Причины успехов интеллектуальных систем было две:

1. Усовершенствовалась технология СБИС. Как следствие выросла производительность компьютеров.

2. Повысилось общее качество разработки программ.

Каждая из нашумевших интеллектуальных систем использовала хорошо известные подходы, которые появились ещё в 1960-х годах. Качественный рывок происходил благодаря лучшей аппаратной платформе и хорошо написанному ПО.

### 2.1.7 Современные направления ИИ

С середины 2010-х годов вокруг исследований в области ИИ начался очередной ажиотаж. Журналисты назвали этот период "Возрождением ИИ" (AI Renaissance).

Новый бум ИИ стал следствием быстрого прогресса и повышенным вниманием СМИ. Прогресс стал возможным благодаря удачному стечению ряда событий:

1. Американский учёный [Эндрю Ын](https://ru.wikipedia.org/wiki/Ын,_Эндрю) предложил использовать [графические процессоры](https://ru.wikipedia.org/wiki/Графический_процессор) (GPU) для моделирования нейронных сетей. Это позволило эффективно обучать более крупные и сложные модели, чем раньше.

2. Повсеместное распространение цифровых данных в различных форматах (изображения, текст, видео, показания датчиков). Все они стали источником огромного объёма исходных данных для обучения моделей.

3. Исследователи ИИ разработали эффективные алгоритмы глубокого обучения (deep learning) для нейронных сетей. Их применение на практике увеличило производительности моделей в задачах распознавания образов и обработки естественного языка.

4. Доступность [фреймворков](https://ru.wikipedia.org/wiki/Фреймворк) (программных платформ) и библиотек для работы с нейронными сетями. Например, [TensorFlow](https://ru.wikipedia.org/wiki/TensorFlow) от Google и [PyTorch](https://ru.wikipedia.org/wiki/PyTorch) от Facebook. Эти инструменты стали распространяться с открытым исходным кодом. Так разработчики, исследователи и просто энтузиасты получили возможность экспериментировать и внедрять модели ИИ в свои приложения.

5. Корпорации Amazon, Microsoft и Google предоставили сервис облачных платформ. Через него организации и частные лица получили доступ к мощным вычислительным ресурсам. Это позволило всем желающим экспериментировать с ИИ без значительных предварительных инвестиций.

6. Правительства и инвесторы осознали потенциал ИИ и начали вкладывать значительные средства в исследования и разработку приложений.

В совокупности эти факторы привели к крупным успехам интеллектуальных систем в областях распознавания образов и обработки естественного языка. Эти достижения вдохновили учёных на дальнейшие исследования.

Рассмотрим некоторые из предпосылок нового периода возрождения ИИ.

#### 2.1.7.1 Платформа для моделирования нейронных сетей

В конце 1990-х и начале 2000-х годов нейронные сети и машинное обучение были малопопулярными направлениями. Над ними продолжали работать несколько групп учёных. Их немногочисленные публикации читали только коллеги, так же работавшие в рамках коннекционизма.

Проблема подходящей аппаратной платформы для моделирования нейронных сетей по-прежнему оставалась нерешенной. Это сильно тормозило их исследование и применение на практике. В начале 2000-х годов обучаемые модели стали очень сложными. Работа с ними на обычных компьютерах требовала слишком много времени.

Эндрю Ын вел курс "Machine Learning" в Стэнфордском университете в 2011 году. На одной из лекций он рассказал о преимуществах использования графических процессоров для обучения нейронных сетей. Видео этих лекции стало доступно через интернет. Так идея Эндрю Ына стала широко известна. Примерно в это же время группы исследователей и компании производители оборудования уже экспериментировали с GPU и машинным обучением.

В 2007 году компания Nvidia выпустила платформу [CUDA](https://ru.wikipedia.org/wiki/CUDA) (Compute Unified Device Architecture). Она позволяла разработчикам программ переносить часть своих вычислений с процессора (CPU) на GPU. Изначально Nvidia рассматривала свой продукт, как средство ускорения работы обычных пользовательских приложений.

Основное преимущество GPU перед CPU в параллельной обработке больших блоков данных. Современный графический процессор имеет от несколько сотен до нескольких тысяч ядер. Каждое из них может работать независимо от других. Поэтому GPU отлично справляется с параллельными вычислениями. Они встречаются в алгоритмах шифрования и сортировки, программах моделирования физики и научных вычислениях. Моделирование нейронных сетей — это тоже обработка больших блоков данных, которую можно распараллелить.

Благодаря работе Эндрю Ына и других исследователей, CUDA и GPU от Nvidia стали основной программно-аппаратной платформой для работы с нейронными сетями.

#### 2.1.7.2 Big Data

В конце 1990-х начале 2000-х годов пользователи компьютерных систем столкнулись с лавинообразным ростом цифровых данных. До этого времени проблема обработки данных большого объёма возникала только в нескольких областях: научные исследования, финансы и телекоммуникации.

В начале 2000-х годов ситуация изменилась по нескольким причинам. Прежде всего из-за распространения компьютеров. Все больше компаний и правительственных учреждений начали переходить на электронный документооборот. В результате начали накапливаться огромные объёмы информации, которые надо было хранить и обрабатывать.

Интернет набирал популярность среди рядовых пользователей ПК. Росло число сайтов и онлайн-сервисов. Появились первые социальные сети. Пользователи и компьютерные системы начали генерировать большие объемы данных. Эти данные оказались важны для владельцев онлайн-сервисов и компаний в сфере интернет-торговли.

В конце 1990-х годов появилась концепция [**интернета вещей**](https://ru.wikipedia.org/wiki/Интернет_вещей) (Internet of things или IoT). Она предлагает объединять в сеть небольшие устройства, оснащённые датчиками. На протяжении 2000-х годов эта технология почти не применялась на практике. Проблема была в высокой стоимости микроконтроллеров и датчиков. В начале 2010-х годов эта проблема была решена. На рынке появились недорогие узкоспециализированные чипы с различными возможностями. Интернет вещей начали внедрять в различных областях: производство, энергетика, сельское хозяйство, здравоохранение. Это создало огромные потоки данных, требующие обработки.

Чтобы справиться с новыми задачами, появилось направление компьютерных наук под названием [**большие данные**](https://ru.wikipedia.org/wiki/Большие_данные) (big data). Это направление занимается методами обработки наборов данных, которые слишком велики для применения традиционных подходов.

Впервые термин big data использовал учёный Впервые термин big data использовал учёный [Джон Маши](https://en.wikipedia.org/wiki/John_Mashey) в своей статье 1998 года "Большие данные и следующая волна ИнфраСтресса" (Big Data and the Next Wave of InfraStress). Статья поднимает проблемы, связанные с крупномасштабными наборами данных. Автор утверждает, что для их обработки нужны новые инновационные технологии.

Дуг Лэйни работал аналитиком данных в американской исследовательской и консалтинговой компании [Gartner](https://ru.wikipedia.org/wiki/Gartner). В 2001 году он предложил характеризовать big data тремя V:

* **Volume** (объём). Количество сгенерированных и сохранённых данных. Обычно составляет от нескольких терабайт до нескольких петабайт. Объём данных определяет их ценность и полезность.

* **Velocity** (скорость). Скорость генерации и обработки данных. Big data обычно обновляются непрерывно, в режиме реального времени. Для решения задач их надо обрабатывать со скоростью близкой к реальному времени.

* **Variety** (разнообразие). Технологии big data рассчитаны на обработку плохо структурированных и неструктурированных данных разных типов: текст, изображения, видео, аудио и т.д.

Эти характеристики big data считаются основными и общепризнанными. Некоторые исследователи и аналитики добавляют к ним что-то своё. Поэтому сейчас в интернете можно найти много статей с разным описанием big data. Но в каждой из них упоминаются три V, которые предложил Дуг Лэйни.

Для обработки больших объёмов данных не достаточно одного инструмента. В этой области сформировалась целая экосистема платформ, технологий и инструментов. Они решают задачи хранения, организации, анализа и извлечения информации из огромных объёмов данных.

Вот некоторые из ключевых технологий big data:

1. Распределенные вычислительные платформы:

  * [**Apache Hadoop**](https://ru.wikipedia.org/wiki/Hadoop) — платформа с открытым исходным кодом для распределенного хранения и обработки больших наборов данных. Она основана на модели [**MapReduce**](https://ru.wikipedia.org/wiki/MapReduce). Согласно ей обработка данных разделяется на одинаковые элементарные задания. Они исполняются на узлах кластера компьютеров и сводятся в конечный результат.

  * [**Apache Spark**](https://ru.wikipedia.org/wiki/Apache_Spark) — универсальная платформа кластерных вычислений, поддерживающая пакетную обработку, потоковую обработку в реальном времени, машинное обучение и обработку графов.

  * [**Apache Flink**](https://ru.wikipedia.org/wiki/Apache_Flink) — инфраструктура потоковой обработки, которая также может выполнять пакетную обработку и предлагает возможности обработки данных с малой задержкой.

2. Распределённые системы хранения.

  * Hadoop Distributed File System (HDFS) — распределённая файловая система, которая хранит огромные объёмы данных в кластере компьютеров. Является частью платформы Apache Hadoop.

3. Базы данных [**NoSQL**](https://ru.wikipedia.org/wiki/NoSQL) и [**NewSQL**](https://ru.wikipedia.org/wiki/NewSQL) позволяют хранить большие объёмы неструктурированных данных и получать к ним быстрый доступ.

4. [**Облачные система хранения**](https://ru.wikipedia.org/wiki/Облачная_система_хранения) — это модель хранения данных в сети компьютеров. Пространство для хранения арендуется у компании, которая владеет этой сетью и обслуживает её. Примеры таких сервисов: Amazon Redshift, Google BigQuery, Snowflake.

5. Машинное обучение и аналитика:

  * TensorFlow, PyTorch — библиотеки с открытым исходным кодом для создания и обучения моделей машинного обучения на больших наборах данных.

  * [**Apache Mahout**](https://ru.wikipedia.org/wiki/Apache_Mahout) — библиотека машинного обучения, построенная на основе Hadoop и Spark.

6. Визуализация данных:

  * Tableau, Microsoft Power BI, QlikView — инструменты для создания интерактивных визуализаций данных и информационных панелей из больших наборов данных.

Технологии big data применяются в разных областях для получения информации, оптимизации процессов и принятия обоснованных решений. Вот некоторые из этих областей:

1. Электронная коммерция и розничная торговля.

  * Анализ поведения клиентов для персонализированных рекомендаций и таргетированного маркетинга.

  * Управление запасами и оптимизация цепочки поставок.

  * Выявление и предотвращение мошенничества.

2. Финансы и банковское дело:

  * Оценка рисков и обнаружение мошенничества.

  * [**Алгоритмическая торговля**](https://ru.wikipedia.org/wiki/Алгоритмическая_торговля) — это метод исполнения крупной сделки на финансовом рынке путем её разделения на ряд мелких операций. Такой подход минимизирует влияние сделки на рынок и риск её неисполнения.

  * Инвестиционный анализ.

  * Анализ настроений клиентов для улучшения обслуживания клиентов.

3. Здравоохранение:

  * Анализ данных пациентов для создания персональных планов лечения.

  * Разработка новых лекарств путём сбора и анализа статистических данных.

  * Предсказание и анализ вспышек заболеваний и эпидемий.

4. Телекоммуникации:

  * Оптимизация сети и мониторинг для улучшения качества обслуживания.

  * Прогнозирование оттока клиентов.

  * Геолокационные сервисы и таргетированная реклама.

5. Производство и промышленность:

  * Профилактическое обслуживание оборудования для сокращения времени его простоя и повышения эффективности.

  * Контроль качества посредством анализа данных в режиме реального времени.

  * Оптимизация цепочки поставок и прогнозирование спроса.

6. Транспорт и логистика:

  * Оптимизация маршрутов для транспортных сетей.

  * Отслеживание транспортных средств и грузов в режиме реального времени.

  * Прогнозирование спроса и планирование мощностей.

Направление big data активно применяет алгоритмы и решения машинного обучения. В то же время специалисты из это области разрабатывают новые подходы для обработки больших данных. Потом эти подходы применяются в передовых исследованиях ИИ. Big data и ИИ являются смежными направлениями. Они развиваются параллельно и взаимно дополняют друг друга.

#### 2.1.7.3 Deep Learning

##### 2.1.7.3.1 Особенности нового направления

Термин [**deep learning**](https://ru.wikipedia.org/wiki/Глубокое_обучение) появился в конце 1980-х годов. Его употребляли только специалисты машинного обучения. Широкую известность он получил в 2000-х годах. Deep learning дословного переводится как "глубокое обучение". Это собирательное название для семейства методов машинного обучения, которые работают с нейронными сетями.

Сложность обучаемых моделей — это главное отличие методов deep learning. Они работают с нейронными сетями, имеющими несколько скрытых слоёв и сотни параметров.

Для всех методов, которые не относятся к deep learning, появился новый термин **shallow learning** (поверхностное обучение). Это собирательное название для более простых алгоритмов и обучения нейронных сетей с одним скрытым слоем. Примеры shallow learning алгоритмов: метод опорных векторов, дерево решений, линейная регрессия и т.д.

Вот ключевые различия deep learning от shallow learning:

1. Сложность обучаемой модели в deep learning.

2. [**Конструирование признаков**](https://habr.com/ru/companies/ruvds/articles/680498/) (feature engineering) в deep learning — это извлечение важных для модели признаков (входных параметров) из исходных данных.

* Deep learning модели автоматически извлекают признаки из исходных данных. Это происходит благодаря способности сети распознавать сложные закономерности.

* Для shallow learning моделей необходима ручное конструирование признаков. Из всего множества признаков, встречающихся в исходных данных, разработчик должен определить самые важные для решаемой задачи. Затем отобранные признаки надо преобразовать в удобный для выбранной модели формат. Конечный результат алгоритма обучения сильно зависит от качества конструирования признаков.

3. [**Обучение представлению**](https://analyticsindiamag.com/a-comprehensive-guide-to-representation-learning-for-beginners/) (representation learning) — это способность модели интерпретировать исходные данные.

* Deep learning модели эффективно представляют исходные данные в виде иерархий абстракций и таким образом понимают сложные закономерности. Каждый слой или набор слоев нейронной сети распознаёт отдельный уровень абстракций. Пример уровней абстракции в порядке возрастания сложности на изображении: отдельные линии, геометрические фигуры (треугольник, квадрат и т.д.), объекты (дом, автомобиль и т.д.).

* Shallow learning модели не способны самостоятельно строить сложные иерархии абстракций. Эти модели полностью полагаются на ручное конструирование признаков и заложенные в них простые абстракции.

4. Требования к исходным данным.

* Deep learning: для качественного обучения сложных моделей нужны исходные данные большого объёма.

* Shallow learning: для обучения моделей достаточно небольших наборов исходных данных. Но качество обучения сильно зависит от результата конструирования признаков.

5. Требования к вычислительным ресурсам.

* Обучение deep learning моделей требует значительных вычислительных ресурсов и специализированного оборудования (например, GPU). Даже используя большие вычислительные мощности, алгоритм обучения может выполнятся несколько дней или недель.

* Shallow learning модели можно обучать на стандартных процессорах. Работа алгоритмов обучения, как правило, не занимает много времени.

6. Интерпретируемость результатов модели

* Deep learning модели из-за своей сложности работают по принципу "чёрного ящика". Разработчикам очень сложно понять, почему сеть приходит к тому или иному выводу.

* Shallow learning модели проще анализировать. Разработчики обычно знают, как именно модель принимает решения.

##### 2.1.7.3.2 История deep learning

История возникновения deep learning началась в 1960-е годы. Первым, кто исследовал многослойные нейронные сети, был Фрэнк Розенблатт. Его исследования ограничивались только теоретическими выводами. Для моделирования многослойной сети нужно высокопроизводительное оборудование. Поэтому технической возможности экспериментировать с этим видом сетей не было до 1980-х годов.

В 1979 году японский учёный [Кунихико Фукусима](https://en.wikipedia.org/wiki/Kunihiko_Fukushima) разработал новую архитектуру нейронной сети [**неокогнитрон**](https://en.wikipedia.org/wiki/Neocognitron). Её прообразом стала модель, предложенная в 1959 году нейрофизиологами Дэвидом Хьюбелом и Торстеном Визелем. Эта модель описывает устройство зрительной коры человека, в которой два типа клеток (простая и сложная) расположены каскадно. Кунихико Фукусима спроектировал неокогнитрон для распознавания рукописных японских иероглифов.

Неокогнитрон стал прототипом новой архитектуры, получившей название [**свёрточная нейронная сеть**](https://ru.wikipedia.org/wiki/Свёрточная_нейронная_сеть) (convolutional neural network или CNN). Она является подвидом сети с прямой связью (FNN) и оптимизирована для обработки изображений.

В 1989 году французский учёный [Ян Лекун](https://ru.wikipedia.org/wiki/Лекун,_Ян) решал задачу распознания рукописных почтовых индексов на конвертах. Он применил метод backpropagation для свёрточной нейронной сети (CNN). После трёх дней обучения сеть смогла распознавать индексы. Свои результаты учёный описал в статье "Применение обратного распространение ошибки к распознаванию рукописного почтового индекса" (Backpropagation Applied to Handwritten Zip Code Recognition). В 1998 году на основе этого решения Ян Лекун разработал сеть LeNet-5. Она распознавала любые рукописные цифры. Несколько банков использовали её для автоматической обработки чеков.

В 1980-х исследователи начали экспериментировать со сложными моделями нейронных сетей. Попытки обучить их методом обратного распространения ошибки привели к проблеме исчезающего градиента.

I> В машинном обучении **градиентом** (gradient) называется скорость изменения функции по отношению к её входным параметрам. Градиент даёт информацию о том, как небольшие изменения входных параметров влияют на результат функции.

[**Проблема исчезающего градиента**](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) (vanishing gradient problem) связана с процессом **присвоения кредитов** (credit assignment) в ходе обучения модели. Присвоение кредитов означает расчёт вклада отдельных нейронов и их соединений в конечный результат работы сети.

В многослойных сетях влияние активации отдельного нейрона может иметь долгосрочное влияние на конечный результат. Другими словами эффекты активации нейрона могут распространятся через несколько слоев сети, прежде чем внести свой вклад. Во время обучения информация в модели распространяется в обратном направлении через множество слоёв. Это может привести к тому, что градиенты становятся чрезвычайно малыми (исчезающий градиент), либо чрезвычайно большими (**взрывающийся градиент**). В результате обучение идёт медленно или оказывается неэффективным.

Первую попытку решить проблему исчезающего градиента предпринял [Юрген Шмидхубер](https://ru.wikipedia.org/wiki/Шмидхубер,_Юрген) в 1992 году. Он предложил обучать каждый слой нейронной сети отдельно. Затем обученную иерархию слоев надо свернуть в единую нейронную сеть. Так получалась законченная модель.

Работа с отдельными слоями решала не только проблему исчезающего градиента, но и недостаточной вычислительной мощности. Обучение сложной модели целиком требовало слишком много времени в 1990-е годы. Этот процесс проходил быстрее при разделении его на отдельные шаги: обучение только одного слоя за раз.

Юрген Шмидхубер работал с рекуррентными нейронными сетями. Информационный поток в нейронных сетях с прямой связью (FNN) однонаправленный. Это означает, что информация в модели распространяется только в одном направлении — вперёд: от входных узлов через скрытые узлы к выходным узлам без циклов и петель. [**Рекуррентные нейронные сети**](https://ru.wikipedia.org/wiki/Рекуррентная_нейронная_сеть) (recurrent neural network или RNN) в отличие от FNN имеют замыкающиеся связи. Такие связи позволяют двунаправленный поток информации: вперёд от входных узлов через скрытые узлы к выходным узлам и в обратном направлении.

Благодаря двунаправленному потоку информации, RNN используют результаты предыдущего временного шага в качестве входных данных для текущего временного шага. Таким образом сеть эффективно изучает и фиксирует закономерности в последовательностях. Поэтому архитектура RNN хорошо подходит для обработки естественного языка, распознавания речи, анализа временных рядов и подобных задач.

В 1991 году Зепп Хохрайтер посвятил свою дипломную работу проблеме исчезающего градиента при обучении рекуррентных нейронных сетей. Он предложил добавить так называемые **остаточные соединения** (residual connections) в архитектуру сети. Эти соединения работают как короткий путь между не соседними, удалёнными друг от друга слоями сети. Таким образом поток информации проходить мимо одного или нескольких слоев. Благодаря остаточным соединениям, алгоритм обучения может лучше оценить разницу между входом и желаемым выходом модели.

В 1997 году Зепп Хохрайтер и Юрген Шмидхубер развили идею остаточных соединений. Они разработали архитектуру нейронной сети, названную [**длинная цепь элементов краткосрочной памяти**](https://habr.com/ru/companies/wunderfund/articles/331310/) (long short-term memory или LSTM). Это особая разновидность рекуррентных сетей, которая может обучаться долговременным зависимостям. Тем самым в ней решается проблема исчезающего градиента.

LSTM использует специальную структуру ячеек, вентилей и модулей памяти. **Ячейки** (cell) — это элементарные строительные блоки LSTM сети. Они содержат в себе вентили и модули памяти. Механизм **вентилей** (gate) управляет потоком информации и памятью внутри сети. Благодаря ему, LSTM способна собирать и сохранять информацию в течении нескольких временных шагов.

В 2006 году Джеффри Хинтон, [Руслан Салахутдинов](https://ru.wikipedia.org/wiki/Салахутдинов,_Руслан_(учёный)), Саймон Осиндеро и [Йи Вай Тех](https://en.wikipedia.org/wiki/Yee_Whye_Teh) опубликовали несколько статей. Учёные повторили подход Юргена Шмидхубера с обучением каждого слоя отдельно. Отличие нового исследования было в том, что команда Джеффри Хинтона работала не с RNN, а с сетями с прямой связью (FNN). Теперь исследователи могли эффективно обучать модели любого типа (RNN и FNN) на обычных компьютерах за приемлемое время.

Исследователи нейронных сетей были вынуждены обучать свои модели послойно до 2010-х годов. В 2011 году значительно выросла производительность GPU. Благодаря идеям Эндрю Ына и усилиям Nvidia, CUDA стала надёжной платформой для разработки алгоритмов обучения нейронных сетей. Теперь сложные модели можно было обучать целиком, а не послойно. Это упростило и ускорило эксперименты с нейронными сетями. Пр этом проблема исчезающего градиента решалась специальными архитектурами сетей, например LSTM.

В 2009 году Фей-Фей Ли из Принстонского университета представила свой проект [**ImageNet**](https://ru.wikipedia.org/wiki/ImageNet) на конференции, посвященной компьютерному зрению. Проект заключался в подготовке огромной базы изображений. Для каждого изображения вручную составлялась аннотация с перечислением попавших на него объектов и их координат. Чтобы подготовить аннотацию изображений, Фей-Фей Ли воспользовалась краудсорсинговой платформой Amazon Mechanical Turk.

Начиная с 2010 года Фей-Фей Ли запустила проект ILSVRC (ImageNet Large Scale Visual Recognition Challenge). Это открытые соревнования между исследовательскими группами. В ходе соревнований обученные модели распознают и классифицирую объекты на изображениях из базы ImageNet.

Ежегодные соревнования ILSVRC привлекли внимание специалистов и СМИ со всего мира. Это событие стало престижным, благодаря известности его участников. База ImageNet свободно доступна через интернет. Любой желающий может её скачать и начать экспериментировать с моделями. Это привело к быстрому прогрессу в задаче распознавания образов.

В 2011 году пятерка лучших моделей распознавала образы с 25% ошибок. В 2012 году глубокая сверточная сеть AlexNet достигла результата в 16% ошибок. Эту сеть разработали Джеффри Хинтон, [Алексей Крижевский](https://en.wikipedia.org/wiki/Alex_Krizhevsky) и [Илья Суцкевер](https://ru.wikipedia.org/wiki/Суцкевер,_Илья). К 2014 году процент ошибок у лучших моделей упал до нескольких процентов. В 2015 году появились сообщения, что некоторые модели превосходят человеческие способности. Однако, эти модели могли распознавать изображения примерно из тысячи категорий. Человек же способен различать намного больше категорий изображений и лучше оценивать их контекст.

Соревнование ILSVRC было не единственным связанным с компьютерным зрением. Кроме него были менее известные ежегодные конкурсы. Например, по распознаванию рукописного китайского текста (ICDAR), выявления раковых опухолей на медицинских изображениях (ICPR), распознаванию речи (Interspeech). Модели на глубоких свёрточных сетях доминировали во всех соревнованиях по распознаванию образов. В распознавании речи лучшие результаты показывали LSTM модели.

Успехи глубоких нейронных сетей в престижных соревнованиях сделали этот подход трендом в современных исследованиях. С 2010-х годов началась так называемая ["революция глубокого обучения"](https://en.wikipedia.org/wiki/Deep_learning#Deep_learning_revolution) в ИИ.

{pagebreak}
