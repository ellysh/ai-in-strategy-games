## 2.1 История

Искусственный интеллект (ИИ) как направление исследований появился на стыке нескольких дисциплин. На ИИ оказали влияние идеи, достижения и методы из нескольких наук. Таблица 2-1 демонстрирует эти науки.

{caption: "Таблица 2-1. Науки, оказавшие влияние на ИИ", width: "100%"}
| Наука | Применяемая в ИИ теория, идея или метод |
| --- | --- |
| Нейрофизиология | Модель искусственного нейрона и нейронной сети |
|  | |
| Математика | Правила формальной логики и логического вывода |
|  | Статистические методы |
|  | Теория вероятностей |
|  | Теория принятия решений |
|  | |
| Информатика | Языки программирования |
|  | Теория вычислительной сложности |
|  | Высокопроизводительные компьютеры |
|  | |
| Кибернетика | Теория управления сложных систем |

Рассмотрим подробнее, как развивался ИИ и почему именно эти науки оказали на него влияние.

### 2.1.1 Появление новой науки 1943 – 1956

#### 2.1.1.1 Нейронная сеть

##### 2.1.1.1.1 Искусственный нейрон

Первая исследовательская работа в области ИИ связана с нейрофизиологией и математикой. Американские учёные [Уоррен Мак-Каллок](https://ru.wikipedia.org/wiki/Мак-Каллок,_Уоррен) и [Уолтер Питтс](https://ru.wikipedia.org/wiki/Питтс,_Уолтер) исследовали мозг человека.

Уоррен Мак-Каллок был известным нейрофизиком. Он изучал медицину в Колледж врачей и хирургов Колумбийского университета в Нью-Йорке, где в 1927 году получил степень доктора медицины. После этого занимался медицинской практикой до 1937 года. После неё Мак-Каллок работал в Лаборатории нейрофизиологии Йельского университета. В 1941 году он переехал в Чикаго и поступил на кафедру психиатрии Иллинойского университета в Чикаго, где был профессором психиатрии.

Уолтер Питтс был самоучкой из бедной семьи. В 1935 году в возрасте 12 лет Питтс прочитал "Основания математики" Бертрана Рассела. Он нашел в книге несколько ошибок и написал о них автору. Благодаря этой переписке с известным английским математиком, Уолтер Питтс смог получить образование в Иллинойсском университете в Чикаго. Его специальностью была [математическая логика](https://ru.wikipedia.org/wiki/Математическая_логика).

Уоррен Мак-Каллок и Уолтер Питтс познакомились Иллинойсском университете. Они объединили свои знания и усилия, чтобы найти логические закономерности работы мозга. Так учёные разработали математическую модель связанных между собой [**искусственных нейронов**](https://ru.wikipedia.org/wiki/Искусственный_нейрон). Эта модель позднее получила название [**binary threshold neurons**](https://www.youtube.com/watch?v=iKKfoP-naN8) (бинарный пороговый нейрон).

[**Нейрон**](https://ru.wikipedia.org/wiki/Нейрон) — это клетка, которая является минимальным строительным блоком [**нервной системы**](https://ru.wikipedia.org/wiki/Нервная_система) человека. Нейроны соединяется друг с другом в [нервную сеть](https://ru.wikipedia.org/wiki/Нервная_сеть), по которой проходят электрические и химические сигналы. С помощью этих сигналов передаётся информация между узлами нервной системы.

Бинарный пороговый нейрон представляет собой упрощённую модель биологического нейрона. Эта модель имеет два состояния: возбуждённое и невозбуждённое. На вход нейрон получает сигналы от других нейронов. Он обрабатывает их с помощью [**функции активации**](https://ru.wikipedia.org/wiki/Функция_активации). Её результат передаётся на выход нейрона, который связан со входами других нейронов.

Функция активации бинарного порогового нейрона называется **ступенчатой** ([step function](https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Activation_Functions#Step_Function)). В виде формулы её можно записать следующим образом:
{width: "50%"}
![](images/ArtificialIntelligence/binary-threshold-neuron-activation-function.png)

Здесь m означает число входных сигналов нейрона. 

Иллюстрация 2-1 демонстрирует график функции активации. Значения функции f(x) отображаются на оси Y. На оси X — значения суммы входных сигналов x. Когда эта сумма достигает значения θ, нейрон переходит в возбуждённое состояние. Его выходной сигнал становится равен единице.

{caption: "Иллюстрация 2-1. Ступенчатая функция активации бинарного порогового нейрона", height: "30%"}
![Ступенчатая функция активации бинарного порогового нейрона](images/ArtificialIntelligence/binary-threshold-neuron-activation-function-graph.png)

Мак-Каллок и Питтс предложили соединить несколько искусственных нейронов так, чтобы выходные сигналы одних служили входными сигналами для других. Такое соединение получило название [**нейронная сеть**](https://ru.wikipedia.org/wiki/Нейронная_сеть).

Мак-Каллок и Питтс доказали, что нейронная сеть способна выполнять числовые и логические операции. Кроме того они предположили, что сети с особенной архитектурой способны обучаться. Свои результаты учёные опубликовали в 1943 году в статье "Логическое исчисление идей, относящихся к нервной активности" (A Logical Calculus of Ideas Immanent in Nervous Activity).

Модель Мак-Каллока и Питтса была только теоретической. Свои гипотезы они подтверждали математическими выкладками. Не существовало программы или устройства, которое бы работало как нейронная сеть и подтверждало идеи учёных на практике.

##### 2.1.1.1.2 Обучение нейронной сети

Мак-Каллок и Питтс продемонстрировали вычислительный потенциал нейронных сетей. В своей работе они представили нейронные сети как универсальные механизмы для выполнения вычислений. Но чтобы применить этот механизм для решения реальных задач, нужны были средства управления сетью. Для универсальных компьютеров такими средствами управления стали программы. Это же решение не подходило для нейронных сетей. Для них нужен был принципиально иной подход.

В 1949 году канадский нейропсихолог [Дональд Хебб](https://ru.wikipedia.org/wiki/Хебб,_Дональд) опубликовал книгу "Организация поведения: нейропсихологическая теория" (Organization of Behavior). Будучи по образованию психологом, он изучал влияние хирургии и травм головного мозга человека на его функции. Также он проводил эксперименты на животных, чтобы выяснить как обучение в детском возрасте влияет на их поведение. Результаты своих исследований и их трактовку Дональд Хебб привёл в своей книге.

Книга посвящена не искусственным нейронным сетям, а нейробиологии. На момент её написания существовало несколько теорий поведения человека: [бихевиоризм](https://ru.wikipedia.org/wiki/Бихевиоризм), [гештальтпсихология](https://ru.wikipedia.org/wiki/Гештальтпсихология) и другие. Каждая из теорий хорошо объясняла некоторые функции, но имела трудности с другими.

Дональд Хебб объединил существующие данные о поведении и мозге в единую теорию. Она основана на связях между биологическими функциями мозга как органа с высшими функциями разума.

Центральная идея книги — связь того как именно мозг обрабатывает информацию и поведения человека. Учёный ввел понятие **сборки клеток** (cell-assembly), которое означает взаимосвязанные нейроны. Он утверждал, что обучение и память основаны на формировании таких сборок клеток. Эти связанные нейроны активируются вместе в результате обучения. Именно такие сборки клеток являются основными единицами мышления и из организация определяет поведение человека.

Согласно Дональду Хеббу поведение человека определяется двумя фундаментальными процессами: физиологическими процессами мозга и переживаниями. Учёный предположил, что эти два фактора неразрывно связаны. Мозг постоянно приспосабливается к окружающей среде, образуя новые связи между нейронами.

Предложенная Дональдом Хеббом теория обучения нейронов человеческого мозга получила название [**обучение Хебба**](http://www.machinelearning.ru/wiki/index.php?title=Правило_Хэбба). Основное правило этой теории можно сформулировать в следующем виде:

*Связи нейронов, которые активируются совместно, усиливаются. Связи нейронов, которые срабатывают независимо, ослабевают*

Это утверждение известное как **правило Хебба** стало фундаментом в теории обучения искусственных нейронных сетей.

#### 2.1.1.2 Статьи Тьюринга

##### 2.1.1.2.1 Статья "Умная машинерия"

Известный английский математик и криптограф [Алан Тьюринг](https://ru.wikipedia.org/wiki/Тьюринг,_Алан) посвятил две статьи вопросу о том, возможно ли создать машину с интеллектом человеческого уровня.

Первая статья была написана в 1948 году и получила название ["Умная машинерия"](https://weightagnostic.github.io/papers/turing1948.pdf) (Intelligent Machinery). Это был отчёт Тьюринга для Национальной физической лаборатории Великобритании (National Physical Laboratory или NPL). Отчёт был засекречен и долгое время нигде не публиковался. Он стал доступен для широкой публики только спустя почти 40 лет с момента написания.

Отчёт "Умная машинерия" написан формальным языком, как и другие научные статьи Тьюринга. Он начинается с вопроса автора: "способны ли машины демонстрировать разумное поведение?". Большинство современников отвечают на него отрицательно. Поэтому учёный подробнее разбирает несколько распространённых возражений.

Далее Алан Тьюринг рассуждает о "машинерии". Так он называет существующие и гипотетические устройства, которые теоретически могли бы демонстрировать разумное поведение. Среди них:

* **Логические вычислительные машины** (logical computing machines) — например, модель абстрактного вычислителя [машина Тьюринга](https://ru.wikipedia.org/wiki/Машина_Тьюринга)

* **Реальные вычислительные машины** (practical computing machines) — например существующие на тот момент универсальные цифровые компьютеры [ENIAC](https://ru.wikipedia.org/wiki/ЭНИАК) и [ACE](https://ru.wikipedia.org/wiki/ACE).

* **Бумажные машины** (paper machine) — когда человек с бумагой и ручкой исполняет набор формальных правила для решения поставленной задачи.

* **Частично случайные машины** (partially random machines) — это гипотетические компьютеры, в которых могу выполнятся несколько альтернативных операций одновременно. Некоторый случайный процесс выбирает один из результатов этих операций в качестве окончательного.

* **Неорганизованные машины** (unorganized machines) — машины собранные из неких стандартных компонентов, конструкция которых изначально не предполагает конкретной цели.

Рассмотрев все возможные типы машин, Алан Тьюринг фокусируется на неорганизованные машинах и способах их применения. Он предлагает некоторый процесс обучения,  который меняет состояние неорганизованной машины. В результате такая машина становится пригодной для решения конкретных задач.

В своих рассуждения автор неоднократно проводит параллели между неорганизованной машиной и корой головного мозга человека. Так же он сравнивает процессы обучения машины и человека. Между ними Алан Тьюринг находит аналогии.

В конце статьи учёный говорит о двух путях к созданию машины, демонстрирующей разумное поведение. Первый путь автор называет "прямым методом" (direct method). Он заключается в программировании реальной вычислительной машины. Тогда поведение машины станет логичным результатом следования небольшому набору общих принципов. Второй путь — это обучение неорганизованной машины. Именно этим двум направлениям следовало развитие ИИ в будущем.

В последнем разделе отчёта Алан Тьюринг размышляет о критерии разумного поведения. Он предлагает некий тест, в котором участвует три человека:

1. Шахматист A.
2. Шахматист С.
3. Оператор B, работающий на бумажной машине.

Участники теста должны сыграть друг с другом в шахматы, находясь в разных комнатах. В результате игры участник C должен определить, кто из оппонентов шахматист A, а кто оператор B.

В отчёте "Умная машинерия" Алан Тьюринг впервые упомянул о возможности применить процесс обучение к машинам особого типа. На практике эта идея была реализована исследователями только спустя десять лет.

##### 2.1.1.2.2 Статья "Вычислительные машины и разум"

Спустя два года в 1950 году Алан Тьюринг написал вторую статью с названием ["Вычислительные машины и разум"](https://ru.wikipedia.org/wiki/Вычислительные_машины_и_разум) (Computing Machinery and Intelligence). Она была опубликована в английском журнале Mind в 1950 году. Этот журнал издаётся небольшим тиражом Оксфордским университетом и посвящён психологии и философии.

Статья Тьюринга стала широко известна в 1956 потому, что попала в сборник математической литературы "Мир Математики" (The Worlds of Mathematics), составленный Джеймсом Ньюменом. В этом же году появился термин "искусственный интеллект". Возможно, авторитет Тьюринга и это совпадение возвело статью в культ.

В своей статье учёный неформальным языком пересказывает свои мысли из засекреченного отчёта "Умная машинерия". В отчёте основной упор был сделан на устройство и свойства различных машин, а также рассуждение о возможности их обучения. В статья же носит более философский характер.

Учёный начинает с определения терминов "машина" и "думать". По его мнению любое однозначное определение вызовет критику. Поэтому автор достаточно вольно подменяет вопрос "может ли машина думать?" на "может ли машина имитировать разумное поведение"?

Для объективной оценки возможностей машины Тьюринг предлагает игру в имитацию. Это продолжение идеи шахматного эксперимента, который описан в конце отчёта "Умная машинерия". Суть игры в том, что человек и машина обмениваются с судьёй текстовыми сообщениями. Все три участника игры находятся в разных комнатах и не видят друг друга. В результате переписки судья должен определить, кто из собеседников является машиной. Если судья не может это сделать, машина выигрывает. Игра в имитацию получила известность как [**тест Тьюринга**](https://ru.wikipedia.org/wiki/Тест_Тьюринга). Автор утверждает, что прошедшая такой тест машина должна считаться разумной в том же смысле, что и человек.

Далее Тьюринг рассматривает объекты, которые можно отнести к категории "машина". Он предлагает ограничиться только **цифровыми компьютерами**, которые оперируют числами 0 и 1. Также эти компьютеры должны быть универсальны в том смысле, что с помощью программирования их можно настроить на решение любой задачи. Возможно, из соображений секретности Тьюринг даёт крайне общее описание машин такого типа, хотя он сам принимал участие в их создании.

После определения терминов Тьюринг рассматривает девять возражений против идеи о том, что машины могут мыслить. Эту же тему он поднимал в отчёте, но на этот раз останавливается на ней подробнее. Среди возражений есть теологическое о том, что машины не могут обладать духовными качествами и сознанием. Так же — математическое о том, что машины ограничены формальными правилами и не могут выйти за их пределы. Рассмотрев все аргументы против, Тьюринг утверждает, что все они основаны на предвзятых представлениях. Они не дают окончательных доказательств невозможности машинного интеллекта в принципе.

В заключительной части статьи Тьюринг положительно оценивает возможность машины пройти игру в имитацию. Он предлагает модель обучающейся машины, которая была бы на это способна. Опять же это неформальный пересказ идей из отчёта "Умная машинерия". Тьюринг простыми словами описывает базовые принципы машинного обучения и генетических алгоритмов. Эти идеи намного опередили своё время. Намного позднее исследователи ИИ стали применять их на практике.

Статья Тьюринга оказала огромное влияние на ранних исследователей в области искусственного интеллекта. Она предложила им простую цель, достижение которой означает создание разумной машины. Многие учёные последовали этому направлению. Но были и те, кто критиковал идеи Тьюринга.

Сегодня есть мнение, что статья Тьюринга была мистификацией или даже розыгрышем. Его сторонники указывают на шутливый тон автора и отсутствие строгих математических выкладок, характерных для других работ учёного.

Более правдоподобным кажется мнение, что автор задумывал статью как попытку спровоцировать широкую дискуссию о разумности машин. И ему это удалось: статья вызывала горячие споры на протяжении последующих десятилетий. Не имея возможности опубликовать секретный отчёт, Алан Тьюринг был вынужден завуалированно пересказать его содержимое. В то же время более неформальная подача сделал мысли автора доступными для учёных нематематиков. Учёные из смежных областей тоже приняли участие в дискуссиях на тему ИИ и внесли свой вклад в развитие этой области.

Так или иначе на сегодняшний день несколько интеллектуальных систем успешно прошли тест Тьюринга. Однако, никто не считает их разумными в каком-либо смысле этого слова. Поэтому современные исследователи отказались как от самого теста в качестве критерия оценки, так и от идеи машины, способной мыслить как человек. Но высказанные Тьюрингом идеи машинного обучения успешно применяются в большинстве современных ИИ систем.

#### 2.1.1.3 Logic Theorist

Первую ИИ систему в виде компьютерной программы разработала группа американских учёных в 1956 году. Эта система получила название [Logic Theorist](https://en.wikipedia.org/wiki/Logic_Theorist). 

Все разработчики Logic Theorist были сотрудниками корпорации [RAND](https://ru.wikipedia.org/wiki/RAND_(корпорация)), которая с 1948 года занималась стратегическими исследованиями для правительства США. Авторами системы были:

* [Герберт Саймон](https://ru.wikipedia.org/wiki/Саймон,_Герберт_Александер) занимался экономикой, социальной и политической науками. Одна из его работа посвящена принятию решений в правительственных учреждениях и компаниях. В своих исследованиях он использовал методы теории принятия решений.

* [Аллен Ньюэлл](https://ru.wikipedia.org/wiki/Ньюэлл,_Аллен) учёный в области логистики и [теории организаций](https://ru.wikipedia.org/wiki/Теория_организаций). Это теория из области социологии, которая исследует взаимодействия людей в политических и коммерческих организациях.

* [Клиффорд Шоу](https://en.wikipedia.org/wiki/Cliff_Shaw) — опытный программист корпорации RAND, который реализовал замыслы Саймона и Ньюэлла.

Первоначальную идею системы разработал Ньюэлл. Он предположил, что простое программируемое устройство вроде компьютера способно на сложное поведение. Чтобы доказать эту гипотезу Ньюэлл и Саймон решили разработать программу для [**доказательства математических теорем**](https://en.wikipedia.org/wiki/Automated_theorem_proving) (automated theorem proving). Тогда к проекту присоединился Шоу, чтобы помочь программированием.

Система Logic Theorist смогла доказать 38 теорем из книги ["Начала математики"](https://ru.wikipedia.org/wiki/Principia_Mathematica) Бертрана Рассела. Учёные рассматривали это как подтверждение гипотезы Ньюэлла. По их мнению универсальный компьютер, доказывающий математические теоремы, демонстрирует способность к разумному поведению.

В середине 1950-х годов считалось, что цифровые компьютеры способны оперировать только числами. Вопреки этому мнению система Logic Theorist работала с символами. Это позволило перейти от математических вычислений к логическим высказываниям. Разработчики утверждали, что создали программу, способную мыслить в нечисловых терминах. Этот подход стал доминирующим в области ИИ на следующие 30 лет.

В Logic Theorist впервые были использованы следующие концепций:

* **Рассуждение как поиск**. Logic Theorist представляет доказательство гипотезы как поиск по дереву. Корень дерева соответствует начальной гипотезе. Исходящие из корня ветви — это логические операции над начальной гипотезой. Каждая ветвь приводит к определённому выводу. Один из этих выводов является целью рассуждения. Именно его и ищет система.

* [**Эвристики**](https://ru.wikipedia.org/wiki/Эвристика) — это дополнительные правила, которые исключают из рассмотрения некоторые ветви дерева поиска. Эвристики позволяют заранее предсказать, что какая-то ветвь не приводит к решению. Это значительно сокращает время поиска решений.

* **Обработка списков**. Чтобы написать программу Logic Theorist, был разработан специальный язык программирования [IPL](https://en.wikipedia.org/wiki/Information_Processing_Language). Для него Шоу впервые применил специальную структур данных под названием [**связанный список**](https://ru.wikipedia.org/wiki/Связный_список). Она позволяла эффективно хранить список символов. Позднее на основе IPL и списков Джон Маккарти разработает язык Lisp. Этот язык станет доминирующим в области ИИ на два десятилетия.

В ходе разработки Logic Theorist были предложены новаторские идеи, которые стали ключевыми для последующих исследований в области ИИ.

#### 2.1.1.4 Дартмутский семинар

В начале 1950-х годов различные учёные проводили первые работы в области искусственного интеллекта. Однако, самого этого термина не существовало до лета 1956 года. Ранние исследования "думающих машин" называли кибернетикой, теорией автоматов или сложной обработкой информации. Название зависело от подхода, выбранного в каждом конкретном проекте.

В 1955 году американский математик Джон Маккарти решил организовать [семинар](https://ru.wikipedia.org/wiki/Дартмутский_семинар), посвященный "думающим машинам". Он хотел собрать группу исследователей в этой области, чтобы обсудить их достижения и возможные новые подходы. На тот момент Маккарти работал в Дартмутском колледже в Хановере (штат Нью-Гэмпшир). Поэтому в дальнейшем это мероприятие стало известно как **Дартмутский семинар**.

В ходе организации семинара и поиска средств для его проведения к Джону Маккарти присоединились Клод Шеннон, Марвин Мински и Натаниэль Рочестер. Спонсором мероприятия стал благотворительный фонд Рокфеллера (Rockefeller Foundation).

[Заявка на проведение семинара](http://raysolomonoff.com/dartmouth/boxa/dart564props.pdf) начиналась так:

*Мы предлагаем провести двухмесячное исследование искусственного интеллекта с участием 10 человек летом 1956 года в Дартмутском колледже в Хановере, штат Нью-Гэмпшир. Исследование основано на предположении, что каждый аспект обучения или любое другое свойство интеллекта можно в принципе описать столь точно, что возможно создать машину, которая сможет его симулировать. Мы попытаемся понять, как заставить машины использовать язык, формировать абстракции и концепции, решать задачи, доступные сейчас только людям, и улучшать самих себя.  Мы считаем, что существенное продвижение в одной или более из этих проблем вполне возможно, если специально подобранная группа учёных будет работать над ними в течение лета.*

Далее документ предлагает следующие темы для обсуждения на семинаре:

1. Компьютеры и их возможности.
2. Обработка естественного языка.
3. Искусственные нейронные сети.
4. Теория вычислений.
5. Самосовершенствование машин.
6. Формирование абстракций машиной.
7. Случайность и творчество в работе машин.

Именно заявка на проведение семинара стала первым официальным документом, в котором употребляется термин "искусственный интеллект". До этого его никто нигде не использовал. Организаторы придумали новый термин, чтобы предотвратить возможные споры относительно подходов. Если бы они выбрали любое уже существующее название научной области, это сфокусировало бы обсуждения только на конкретном подходе. Цель же семинара была в [мозговом штурме](https://ru.wikipedia.org/wiki/Метод_мозгового_штурма), т.е. в разработке совершенно новых идей.

В семинаре принимали участие ведущие учёные из следующих областей:

* Теория управления
* Теория автоматов
* Нейрофизиология
* Теорией игр
* Когнитивная психология.

Самыми обсуждаемыми темами на семинаре стали: обработка естественных языков, ориентированные на прикладные области системы (ранние экспертные системы), дедуктивные и индуктивные системы логического вывода. Искусственные нейронные сети и машинное обучение не получили должного внимания.

Темы затронутые на семинаре было решено объединить в единое научное направление под названием "искусственный интеллект". Это решение оказало огромное влияние на последующие исследования. Во-первых доминирующими направлениями стали именно те, которые активно обсуждались на семинаре. Во-вторых, учёные получили возможность свободно экспериментировать и искать новые подходы к построению интеллектуальных машин. Их больше не ограничивали аналоговые вычисления кибернетики и математический аппарат теории автоматов. Новое научное направление началось как экспериментальная дисциплина.

### 2.1.2 Формирование основных направлений в ИИ 1956 – 1974

Дартмутский семинар дал мощный толчок для исследований в области ИИ. Этому поспособствовало то, что участники семинара смогли найти поддержку в правительственных кругах и привлечь колоссальные средства для своей работы.

Выделенные средства пошли на создание лабораторий на базе известных учебных заведений. Их основателями стали некоторые из участников семинара. Они перечислены в таблице 2-2. Эти лаборатории специализировались на исследованиях в области вычислительной техники и ИИ.

{caption: "Таблица 2-2. Лаборатории по исследованию ИИ", width: "100%"}
| Учебное заведение | Основатели лаборатории ИИ |
| --- | --- |
| [Университет Карнеги — Меллона](https://ru.wikipedia.org/wiki/Университет_Карнеги_—_Меллона) | Аллен Ньюэлл и Герберт Саймон |
|  | |
| [Стэнфордский университет](https://ru.wikipedia.org/wiki/Стэнфордский_университет) | Джон Маккарти |
|  | |
| [Массачусетский](https://ru.wikipedia.org/wiki/Массачусетский_технологический_институт) |  Марвин Минский |
| технологический институт (МТИ) | Джон Маккарти (впоследствии покинул МТИ) |

Каждая из лабораторий разрабатывала собственные подходы в создании интеллектуальных систем. Некоторые из них задали направления для дальнейших исследований. Таблица 2-3 демонстрирует эти направления.

{caption: "Таблица 2-3. Направления в ИИ", width: "100%"}
| Название | Идея | Основоположники |
| --- | --- | --- |
| [Символьный](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | Задача решается | Аллен Ньюэлл |
| [подход](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | через действия над понятными человеку символическими обозначениями. | Герберт Саймон |
|  | | |
| [Логическое программирование](https://ru.wikipedia.org/wiki/Логическое_программирование) | Задача решается методами формальной логики. | Джон Маккарти |
|  | | |
| [Коннекционизм](https://ru.wikipedia.org/wiki/Коннекционизм) | Задача решается | Уоррен Мак-Каллок |
| | сетью из связанных между собой простых элементов (нейронной сетью). | Уолтер Питтс |

Эти направления сформировались в начальный период развития области ИИ в конце 1950-х годов. Их популярность менялась в зависимости от успехов и неудач в исследованиях. Сегодня самым многообещающим подходом считается коннекционизм.

Рассмотрим подробнее достижения каждого из направлений ИИ.

#### 2.1.2.1 Символьный подход

Система Logic Theorist произвела впечатление на участников Дартмутского семинара. Среди всех представленных идей и проектов, Logic Theorist была единственным работающим решением. Остальные исследования находились только на этапе теоретических моделей.

Следующим проектом Ньюэлла, Саймона и Шоу стала универсальная система для решения задач. Она получила название [General Problem Solver](https://ru.wikipedia.org/wiki/Универсальный_решатель_задач) (GPS). В отличие от Logic Theorist её область применения не ограничивалась математическими задачами. Вместо этого GPS моделировала процесс решения задач человеком.

Система GPS была готова в 1959 году. В своей работе она использовала особенную технику поиска под названием [**анализ средств и результатов**]((https://en.wikipedia.org/wiki/Means–ends_analysis)) (means–ends analysis или MEA). Эта техника стала развитием идеи "рассуждение как поиск", впервые реализованной в Logic Theorist.

Алгоритм анализа средств и результатов выглядит так:

1. Система оценивает своё текущее состояние. Если поставлена задача, необходимы действия для её решения.

2. Определяется конечная цель. Она выражается в некотором состоянии системы, которое надо достигнуть. Достижение этого состояние означает решение поставленной задачи.

3. Конечная цель делится на составные части, называемые подцелями. Если подцели остаются сложными, они так же делятся на составные части.

4. Составляется список действий, выполнение которых приведёт к конечной цели, т.е. решению задачи.

5. Каждая из подцелей связывается с соответствующим ей действием из списка.

6. Выполняются все действия из списка.

7. Сравнение полученного состояния системы с тем, которое надо достигнуть для решения поставленной задачи. Если эти состояния отличаются, алгоритм повторяется начиная со второго шага.

Система GPS доказывала теоремы [евклидовой геометрии](https://ru.wikipedia.org/wiki/Евклидова_геометрия) и логики предикатов. Также она решала шахматные задачи.

Основываясь на опыте разработки и применения системы GPS, Ньюэлл и Саймон сформулировали [**гипотезу о физической символьной системе**](https://ru.wikipedia.org/wiki/Гипотеза_Ньюэлла_—_Саймона) в 1976 году. Эта гипотеза звучит так:

*Физическая символьная система обладает необходимыми и достаточными средствами для разумного поведения.*

Эта гипотеза обосновывается примерно следующим образом. Без символьной системы невозможно разумное поведение. Следовательно, мышление человека основано на символьной системе и заключается в манипулировании символами. Универсальный компьютер также может манипулировать символами. Следовательно, он теоретически способен на разумное поведение.

Исследования и идеи Ньюэлла и Саймона заложили основу **символьного подхода**. Этот подход предлагает создавать системы, работа которых основана на манипулировании символами. Эти символы могут быть абстрактными, но должны быть понятны человеку. Сама система должна программироваться вручную как и любая другая компьютерная программа. Это именно тот самый "прямой метод" (direct method) создания "думающих машин", о котором писал Алан Тьюринг в свой статье "Умная машинерия".

Символьный подход оставался доминирующей парадигмой в области ИИ с середины 1950-х до конца 1980-х годов.

#### 2.1.2.2 Логическое программирование

В 1958 году Маккарти разработал модель системы под названием [Advice Taker](https://en.wikipedia.org/wiki/Advice_taker). Он описал её принципы работы в статье "Программы со здравым смыслом" (["Programs with Common Sense"](http://www-formal.stanford.edu/jmc/mcc59.pdf)). Принцип работы этой системы был очень похож на Logic Theorist. Она также работала с набором логических высказываний и осуществляла по ним поиск для вывода результатов.

Согласно идее Маккарти, Advice Taker должна была получать от пользователя информацию в форме логических утверждений на некотором формальном языке. Затем система использовала полученную информацию для решения сложных задач путём логических рассуждений.

Маккарти предполагал, что система будет универсальной, если сообщить ей достаточно общей информации об окружающем мире. Благодаря этому, Advice Taker смог бы самостоятельно делать выводы обо всём, что ему сообщают и что он уже знает. Тогда можно было бы утверждать, что система рассуждает с позиции [здравого смысла](https://ru.wikipedia.org/wiki/Здравый_смысл).

В отличие от Ньюэлла и Саймона, Маккарти делал ставку не на продвинутые алгоритмы поиска по множеству высказываний, а на применение [**формальной**](https://ru.wikipedia.org/wiki/Формальная_логика) и [**математической**](https://ru.wikipedia.org/wiki/Математическая_логика) логики. По его мнению такой подход позволил бы моделировать системы ИИ и формально доказывать их работоспособность.

I> Формальная логика — раздел логики, в котором применяется формальный язык и строгие правила операций над высказываниями. Математическая логика — это направление формальной логики, в которой активно применяется математический аппарат.

Для Advice Taker Маккарти предложил новый способ представления знаний. Система Logic Theorist хранила все знания и эвристики в коде самой программы. Из-за этого редактировать логические высказывания было сложно. Чтобы добавить новое утверждение или исправить существующее, приходилось исправлять программный код на языке IPL.

В системе Advice Taker знания и механизм рассуждений чётко разделялись. Знания хранились в виде правил на некотором формальном языке. Правила помещались в списки. Благодаря этому, редактировать высказывания становилось проще: для этого больше не требовались навыки программирования. Сам логический вывод по прежнему требовал поиска по спискам, как и в Logic Theorist. Однако, Маккарти искал возможность вынести алгоритм поиска из кода ИИ системы в механизм языка программирования. Такой подход значительно упростил бы создание специализированных ИИ систем.

В качестве первого шага для реализации Advice Taker, Маккарти разработал язык программирования LISt Processing более известный как [Lisp](https://ru.wikipedia.org/wiki/Лисп). Учёный описал Lisp в статье для журнала Communications of the ACM в 1960 году. Первый работающий интерпретатор языка появился в 1958 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704).

Некоторые идеи языка Lisp Маккарти высказал ещё в статье "Программы со здравым смыслом". В ней он рассуждал над преимуществами **декларативных** и **императивных** инструкций. Декларативные инструкции описывают свойства результата, который должна выдать программа. Императивные — задают чёткий алгоритм вычисления результата. Маккарти утверждал, что декларативные инструкции лучше подходят для разработки ИИ систем и упрощают работу с логическими правилами.

Центральной идеей Lisp стала работа с выражениями. В отличие от большинства других языков того времени Lisp не делал различий между выражениями и инструкциями: и то и другое записывается как выражение. Эти выражения представляются в виде списков, заключенные в круглые скобки.

Первоначально Lisp задумывался как чисто декларативный язык. Но в процессе его реализации Маккарти добавил такие конструкции императивного языка как циклы и изменяемые переменные. Благодаря этому, Lisp стал универсальным языком, пригодным для широкого спектра задач и вне ИИ области. Его применяли и продолжают применять в различных прикладных областях.

Lisp оказал влияние на последующие специализированные языки программирования. Одним из них стал [Prolog](https://ru.wikipedia.org/wiki/Пролог_(язык_программирования)). Его разработал французский учёный Ален Колмероэ в 1972 году.

В отличие от Lisp, Prolog — это чисто декларативный язык, основанный на математической логике. Программы на нём представляют собой наборы логических утверждений и правил вывода. Prolog стал первым и самым известным языком логического программирования. Исследователи ИИ долгое время сохраняли к нему интерес.

Система Advice Taker так никогда и не была реализована. Она была полезна как модель типичной ИИ системы, которая
помогла Маккарти лучше понять нужды разработчиков. Опираясь на это понимание, он разработал язык, который несколько десятилетий был востребован исследователями ИИ.

#### 2.1.2.3 Коннекционизм

Модель нейронной сети Мак-Каллока — Питтса и теория обучения Хебба заложили основу **коннекционизма**. Коннекционизм — это направление [когнитивной науки](https://ru.wikipedia.org/wiki/Когнитивистика), которое моделирует и исследует психические явления с помощью искусственных нейронных сетей.

После исследований Хебба следующим значительным шагом в развитии коннекционизма стала модель под названием **перцептрон**.

##### 2.1.2.3.1 Перцептрон

В середине 1950-х годов американский психолог и нейрофизиолог [Фрэнк Розенблатт](https://ru.wikipedia.org/wiki/Розенблатт,_Фрэнк) изучал организацию памяти в биологических системах. Скоро он пришел к выводу, что механизм памяти неразрывно связан с процессом восприятия. Тогда учёный сменил направление исследований и начал изучать этот процесс.

В конце 1950-х годов Розенблатт представил результат своей работы в виде модели того, как мозг человека воспринимает информацию. Эта модель получила название [**перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон). Позднее модели такого типы стали называться [**binary classifier**](https://www.youtube.com/watch?v=mI6jTc-8sUY) (бинарный классификатор).

Термин "перцептрон" нередко вызывает путаницу. Причина в том, что его применяют для обозначения следующих разных понятий:

1. Алгоритм обучения с учителем для бинарных классификаторов (алгоритмы обучения мы рассмотрим далее).

2. Модель отдельного нейрона.

3. Модель однослойной нейронной сети.

4. Модель многослойной нейронной сети.

Для начала рассмотрим модель отдельного нейрона под названием перцептрон. Такой нейрон получает на вход несколько сигналов. Каждый входной сигнал имеет **вес**. Вес — это вещественное число, которое пропорционально важности сигнала: чем важнее сигнал, тем больше вес и наоборот. Вес нужен для расчёта **взвешенной суммы входных сигналов** (Y) по следующей формуле:
{width: "50%"}
![](images/ArtificialIntelligence/perceptron-dot-product.png)

В этой формуле m означает число входных сигналов перцептрона. 

В некоторых случаях к взвешенной сумме входных сигналов прибавляют некоторую константу. Она называется **смещением** (bias). Благодаря смещению, результат функции активации смещается в область положительных или отрицательных значений. Таким образом решаются некоторые проблемы при обучении сетей.

Обозначим смещение буквой b. Тогда функцию активации перцептрона можно записать так:
{width: "50%"}
![](images/ArtificialIntelligence/perceptron-activation-function.png)

Здесь f(x) означает функцию активации. Она принимает значение 1, если взвешенная сумма входных сигналов плюс смещение больше нуля. В противном случае, функция активации равна 0. Величина выходного сигнала перцептрона совпадает со значением его функции активации.

Первоначально Розенблатт использовал в функцию Хевисайда в качестве функции активации для перцептрона. Иллюстрация 2-2 демонстрирует её график. Её поведение похоже на ступенчатую функцию активации бинарного порогового нейрона.

{caption: "Иллюстрация 2-2. Функция Хевисайда", height: "30%"}
![Функция Хевисайда](images/ArtificialIntelligence/heaviside-step-function.png)

Чтобы лучше понять особенности модели нейрона под названием перцептрон, сравним её с более ранней моделью Мак-Каллок и Питтса (бинарный пороговый нейрон). Вот их ключевые различия:

1. Бинарный пороговый нейрон получает на вход сигналы, которые представляются двоичными числами (0 или 1). Входные сигналы перцептрона представляются вещественными числами.

2. В отличие от бинарного порогового нейрона, каждый входной сигнал перцептрона имеет вес.

3. Функция активации бинарного порогового нейрона получает на вход сумму всех входных сигналов. Функция активации перцептрона получает взвешенную сумму входных сигналов.

4. Модель Мак-Каллок и Питтса не предусматривает никакого алгоритма обучения. В отличие от неё перцептрон может обучаться. Его процесс обучения заключается в автоматическом подборе значений весов для каждого входного сигнала. Для разработки методов обучения перцептрона Розенблатт применил теорию Хебба.

5. Модель Мак-Каллок и Питтса была только теоретической. Она не решала никакую практическую задачу. Перцептрон разрабатывался как инструмент для [**распознавания образов**](https://en.wikipedia.org/wiki/Pattern_recognition) (Pattern recognition).

Теперь рассмотрим модель [однослойной нейронной сети под названием перцептрон](https://en.wikipedia.org/wiki/Feedforward_neural_network#Single-layer_perceptron). Впоследствии этот класс моделей стал называться [**нейронные сети с прямой связью**](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью) (feedforward neural network или FNN). Чтобы проверить свои идеи на практике, Розенблатт применил модель нейрона для распознавания образов. Для решения этой задачи отдельному нейрону не хватало вычислительных возможностей. Переход к нейронной сети увеличил вычислительную мощность модели.

Предложенная Розенблаттом нейронная сеть, представляла собой параллельно подключенные нейроны перцептроны. В 1957 году Розенблатт смоделировал работу такой сети в виде программы для универсального компьютера IBM 704. Годом позже учёный сконструировал первый [нейрокомпьютер](https://ru.wikipedia.org/wiki/Нейрокомпьютер) под названием [Mark I Perceptron](https://ru.wikipedia.org/wiki/Марк-1). 

Mark I представлял собой однослойную нейронную сеть, работающую по принципу перцептрона. Компьютер работал на аналоговых компонентах. Входное изображение поступало на матрицу из фотодетекторов размером 20x20. Сигналы с неё передавались на отдельные "нейроны". Чтобы регулировать веса входных сигналов, применялись потенциометры. Их настройки менялись в процессе обучения с помощью электромоторов. 

Mark I должен был распознавать буквы английского алфавита. Финальная версия компьютера научилась распознавать только некоторые буквы.

Работа с компьютером была очень трудоемкой. Его компоненты были ненадежны и часто выходили из строя. Чтобы поддерживать Mark I в рабочем состоянии, требовалось постоянное вмешательство оператора и замена выходящих из строя компонентов.

Иллюстрация 2-3 демонстрирует архитектуру однослойной нейронной сети под названием перцептрон.

{caption: "Иллюстрация 2-3. Архитектура нейронной сети под названием перцептрон", height: "30%"}
![Архитектура нейронной сети перцептрон](images/ArtificialIntelligence/perceptron.png)

Сеть состоит из трёх типов элементов:

1. S-элементы (сенсорные)
2. A-элементы (ассоциативные)
3. R-элементы (реагирующие)

I> Несмотря на три слоя элементов, перцептрон на иллюстрации 2-3 называется однослойным. Причина в том, что у него только один **скрытый слой** A-элементов. Скрытыми называются слои, не содержащие входных и выходных нейронов.

Перцептрон создаёт набор ассоциаций (A-элементы) между входными сигналами (S-элементы) и реакцией на них (R-элементы).

Можно провести аналогию между работой сети и мозгом. Пример обработки сигнала мозгом — реакция человека на зрительную информацию. Если человек видит опасность, физиологическим ответом на неё будет активация [двигательных нейронов](https://ru.wikipedia.org/wiki/Мотонейрон). Эти нейроны отвечают за мышечную активность. Похожим образом перцептрон обрабатывает входные сигналы: реагирующие нейроны R возбуждаются в ответ на импульсы сенсорных нейронов S, согласно ассоциациям A.

Первоначальная модель нейронной сети имела только один R-элемент. Из-за этого она могла различать только два класса объектов. Отсюда и название модели: бинарный классификатор (т.е. два класса). В более поздних моделях Розенблатт экспериментировал с несколькими R-элементами. Так ему удалось добиться распознавания нескольких классов.

В конце 1950-х годов ещё не существовало общепринятой терминологии нейронных сетей. Розенблатт вводил новые понятия, которые позднее вышли из употребления. Это приводит к ошибкам при обсуждении идей учёного сегодня.

В 1962 году Розенблатт опубликовал книгу "Принципы нейродинамики" (Principles of Neurodynamics). В ней учёный рассматривает различные архитектуры перцептронов, в том числе и многослойные. Также в книге доказана [теорема сходимости перцептрона](https://ru.wikipedia.org/wiki/Теорема_сходимости_перцептрона). Согласно теореме, перцептрон можно обучить за конечное число шагов. После такого обучения он сможет решить поставленную задачу.

Книга "Принципы нейродинамики" оказала большое влияние на развитие коннекционизма. Теорема сходимости перцептрона и её выводы позволили сформулировать требования к архитектурам нейронных сетей и методам их обучения.

#### 2.1.2.4 Экспериментальный подход

Исследователи из лаборатории ИИ Массачусетского технологического института следовали подходу, который в 1970-е годы получил название [**scruffy**](https://en.wikipedia.org/wiki/Neats_and_scruffies) или "неряшливый". Его также можно назвать "экспериментальным". Идея подхода в разработке прототипов ИИ систем для небольших задач из разных областей. Затем полученные системы должны комбинироваться и совершенствоваться. Так исследователи надеялись прийти к решению реальных сложных задачи.

Противоположный подход получил название **neat**. Дословно переводится как "аккуратный". Его идею хорошо передаёт слово "теоретический". Этот подход предлагает использовать [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы), основанные на математике и логике. Таким образом получается более надёжный и научно обоснованный результат. Этого подхода придерживались исследователи из университетов Карнеги — Меллона и Стэнфордского.

В первые годы развития ИИ экспериментальный подход казался весьма плодотворным. Исследователи из МТИ разработали и продемонстрировали ряд систем для решения прикладных задач. Эти системы произвели большое впечатление на научные и политические круги, а также на инвесторов. Рассмотрим самые известные из этих разработок.

##### 2.1.2.4.1 Обработка естественного языка

Первой системой обработки естественного языка считается программа [STUDENT](https://en.wikipedia.org/wiki/STUDENT_(computer_program)). Её написал Даниэль Бобров в рамках свой докторской работы в 1964 году. Его научным руководителем был Марвин Минский.

Программа STUDENT читала и решала задачи из школьного учебника по алгебре. На вход она получала описание задачи на английском языке. На выходе система печатала решение в виде числа.

Для анализа текста STUDENT использовала запрограммированные правила и логический вывод. Функции машинного обучения у системы не было.

Другой системой обработки естественного языка была [ELIZA](https://ru.wikipedia.org/wiki/Элиза_(программа)). Её разработал профессор МТИ [Джозеф Вейценбаум](https://ru.wikipedia.org/wiki/Вейценбаум,_Джозеф) в 1966 году.

ELIZA представляет собой [виртуального собеседника](https://ru.wikipedia.org/wiki/Виртуальный_собеседник). Она обменивается с пользователем сообщениями. Направление разговора задаётся специальными сценариями. Самым популярным сценарием разговора был DOCTOR. Согласно ему, программа парадировала психотерапевта и строила вопросы на основе прошлых сообщений от пользователя.

ELIZA не понимала суть разговора. Она находила во входной фразе ключевые слова и подставляла их в шаблонные фразы. Эти фразы и были ответами системы. Для поиска ключевых слов программа использовала закодированные вручную синтаксические правила построения предложений.

ELIZA считается первой реальной программой, которая пыталась пройти тест Тьюринга.

##### 2.1.2.4.2 Микромиры

В конце 1960-х годов Марвин Минский и Сеймур Пейперт предложили сфокусировать исследования ИИ на упрощённых проблемных областях. Такие области получили название **микромиры**. Минский и Пейперт утверждали, что полученные системы ИИ смогут работать и для реальных задач.

Студенты МТИ выбирали для себя какой-то "микромир" и разрабатывали для него ИИ систему в качестве дипломной работы. Наибольшей популярностью у студентов пользовался [мир блоков](https://en.wikipedia.org/wiki/Blocks_world). Он представлял собой плоскую поверхность (table), на которой можно было размещать объекты. Изначально эти объекты находятся в коробке (box). Сами объекты представляют собой геометрические фигуры различных цветов, размеров и форм (шары, конусы, кубы и т.д).

Самым известным проектом для мира блоков была программа [SHRDLU](https://ru.wikipedia.org/wiki/SHRDLU). Её разработал [Терри Виноград](https://ru.wikipedia.org/wiki/Виноград,_Терри) в 1970 году. Программа работала на компьютере DEC PDP-6 с графическим терминалом. Терминал отрисовывал полную 3D картину текущего состояния мира блоков.

Программа представляла собой текстовый интерфейс для работы с миром блоков. Пользователь вводил команды на английском языке. SHRDLU понимал следующие типы команд:

1. Указание к действию. Например: "положи красный шар на синий блок".

2. Вопрос о состоянии мира блоков. Например: "сколько объектов находится на плоскости?".

3. Вопрос о выполненных ранее командах. Например: "перемещался ли красный куб?".

4. Вопрос о возможности выполнения действия. Например: "можно ли поставить красную пирамиду на синий куб?"

Программа вела себя так, будто понимала что имеет в виду пользователь. Это понимание достигалось благодаря простоте мира блоков. Для его полного описания хватало порядка 50 слов: существительных (названия объектов), глаголов (описание действий) и прилагательных (описание объектов). Комбинации этих слов были элементарны. Простые правила синтаксического разбора, закодированные в программе, хорошо справлялись с такими предложениями.

Кроме правил синтаксического разбора, у программы была память для сохранения выполненных действий. Это позволяло SHRDLU отслеживать состояние мира блоков. Также программа имела простейшие правила физики твёрдых тел. Благодаря правилам, SHRDLU делала выводы о выполнимости команд пользователя.

В лаборатории МТИ разрабатывали не только программы для мира блоков, но и роботов. Было создано несколько версий руки-манипулятора для передвижения блоков:

* [Робот MH-1](https://www.csail.mit.edu/node/6674) был разработан Генри Эрнстом в 1961 году. Роботом [подключался к компьютеру TX-0](https://www.semanticscholar.org/paper/MH-1%2C-a-computer-operated-mechanical-hand-Ernst/06600e1ca9451d81e89d078a924184683ace9196). Через него пользователь давал команды для исполнения. MH-1 пытался выполнить введённую команду. Для обратной связи у него было несколько датчиков. MH-1 служил прототипом для изучения автономной работы подобных механизмов. Его демонстрирует иллюстрация 2-4.

* [Робот Минский-Беннета](https://cyberneticzoo.com/underwater-robotics/1968-minsky-bennett-arm-marvin-minsky-and-bill-bennett-american/) был разработан Марвином Минский и Вильямом Беннетом в 1968 году. Он [управлялся с помощью джойстика и компьютера DEC PDP-6](https://commodorez.tumblr.com/post/710801395944767488).

* Робот ["Серебряная рука"](https://www.computerhistory.org/timeline/1974/#169ebbe2ad45559efbc6eb35720d99bc) (Silver Arm) был разработан [Дэвидом Сильвером](https://en.wikipedia.org/wiki/David_Silver_(roboticist)), в 1974 году. Робот мог работать с мелкими деталями благодаря датчикам прикосновения и давления. Его демонстрирует иллюстрация 2-5.

{caption: "Иллюстрация 2-4. Рука-манипулятор MH-1", height: "40%"}
![Рука-манипулятор MH-1](images/ArtificialIntelligence/mh-1-arm-robot.jpg)

{caption: "Иллюстрация 2-5. Робот Серебряная рука", height: "60%"}
![Робот Серебряная рука](images/ArtificialIntelligence/the-silver-arm.jpeg)

### 2.1.3 Первая зима ИИ 1974 – 1980

Первые успехи конца 1950-х, начала 1960-х годов в области ИИ привлекли к себе внимание прессы. Учёные не стеснялись делать оптимистичные прогнозы. Они утверждали, что "в ближайшем будущем" машины смогут решать задачи, с которыми раньше справлялись только люди.

Громкие заявления о скором прогрессе ИИ разнесла пресса. В результате к исследованиям стали проявлять интерес лица принимающие решения о финансировании: правительственные чиновники, военные, инвесторы, руководители частных и государственных организаций.

Вокруг темы ИИ возник ажиотаж, который продолжался до середины 1970-х годов. Вслед за ним наступил спад и разочарование в достигнутых результатах. Позже этот период станут называть "первая зима ИИ". Рассмотрим её причины.

#### 2.1.3.1 Проект машинного перевода

В 1957 году СССР запустил первый искусственный спутник земли. После этого [Национальный научно-исследовательский совет США](https://ru.wikipedia.org/wiki/Национальные_академии_наук,_инженерии_и_медицины) (National Research Council или NRC) стал внимательно следить за советскими научными статьями. Чтобы ускорить их перевод на английский язык, было решено создать специальную ИИ систему. Её разработкой занимались совместно компания IBM и университет Вашингтона в Сент-Луисе.

В начале проекта считалось, что для машинного перевода достаточно простых синтаксических преобразований и замены слов по словарю. Для синтаксических преобразований нужны знания грамматики русского и английского языка, которые достаточно просто закодировать. Но скоро выяснилось, что для устранения неоднозначностей и определения смысла предложения нужные общие знания о предметной области. Позже это затруднение получит название [**проблема здравого смысла**](https://en.wikipedia.org/wiki/Commonsense_knowledge_(artificial_intelligence)).

К 1964 году NRC вложил в проект машинного перевода около 20 миллионов долларов. Но несмотря на почти десять лет разработки, заметного прогресса достигнуто не было. Тогда NRC сформировал комитет для изучения этой проблемы. В 1966 году этот комитет подготовил отчёт. В нём говорилось, что машинный перевод дороже, менее точен и медленнее, чем выполненный человеком. После этого правительство США полностью прекратило финансирование проекта. Исследования были полностью прекращены.

#### 2.1.3.2 Финансирование DARPA

В 1958 году министерство обороны США организовало [управление перспективных исследовательских проектов](https://ru.wikipedia.org/wiki/Управление_перспективных_исследовательских_проектов_Министерства_обороны_США) ARPA, которое позднее было переименовано в DARPA. Эта организация искала и финансировала перспективные научные исследования, которые могли бы применяться в военных целях.

Благодаря громким заявлениям в прессе, исследования ИИ привлекли внимание специалистов ARPA. Они посчитали, что исследования в новой области могут принести пользу для военных. Это решение привело к тому, что на протяжении 1960-х годов лаборатории ИИ в МТИ, университетах Карнеги — Меллона и Стэнфордском получали гранты в размере нескольких миллионов долларов ежегодно. Эти деньги выделялись не на конкретные проекты с жёсткими сроками. Лаборатории получали их на фундаментальные исследования, не имевшие применения на практике. В то время решения, связанные с компьютерными технологиями, в ARPA принимал известный американский учёный
[Джозеф Ликлайдер](https://en.wikipedia.org/wiki/J._C._R._Licklider). Он верил, что финансирование "людей, а не проектов" даст результаты. К сожалению, он ошибся.

Отсутствие результатов и провал одного из крупных проектов заставил ARPA изменить политику финансирования. SUR был проектом голосового управления для пилотов. Над ним работала команда из университета Карнеги — Меллона. Исследователи разработали систему распознавания речи, но она оказалась очень ограниченной. Например, порядок произнесения слов был строго определён. Реальные возможности системы оказались очень далеки от обещанных. В 1974 году ARPA полностью прекратила финансирование этого проекта.

На раздутый бюджет военных исследований обратил внимание сенат США. В результате в 1969 году была принята поправка Мэнсфилда. Она требовала от ARPA финансировать только целевые исследования. Теперь учёные были обязаны доказать, что их работа связана с военными технологиями. Их заявки на финансирование рассматривались по очень строгим стандартам. Это привело к значительному сокращению бюджета лабораторий ИИ по всей стране.

#### 2.1.3.3 Отчёт Лайтхилла

В 1965 году английский учёный [Дональд Мичи](https://en.wikipedia.org/wiki/Donald_Michie) организовал лабораторию ИИ в [Эдинбургском университете](https://ru.wikipedia.org/wiki/Эдинбургский_университет). Позднее подобные лаборатории открылись в университетах Сассекс и Эссекс. В конце 1960-х и начале 1970-х они получали значительные гранты от правительства Англии.

Распределением средств на исследования ИИ в Англии занимался [совет по научным и инженерным исследованиям](https://en.wikipedia.org/wiki/Science_and_Engineering_Research_Council) (Science and Engineering Research Council или SERC). В конце 1970-х совет решил проверить достигнутые успехи исследований. В то время часто звучали утверждения о скором создании разумных машин. Но научная основа таких утверждений была неясна. Кроме этого совет хотел убедиться, что значительные инвестиции на исследования были оправданы и направлены на наиболее перспективные области.

В 1973 году SERC поручил профессору в области прикладной математики и физики [Джеймсу Лайтхиллу](https://ru.wikipedia.org/wiki/Лайтхилл,_Джеймс) оценить текущее состояние исследований в области ИИ. Лайтхилл ранее работал ректором в Имперском колледже Лондона. Он был известен своим критическим анализом научных и математических проблем и поэтому считался подходящим кандидатом.

Лайтхилл провёл всестороннее исследование: он изучил доступные материалы, побеседовал с наиболее известными экспертами в области ИИ из США и Европы, а затем классифицировал полученные данные. Результаты своей оценки он опубликовал в статье под названием "Искусственный интеллект: общий обзор" ([Artificial Intelligence: A General Survey](www.chilton-computing.org.uk/inf/literature/reports/lighthill_report/p001.htm)). Позднее она стала широко известна как [отчёт Лайтхилла](https://ru.wikipedia.org/wiki/Отчёт_Лайтхилла).

В первой части отчёта Лайтхилл описывает три основных направления исследований ИИ того времени:

* A — Advanced Automation (продвинутая автоматизация). К этой области он относит разработку систем, которые могут заменить людей для решения конкретных прикладных задач. Такие системы Лайтхилл подразделяет на два типа. Первый — для решения промышленных и военных задач. Второй — для математической и научной работы.

* C — Computer-based CNS research (исследование центральной нервной системы человека с помощью компьютера). К этому направлению относятся все теоретические исследования в области нейрофизиологии и психологии. Лайтхилл подчеркивает, что эти исследования занимаются моделированием работы мозга с помощью компьютера.

* B — Building Robots (создание роботов). Это направление связывает A и C для создания автоматических устройств, которые имитируют определённый набор человеческих функций.

Далее автор переходит ко второй части, где разбирает ожидания и реальные достижения каждого из трёх направлений: A, C и B. Лайтхилл признаёт, что исследования в областях A и C имели некоторые успехи. Однако, ни одна из заявленных целей направления B так и не была достигнута.

Чтобы оценить достижения в Advanced Automation, Лайтхилл прибегает к сравнению. Он оценивает уже существующими коммерческие системы автоматизированного управления, применяемые в авиации и космической индустрии. Эти системы оказываются значительно сложнее и эффективнее, чем системы, созданные в рамках ИИ исследований. Также автор упоминает провал систем для машинного перевода и доказательства математических теорем.

Автор рассматривает направление Computer-based CNS research больше как помощь для фундаментальных исследований в области психологии. Он утверждает, что затраты вычислительных мощностей и труда для моделирования процессов нервной системы оказываются неоправданно высоки. Основную проблему этого направления Лайтхилл видит в несовершенстве современной компьютерной техники.

Проблемы последнего направления Building Robots Лайтхилл связывает с неудачами областей A и C. Не имея надёжных систем распознавания образов, речи и логического рассуждения, нет никакой возможности построить роботов или даже узкоспециализированные машины с интеллектом близким человеческому.

В заключении статьи Лайтхилл весьма сдержанно оценивает возможные достижения ИИ исследований в последующие 25 лет.

Отчёт Лайтхилла стал причиной, по которой SERC прекратил финансирование большинства исследований ИИ в университетах. Это решение привлекло к себе внимание всех европейских стран. В итоге финансирование разработок в новой области сократились по всей Европе.

#### 2.1.3.4 Ограничения систем ИИ

Проблемы с финансированием исследований ИИ в середине 1970-х возникли по вине самих учёных. Они недооценили сложность задач, которые им предстоит решить. Поэтому их прогнозы и сроки выполнения проектов оказались слишком оптимистичными. В результате ожидания инвесторов были очень высоки.

Крупные инвестиции в область ИИ начались в середине 1960-х годов. К началу 1970-х стали ясны результаты разработок, на которые ушли несколько лет. Эти результаты оказались неудовлетворительными. Возможности реальных систем ИИ были далеки от об обещанных.

Есть мнение, что учёные умышленно вводили в заблуждение инвесторов, чтобы получить финансирование. Вполне возможно, что некоторые из них действительно делали громкие заявления, стараясь привлечь внимание прессы и подогреть оптимизм инвесторов. Но тем не менее ошибочными оказались абсолютно все прогнозы о перспективах развития ИИ, сделанные в начале 1960-х годов. Разберёмся, почему это произошло.

##### 2.1.3.4.1 Производительность компьютеров

В конце 1950-х годов сменилась технология производства компьютеров. Раньше их рабочими элементами были [электровакуумные лампы](https://ru.wikipedia.org/wiki/Электронная_лампа). В 1958-м году компания IBM выпустила первый компьютер, который работал на [транзисторах](https://ru.wikipedia.org/wiki/Транзистор). Они превосходили лампы по компактности, надежности и скорости работы.

Переход на транзисторы должен был значительно увеличить быстродействие компьютеров. Однако, конструкция самих транзисторов [продолжала развиваться](https://en.wikipedia.org/wiki/MOSFET#Commercialization) на протяжении 1960-х годов. Только в начале 1970-х годов она достигла такого уровня, который позволил наращивать производительность компьютеров. После этого момента начал действовать [закон Мура](https://ru.wikipedia.org/wiki/Закон_Мура). Он говорит о том, что число транзисторов на [интегральной схеме](https://ru.wikipedia.org/wiki/Интегральная_схема) удваивается примерно каждые два года. Соответственно растёт скорость вычислений и объём памяти.

Исследователи ИИ разрабатывали прототипы своих систем для компьютеров 1960-х годов со слабой вычислительной мощностью и ограниченной памятью. Эти прототипы могли решать относительно простые задачи. Полученные результаты позволяли исследователям сравнивать эффективность разных подходов и методов. Но оценить [**масштабируемость**]((https://ru.wikipedia.org/wiki/Масштабируемость)) прототипа системы очень сложно. Для этого её надо запустить на более мощном компьютере. На тот момент таких компьютеров просто не существовало.

I> Масштабируемость означает повышение производительности системы при добавлении ресурсов.

Вот один из примеров. Первые версии систем для машинного перевода обрабатывали небольшие специально подготовленные тексты. Памяти компьютера 1960-ого года хватало только на несколько десятков слов. Поэтому система могла переводить только маленькие тексты. Чтобы проверить насколько система универсальна, нужен был компьютер с намного большим объёмом памяти. Учёные были уверены, что более мощное оборудование решит все проблемы. Но при переводе реальных текстов в начале 1970-х неожиданно возникла "проблема здравого смысла".

Ограничением была не только память, но и быстродействие компьютеров. В 1976 году учёный [Ханс Моравек](https://ru.wikipedia.org/wiki/Моравек,_Ханс) из университета Карнеги — Меллона дал следующую оценку. Чтобы распознавать грани объектов и движение в реальном времени, система ИИ должна работать на компьютере с производительностью 10^9^ [операций в секунду](https://ru.wikipedia.org/wiki/IPS_(быстродействие)) (1000 мегаинструкций в секунду или MIPS). Однако, самый быстрый суперкомпьютер 1976 года [Cray-1](https://ru.wikipedia.org/wiki/Cray-1) выполнял всего 160 MIPS.

В 1960-е годы исследователи ИИ не смогли правильно оценить вычислительные мощности, которые понадобятся для работы их систем. Многие принципиальные проблемы обнаружились только при тестировании прототипов на более мощных компьютерах начала 1970-х годов. Для их решения требовались новые исследования и время, но инвесторы уже ждали готовых результатов.

##### 2.1.3.4.2 Комбинаторный взрыв

В отчёте Лайтхилла упоминается проблема [**комбинаторного взрыва**](https://ru.wikipedia.org/wiki/Комбинаторный_взрыв) (combinatorial explosion). Этот термин означает быстрый рост сложности задачи при увеличении размера входных данных. Именно комбинаторный взрыв стал одной из причин, помешавших развитию направления Advanced Automation.

Разберёмся в этой проблеме подробнее. Одну и ту же вычислительную задачу можно решить разными алгоритмами. Некоторые из них окажутся эффективнее, чем другие. Для выбора подходящего алгоритма, нужен надёжный способ сравнения. Самое простое решение — замерить время работы каждого алгоритма на конкретном наборе входных данных. К сожалению, такой прямолинейный подход ненадёжен. Какой-то алгоритм может быстрее других работать на большом наборе входных данных (например, обрабатывать длинные строки), но на малых наборах (коротки строки) он будет уступать другим.

Для адекватной оценки алгоритма надо учитывать зависимость его показателей от размера входных данных. Поэтому сегодня применяют две основных оценки:

* [**Временная сложность**](https://ru.wikipedia.org/wiki/Временная_сложность_алгоритма) (time complexity) — это зависимость количество итераций алгоритма от размера входных данных. Другими словами — на сколько шагов увеличится алгоритм при увеличении входных данных.

* **Пространственная сложность** — это зависимость количества занимаемой памяти от размера входных данных.

Лайтхилл демонстрирует проблему комбинаторного взрыва на системах ИИ для доказательства теорем. Такие системы следуют подходу "рассуждение как поиск". Суть подхода в применении методов поиска для выполнения логических выводов из доступной информации.

Чтобы применить эти методы, информация представляется в структурированном формате, например как граф. Его вершинами могут быть некоторые факты, а рёбрами отношения "предпосылка->вывод". Тогда система с помощью алгоритма поиска может обойти построенный граф и найти путь для доказательства какого-то факта из всего доступного набора возможных предпосылок.

Такие системы хорошо справлялись с небольшими формальными задачами, такими как теоремы из книги "Начала математики". Дерево поиска построенное для исходной информации теоремы оказывалось относительно небольшим. Когда же дело доходило до реальных прикладных задач, дерево поиска оказывалось на несколько порядков больше.

Высокая временная и пространственная сложность применявшихся в то время алгоритмов поиска приводила к тому, что вычислительные ресурсы компьютера исчерпывались задолго до нахождения решения задачи. Именно в этом и состояла проблема комбинаторного взрыва. В реальной прикладной задаче объем информации для обработки быстро увеличивался при незначительном увеличении размера входных данных. Существующие алгоритмы просто были к этому не готовы.

В своих рассуждениях Лайтхилл ссылался на [теорию вычислительной сложности](https://ru.wikipedia.org/wiki/Теория_сложности_вычислений). Как отдельное направление информатики она появилась в 1965 году. В 1970-е годы теория активно развивалась. Согласно её выводам, некоторые классы задач в принципе не имеют эффективных решений. Это значит, что не существует алгоритмов для их решения за приемлемое время. Такие задачи называются [**трудноразрешимыми**](https://www.slideshare.net/mkurnosov/12-34608847).

Концепция трудноразрешимых задач устанавливает строгие ограничения для возможностей систем ИИ. Эти системы способны решать только задачи, для которых существуют эффективные алгоритмы решения.

#### 2.1.3.5 Проблемы коннекционизма

В начале 1960-х годов модель перцептрона Розенблатта выглядела многообещающей. Группы учёных из разных университетов исследовали её возможности. Но скоро они пришли к выводу, что перцептрон хорошо справляется только  с простыми задачами. Он оказался не способен решать сложные прикладные задачи.

Понимал ограничения своей модели и Розенблатт. В книге "Принципы нейродинамики" он указал следующие недостатки однослойных перцептронов:

1. Для выполнение некоторых задач нужна нейронная сеть с очень большим количеством элементов.

2. В некоторых случаях обучение занимает очень много времени.

3. Качество обучения сильно зависит от оценок системы во время обучения.

4. Перцептрон плохо справляется с задачей обобщения.

5. Перцептрон плохо выделяет существенные элементы в сложных входных сигналах.

Первый и второй пункт говорят о высоких требованиях перцептрона к памяти и производительности компьютера, на котором он моделируется. Реальная сложная задача требует большой сети. Каждый её элемент должен храниться в памяти компьютера. Чтобы такую сеть обучить, нужна высокая вычислительная мощность.

Третий пункт говорит о том, что обучение сети — итеративный процесс, результат которого нельзя предсказать наверняка. Если обучение не дало нужной точности работы сети, его нужно повторить снова. 

Из четвертого пункта следует, что перцептрон правильно обрабатывает только те входные данные, на которых он учился. Если условия задачи похожи на учебный пример, но полностью с ним не совпадают, перцептрон скорее всего не сможет её решить.

Пятый пункт приводит к тому, что перцептрон плохо справляется со сложными задачами. Наиболее эффективный метод их решения — разделение на простые подзадачи. Но перцептрон не способен на такое разделение. Он анализирует задачу целиком как есть.

Розенблатт надеялся, что многослойные перцептроны смогут преодолеть некоторые из этих ограничений. Он начал рассматривать архитектуры таких нейронных сетей в своей книге. Но эта теория осталась недоработанной.

Исследовать многослойные перцептроны на практике в 1960-х годах было сложно. Для моделирования их работы на универсальных компьютерах требовалось больше памяти и времени обучения, чем для однослойных перцептронов. Часто модель сети не помещалась в память компьютера или для её обучения требовалось слишком много времени.

Аппаратная реализация перцептронов в виде специальных компьютеров наподобие Марк-1 имела технические проблемы. В 1960-х годах не было надёжных и дешёвых электронных компонентов, на которых можно было бы построить нейрокомпьютер. Архитектура Марк-1 не масштабировалась. Это признал сам Розенблатт. Поэтому строить более сложные нейрокомпьютеры для многослойных перцептронов в то время было невозможно.

К середине 1960-х годов работы с моделью перцептрона зашли в тупик. Розенблатт тоже оставил эту тему, как малоперспективную. Продолжать исследования можно было только развивая математические модели, но на практике их нельзя было проверить. Главным ограничением стала недостаточная мощность компьютеров того времени.

Начиная с 1965 года Марвин Минский и Сеймур Пейперт провели ряд экспериментов над перцептронами. Свои результаты они опубликовали в книге 1969 года под названием ["Перцептроны"](https://ru.wikipedia.org/wiki/Перцептроны_(книга)) (Perceptrons: an introduction to computational geometry).

Книга подробно рассматривает ряд типовых задач по распознаванию образов, с которыми однослойный перцептрон не может справиться. Все эти задачи связаны с **инвариантным представлением** образов. Примеры такого представления: поворот объекта, его перенос и растяжение-сжатие. После таких действий над исходным образом перцептрон не может его распознать. Причина в неспособности нейронной сети к обобщению.

Из своих результатов Минский и Пейперт сделали смелые выводы. Они заявили, что рассмотренные ими ограничения справедливы для любых параллельных вычислений. Именно к этому типу вычислений относятся нейронные сети. При этом авторы подчёркивают, что последовательные вычисления могут справиться с проблемой инвариантного представления. Другими словами они заявляли превосходство своего символьного подхода над коннекционизмом.

Есть мнение, что Минский и Пейперт стремились не столько дать объективную оценку возможностей перцептрона, сколько очернить конкурирующее направление ИИ. Это вполне возможно после того, как ARPA урезала финансирование и началась жёсткая конкуренция за гранты.

Так или иначе, но выводы книги "Перцептроны" оказались неверными для многослойных нейронных сетей. К сожалению, многослойными сетями в те годы мало кто занимался. Поэтому ошибки авторов выявили намного позже.

Наверняка неизвестно как книга повлияла на отношение к коннекционизму в научных кругах. К моменту её выхода в 1969 году параллельные вычисления уже считались малоперспективным направлением.

На развитие коннекционизма также повлияла поправка Мэнсфилда. В большинстве исследований нейронные сети рассматривались как теоретическая модель для изучения мозга. Практические результаты от таких проектов ожидались редко. Поэтому ARPA перестало спонсировать исследования в рамках коннекционизма. Не имея финансирования, учёные были вынуждены переключаться на другие проекты.

### 2.1.4 Развитие ИИ 1980 – 1987

#### 2.1.4.1 Экспертные системы

Ранние символьные системы ИИ конца 1950-х годов, такие как General Problem Solver и Advice Taker, разрабатывались как универсальные. Их ключевым элементом был алгоритм поиска решений. Знания, которыми он оперировал, считались чем-то второстепенными. Системы могли работать с любыми фактами, следуя одному и тому же алгоритму. Так они должны были решать задачи из разных прикладных областей. Но этот подход не сработал для реальных задач из-за комбинаторного взрыва.

В середине 1960-х годов [Эдвард Фейгенбаум](https://ru.wikipedia.org/wiki/Фейгенбаум,_Эдвард_Альберт) и его коллеги из Стэнфордского университета предложили новый подход к разработке символьных ИИ систем. Они отказались от попыток создать универсальную программу, способную решать любые задачи. Вместо этого учёные предложили выбрать одну конкретную прикладную задачу и разработать систему для её решения. Сформулированная таким образом цель продиктовала дальнейшие технические решения.

Новый тип программы получил название [**экспертная система**](https://en.wikipedia.org/wiki/Expert_system). Она имитировала процесс принятия решений человеком-экспертом в конкретной прикладной области. Для этого системе не нужны общие знания об окружающем мире. Ей достаточно только знаний человека-эксперта и правила логического вывода для работы с ними.

Экспертная система состоит из двух частей: [**базы знаний**](https://ru.wikipedia.org/wiki/База_знаний) и [**механизма вывода**](https://ru.wikipedia.org/wiki/Машина_вывода). Такое разделений данных и кода впервые предложил Джон Маккарти для своей гипотетической системы Advice Taker. Оно отлично подошло для нового подхода, центральное в котором занимали именно экспертные знания. Так человек-эксперт мог работать с базой знаний без навыков программирования.

База знаний содержит информацию об опыте и знаниях человека-эксперта в некоторой предметной области, а также правила логического вывода. Информация представляется иерархически в строго определённом форме. Такая форма называется [**онтологией**](https://ru.wikipedia.org/wiki/Онтология_(информатика)). Онтология показывает свойства предметной области их связи. Для этого она определяет понятия и категории, которые представляют сам предмет.

Механизм вывода применяет логические правила к информации из базы знаний. Таким образом он выводит новые знания, необходимые для решения поставленной задачи. Этот процесс работает итеративно. Полученное новое знание может запустить выполнение дополнительного правила в механизме. Есть два режима его работ: **прямой вывод** и **обратный**. Прямой вывод начинается с известных фактов и доказывает новые факты. Обратный вывод начинает с целей. Он определяет какие факты надо доказать, для достижения этих целей.

Главным достижением экспертных систем стало решение проблемы комбинаторного взрыва. Ранние символьные ИИ системы полагались на алгоритмы поиска по дереву, составленному из элементарных общих фактов об окружающем мире. Для решения реальной прикладной задачи этих фактов оказывалось слишком много, чтобы обработать их за разумное время.

Экспертная система работает более целенаправленно. У неё изначально есть только факты, необходимые для решения поставленной задачи, и логические правила для их обработки. Вместо поиска по огромному массиву данных система последовательно применяет заданные ей правила к конкретным фактам.

Рассмотрим первые экспертные системы и их возможности.

##### 2.1.4.1.1 Dendral

В 1965 году группа учёных из Стэнфордского университета начала проект первой экспертной системы. Она получила название Dendritic Algorithm или сокращённо [Dendral](https://ru.wikipedia.org/wiki/Dendral). Ей разрабатывали [Эдвард Фейгенбаум](https://ru.wikipedia.org/wiki/Фейгенбаум,_Эдвард_Альберт), [Джошуа Ледерберг](https://ru.wikipedia.org/wiki/Ледерберг,_Джошуа), Брюс Бьюкенен и [Карл Джерасси](https://ru.wikipedia.org/wiki/Джерасси,_Карл).

Всё началось с того, что Джошуа Ледерберг занимался исследованиями в области [астробиологии](https://ru.wikipedia.org/wiki/Астробиология). Эта наука изучает жизнь на других планетах. Учёный задался вопросом: может ли компьютер помочь ему проанализировать незнакомые органические соединения?

Ледерберг обратился за помощью к химику Карлу Джерасси и информатику Эдварду Фейгенбаум. Вместе они спроектировали первую версию системы Dendral. Позже к проекту присоединился программист Брюс Бьюкенен.

Система Dendral должна была определять структуру неизвестных молекул по картине их масс-спектра. Масс-спектрометрия измеряет отношение массы фрагментов молекулы к их заряду.

Чтобы решить поставленную задачу, Джошуа Ледерберг и Гарольд Браун разработали вспомогательный алгоритм. Он [генерировал](https://en.wikipedia.org/wiki/Chemical_graph_generator) все возможные химические соединения по заданным параметрам. Каждое соединение представлялось в виде графа. Для генерации использовались картины масс-спектров известных молекул, общие знания по химии и теории графов.

Для каждого сгенерированного химического соединения экспертная система вычисляла ожидаемую картину масс-спектра. Далее Dendral сравнивала её с картиной неизвестной молекулы. Если масс-спектры совпадали, система делала вывод, что сгенерирована именно неизвестная молекула.

Dendral решал задачу, которую в общем виде можно сформулировать так:

*Разработать решение с учётом данного набора ограничений.*

Именно в задачах такого типа оказались сильны экспертные системы.

Dendral была готова к использованию в 1969 году. Её применяли химики в своих исследованиях на протяжении 1970-х и 1980-х годов. Это был первый случай, когда символьная система ИИ смогла решать реальные задачи из прикладной области.

##### 2.1.4.1.2 Mycin

Успех Dendral показал, что экспертные системы могут решать прикладные задачи. Поэтому учёные из Стэнфордского университета продолжили исследования в этом направлении.

В начале 1970-х годов Эдвард Фейгенбаум, [Эдвард Шортлифф](https://en.wikipedia.org/wiki/Edward_H._Shortliffe), Бьюкенен и генетик [Стэнли Коэн](https://ru.wikipedia.org/wiki/Коэн,_Стэнли_Норман) разработали экспертную систему [Mycin](https://ru.wikipedia.org/wiki/MYCIN). Она анализировала симптомы пациента с тяжелым инфекционным заболеванием и определяла, какие бактерии его вызвали. Затем система рекомендовала антибиотики и дозировку для лечения в зависимости от веса больного.

Mycin имела несколько принципиальных отличий от системы Dendral. Во-первых, пользователь работал с Mycin интерактивно. Система задавала длинную серию вопросов о симптомах пациента. Вопросы были двух типов: с простым ответом да/нет, с развернутым ответом в виде текста. Mycin ставила диагноз, ориентируясь на полученную от пользователя информацию.

Второе отличие системы Mycin заключается в характере знаний, с которыми она работала. В медицине нет такой строгой теоретической модели как в химии. Поэтому Mycin не могла точно вычислить диагноз пациента. Результат работы системы выглядел как список возможных бактерий, вызвавших заболевание. Этот список был отсортирован по убыванию вероятности диагноза. В каждой строке списка Mycin указывала рекомендуемый курс антибиотиков.

Третье отличие системы Mycin от Dendral было в механизме вывода. У Dendral был механизм генерации химических соединений. С его помощью система сама генерировала гипотезы, которые затем проверяла по правилам вычисления масс-спектра.

Mycin имела базу знаний примерно из 600 правил. Каждое правило описывало некоторый симптом заболевания и **вес доказательства** (weight of evidence) того, что пациент заражен конкретной бактерией. Большее значение веса означало большую вероятность. Получив все ответы пользователя, система подставляла в формулу веса для каждого заболевания. Эта формула вычисляла вероятность, которая указывалась в списке с результатами.

Разработчики системы Mycin провели эксперимент, чтобы оценить точность её диагнозов. Для этого они подготовили данные по нескольким пациентам с симптомами заболеваний и уже известными диагнозами. Симптомы проанализировала Mycin и пять преподавателей медицинского факультета Стэнфорда. Система поставила правильный диагноз в 65% случаев. Точность диагнозов у каждого преподавателя была разной: от 42.5% до 62.5%.

Несмотря на многообещающие результаты, Mycin осталась исследовательской разработкой и не применялась в больницах. На это было несколько причин.

Во-первых, работа с интерфейсом системы оказалась слишком трудоёмкой. В 1970-х годах больницы не имели электронного документооборота. Вся информация о пациентах хранилась в бумажном виде. Поэтому врач должен был проходить через весь список вопросов для каждого пациента. Один сеанс работы с Mycin мог длиться до получаса. Для врачей такие потери времени были неприемлемы.

Вторая проблема заключалась в высокой стоимости вычислительного времени. Mycin работала на компьютере PDP-10 от компании DEC по цене от 500000$ до 1000000$ долларов. Чтобы окупить приобретение такого компьютера, каждая минута расчётов на нём должна приносить прибыль. Система Mycin использовала вычислительное время очень неэффективно. Большую часть сеанса работы она ожидала ответ пользователя на заданный вопрос.

Третья причина была юридическая. Система ставила неверный диагноз примерно с 35% вероятностью. В этом случае было неясно, кто несёт ответственность: разработчики или врачи, которые использовали систему в качестве советчика.

Mycin ещё раз подтвердила эффективность экспертных систем в решении практических задач. В то же время она обозначила будущие проблемы нового подхода. Разработчики обратили внимание на то, что сбор и занесение в систему экспертных знаний — очень трудоёмкий задача.

##### 2.1.4.1.3 XCON

Digital Equipment Corporation (DEC) стала первой компанией, которая внедрили экспертную систему для своих бизнес-процессов.

В 1970-е годы DEC занимала второе место после IBM по производству компьютеров. Она была известна своими машинами серии PDP и VAX. Именно на компьютерах PDP разрабатывались первые ИИ системы. DEC была главным поставщиком оборудования для лабораторий ИИ и поддерживала хорошие контакты с исследователями. Инженеры компании знали о последних разработках в сфере ИИ.

Компьютеры DEC имели много комплектующих и кабелей соединения. Поэтому при оформлении заказов часто происходили ошибки. Покупатели получали несовместимое между собой оборудование или им не хватало кабелей для подключения. Эта проблема приводила к лишним расходам. Инженеры DEC неоднократно пытались её решить с помощью автоматизации, но это ни к чему не привело.

В конце 1970-х годов Джон Макдермотт работал научным сотрудником в университете Карнеги — Меллона. Он предположил, что экспертная система может решить проблему DEC с конфигурированием оборудования. Вместе со своими коллегами он спроектировал её прототип. Для составления базы знаний Макдермотт связывался с инженерами DEC и собирал необходимые правила конфигурации компьютеров. Компания DEC поддерживала и полностью финансировала эту работу.

В 1980-ом году DEC получила прототип системы, получивший название [R1](https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/460/396&usg=AOvVaw0VSwYr6eysX2PsWS3AykcU&opi=89978449). Эта версия содержала около 750 правил и могла конфигурировать некоторые вводимые в неё заказы. Но для реального применения отделом продаж DEC систему необходимо было доработать. Этой задачей занимался новый специально созданный отдел компании. Его задачей стало поддержание существующих и разработка новых экспертных систем для внутренних нужд.

Доработанная система конфигурации заказов получила название XCON. Её база знаний и механизм вывода постоянно развивалась. В конце срока эксплуатации системы её база начитывала около 2500 правил. За весь срок службы она обработала около 80000 заказов. Точность её работы оценивали на уровне 95%. Благодаря XCON, компания DEC экономила до 25 миллионов долларов ежегодно.

Коммерческий успех системы XCON вызвал ажиотаж. Корпорации по всему миру начали внедрять экспертные системы для внутреннего использования. Для этого создавались новые отделы и обучались технические специалисты. В курсе многих университетов появилась новая программа, связанная с разработкой экспертных систем. Вокруг этой технологии выросла целая индустрия.

Система XCON была разработана на языке OPS-4. Его применяли исследователи университета Карнеги — Меллона. За пределами учебного заведения язык никто не знал. Это стало проблемой для инженеров DEC, которые поддерживали систему XCON. Им пришлось изучать OPS-4 с нуля.

Более ранние системы Dendral и Mycin были написаны на языке Lisp. Он был широко известен и распространён. Его возможности отлично подходили для разработки экспертных систем. Поэтому именно Lisp, а не OPS-4 стал стандартом в новой области программного обеспечения.

К середине 1980-х годов рынок экспертных систем переживал активный рост. Появились специальные компьютеры под названием [Lisp-машины](https://ru.wikipedia.org/wiki/Лисп-машина). Их архитектура была оптимизирована для запуска программ, написанных на языке Lisp. Производство таких компьютеров приносило огромные прибыли, а спрос на них увеличивался до 1987 года.

#### 2.1.4.2 Успехи коннекционизма

В 1970-е и 1980-е годы исследования в рамках коннекционизма проводили учёные не связанные с ИИ.

##### 2.1.4.2.1 Сеть Хопфилда

Японский учёный Шуничи Амари в 1972 году первым провёл параллели между [**моделью Изинга**](https://ru.wikipedia.org/wiki/Модель_Изинга) из статистической физики и нейронными сетями. Эта математическая модель описывает намагничивание материала и была разработана для изучения спиновых стёкол. Так называются сплавы немагнитных материалов с магнитными примесями. Их поведение намного сложнее чем у обычных магнитов.

Идеи Шуничи Амари продолжил развивать Уильям Литтл из Стэнфордского университета. В своей статье 1974 года ["Существование устойчивых состояний в мозгу"](https://www.sciencedirect.com/science/article/abs/pii/0025556474900315?via%3Dihub) (The existence of persistent states in the brain) он рассматривает возможность математического моделирования деятельности мозга. В следующей статье 1980 года ["Модель Изинга для нейронных сетей"](https://link.springer.com/chapter/10.1007/978-3-642-61850-5_18) (An Ising Model of a Neural Network) Уильям Литтл подробно разбирает, как применить модель Изинга для нейронных сетей.

Следующий шаг сделал американский физик [Джон Хопфилд](https://ru.wikipedia.org/wiki/Хопфилд,_Джон). Он изучал свойства хранения данных в нейронной сети. Для описания такой сети учёный применил модель Изинга и наработки Уильяма Литтла. В результате Хопфилд разработал [новую архитектуру нейронной сети](https://ru.wikipedia.org/wiki/Нейронная_сеть_Хопфилда), которая была названа в его честь.

Сеть Хопфилда стала моделью для изучения человеческой памяти. Она получала на вход новый образец данных и искала ближайший похожий образец из уже известных. Таким образом сеть выполняла функцию ассоциативной памяти. Кроме этого сеть могла решать следующие задачи:

 1. Распознавать образы.

 2. Восстанавливать повреждённые изображения.
 
 3. Решать [комбинаторные задачи оптимизации](https://ru.wikipedia.org/wiki/Комбинаторная_оптимизация).

Хопфилд подробно описал свои идеи в статье 1982 года под названием ["Нейронные сети и физические системы с возникающими коллективными вычислительными способностями"](https://www.pnas.org/doi/10.1073/pnas.79.8.2554) (Neural networks and physical systems with emergent collective computational abilities). Новым в его работе стало применение хорошо проработанного математического аппарата модели Изинга к нейронным сетям.

##### 2.1.4.2.2 Машина Больцмана

Идеи Хопфилда продолжили другие учёные. Они искал альтернативные математические модели для описания нейронных сетей. Одной из таких моделей стала [**машина Больцмана**](https://ru.wikipedia.org/wiki/Машина_Больцмана). Её разработала группа учёных: психолог [Джеффри Хинтон](https://ru.wikipedia.org/wiki/Хинтон,_Джеффри), математик Дэвид Окли и биолог Терри Сейновски. Устройство машины описано в статье 1985 года "Обучающий алгоритм для машины Больцмана" (A Learning Algorithm for Boltzmann Machines).

Авторы статьи представляли машину Больцмана как модель нейронного компьютера, выполняющего параллельные вычисления. Такой компьютер состоял из процессоров, соединённых в сеть. На эту идею учёных подтолкнуло развитие технологии транзисторов и сверхбольших интегральных схем (СБИС) в начале 1980-х.

Машина Больцмана строится на одном из вариантов модели Изинга, который известен как стохастический. В приложении к нейронным сетям это означает, что функция активации недетерминирована. Нейроны сети находятся в состоянии "включено" или "выключено" с некоторой вероятностью. В это одно из основных отличий машины Больцмана от детерминированной сети Хопфилда.

Создатели машина Больцмана предлагали решать с её помощью следующие задачи:

1. Генерация данных (в том числе изображений). Машина способна производить данные похожие на те, что применялись в процессе обучения.

2. Дополнение неполных входных данных по обучающим примерам.

3. Обнаружение во входных данных общих признаков и шаблонов.

Идею создания надёжных нейрокомпьютеров на СБИС продолжили развивать Карвер Мид и Мохаммед Исмаил. В 1989 году они опубликовали книгу "Аналоговая реализация нейронных сетей на сверхбольших интегральных схемах" (Analog VLSI Implementation of Neural Systems). В ней они описали возможную архитектуру нейрокомпьютера.

##### 2.1.4.2.3 Метод обратного распространения ошибки

В 1962 году Фрэнк Розенблатт впервые ввёл термин **исправление ошибки обратным распространением**(back-propagating error correction). Так он назвал способ обучения перцептрона, в ходе которого корректируются веса его соединений. В начале 1960-х годов этот способ так и остался только теоретическим. Розенблатт не смог реализовать его на практике.

В 1970 году финский математик Сеппо Линнайнмаа защитил магистерскую диссертацию. В ней он описал, как эффективно применить [**метод обратного распространения ошибки**](https://en.wikipedia.org/wiki/Backpropagation) (backpropagation) к сетям произвольной архитектуры, которые похожи на нейронные. В диссертации нейронные сети не упоминаются явно. Но разработанный Сеппо Линнайнмаа математический аппарат применяется в современных алгоритмах обучения практически без изменений.

Пол Вербос был первым, кто подробно описал обучение именно нейронной сети методом обратного распространения ошибки. Это стало темой его диссертации в 1974 году. К сожалению, сообщество исследователей не обратило внимание на работу молодого учёного.

В 1982 году Пол Вербос опубликовал статью "Применение достижений в нелинейном анализе чувствительности" (Applications of advances in nonlinear sensitivity analysis). В ней он применил метод обратного распространения ошибки к многослойным сетям [с прямой связью](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью).

Спустя четыре года эту же тему подняли Джеффри Хинтон и психолог [Дэвид Румельхарт](https://ru.wikipedia.org/wiki/Румельхарт,_Дэвид). В 1986 году они опубликовали статью "Изучение представлений путем обратного распространения ошибок" (Learning representations by back-propagating errors). Статья описывает обучение [**многослойного перцептрона Румельхарта**](https://ru.wikipedia.org/wiki/Многослойный_перцептрон_Румельхарта) методом обратного распространения ошибки. Эта нейронная сеть является частным случаем перцептрона Розенблатта.

Вот шаги алгоритма обратного распространения ошибки:

1. **Инициализация**. Весам всех соединений нейронной сети присваиваются случайные числа.

2. **Прямой проход**. Нейронная сеть получает на вход обучающий пример. Сигналы распространяются по сети от входных нейронов к выходам. Каждый нейрон вычисляет взвешенную функцию своих входов и с помощью функции активации рассчитывает свой выходной сигнал.

3. **Ошибка вычисления**. После прямого прохода выход сети сравнивался с желаемым результатом. Разница между ними представляла собой ошибку вычисления.

4. **Обратный проход**. При обратном проходе ошибка распространяется по сети в направлении от выходов к входам. Начиная с выходного слоя, алгоритм вычисляет вклад каждого веса в общую ошибку вычисления.

5. **Обновление веса**. Алгоритм обучения обновляет все веса сети, используя вклад каждого веса в общую ошибку. Веса корректируются в направлении, которое минимизирует ошибку. Для этого применяется алгоритм оптимизации, например **градиентный спуск**.

6. **Повторение процесса**. Шаги со второго по пятый повторяются для каждого обучающего примера. Алгоритм продолжает корректировать веса сети итеративно. Тем самым он постепенно уменьшает ошибку.

7. **Критерий остановки** Процесс обучения продолжает до тех пор, пока не выполнен критерий остановки. Это может быть максимально допустимое число итераций. Другой вариант — ошибка вычисления падает ниже заданного значения.

В 1986 году Дэвид Румельхарт и [Джеймс Макклелланд](https://ru.wikipedia.org/wiki/Макклелланд,_Джеймс) опубликовали цикл статей под названием "Параллельная распределенная обработка" (Parallel Distributed Processing). В этом цикле авторы демонстрировали области применения метода обратного распространения ошибки в компьютерных науках и психологии. Благодаря статьям Хинтона, Румельхарта и Макклелланда, исследователи ИИ снова заинтересовались коннекционизмом.

### 2.1.5 Вторая зима ИИ 1987 — 1993

В 1984 году состоялась ежегодная встреча Американской ассоциации искусственного интеллекта (AAAI). На одном из обсуждений Марвин Минский и Роджер Шэнк обратились к предпринимателям. Они предупредили о  необоснованно завышенных ожиданиях в отношении разработок ИИ. Именно на их выступлении впервые прозвучал термин "зима ИИ". Так Минский и Шэнк назвали период разочарования и сокращения финансирования исследований в 1974 – 1980 годах.

После успеха XCON в начале 1980-х инвестиции компаний в разработку экспертных систем росли ежегодно. К 1985 году корпорации по всему миру потратили на это в сумме свыше миллиарда долларов. Большая часть этих средств ушла на развитие внутренних отделов искусственного интеллекта.

Внедрение экспертных систем в больших масштабах создало спрос на связанные с ними услуги. На рынке появлялись новые компании. Они предлагали программные и аппаратные решения для экспертных систем.

Несмотря на бурный рост, в 1987 году рынок экспертных систем рухнул по сценарию [экономического пузыря](https://ru.wikipedia.org/wiki/Экономический_пузырь). Это стало следствием сразу нескольких неудачных для области ИИ событий. Но главной причиной были именно необоснованный энтузиазм, о котором говорили Марвин Минский и Роджер Шэнк.

Инвесторы ожидали высоких прибылей, которые в реальности были невозможны. Обслуживающие экспертные системы компании проваливали слишком оптимистичные сроки поставки своих продуктов. В результате многие проекты были закрыты, а контракты на поддержку расторгнуты.

Такой поворот разочаровал инвесторов. Появились сомнения в том, что разработки ИИ систем и специального оборудования для них вообще могут приносить прибыль.

#### 2.1.5.1 Банкротство производителей Lisp-машин

В конце 1979-х сотрудники лаборатории ИИ Массачусетского технологического института начали работать над специальным компьютером. Его задачей был запуск экспертных систем. Стандартом для их разработки стал язык программирования Lisp. Поэтому новый компьютер был нацелен на исполнение только Lisp-программ. Он получил название Lisp-машина.

В 1979 году на базе института была создана компания [Lisp Machines](https://en.wikipedia.org/wiki/Lisp_Machines). Её первым клиентом стала [Control Data Corporation](https://ru.wikipedia.org/wiki/Control_Data_Corporation) (CDC) — крупный производитель компьютерной периферии и суперкомпьютеров. Именно благодаря заказам и поддержки со стороны CDC, компания Lisp Machines смогла начать свою деятельность.

В феврале 1979 года между сотрудниками Lisp Machines возникли разногласия. Вопрос касался источников финансирования. Часть из них хотела сохранить контроль над компанией, другая настаивала на привлечении инвесторов. В результате группа, заинтересованная в привлечении инвестиций, покинула Lisp Machines и организовала новую компанию [Symbolics](https://en.wikipedia.org/wiki/Symbolics).

Позднее к производству Lisp-машин подключились крупные производители электроники: [Texas Instruments](https://ru.wikipedia.org/wiki/Texas_Instruments) и [Xerox](https://ru.wikipedia.org/wiki/Xerox). Рынок специализированных компьютеров выглядел перспективно и обещал долгосрочный рост. Инвестиции в разработки Lisp-машин достигли полмиллиарда долларов.

Спрос на Lisp-машины рос до 1987 года. Затем рынок неожиданно рухнул. Специализированные компьютеры стали никому не нужны. Это произошло из-за появления [**рабочих станций**](https://en.wikipedia.org/wiki/Workstation) от компании Sun Microsystems. Рабочии станции оказались более выгодным решением, чем Lisp-машины.

I> Рабочая станция отличается от персонального компьютера (ПК) более высокой ценой и производительностью. Её аппаратное обеспечение оптимизировано для задач визуализации, 3D моделирования и математических расчётов. При этом рабочая станция остаётся [компьютером общего назначения](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения).

Рабочие станции от Sun Microsystems имели мощное для своего времени оборудование. Их производительность была выше, чем у специализированных Lisp-машин. Несмотря на очевидные преимущества, корпорации отказывались переходить на рабочие станции. Проблема была в том, что они не поддерживали программы на языке Lisp. Это означало, что экспертные системы на них не запускались.

В 1987 году компания [Lucid](https://en.wikipedia.org/wiki/Lucid_Inc.) разработала интерпретатор языка Lisp для операционной системы Unix. Именно эта система управляла рабочими станциями Sun.

У интерпретатора от компании Lucid были альтернативы. Одна из них была разработана в  университете Беркли в 1980-м году. Этот интерпретатор назывался [Franz Lisp](https://en.wikipedia.org/wiki/Franz_Lisp). Его разрабатывали для запуска университетской системы компьютерной алгебры Macsyma. В 1982 году Franz Lisp портировали на компьютеры Sun. Позднее сотрудники Беркли организовали компанию Franz Inc., которая занималась развитием интерпретатора.

Благодаря усилиям компаний Lucid и Franz Inc., у Lisp-машин появился сильный конкурент в лице рабочих станций от Sun Microsystems. Цена обоих решений была соизмерима, но станции от Sun были мощнее.

К концу 1980-х годов относительно недорогие ПК от компаний Apple и IBM достигли производительности Lisp-машин. В 1987-м году на них уже запускались популярные интерпретаторы языка Lisp.

Пользователям экспертных систем не осталось причин переплачивать за специальное оборудование. Корпорации стали массово отказываться от Lisp-машин в пользу дешёвых и универсальных компьютеров с поддержкой языка Lisp.

#### 2.1.5.2 Проблемы экспертных систем

К началу 1990-х годов компании накопили достаточно опыта в использовании и сопровождении экспертных систем. Оказалось, что их обслуживание обходится слишком дорого.

Проблема возникала при добавлении новой информации в базу знаний. Сама экспертная система не имеет функции обучения. Поэтому специалисты вносили все изменения вручную. После этого всю базу знаний надо было проверять на [**согласованность**](https://ru.wikipedia.org/wiki/Согласованность_данных). Согласованность означает, что в базе нет правил противоречащих друг другу. На такую проверку и исправление найденных ошибок уходило много времени и сил.

К 1990-м годам научные круги потеряли интерес к экспертным системам. В те годы многих учёных занимала тема универсального ИИ. Но на экспертных системах создать его было невозможно. Для работы такому ИИ требуются общие знания о реальном мире. Но разработки в области архитектуры баз знаний показали, что представление общих знаний — трудновыполнимая задача. Как следствие, учёные перестали развивать технологию экспертных систем и искать принципиальные решения для обнаруженных с ними проблем.

Одной из немногих попыток представить общие знания о мире в базе знаний был проект [Дугласа Лената](https://ru.wikipedia.org/wiki/Ленат,_Дуглас) под названием [Cyc](https://ru.wikipedia.org/wiki/Cyc). Этот проект неоднократно подвергался критики со стороны научного сообщества. Многие учёные считают его бесполезным.

Экспертные системы доказали свою эффективность в некоторых узкоспециализированных прикладных областях. Но из-за коммерческих неудач инвесторы потеряли интерес к этому направлению. Не имея финансирования и поддержки со стороны научного сообщества, активная разработка экспертных систем прекратилась.

#### 2.1.5.3 Провал проекта компьютера пятого поколения

В 1982 году правительство Японии запустило проект [компьютера пятого поколения](https://ru.wikipedia.org/wiki/Компьютеры_пятого_поколения). За 10 лет планировалось разработать производительный суперкомпьютер и запустить его в серийное производство.

Почему новый компьютер отнесли к пятому поколению? Поколения компьютеров принято различать по рабочим элементам, которые выполняют элементарные вычисления. Таблица 2-4 демонстрирует четыре поколения компьютеров и соответствующие им рабочие элементы.

{caption: "Таблица 2-4. Поколения компьютеров", width: "100%"}
| Поколение | Рабочий элемент |
| --- | --- |
| Первое | [Электровакуумная лампа](https://ru.wikipedia.org/wiki/Электронная_лампа) |
|  | |
| Второе | [Транзистор](https://ru.wikipedia.org/wiki/Транзистор) |
|  | |
| Третье | [Интегральная схема](https://ru.wikipedia.org/wiki/Интегральная_схема) |
|  | |
| Четвёртое | [Микропроцессор](https://ru.wikipedia.org/wiki/Микропроцессор) |

До 1970-х годов Япония отставала в производстве компьютеров. Самыми передовыми технологиями в этой области владели США и Англия. Поэтому в середине 1970-х министерство международной торговли и промышленности Японии (MITI) начало исследовать перспективные компьютерные технологий. Это исследование было поручено Японскому центру развития обработки информации (JIPDEC).

Центр JIPDEC определил следующие перспективные направления:

* Технологии логического вывода для обработки знаний.
* Технологии для обработки баз знаний большого масштаба.
* Высокопроизводительные рабочие станции.
* [Параллельные вычисления](https://ru.wikipedia.org/wiki/Параллельные_вычисления).
* Суперкомпьютеры для научных вычислений.

Министерство MITI решило объединить работу по этим направлениям в одном проекте.

Чтобы достичь высокой производительности, разработчики решили применить многопроцессорную архитектуру. Большинство компьютеров того времени имели один процессор. Поэтому в любой момент времени они могли выполнять только одну программу.

Многопроцессорная архитектура позволяла решать несколько задач одновременно. В этом состоит суть параллельных вычислений. Также появлялась возможность разделить одну задачу на подзадачи и выполнять их все разом на нескольких процессорах.

В качестве парадигмы разработки программ для проекта было выбрано логическое программирование. Центр JIPDEC высоко оценил перспективы этого подхода. Поэтому языком программирования для суперкомпьютера стал Prolog, а не более универсальный Lisp.

На логическое программирование возлагались большие надежды. Ожидалось, что эта концепция хорошо сочетается с параллельными вычислениями. С её помощью планировалось реализовать следующие функции ИИ для суперкомпьютера:

* Распознавание речи и автоматический набор текста.
* Машинный перевод.
* Анализ печатного текста и его категоризация.
* Распознавание образов.
* Саморазвитие системы.

Другие страны не могли проигнорировать амбициозные планы Японии. В 1984 году правительство Великобритании запустило программу [Alvey](https://en.wikipedia.org/wiki/Alvey). Её целью стали исследования по следующим направлениям:

* Сверхбольшие интегральные схемы (VLSI).
* Системы ИИ, основанные на знаниях.
* Разработка программ.
* Интерфейс взаимодействия человека и машины.

Группа американских компаний объединилась и создала [корпорацию MCC](https://en.wikipedia.org/wiki/Microelectronics_and_Computer_Technology_Corporation), также известную как Консорциум Микроэлектроники и Компьютеров. Эта корпорация должна была спонсировать фундаментальные исследования в области ИИ и информационных технологий. В то же время управление министерства обороны США DARPA утроило финансирование в области ИИ.

К 1991 году японский проект компьютера пятого поколения не достиг поставленных целей. В рамках проекта инженеры собрали несколько рабочих станций. На них запускались следующие [демонстрационные приложения](https://instadeq.com/blog/posts/japans-fifth-generation-computer-systems-success-or-failure/):

* Распределённая система управления данными Kappa.
* [Правовая экспертная система](https://ru.wikipedia.org/wiki/Правовая_экспертная_система) HELIC-II.
* Система для доказательства теорем MGTP.
* Система для обработки естественного языка Laputa.

Полученные результаты оказались неудовлетворительными. В проект были инвестированы огромные средства и усилия. Но несмотря на это, рабочие станции не пошли в серийное производство и не попали на рынок. У этой неудачи было несколько причин.

Когда прототипы рабочих станций были готовы, они уже оказались устаревшими. Проект длился 10 лет. В момент его запуска исследователи предполагали, что однопроцессорные компьютеры достигли предела производительности. Специалисты пришли к выводу, что параллельные вычисления — это единственный способ увеличить мощность компьютера. Этот прогноз оказался неверным. Число транзисторов на интегральной схеме продолжало увеличиваться, согласно закону Мура. В результате к 1991 году недорогие однопроцессорные ПК, собранные на стандартных компонентах, превзошли по производительности рабочие станции пятого поколения.

Рабочие станции устарели не только из-за низкой производительности. Вместе с микропроцессорами развивались и информационные технологии. В 1984 году компания Apple разработала графический интерфейс для своих ПК. В начале 1990-х появился Internet. Рабочие станции пятого поколения не поддерживали эти передовые технологии. В результате они стали неинтересны пользователям.

Другая проблема компьютера пятого поколения связана с его программами. Разработчики выбрали концепцию логического программирования и язык Prolog. Но оказалось, что эта концепция плохо совместима с параллельными вычислениями. Сам язык Prolog не предоставлял средств для выполнения программы на нескольких процессорах. Все попытки добавить такие средства в язык провалились.

Запланированные возможности ИИ потребовали более производительного оборудования, чем ожидалось. Средств только логического программирования оказалось недостаточно для их реализации. Нужны были принципиально иные подходы к разработке систем ИИ.

Провал проекта компьютера пятого поколения повлиял на развитие информационных технологий в целом. Во-первых, проект подорвал веру разработчиков программ и учёных в логическое программирование. Недостатки этого подхода считались одной из главных причин неудачи проекта. Крупные исследования и финансирование этого направления ИИ прекратились.

Во-вторых, правительства США и Англии сократили инвестиции в компьютерные технологии и исследования ИИ. Эти страны остались лидерами в обеих областях. Япония прекратила попытки их догнать.

### 2.1.6 Развитие ИИ в 1993–2011

#### 2.1.6.1 Байесовская сеть

В начале 1990-х годов в исследованиях ИИ начал доминировать подход теоретиков (neat). Этому способствовали достижения коннекционизма в 1980-е годы. Оказалось, что существующие физические модели могут стать отправной точкой для разработки новых архитектур нейронных сетей.

Начали появляться новые статистические и математические подходы к разработке ИИ. Одним из них стала [**математическая оптимизация**](https://ru.wikipedia.org/wiki/Оптимизация_(математика)). Она занимается поиском наилучшего решения с заданными критериями между несколькими альтернативами.

В 1988 году учёный в области информатики Джудиа Перл опубликовал книгу "Вероятностное рассуждение в интеллектуальных системах" (Probabilistic Reasoning in Intelligent Systems). В ней автор предлагает теоретические основы и вычислительные методы для создания систем ИИ, которые принимают решения в условиях неопределённости. Книга получила признание среди специалистов. Она убедила многих в том, что теория вероятности и теория принятия решений применимы для ИИ.

Используя математический аппарат теории вероятностей, Джудиа Перл разработал модель [**байесовской сети**](https://ru.wikipedia.org/wiki/Байесовская_сеть). Эта модель отражает связи между множеством переменных и их вероятностными зависимостями по теореме Байеса. Эта теорема определяет вероятность события при условии, что произошло другое статистически взаимозависимое с ним событие.

Байесовская сеть представляет собой ориентированный ациклический граф. Его узлы — это некоторые переменные. Например, это могут быть симптомы и вызвавшие их заболевания в системе медицинской диагностики.

Ребра графа соответствуют вероятностным взаимосвязям между узлами. В случае системы медицинской диагностики они показывают причинно-следственную связь между симптомом и заболеванием.

Для каждого ребра определяется условная вероятность. Она отражает вероятность переменной с учётом её родителей. Родитель — это узел из которого выходит ребро, входящее в данный узел. В медицинской системе условная вероятность может определятся экспертами, клиническими испытаниями и статистическими данными. 

Готовая байесовская сеть получает на вход данные. Для системы диагностики данные — это симптомы пациента. По ним сеть выдаёт наиболее вероятный диагноз.

Мы рассмотрели **причинно-следственную байесовскую сеть** (causal bayesian network). Кроме неё есть и другие виды байесовских сетей:

1. **Статическая** (Static Bayesian Network) — в ней отношения между переменными фиксированы и не меняются.

2. **Динамическая** (Dynamic Bayesian Network) — может моделировать временные зависимости и изменения во времени. Используется, когда моделируемая система подвержена динамическим процессам.

3. **Гибридная** (Hybrid Bayesian Network) — объединяет разные типы переменных: дискретные и непрерывные. Используется, когда переменные имеют разные типы данных.

4. **Временные** (Temporal Bayesian Network) — обобщённая версия динамической сети. Может обрабатывать данные [**временных рядов**](https://ru.wikipedia.org/wiki/Временной_ряд). Временной ряд — это замеры каких-либо параметров в разные моменты времени.

5. **Скрытая марковская модель** (Hidden Markov Model или HMM) — особый вид динамической сети, который используют для моделирования последовательностей наблюдаемых событий со скрытыми состояниями. HMM решает задачи распознавания речи, обработки естественного языка и последовательного анализа данных.

6. **Диаграмма влияния** (Influence Diagram) — представляют собой единую графическую модель, которая включает неопределённость и данные для принятия решений. Используются в задачах анализа решений и оптимизации.

7. **Полидеревья и цепные графы** (Polytrees and Chain Graphs). Байесовская сеть представляет собой направленный ациклический граф. Полидеревья и цепные графы ослабляют это ограничение. Полидеревья допускают не более одного цикла. Цепные графы могут содержать как ориентированные, так и неориентированные ребра.

Алгоритмы машинного обучения применимы ко всем видам байесовских сетей. На основе обучающих данных определяют структуру и параметры этих сетей для каждой конкретной задачи.

#### 2.1.6.2 Интеллектуальные агенты

В 1995 году Стюарт Рассел и Питер Норвиг опубликовали книгу "Искусственный интеллект: современный подход". В ней авторы предложили концепцию **интеллектуального агента**. Она заимствована из экономики и теории принятия решений. В этих науках есть понятие рационального агента. Интеллектуальный агент — это тот же рациональный агент только в контексте ИИ.

В экономике рациональный агент стремится максимизировать свою прибыль. Точно так же интеллектуальный агент пытается максимизировать свою эффективность при решении поставленной задачи.

Большинство исследователей согласилось с концепцией интеллектуального агента. Это разрешило несколько философских проблем в области ИИ. Первой проблемой были разногласия учёных о том, что именно считать интеллектом. Тест Тьюринга подразумевает сравнение искусственных систем с человеческим интеллектом. Понятие рационального агента устранило это сравнение. Теперь любое поведение агента стало интеллектуальным, если оно приводит к эффективному достижению цели.

Вторая философская проблема заключалась в вопросе: может ли машина обладать сознанием и настоящим пониманием? Учёные давали разные ответы на этот вопрос. В зависимости от своей точки зрения, они выбирали соответствующее направление исследований. Для интеллектуального агента сознание и понимание оказались совершенно неважны. Новая концепция ставила на первое место эффективность решения. Метод поиска решения мог быть любым.

Теперь исследователи смогли сконцентрироваться на решении конкретных практических задач. Им больше не надо было защищать свои методы с философской точки зрения. Достаточно было математически  доказать их эффективность.

Концепция интеллектуального агента помогла исследователям не только с философской, но и с практической точки зрения. Она дала надёжный и научный способ сравнивать системы, основанные на разных подходах. Принцип их работы отошёл на второй план. Теперь главным показателем стала заданная **функция полезности**. Если агент лучше максимизирует эту функцию, он лучше справляется с поставленной задачей. Благодаря новому методу оценки, учёные стали быстрее добиваться практических результатов.

Раньше каждый исследователь работал в рамках только одного подхода (например, коннекционизма). Когда приоритетом стала измеряемая эффективность, учёные начали совмещать разные подходы в одной системе. В некоторых случаях такие эксперименты давали положительные результаты.

Формальные методы оценки результатов дали исследователям ИИ средство общения с другими научными направлениями. Математическая оптимизация, теория вероятностей и теория принятия решений внесли свой вклад в развитие ИИ. Использование математического аппарата ускорило обмен идеями со смежными науками.

#### 2.1.6.3 Восстановление репутации ИИ

Многие инвесторы разочаровались в области ИИ после краха рынка Lisp-машин, проблем с экспертными системами и провала проекта компьютера пятого поколения. Правительства стран и компании потеряли деньги, когда пузырь экспертных систем лопнул. Они больше не хотели вкладываться в исследования ИИ.

На протяжении 1990-х годов учёные избегали термина "искусственный интеллект". Считалось, что он означает невыполнимые обещания и отпугивает инвесторов. Вместо этого исследователи ИИ называли свою работу информатикой, когнитивными системами или вычислительным интеллектом. Это привело к двум долгосрочным последствиям:

1. [Алгоритмы и концепции](https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence#Historical_contributions), разработанные в рамках исследований ИИ, начали интегрировать в обычные компьютерные системы. Как следствие, эти достижения ошибочно считаются результатом развития информатики, а не ИИ.

2. Область ИИ оказалась раздробленной. Достижения учёных 1990-х годов приписываются новым, выдуманным им направлениям. На самом деле все эти достижения относятся к ИИ.

В конце 1990-х и 2000-х годах несколько систем ИИ достигли впечатляющих успехов. Они широко освещались в СМИ и привлекли общественное внимание. Благодаря этому, испорченная репутация науки об ИИ была частично восстановлена.

Вот некоторые из самых известных систем ИИ:

* В 1997 году суперкомпьютер [DeepBlue](https://ru.wikipedia.org/wiki/Deep_Blue) от IBM обыграл чемпиона мира по шахматам Гарри Каспарова.

* В 2005 году робот, разработанный в Стэнфордском университете, победил в гонках [DARPA Grand Challenge](https://ru.wikipedia.org/wiki/DARPA_Grand_Challenge). Автономно управляемая машина смогла проехать весь маршрут в 211 километров по пустыне Мохаве. На это у робота ушло почти семь часов.

* В 2011 году ИИ система [Watson](https://ru.wikipedia.org/wiki/IBM_Watson) от компании IBM обыграла двух лучших игроков в телевизионной игре-викторине Jeopardy!. В этой игре участники отвечают на вопросы из области общих знаний.

Причиной успехов стала выросшая производительность компьютеров и качественная разработка программ. Каждая из нашумевших ИИ систем использовала хорошо известные подходы, появившиеся ещё в 1960-х годах.

### 2.1.7 Современные направления ИИ

С середины 2010-х годов вокруг исследований в области ИИ начался очередной ажиотаж. Журналисты назвали этот период "Возрождением ИИ" (AI Renaissance).

Новый бум ИИ стал следствием быстрого прогресса и повышенным вниманием СМИ. Погресс стал возможным благодаря удачному стечению ряда событий:

1. Американский учёный [Эндрю Ын](https://ru.wikipedia.org/wiki/Ын,_Эндрю) предложил использовать [графические процессоры](https://ru.wikipedia.org/wiki/Графический_процессор) (GPU) для моделирования нейронных сетей. Это позволило эффективно обучать более крупные и сложные модели, чем раньше.

2. Распространение цифровых данных в различных форматах (изображения, текст, видео, данные датчиков) стало источником огромного объёма исходных данных для обучения моделей ИИ.

3. Исследователи ИИ разработали эффективные алгоритмы глубокого обучения (deep learning) нейронных сетей. Их применение на практике увеличило производительности моделей в задачах распознавания образов, обработки естественного языка и обучения с подкреплением.

4. Доступность [фреймворков](https://ru.wikipedia.org/wiki/Фреймворк) (программных платформ) и библиотек для работы с нейронными сетями. Например, [TensorFlow](https://ru.wikipedia.org/wiki/TensorFlow) от Google и [PyTorch](https://ru.wikipedia.org/wiki/PyTorch) от Facebook. Эти инструменты стали распространяться с открытым исходным кодом. Так разработчики, исследователи и просто энтузиасты получили возможность экспериментировать и внедрять модели ИИ в свои приложения.

5. Корпорации Amazon, Microsoft и Google предоставили сервис облачных платформ. Через него организации и частные лица получили доступ к мощным вычислительным ресурсам. Это позволило всем желающим экспериментировать с ИИ без значительных предварительных инвестиций.

6. Правительства и инвесторы осознали потенциал ИИ и начали вкладывать значительные средства в исследования и разработку приложений.

В совокупности эти факторы привели к крупным успехам систем ИИ в областях распознавания образов и обработки естественного языка. Эти достижения вдохновили учёных на дальнейшие исследования.

Рассмотрим некоторые из предпосылок нового периода возрождения ИИ.

#### 2.1.7.1 Платформа для моделирования нейронных сетей

В конце 1990-х и начале 2000-х годов нейронные сети и машинное обучение были малопопулярными направлениями. Над ними продолжали работать отдельные группы учёных. Их немногочисленные публикации читали только коллеги, так же работавшие в рамках коннекционизма.

Проблема подходящей аппаратной платформы для моделирования нейронных сетей по-прежнему оставалась нерешенной. Это сильно тормозило их исследование и применение на практике. В начале 2000-х годов обучаемые модели стали очень сложными. Работа с ними на обычных компьютерах требовала слишком много времени.

Эндрю Ын вел курс "Machine Learning" в Стэнфордском университете в 2011 году. На одной из лекций он рассказал о преимуществах использования графических процессоров для обучения нейронных сетей. Видео этих лекции стало доступно через интернет. Так идея Эндрю Ына стала широко известна. Примерно в это же время группы исследователей и компании производители оборудования уже экспериментировали с GPU и машинным обучением.

В 2007 году компания Nvidia выпустила платформу [CUDA](https://ru.wikipedia.org/wiki/CUDA) (Compute Unified Device Architecture). Она позволяла разработчикам программ переносить часть своих вычислений с процессора (CPU) на GPU. Изначально Nvidia рассматривала свой продукт, как средство ускорения работы обычных пользовательских приложений.

Основное преимущество GPU перед CPU в параллельной обработке больших блоков данных. Современный графически процессор имеет от несколько сотен до нескольких тысяч ядер. Каждое из них может работать независимо от других. Поэтому GPU отлично справляется с параллельными вычислениями. Они встречаются в алгоритмах шифрования и сортировки, программах моделирования физики и научных вычислениях. Моделирование нейронных сетей — это тоже обработка больших блоков данных, которую можно распараллелить.

Благодаря работе Эндрю Ына и других исследователей, GPU от Nvidia и CUDA стали основной программно-аппаратной платформой для работы с нейронными сетями.

#### 2.1.7.2 Big Data

В конце 1990-х начале 2000-х годов пользователи компьютерных систем столкнулись лавинообразным ростом цифровых данных. До этого времени проблема обработки данных большого объема возникала только в некоторых областях: научные исследования, финансы, телекоммуникации.

В начале 2000-х годов ситуация изменилась по нескольким причинам. Прежде всего из-за распространения компьютеров. Все больше компаний и правительственных учреждений начали переходить на электронный документооборот. В результате начали накапливаться огромные объёмы информации, которые надо было хранить и обрабатывать.

Интернет становился все более популярен среди рядовых пользователей ПК. Росло число сайтов и онлайн-сервисов, появились первые социальные сети. Пользователи и системы начали генерировать большие объемы данных. Эти данные представляют интерес для владельцев онлайн-сервисов и компаний в сфере интернет-торговли.

В конце 1990-х годов появилась концепция [**интернета вещей**](https://ru.wikipedia.org/wiki/Интернет_вещей) (Internet of things или IoT). Её идея в объединении небольших устройств, оснащённых датчиками в компьютерную сеть. На протяжении 2000-х годов эта технология почти не применялась на практике. Проблема была в высокой стоимости микроконтроллеров и датчиков. В начале 2010-х годов эта проблема была решена. На рынке появились недорогие узкоспециализированные чипы с различными возможностями. Интернет вещей начали внедрять в различных областях: производство, энергетика, сельское хозяйство, здравоохранение. Это создало огромные потоки данных, требующие обработки.

Возникло новое направление компьютерных наук под названием [**большие данные**](https://ru.wikipedia.org/wiki/Большие_данные) (big data). Оно изучает и разрабатывает новые методы обработки наборов данных, которые слишком велики для применения традиционных подходов.

Впервые термин big data использовал учёный [Джон Маши](https://en.wikipedia.org/wiki/John_Mashey) в своей статье 1998 года "Большие данные и следующая волна ИнфраСтресса" (Big Data and the Next Wave of InfraStress). В ней он обсуждает проблемы, связанные с крупномасштабными наборами данных. Автор утверждает, что для их обработки нужны новые инновационные технологии.

Дуг Лэйни работал аналитиком данных в американской исследовательской и консалтинговой компании [Gartner](https://ru.wikipedia.org/wiki/Gartner). В 2001 году он предложил характеризовать big data тремя V:

* **Volume** (объём). Количество сгенерированных и сохранённых данных. Обычно составляет от нескольких терабайт до петабайт. Объём данных определяет их ценность и полезность.

* **Velocity** (скорость). Скорость генерации и обработки данных. Big data обычно обновляются непрерывно, в режиме реального времени. Для решения задач их надо обрабатывать со скоростью близкой к реальному времени.

* **Variety** (разнообразие). Технологии big data рассчитаны на обработку плохо структурированных и неструктурированных данных разных типов: текст, изображения, видео, аудио и т.д.

Эти характеристики big data считаются основными и общепризнанными. Некоторые исследователи и аналитики добавляют к ним что-то свое. Поэтому сейчас в интернете можно найти много статей с разным описанием big data. Но в каждой из них всегда есть три V, предложенные Дугом Лэйни.

Для обработки больших объемов данных не достаточно одного инструмента. В этой области сформировалась целая экосистема платформ, технологий и инструментов. Они решают задачи хранения, организации, анализа и извлечения информации из огромных объёмов данных.

Вот некоторые из ключевых технологий big data:

1. Распределенные вычислительные платформы:

* [**Apache Hadoop**](https://ru.wikipedia.org/wiki/Hadoop): платформа с открытым исходным кодом для распределенного хранения и обработки больших наборов данных. Она основана на вычислительной программирования [**MapReduce**](https://ru.wikipedia.org/wiki/MapReduce). Согласно ей обработка данных разделяется на одинаковые элементарные задания. Они исполняются на узлах кластера компьютеров и сводятся в конечный результат.

* [**Apache Spark**](https://ru.wikipedia.org/wiki/Apache_Spark): универсальная платформа кластерных вычислений, поддерживающая пакетную обработку, потоковую обработку в реальном времени, машинное обучение и обработку графов.

* [**Apache Flink**](https://ru.wikipedia.org/wiki/Apache_Flink): инфраструктура потоковой обработки, которая также может выполнять пакетную обработку и предлагает возможности обработки данных с малой задержкой.
         
2. Распределённые системы хранения.

* Hadoop Distributed File System (HDFS): распределённая файловая система, которая хранит огромные объёмы данных в кластере компьютеров. Является частью платформы Apache Hadoop.

3. Базы данных [**NoSQL**](https://ru.wikipedia.org/wiki/NoSQL) и [**NewSQL**](https://ru.wikipedia.org/wiki/NewSQL)  представляют собой средства для хранения больших объемов неструктурированных данных и быстрого доступа к ним.

4. [**Облачные система хранения**](https://ru.wikipedia.org/wiki/Облачная_система_хранения) — это модель хранения данных в сети компьютеров. Пространство для хранения арендуется у компании, которая владеет этой сетью и обслуживает её. Примеры таких сервисов: Amazon Redshift, Google BigQuery, Snowflake.

5. Машинное обучение и аналитика:

* TensorFlow, PyTorch: библиотеки с открытым исходным кодом для создания и обучения моделей машинного обучения на больших наборах данных.

* [**Apache Mahout**](https://ru.wikipedia.org/wiki/Apache_Mahout): библиотека машинного обучения, построенная на основе Hadoop и Spark.

6. Визуализация данных:

* Tableau, Microsoft Power BI, QlikView: инструменты для создания интерактивных визуализаций данных и информационных панелей из больших наборов данных.

Технологии big data применяются в разных областях для получения информации, оптимизации процессов и принятия обоснованных решений. Вот некоторые из таких областей:

1. Электронная коммерция и розничная торговля.

* Анализ поведения клиентов для персонализированных рекомендаций и таргетированного маркетинга.

* Управление запасами и оптимизация цепочки поставок.

* Выявление и предотвращение мошенничества.

2. Финансы и банковское дело:

* Оценка рисков и обнаружение мошенничества.

* [**Алгоритмическая торговля**](https://ru.wikipedia.org/wiki/Алгоритмическая_торговля) — это метод исполнения крупной сделки на финансовом рынке путем её разделения на ряд мелких сделок. Это нужно для минимизации влияния на рынок и риска неисполнения сделки,

* Инвестиционный анализ.

* Анализ настроений клиентов для улучшения обслуживания клиентов.

3. Здравоохранение:

* Анализ данных пациентов для создания персональных планов лечения.

* Разработка новых лекарств путём сбора и анализа статистических данных.

* Предсказание и анализ вспышек заболеваний и эпидемий.

4. Телекоммуникации:

* Оптимизация сети и мониторинг для улучшения качества обслуживания.

* Прогнозирование оттока клиентов.

* Геолокационные сервисы и таргетированная реклама.

5. Производство и промышленность:

* Профилактическое обслуживание оборудования для сокращения времени его простоя и повышения эффективности.

* Контроль качества посредством анализа данных в режиме реального времени.

* Оптимизация цепочки поставок и прогнозирование спроса.

6. Транспорт и логистика:

* Оптимизация маршрутов для транспортных сетей.

* Отслеживание транспортных средств и грузов в режиме реального времени.

* Прогнозирование спроса и планирование мощностей.

Big data активно использует алгоритмы и решения машинного обучения. В то же время специалисты из это области разрабатывают новые подходы для обработки больших данных, которые применяются в передовых исследованиях ИИ. Поэтому big data и ИИ являются смежными направлениями. Они развиваются параллельно и взаимно дополняют друг друга.

#### 2.1.7.3 Deep Learning

##### 2.1.7.3.1 Особенности нового направления

Термин [**deep learning**](https://ru.wikipedia.org/wiki/Глубокое_обучение) появился в конце 1980-х годов. Его употребляли только специалисты машинного обучения. Широкую известность он получил в 2000-х годах. Deep learning дословного переводится как "глубокое обучение". Это собирательное название для семейства методов машинного обучения, которые работают с нейронными сетями.

Сложность обучаемых моделей — это главное отличие методов deep learning. Они работают с нейронными сетями, имеющими несколько скрытых слоёв и сотни параметров.

Для всех методов, которые не относятся к deep learning, появился новый термин **shallow learning** (поверхностное обучение). Это собирательное название для более простых алгоритмов и обучения нейронных сетей с одним скрытым слоем. Примеры shallow learning алгоритмов: метод опорных векторов, дерево решений, линейная регрессия и т.д.

Вот ключевые различия между deep learning и shallow learning:

1. Сложность обучаемой модели.

2. [**Feature engineering**](https://habr.com/ru/companies/ruvds/articles/680498/) (конструирование признаков) — это извлечение важных для модели признаков (входных параметров) из исходных данных.

* Deep learning модели автоматически извлекают признаки из исходных данных. Это происходит благодаря способности сети распознавать сложные закономерности.

* Для shallow learning моделей необходима ручное конструирование признаков. Из всего множества признаков, встречающихся в исходных данных, разработчик должен определить самые важные для решаемой задачи. Затем отобранные признаки надо преобразовать в удобный для выбранной модели формат. Конечный результат алгоритма обучения сильно зависит от качества конструирования признаков.

3. [**Representation learning**](https://analyticsindiamag.com/a-comprehensive-guide-to-representation-learning-for-beginners/) (обучение представлению) — это способность модели интерпретировать исходные данные.

* Deep learning модели эффективно представляют исходные данные в виде иерархий абстракций и таким образом понимают сложные закономерности. Каждый слой или набор слоев нейронной сети распознаёт отдельный уровень абстракций. Пример уровней абстракции в порядке возрастания сложности на изображении: отдельные линии, геометрические фигуры (треугольник, квадрат и т.д.), объекты (дом, автомобиль и т.д.).

* Shallow learning модели не способны самостоятельно строить сложные иерархии абстракций. Эти модели полностью полагаются на ручное конструирование признаков и заложенные в них простые абстракции.

4. Требования к исходным данным.

* Deep learning: для качественного обучения сложных моделей нужны исходные данные большого объёма.

* Shallow learning: для обучения моделей достаточно небольших наборов исходных данных. Но качество обучения сильно зависит от результата конструирования признаков.

5. Требования к вычислительным ресурсам.

* Обучение deep learning моделей требует значительных вычислительных ресурсов и специализированного оборудования (например, GPU). Даже используя большие вычислительные мощности, алгоритм обучения может выполнятся несколько дней или недель.

* Shallow learning модели можно обучать на стандартных процессорах. Работа алгоритмов обучения, как правило, не занимает много времени.

6. Интерпретируемость результатов модели

* Deep learning модели из-за своей сложности работают по принципу "чёрного ящика". Разработчикам очень сложно понять, почему сеть приходит к тому или иному выводу.

* Shallow learning модели проще анализировать. Разработчики обычно знают, как именно модель принимает решения.

##### 2.1.7.3.2 История deep learning

История возникновения deep learning началась в 1960-е годы. Первым, кто исследовал многослойные нейронные сети, был Фрэнк Розенблатт. Его исследования ограничивались только теоретическими выводами. Для моделирования многослойной сети нужно высокопроизводительное оборудование. Поэтому технической возможности экспериментировать с этим видом сетей не было до 1980-х годов.

В 1979 году японский учёный [Кунихико Фукусима](https://en.wikipedia.org/wiki/Kunihiko_Fukushima) разработал новую архитектуру нейронной сети [**неокогнитрон**](https://en.wikipedia.org/wiki/Neocognitron). Её прообразом стала модель, предложенная в 1959 году нейрофизиологами Дэвидом Хьюбелом и Торстеном Визелем. Эта модель описывает устройство зрительной коры человека, в которой два типа клеток (простая и сложная) расположены каскадно. Кунихико Фукусима спроектировал неокогнитрон для распознавания рукописных японских иероглифов.

Неокогнитрон стал прототипом новой архитектуры, получившей название [**свёрточная нейронная сеть**](https://ru.wikipedia.org/wiki/Свёрточная_нейронная_сеть) (convolutional neural network или CNN). Она является подвидом сети с прямой связью (FNN) и оптимизирована для одной единственной задачи — распознавание образов.

В 1989 году французский учёный [Ян Лекун](https://ru.wikipedia.org/wiki/Лекун,_Ян) решал задачу распознания рукописных почтовых индексов на конвертах. Он применил метод backpropagation для свёрточной нейронной сети (CNN). После трёх дней обучения сеть смогла распознавать индексы. Свои результаты учёный описал в статье "Применение обратного распространение ошибки к распознаванию рукописного почтового индекса" (Backpropagation Applied to Handwritten Zip Code Recognition). В 1998 году на основе этого решения Ян Лекун разработал сеть LeNet-5. Она распознавала любые рукописные цифры. Несколько банков использовали её для автоматической обработки чеков.

В 1980-х исследователи начали экспериментировать со сложными моделями нейронных сетей. Попытки обучить их методом обратного распространения ошибки привели к [**проблеме исчезающего градиента**](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). В машинном обучении **градиентом** называется скорость изменения функции по отношению к её входным переменным. Градиент даёт информацию о том, как небольшие изменения входных параметров влияют на результат функции.

Проблема исчезающего градиента связана с процессом **присвоения кредитов** (credit assignment) в ходе обучения модели. Присвоение кредитов означает расчёт вклада отдельных нейронов и их соединений в конечный результат работы сети.

В многослойных сетях влияние активации отдельного нейрона может иметь долгосрочное влияние на конечный результат. Другими словами эффекты активации нейрона могут распространятся через несколько слоев сети, прежде чем внести свой вклад. Во время обучения информация в модели распространяется в обратном направлении через множество слоёв. Это может привести к тому, что градиенты становятся чрезвычайно малыми (исчезающий градиент), либо чрезвычайно большими (**взрывающийся градиент**). В результате обучение идёт медленно или оказывается неэффективным.

Первую попытку решить проблему исчезающего градиента предпринял [Юрген Шмидхубер](https://ru.wikipedia.org/wiki/Шмидхубер,_Юрген) в 1992 году. Он предложил обучать каждый слой нейронной сети отдельно. Затем обученную иерархию слоев надо свернуть в единую нейронную сеть. Так получалась законченная модель.

Работа с отдельными слоями решала не только проблему исчезающего градиента, но и недостаточной вычислительной мощности. Обучение сложной модели целиком требовало слишком много времени в 1990-е годы. Этот процесс проходил быстрее при разделении его на отдельные шаги: обучение только одного слоя за раз.

Юрген Шмидхубер работал с [**рекуррентными нейронными сетями**](https://ru.wikipedia.org/wiki/Рекуррентная_нейронная_сеть) (recurrent neural network или RNN). Информационный поток в нейронных сетях с прямой связью (FNN) однонаправленный. Это означает, что информация в модели распространяется только в одном направлении — вперёд: от входных узлов через скрытые узлы к выходным узлам без циклов и петель. Рекуррентные нейронные сети в отличие от FNN имеют замыкающиеся связи. Поэтому поток информации в RNN двунаправленный.

Благодаря двунаправленному потоку информации, RNN используют результаты предыдущего временного шага в качестве входных данных для текущего временного шага. Таким образом сеть эффективно изучает и фиксирует закономерности в последовательностях. Поэтому архитектура RNN хорошо подходит для обработки естественного языка, распознавания речи, анализа временных рядов и подобных задач.

В 1991 году Зепп Хохрайтер посвятил свою дипломную работу проблеме исчезающего градиента при обучении рекуррентных нейронных сетей. Он предложил добавить так называемые **остаточные соединения** (residual connections) в архитектуру сети. Эти соединения работают как короткий путь между не соседними, удалёнными друг от друга слоями сети. Таким образом поток информации игнорирует один или несколько слоев. Благодаря остаточным соединениям, алгоритм обучения может лучше оценить разницу между входом и желаемым выходом модели.

В 1997 году Зепп Хохрайтер и Юрген Шмидхубер развили идею остаточных соединений. Они разработали архитектуру нейронной сети, названную [**длинная цепь элементов краткосрочной памяти**](https://habr.com/ru/companies/wunderfund/articles/331310/) (long short-term memory или LSTM). Это особая разновидность рекуррентных сетей, которая может обучаться долговременным зависимостям. Тем самым в ней решается проблема исчезающего градиента.

LSTM использует специальную структуру **ячеек** (cell), **вентилей** (gate) и модулей памяти. Ячейки — это элементарные строительные блоки LSTM сети. Они содержат в себе вентили и модули памяти. Механизм вентилей управляет потоком информации и памятью внутри сети. Благодаря ему, LSTM способна собирать и сохранять информацию в течении нескольких временных шагов.

В 2006 году Джеффри Хинтон, [Руслан Салахутдинов](https://ru.wikipedia.org/wiki/Салахутдинов,_Руслан_(учёный)), Саймон Осиндеро и [Йи Вай Тех](https://en.wikipedia.org/wiki/Yee_Whye_Teh) опубликовали несколько статей. Учёные повторили подход Юргена Шмидхубера с обучением каждого слоя отдельно. Отличие нового исследования было в том, что команда Джеффри Хинтона работала не с RNN, а с сетями с прямой связью (FNN). Теперь исследователи могли эффективно обучать модели любого типа (RNN и FNN) на обычных компьютерах за приемлемое время.

Исследователи нейронных сетей были вынуждены обучать свои модели послойно до 2010-х годов. В 2011 году значительно выросла производительность GPU. Благодаря идеям Эндрю Ына и усилиям Nvidia, CUDA стала надёжной платформой для разработки алгоритмов обучения нейронных сетей. Теперь сложные модели можно было обучать целиком, а не послойно. Это упростило и ускорило эксперименты с нейронными сетями. Пр этом проблема исчезающего градиента решалась специальными архитектурами сетей, например LSTM.

В 2009 году Фей-Фей Ли из Принстонского университета представила свой проект [**ImageNet**](https://ru.wikipedia.org/wiki/ImageNet) на конференции, посвященной компьютерному зрению. Проект заключался в подготовке огромной базы изображений. Для каждого изображения вручную составлялась аннотация с перечислением попавших на него объектов и их координат. Чтобы подготовить аннотацию изображений, Фей-Фей Ли воспользовалась краудсорсинговой платформой Amazon Mechanical Turk.

Начиная с 2010 года Фей-Фей Ли запустила проект ILSVRC (ImageNet Large Scale Visual Recognition Challenge). Это открытые соревнования между исследовательскими группами. В ходе соревнований обученные модели распознают и классифицирую объекты на изображениях из базы ImageNet.

Ежегодные соревнования ILSVRC привлекли внимание специалистов и СМИ со всего мира. Это событие стало престижным, благодаря известности его участников. База ImageNet свободно доступна через интернет. Любой желающий может её скачать и начать экспериментировать с моделями. Это привело к быстрому прогрессу в задаче распознавания образов.

В 2011 году пятерка лучших моделей распознавала образы с 25% ошибок. В 2012 году глубокая сверточная сеть AlexNet достигла результата в 16% ошибок. Эту сеть разработали Джеффри Хинтон, [Алексей Крижевский](https://en.wikipedia.org/wiki/Alex_Krizhevsky) и [Илья Суцкевер](https://ru.wikipedia.org/wiki/Суцкевер,_Илья). К 2014 году процент ошибок у лучших моделей упал до нескольких процентов. В 2015 году появились сообщения, что некоторые модели превосходят человеческие способности. Однако, эти модели могли распознавать изображения примерно из тысячи категорий. Человек же способен различать намного больше категорий изображений и лучше оценивать их контекст.

Соревнование ILSVRC было не единственным связанным с компьютерным зрением. Кроме него были менее известные ежегодные конкурсы. Например, по распознаванию рукописного китайского текста (ICDAR), выявления раковых опухолей на медицинских изображениях (ICPR), распознаванию речи (Interspeech). Модели на глубоких свёрточных сетях доминировали во всех соревнованиях по распознаванию образов. В распознавании речи лучшие результаты показывали LSTM модели.

Успехи глубоких нейронных сетей в престижных соревнованиях сделали этот подход трендом в современных исследованиях. С 2010-х годов началась так называемая ["революция глубокого обучения"](https://en.wikipedia.org/wiki/Deep_learning#Deep_learning_revolution) в ИИ.
