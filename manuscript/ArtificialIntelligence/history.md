## 2.1 История

Искусственный интеллект (ИИ) как направление исследований появился на стыке нескольких дисциплин. На ИИ оказали влияние идеи, достижения и методы из нескольких наук. Таблица 2-1 демонстрирует эти науки.

{caption: "Таблица 2-1. Науки, оказавшие влияние на ИИ", width: "100%"}
| Наука | Применяемая в ИИ теория, идея или метод |
| --- | --- |
| Нейрофизиология | Модель искусственного нейрона и нейронной сети |
|  | |
| Математика | Правила формальной логики и логического вывода |
|  | Статистические методы |
|  | Теория вероятностей |
|  | Теория принятия решений |
|  | |
| Информатика | Языки программирования |
|  | Теория вычислительной сложности |
|  | Высокопроизводительные компьютеры |
|  | |
| Кибернетика | Теория управления сложных систем |

Рассмотрим подробнее, как развивался ИИ и почему именно эти науки оказали на него влияние.

### 2.1.1 Появление новой науки 1943 – 1956

#### 2.1.1.1 Нейронная сеть

##### 2.1.1.1.1 Искусственный нейрон

Первая исследовательская работа в области ИИ связана с нейрофизиологией и математикой. Американские учёные [Уоррен Мак-Каллок](https://ru.wikipedia.org/wiki/Мак-Каллок,_Уоррен) и [Уолтер Питтс](https://ru.wikipedia.org/wiki/Питтс,_Уолтер) исследовали мозг человека.

Уоррен Мак-Каллок был известным нейрофизиком. Он изучал медицину в Колледж врачей и хирургов Колумбийского университета в Нью-Йорке, где в 1927 году получил степень доктора медицины. После этого занимался медицинской практикой до 1937 года. После неё Мак-Каллок работал в Лаборатории нейрофизиологии Йельского университета. В 1941 году он переехал в Чикаго и поступил на кафедру психиатрии Иллинойского университета в Чикаго, где был профессором психиатрии.

Уолтер Питтс был самоучкой из бедной семьи. В 1935 году в возрасте 12 лет Питтс прочитал "Основания математики" Бертрана Рассела. Он нашел в книге несколько ошибок и написал о них автору. Благодаря этой переписке с известным английским математиком, Уолтер Питтс смог получить образование в Иллинойсском университете в Чикаго. Его специальностью была [математическая логика](https://ru.wikipedia.org/wiki/Математическая_логика).

Уоррен Мак-Каллок и Уолтер Питтс познакомились Иллинойсском университете. Они объединили свои знания и усилия, чтобы найти логические закономерности работы мозга. Так учёные разработали математическую модель связанных между собой [**искусственных нейронов**](https://ru.wikipedia.org/wiki/Искусственный_нейрон). Эта модель позднее получила название [**binary threshold neurons**](https://www.youtube.com/watch?v=iKKfoP-naN8) (бинарный пороговый нейрон).

[**Нейрон**](https://ru.wikipedia.org/wiki/Нейрон) — это клетка, которая является минимальным строительным блоком [**нервной системы**](https://ru.wikipedia.org/wiki/Нервная_система) человека. Нейроны соединяется друг с другом в [нервную сеть](https://ru.wikipedia.org/wiki/Нервная_сеть), по которой проходят электрические и химические сигналы. С помощью этих сигналов передаётся информация между узлами нервной системы.

Бинарный пороговый нейрон представляет собой упрощённую модель биологического нейрона. Эта модель имеет два состояния: возбуждённое и невозбуждённое. На вход нейрон получает сигналы от других нейронов. Он обрабатывает их с помощью [**функции активации**](https://ru.wikipedia.org/wiki/Функция_активации). Её результат передаётся на выход нейрона, который связан со входами других нейронов.

Функция активации бинарного порогового нейрона называется **ступенчатой** ([step function](https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Activation_Functions#Step_Function)). В виде формулы её можно записать следующим образом:
{width: "50%"}
![](images/ArtificialIntelligence/binary-threshold-neuron-activation-function.png)

Здесь m означает число входных сигналов нейрона. 

Иллюстрация 2-1 демонстрирует график функции активации. Значения функции f(x) отображаются на оси Y. На оси X — значения суммы входных сигналов x. Когда эта сумма достигает значения θ, нейрон переходит в возбуждённое состояние. Его выходной сигнал становится равен единице.

{caption: "Иллюстрация 2-1. Ступенчатая функция активации бинарного порогового нейрона", height: "30%"}
![Ступенчатая функция активации бинарного порогового нейрона](images/ArtificialIntelligence/binary-threshold-neuron-activation-function-graph.png)

Мак-Каллок и Питтс предложили соединить несколько искусственных нейронов так, чтобы выходные сигналы одних служили входными сигналами для других. Такое соединение получило название [**нейронная сеть**](https://ru.wikipedia.org/wiki/Нейронная_сеть).

Мак-Каллок и Питтс доказали, что нейронная сеть способна выполнять числовые и логические операции. Кроме того они предположили, что сети с особенной архитектурой способны обучаться. Свои результаты учёные опубликовали в 1943 году в статье "Логическое исчисление идей, относящихся к нервной активности" (A Logical Calculus of Ideas Immanent in Nervous Activity).

Модель Мак-Каллока и Питтса была только теоретической. Свои гипотезы они подтверждали математическими выкладками. Не существовало программы или устройства, которое бы работало как нейронная сеть и подтверждало идеи учёных на практике.

##### 2.1.1.1.2 Обучение нейронной сети

Мак-Каллок и Питтс продемонстрировали вычислительный потенциал нейронных сетей. В своей работе они представили нейронные сети как универсальные механизмы для выполнения вычислений. Но чтобы применить этот механизм для решения реальных задач, нужны были средства управления сетью. Для универсальных компьютеров такими средствами управления стали программы. Это же решение не подходило для нейронных сетей. Для них нужен был принципиально иной подход.

В 1949 году канадский нейропсихолог [Дональд Хебб](https://ru.wikipedia.org/wiki/Хебб,_Дональд) опубликовал книгу "Организация поведения: нейропсихологическая теория" (Organization of Behavior). Будучи по образованию психологом, он изучал влияние хирургии и травм головного мозга человека на его функции. Также он проводил эксперименты на животных, чтобы выяснить как обучение в детском возрасте влияет на их поведение. Результаты своих исследований и их трактовку Дональд Хебб привёл в своей книге.

Книга посвящена не искусственным нейронным сетям, а нейробиологии. На момент её написания существовало несколько теорий поведения человека: [бихевиоризм](https://ru.wikipedia.org/wiki/Бихевиоризм), [гештальтпсихология](https://ru.wikipedia.org/wiki/Гештальтпсихология) и другие. Каждая из теорий хорошо объясняла некоторые функции, но имела трудности с другими.

Дональд Хебб объединил существующие данные о поведении и мозге в единую теорию. Она основана на связях между биологическими функциями мозга как органа с высшими функциями разума.

Центральная идея книги — связь того как именно мозг обрабатывает информацию и поведения человека. Учёный ввел понятие **сборки клеток** (cell-assembly), которое означает взаимосвязанные нейроны. Он утверждал, что обучение и память основаны на формировании таких сборок клеток. Эти связанные нейроны активируются вместе в результате обучения. Именно такие сборки клеток являются основными единицами мышления и из организация определяет поведение человека.

Согласно Дональду Хеббу поведение человека определяется двумя фундаментальными процессами: физиологическими процессами мозга и переживаниями. Учёный предположил, что эти два фактора неразрывно связаны. Мозг постоянно приспосабливается к окружающей среде, образуя новые связи между нейронами.

Предложенная Дональдом Хеббом теория обучения нейронов человеческого мозга получила название [**обучение Хебба**](http://www.machinelearning.ru/wiki/index.php?title=Правило_Хэбба). Основное правило этой теории можно сформулировать в следующем виде:

*Связи нейронов, которые активируются совместно, усиливаются. Связи нейронов, которые срабатывают независимо, ослабевают*

Это утверждение известное как **правило Хебба** стало фундаментом в теории обучения искусственных нейронных сетей.

#### 2.1.1.2 Статьи Тьюринга

##### 2.1.1.2.1 Статья "Умная машинерия"

Известный английский математик и криптограф [Алан Тьюринг](https://ru.wikipedia.org/wiki/Тьюринг,_Алан) посвятил две статьи вопросу о том, возможно ли создать машину с интеллектом человеческого уровня.

Первая статья была написана в 1948 году и получила название ["Умная машинерия"](https://weightagnostic.github.io/papers/turing1948.pdf) (Intelligent Machinery). Это был отчёт Тьюринга для Национальной физической лаборатории Великобритании (National Physical Laboratory или NPL). Отчёт был засекречен и долгое время нигде не публиковался. Он стал доступен для широкой публики только спустя почти 40 лет с момента написания.

Отчёт "Умная машинерия" написан формальным языком, как и другие научные статьи Тьюринга. Он начинается с вопроса автора: "способны ли машины демонстрировать разумное поведение?". Большинство современников отвечают на него отрицательно. Поэтому учёный подробнее разбирает несколько распространённых возражений.

Далее Алан Тьюринг рассуждает о "машинерии". Так он называет существующие и гипотетические устройства, которые теоретически могли бы демонстрировать разумное поведение. Среди них:

* **Логические вычислительные машины** (logical computing machines) — например, модель абстрактного вычислителя [машина Тьюринга](https://ru.wikipedia.org/wiki/Машина_Тьюринга)

* **Реальные вычислительные машины** (practical computing machines) — например существующие на тот момент универсальные цифровые компьютеры [ENIAC](https://ru.wikipedia.org/wiki/ЭНИАК) и [ACE](https://ru.wikipedia.org/wiki/ACE).

* **Бумажные машины** (paper machine) — когда человек с бумагой и ручкой исполняет набор формальных правила для решения поставленной задачи.

* **Частично случайные машины** (partially random machines) — это гипотетические компьютеры, в которых могу выполнятся несколько альтернативных операций одновременно. Некоторый случайный процесс выбирает один из результатов этих операций в качестве окончательного.

* **Неорганизованные машины** (unorganized machines) — машины собранные из неких стандартных компонентов, конструкция которых изначально не предполагает конкретной цели.

Рассмотрев все возможные типы машин, Алан Тьюринг фокусируется на неорганизованные машинах и способах их применения. Он предлагает некоторый процесс обучения,  который меняет состояние неорганизованной машины. В результате такая машина становится пригодной для решения конкретных задач.

В своих рассуждения автор неоднократно проводит параллели между неорганизованной машиной и корой головного мозга человека. Так же он сравнивает процессы обучения машины и человека. Между ними Алан Тьюринг находит аналогии.

В конце статьи учёный говорит о двух путях к созданию машины, демонстрирующей разумное поведение. Первый путь автор называет "прямым методом" (direct method). Он заключается в программировании реальной вычислительной машины. Тогда поведение машины станет логичным результатом следования небольшому набору общих принципов. Второй путь — это обучение неорганизованной машины. Именно этим двум направлениям следовало развитие ИИ в будущем.

В последнем разделе отчёта Алан Тьюринг размышляет о критерии разумного поведения. Он предлагает некий тест, в котором участвует три человека:

1. Шахматист A.
2. Шахматист С.
3. Оператор B, работающий на бумажной машине.

Участники теста должны сыграть друг с другом в шахматы, находясь в разных комнатах. В результате игры участник C должен определить, кто из оппонентов шахматист A, а кто оператор B.

В отчёте "Умная машинерия" Алан Тьюринг впервые упомянул о возможности применить процесс обучение к машинам особого типа. На практике эта идея была реализована исследователями только спустя десять лет.

##### 2.1.1.2.2 Статья "Вычислительные машины и разум"

Спустя два года в 1950 году Алан Тьюринг написал вторую статью с названием ["Вычислительные машины и разум"](https://ru.wikipedia.org/wiki/Вычислительные_машины_и_разум) (Computing Machinery and Intelligence). Она была опубликована в английском журнале Mind в 1950 году. Этот журнал издаётся небольшим тиражом Оксфордским университетом и посвящён психологии и философии.

Статья Тьюринга стала широко известна в 1956 потому, что попала в сборник математической литературы "Мир Математики" (The Worlds of Mathematics), составленный Джеймсом Ньюменом. В этом же году появился термин "искусственный интеллект". Возможно, авторитет Тьюринга и это совпадение возвело статью в культ.

В своей статье учёный неформальным языком пересказывает свои мысли из засекреченного отчёта "Умная машинерия". В отчёте основной упор был сделан на устройство и свойства различных машин, а также рассуждение о возможности их обучения. В статья же носит более философский характер.

Учёный начинает с определения терминов "машина" и "думать". По его мнению любое однозначное определение вызовет критику. Поэтому автор достаточно вольно подменяет вопрос "может ли машина думать?" на "может ли машина имитировать разумное поведение"?

Для объективной оценки возможностей машины Тьюринг предлагает игру в имитацию. Это продолжение идеи шахматного эксперимента, который описан в конце отчёта "Умная машинерия". Суть игры в том, что человек и машина обмениваются с судьёй текстовыми сообщениями. Все три участника игры находятся в разных комнатах и не видят друг друга. В результате переписки судья должен определить, кто из собеседников является машиной. Если судья не может это сделать, машина выигрывает. Игра в имитацию получила известность как [**тест Тьюринга**](https://ru.wikipedia.org/wiki/Тест_Тьюринга). Автор утверждает, что прошедшая такой тест машина должна считаться разумной в том же смысле, что и человек.

Далее Тьюринг рассматривает объекты, которые можно отнести к категории "машина". Он предлагает ограничиться только **цифровыми компьютерами**, которые оперируют числами 0 и 1. Также эти компьютеры должны быть универсальны в том смысле, что с помощью программирования их можно настроить на решение любой задачи. Возможно, из соображений секретности Тьюринг даёт крайне общее описание машин такого типа, хотя он сам принимал участие в их создании.

После определения терминов Тьюринг рассматривает девять возражений против идеи о том, что машины могут мыслить. Эту же тему он поднимал в отчёте, но на этот раз останавливается на ней подробнее. Среди возражений есть теологическое о том, что машины не могут обладать духовными качествами и сознанием. Так же — математическое о том, что машины ограничены формальными правилами и не могут выйти за их пределы. Рассмотрев все аргументы против, Тьюринг утверждает, что все они основаны на предвзятых представлениях. Они не дают окончательных доказательств невозможности машинного интеллекта в принципе.

В заключительной части статьи Тьюринг положительно оценивает возможность машины пройти игру в имитацию. Он предлагает модель обучающейся машины, которая была бы на это способна. Опять же это неформальный пересказ идей из отчёта "Умная машинерия". Тьюринг простыми словами описывает базовые принципы машинного обучения и генетических алгоритмов. Эти идеи намного опередили своё время. Намного позднее исследователи ИИ стали применять их на практике.

Статья Тьюринга оказала огромное влияние на ранних исследователей в области искусственного интеллекта. Она предложила им простую цель, достижение которой означает создание разумной машины. Многие учёные последовали этому направлению. Но были и те, кто критиковал идеи Тьюринга.

Сегодня есть мнение, что статья Тьюринга была мистификацией или даже розыгрышем. Его сторонники указывают на шутливый тон автора и отсутствие строгих математических выкладок, характерных для других работ учёного.

Более правдоподобным кажется мнение, что автор задумывал статью как попытку спровоцировать широкую дискуссию о разумности машин. И ему это удалось: статья вызывала горячие споры на протяжении последующих десятилетий. Не имея возможности опубликовать секретный отчёт, Алан Тьюринг был вынужден завуалированно пересказать его содержимое. В то же время более неформальная подача сделал мысли автора доступными для учёных нематематиков. Учёные из смежных областей тоже приняли участие в дискуссиях на тему ИИ и внесли свой вклад в развитие этой области.

Так или иначе на сегодняшний день несколько интеллектуальных систем успешно прошли тест Тьюринга. Однако, никто не считает их разумными в каком-либо смысле этого слова. Поэтому современные исследователи отказались как от самого теста в качестве критерия оценки, так и от идеи машины, способной мыслить как человек. Но высказанные Тьюрингом идеи машинного обучения успешно применяются в большинстве современных ИИ систем.

#### 2.1.1.3 Logic Theorist

Первую ИИ систему в виде компьютерной программы разработала группа американских учёных в 1956 году. Эта система получила название [Logic Theorist](https://en.wikipedia.org/wiki/Logic_Theorist). 

Все разработчики Logic Theorist были сотрудниками корпорации [RAND](https://ru.wikipedia.org/wiki/RAND_(корпорация)), которая с 1948 года занималась стратегическими исследованиями для правительства США. Авторами системы были:

* [Герберт Саймон](https://ru.wikipedia.org/wiki/Саймон,_Герберт_Александер) занимался экономикой, социальной и политической науками. Одна из его работа посвящена принятию решений в правительственных учреждениях и компаниях. В своих исследованиях он использовал методы теории принятия решений.

* [Аллен Ньюэлл](https://ru.wikipedia.org/wiki/Ньюэлл,_Аллен) учёный в области логистики и [теории организаций](https://ru.wikipedia.org/wiki/Теория_организаций). Это теория из области социологии, которая исследует взаимодействия людей в политических и коммерческих организациях.

* [Клиффорд Шоу](https://en.wikipedia.org/wiki/Cliff_Shaw) — опытный программист корпорации RAND, который реализовал замыслы Саймона и Ньюэлла.

Первоначальную идею системы разработал Ньюэлл. Он предположил, что простое программируемое устройство вроде компьютера способно на сложное поведение. Чтобы доказать эту гипотезу Ньюэлл и Саймон решили разработать программу для доказательства математических теорем. Тогда к проекту присоединился Шоу, чтобы помочь программированием.

Система Logic Theorist смогла доказать 38 теорем из книги ["Начала математики"](https://ru.wikipedia.org/wiki/Principia_Mathematica) Бертрана Рассела. Учёные рассматривали это как подтверждение гипотезы Ньюэлла. По их мнению универсальный компьютер, доказывающий математические теоремы, демонстрирует способность к разумному поведению.

В середине 1950-х годов считалось, что цифровые компьютеры способны оперировать только числами. Вопреки этому мнению система Logic Theorist работала с символами. Это позволило перейти от математических вычислений к логическим высказываниям. Разработчики утверждали, что создали программу, способную мыслить в нечисловых терминах. Этот подход стал доминирующим в области ИИ на следующие 30 лет.

В Logic Theorist впервые были использованы следующие концепций:

* **Рассуждение как поиск**. Logic Theorist представляет доказательство гипотезы как поиск по дереву. Корень дерева соответствует начальной гипотезе. Исходящие из корня ветви — это логические операции над начальной гипотезой. Каждая ветвь приводит к определённому выводу. Один из этих выводов является целью рассуждения. Именно его и ищет система.

* [**Эвристики**](https://ru.wikipedia.org/wiki/Эвристика) — это дополнительные правила, которые исключают из рассмотрения некоторые ветви дерева поиска. Эвристики позволяют заранее предсказать, что какая-то ветвь не приводит к решению. Это значительно сокращает время поиска решений.

* **Обработка списков**. Чтобы написать программу Logic Theorist, был разработан специальный язык программирования [IPL](https://en.wikipedia.org/wiki/Information_Processing_Language). Для него Шоу впервые применил специальную структур данных под названием [**связанный список**](https://ru.wikipedia.org/wiki/Связный_список). Она позволяла эффективно хранить список символов. Позднее на основе IPL и списков Джон Маккарти разработает язык Lisp. Этот язык станет доминирующим в области ИИ на два десятилетия.

В ходе разработки Logic Theorist были предложены новаторские идеи, которые стали ключевыми для последующих исследований в области ИИ.

#### 2.1.1.4 Дартмутский семинар

В начале 1950-х годов различные учёные проводили первые работы в области искусственного интеллекта. Однако, самого этого термина не существовало до лета 1956 года. Ранние исследования "думающих машин" называли кибернетикой, теорией автоматов или сложной обработкой информации. Название зависело от подхода, выбранного в каждом конкретном проекте.

В 1955 году американский математик Джон Маккарти решил организовать [семинар](https://ru.wikipedia.org/wiki/Дартмутский_семинар), посвященный "думающим машинам". Он хотел собрать группу исследователей в этой области, чтобы обсудить их достижения и возможные новые подходы. На тот момент Маккарти работал в Дартмутском колледже в Хановере (штат Нью-Гэмпшир). Поэтому в дальнейшем это мероприятие стало известно как **Дартмутский семинар**.

В ходе организации семинара и поиска средств для его проведения к Джону Маккарти присоединились Клод Шеннон, Марвин Мински и Натаниэль Рочестер. Спонсором мероприятия стал благотворительный фонд Рокфеллера (Rockefeller Foundation).

[Заявка на проведение семинара](http://raysolomonoff.com/dartmouth/boxa/dart564props.pdf) начиналась так:

*Мы предлагаем провести двухмесячное исследование искусственного интеллекта с участием 10 человек летом 1956 года в Дартмутском колледже в Хановере, штат Нью-Гэмпшир. Исследование основано на предположении, что каждый аспект обучения или любое другое свойство интеллекта можно в принципе описать столь точно, что возможно создать машину, которая сможет его симулировать. Мы попытаемся понять, как заставить машины использовать язык, формировать абстракции и концепции, решать задачи, доступные сейчас только людям, и улучшать самих себя.  Мы считаем, что существенное продвижение в одной или более из этих проблем вполне возможно, если специально подобранная группа учёных будет работать над ними в течение лета.*

Далее документ предлагает следующие темы для обсуждения на семинаре:

1. Компьютеры и их возможности.
2. Обработка естественного языка.
3. Искусственные нейронные сети.
4. Теория вычислений.
5. Самосовершенствование машин.
6. Формирование абстракций машиной.
7. Случайность и творчество в работе машин.

Именно заявка на проведение семинара стала первым официальным документом, в котором употребляется термин "искусственный интеллект". До этого его никто нигде не использовал. Организаторы придумали новый термин, чтобы предотвратить возможные споры относительно подходов. Если бы они выбрали любое уже существующее название научной области, это сфокусировало бы обсуждения только на конкретном подходе. Цель же семинара была в [мозговом штурме](https://ru.wikipedia.org/wiki/Метод_мозгового_штурма), т.е. в разработке совершенно новых идей.

В семинаре принимали участие ведущие учёные из следующих областей:

* Теория управления
* Теория автоматов
* Нейрофизиология
* Теорией игр
* Когнитивная психология.

Самыми обсуждаемыми темами на семинаре стали: обработка естественных языков, ориентированные на прикладные области системы (ранние экспертные системы), дедуктивные и индуктивные системы логического вывода. Искусственные нейронные сети и машинное обучение не получили должного внимания.

Темы затронутые на семинаре было решено объединить в единое научное направление под названием "искусственный интеллект". Это решение оказало огромное влияние на последующие исследования. Во-первых доминирующими направлениями стали именно те, которые активно обсуждались на семинаре. Во-вторых, учёные получили возможность свободно экспериментировать и искать новые подходы к построению интеллектуальных машин. Их больше не ограничивали аналоговые вычисления кибернетики и математический аппарат теории автоматов. Новое научное направление началось как экспериментальная дисциплина.

### 2.1.2 Формирование основных направлений в ИИ 1956 – 1974

Дартмутский семинар дал мощный толчок для исследований в области ИИ. Этому поспособствовало то, что участники семинара смогли найти поддержку в правительственных кругах и привлечь колоссальные средства для своей работы.

Выделенные средства пошли на создание лабораторий на базе известных учебных заведений. Их основателями стали некоторые из участников семинара. Они перечислены в таблице 2-2. Эти лаборатории специализировались на исследованиях в области вычислительной техники и ИИ.

{caption: "Таблица 2-2. Лаборатории по исследованию ИИ", width: "100%"}
| Учебное заведение | Основатели лаборатории ИИ |
| --- | --- |
| [Университет Карнеги — Меллона](https://ru.wikipedia.org/wiki/Университет_Карнеги_—_Меллона) | Аллен Ньюэлл и Герберт Саймон |
|  | |
| [Стэнфордский университет](https://ru.wikipedia.org/wiki/Стэнфордский_университет) | Джон Маккарти |
|  | |
| [Массачусетский](https://ru.wikipedia.org/wiki/Массачусетский_технологический_институт) |  Марвин Минский |
| технологический институт (МТИ) | Джон Маккарти (впоследствии покинул МТИ) |

Каждая из лабораторий разрабатывала собственные подходы в создании интеллектуальных систем. Некоторые из них задали направления для дальнейших исследований. Таблица 2-3 демонстрирует эти направления.

{caption: "Таблица 2-3. Направления в ИИ", width: "100%"}
| Название | Идея | Основоположники |
| --- | --- | --- |
| [Символьный](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | Задача решается | Аллен Ньюэлл |
| [подход](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | через действия над понятными человеку символическими обозначениями. | Герберт Саймон |
|  | | |
| [Логическое программирование](https://ru.wikipedia.org/wiki/Логическое_программирование) | Задача решается методами формальной логики. | Джон Маккарти |
|  | | |
| [Коннекционизм](https://ru.wikipedia.org/wiki/Коннекционизм) | Задача решается | Уоррен Мак-Каллок |
| | сетью из связанных между собой простых элементов (нейронной сетью). | Уолтер Питтс |

Эти направления сформировались в начальный период развития области ИИ в конце 1950-х годов. Их популярность менялась в зависимости от успехов и неудач в исследованиях. Сегодня самым многообещающим подходом считается коннекционизм.

Рассмотрим подробнее достижения каждого из направлений ИИ.

#### 2.1.2.1 Символьный подход

Система Logic Theorist произвела впечатление на участников Дартмутского семинара. Среди всех представленных идей и проектов, Logic Theorist была единственным работающим решением. Остальные исследования находились только на этапе теоретических моделей.

Следующим проектом Ньюэлла, Саймона и Шоу стала универсальная система для решения задач. Она получила название [General Problem Solver](https://ru.wikipedia.org/wiki/Универсальный_решатель_задач) (GPS). В отличие от Logic Theorist её область применения не ограничивалась математическими задачами. Вместо этого GPS моделировала процесс решения задач человеком.

Система GPS была готова в 1959 году. В своей работе она использовала особенную технику поиска под названием [**анализ средств и результатов**]((https://en.wikipedia.org/wiki/Means–ends_analysis)) (means–ends analysis или MEA). Эта техника стала развитием идеи "рассуждение как поиск", впервые реализованной в Logic Theorist.

Алгоритм анализа средств и результатов выглядит так:

1. Система оценивает своё текущее состояние. Если поставлена задача, необходимы действия для её решения.

2. Определяется конечная цель. Она выражается в некотором состоянии системы, которое надо достигнуть. Достижение этого состояние означает решение поставленной задачи.

3. Конечная цель делится на составные части, называемые подцелями. Если подцели остаются сложными, они так же делятся на составные части.

4. Составляется список действий, выполнение которых приведёт к конечной цели, т.е. решению задачи.

5. Каждая из подцелей связывается с соответствующим ей действием из списка.

6. Выполняются все действия из списка.

7. Сравнение полученного состояния системы с тем, которое надо достигнуть для решения поставленной задачи. Если эти состояния отличаются, алгоритм повторяется начиная со второго шага.

Система GPS доказывала теоремы [евклидовой геометрии](https://ru.wikipedia.org/wiki/Евклидова_геометрия) и логики предикатов. Также она решала шахматные задачи.

Основываясь на опыте разработки и применения системы GPS, Ньюэлл и Саймон сформулировали [**гипотезу о физической символьной системе**](https://ru.wikipedia.org/wiki/Гипотеза_Ньюэлла_—_Саймона) в 1976 году. Эта гипотеза звучит так:

*Физическая символьная система обладает необходимыми и достаточными средствами для разумного поведения.*

Эта гипотеза обосновывается примерно следующим образом. Без символьной системы невозможно разумное поведение. Следовательно, мышление человека основано на символьной системе и заключается в манипулировании символами. Универсальный компьютер также может манипулировать символами. Следовательно, он теоретически способен на разумное поведение.

Исследования и идеи Ньюэлла и Саймона заложили основу **символьного подхода**. Этот подход предлагает создавать системы, работа которых основана на манипулировании символами. Эти символы могут быть абстрактными, но должны быть понятны человеку. Сама система должна программироваться вручную как и любая другая компьютерная программа. Это именно тот самый "прямой метод" (direct method) создания "думающих машин", о котором писал Алан Тьюринг в свой статье "Умная машинерия".

Символьный подход оставался доминирующей парадигмой в области ИИ с середины 1950-х до конца 1980-х годов.

#### 2.1.2.2 Логическое программирование

В 1958 году Маккарти разработал модель системы под названием [Advice Taker](https://en.wikipedia.org/wiki/Advice_taker). Он описал её принципы работы в статье "Программы со здравым смыслом" (["Programs with Common Sense"](http://www-formal.stanford.edu/jmc/mcc59.pdf)). Принцип работы этой системы был очень похож на Logic Theorist. Она также работала с набором логических высказываний и осуществляла по ним поиск для вывода результатов.

Согласно идее Маккарти, Advice Taker должна была получать от пользователя информацию в форме логических утверждений на некотором формальном языке. Затем система использовала полученную информацию для решения сложных задач путём логических рассуждений.

Маккарти предполагал, что система будет универсальной, если сообщить ей достаточно общей информации об окружающем мире. Благодаря этому, Advice Taker смог бы самостоятельно делать выводы обо всём, что ему сообщают и что он уже знает. Тогда можно было бы утверждать, что система рассуждает с позиции [здравого смысла](https://ru.wikipedia.org/wiki/Здравый_смысл).

В отличие от Ньюэлла и Саймона, Маккарти делал ставку не на продвинутые алгоритмы поиска по множеству высказываний, а на применение [**формальной**](https://ru.wikipedia.org/wiki/Формальная_логика) и [**математической**](https://ru.wikipedia.org/wiki/Математическая_логика) логики. По его мнению такой подход позволил бы моделировать системы ИИ и формально доказывать их работоспособность.

I> Формальная логика — раздел логики, в котором применяется формальный язык и строгие правила операций над высказываниями. Математическая логика — это направление формальной логики, в которой активно применяется математический аппарат.

Для Advice Taker Маккарти предложил новый способ представления знаний. Система Logic Theorist хранила все знания и эвристики в коде самой программы. Из-за этого редактировать логические высказывания было сложно. Чтобы добавить новое утверждение или исправить существующее, приходилось исправлять программный код на языке IPL.

В системе Advice Taker знания и механизм рассуждений чётко разделялись. Знания хранились в виде правил на некотором формальном языке. Эти правила помещались в списки. Благодаря этому, редактировать высказывания становилось проще: для этого больше не требовались навыки программирования. Сам логический вывод по прежнему требовал поиска по спискам, как и в Logic Theorist. Однако, Маккарти искал возможность вынести алгоритм поиска из кода ИИ системы в язык программирования. Такой подход значительно упростил бы создание специализированных ИИ систем.

В качестве первого шага для реализации Advice Taker, Маккарти разработал язык программирования LISt Processing более известный как [Lisp](https://ru.wikipedia.org/wiki/Лисп). Учёный описал Lisp в статье для журнала Communications of the ACM в 1960 году. Первый работающий интерпретатор языка появился в 1958 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704).

Некоторые идеи языка Lisp Маккарти высказал ещё в статье "Программы со здравым смыслом". В ней он рассуждал над преимуществами **декларативных** и **императивных** инструкций. Декларативные инструкции описывают свойства результата, который должна выдать программа. Императивные — задают чёткий алгоритм вычисления результата. Маккарти утверждал, что декларативные инструкции лучше подходят для разработки ИИ систем и упрощают работу с логическими правилами.

Центральной идеей Lisp стала работа с выражениями. В отличие от большинства других языков того времени Lisp не делал различий между выражениями и инструкциями: и то и другое записывается как выражение. Эти выражения представляются в виде списков, заключенные в круглые скобки.

Первоначально Lisp задумывался как чисто декларативный язык. Но в процессе его реализации Маккарти добавил такие конструкции императивного языка как циклы и изменяемые переменные. Благодаря этому, Lisp стал универсальным языком, пригодным для широкого спектра задач и вне ИИ области. Его применяли и продолжают применять в различных прикладных областях.

Lisp оказал влияние на последующие специализированные языки программирования. Одним из них стал [Prolog](https://ru.wikipedia.org/wiki/Пролог_(язык_программирования)). Его разработал французский учёный Ален Колмероэ в 1972 году.

В отличие от Lisp, Prolog — это чисто декларативный язык, основанный на математической логике. Программы на нём представляют собой наборы логических утверждений и правил вывода. Prolog стал первым и самым известным языком логического программирования. Исследователи ИИ долгое время сохраняли к нему интерес.

Система Advice Taker так никогда и не была реализована. Она была полезна как модель типичной ИИ системы, которая
помогла Маккарти лучше понять нужды разработчиков. Опираясь на это понимание он разработал язык, который несколько десятилетий был востребован исследователями ИИ.

#### 2.1.2.3 Коннекционизм

Модель нейронной сети Мак-Каллока — Питтса и теория обучения Хебба заложили основу **коннекционизма**. Коннекционизм — это направление [когнитивной науки](https://ru.wikipedia.org/wiki/Когнитивистика), которое моделирует и исследует психические явления с помощью искусственных нейронных сетей.

После исследований Хебба следующим значительным шагом в развитии коннекционизма стала модель под названием **перцептрон**.

##### 2.1.2.3.1 Перцептрон

В середине 1950-х годов американский психолог и нейрофизиолог [Фрэнк Розенблатт](https://ru.wikipedia.org/wiki/Розенблатт,_Фрэнк) изучал организацию памяти в биологических системах. Скоро он пришел к выводу, что механизм памяти неразрывно связан с процессом восприятия. Тогда учёный сменил направление исследований и начал изучать этот процесс.

В конце 1950-х годов Розенблатт представил результат своей работы в виде модели того, как мозг человека воспринимает информацию. Эта модель получила название [**перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон). Позднее модели такого типы стали называться [**binary classifier**](https://www.youtube.com/watch?v=mI6jTc-8sUY) (бинарный классификатор).

Термин "перцептрон" нередко вызывает путаницу. Причина в том, что его применяют для обозначения следующих разных понятий:

1. Алгоритм обучения с учителем для бинарных классификаторов (алгоритмы обучения мы рассмотрим далее).

2. Модель отдельного нейрона.

3. Модель однослойной нейронной сети.

4. Модель многослойной нейронной сети.

Для начала рассмотрим модель отдельного нейрона под названием перцептрон. Такой нейрон получает на вход несколько сигналов. Каждый входной сигнал имеет **вес**. Вес — это вещественное число, которое пропорционально важности сигнала: чем важнее сигнал, тем больше вес и наоборот. Вес нужен для расчёта **взвешенной суммы входных сигналов** (Y) по следующей формуле:
{width: "50%"}
![](images/ArtificialIntelligence/perceptron-dot-product.png)

В этой формуле m означает число входных сигналов перцептрона. 

В некоторых случаях к взвешенной сумме входных сигналов прибавляют некоторую константу. Она называется **смещением** (bias). Благодаря смещению, результат функции активации смещается в область положительных или отрицательных значений. Таким образом решаются некоторые проблемы при обучении сетей.

Обозначим смещение буквой b. Тогда функцию активации перцептрона можно записать так:
{width: "50%"}
![](images/ArtificialIntelligence/perceptron-activation-function.png)

Здесь f(x) означает функцию активации. Она принимает значение 1, если взвешенная сумма входных сигналов плюс смещение больше нуля. В противном случае, функция активации равна 0. Величина выходного сигнала перцептрона совпадает со значением его функции активации.

Первоначально Розенблатт использовал в функцию Хевисайда в качестве функции активации для перцептрона. Иллюстрация 2-2 демонстрирует её график. Её поведение похоже на ступенчатую функцию активации бинарного порогового нейрона.

{caption: "Иллюстрация 2-2. Функция Хевисайда", height: "30%"}
![Функция Хевисайда](images/ArtificialIntelligence/heaviside-step-function.png)

Чтобы лучше понять особенности модели нейрона под названием перцептрон, сравним её с более ранней моделью Мак-Каллок и Питтса (бинарный пороговый нейрон). Вот их ключевые различия:

1. Бинарный пороговый нейрон получает на вход сигналы, которые представляются двоичными числами (0 или 1). Входные сигналы перцептрона представляются вещественными числами.

2. В отличие от бинарного порогового нейрона, каждый входной сигнал перцептрона имеет вес.

3. Функция активации бинарного порогового нейрона получает на вход сумму всех входных сигналов. Функция активации перцептрона получает взвешенную сумму входных сигналов.

4. Модель Мак-Каллок и Питтса не предусматривает никакого алгоритма обучения. В отличие от неё перцептрон может обучаться. Его процесс обучения заключается в автоматическом подборе значений весов для каждого входного сигнала. Для разработки методов обучения перцептрона Розенблатт применил теорию Хебба.

5. Модель Мак-Каллок и Питтса была только теоретической. Она не решала никакую практическую задачу. Перцептрон разрабатывался как инструмент для распознавания изображений.

Теперь рассмотрим модель [однослойной нейронной сети под названием перцептрон](https://en.wikipedia.org/wiki/Feedforward_neural_network#Single-layer_perceptron). Чтобы проверить свои идеи на практике, Розенблатт применил модель нейрона для распознавания изображений. Для решения этой задачи отдельному нейрону не хватало вычислительных возможностей. Переход к нейронной сети увеличил вычислительную мощность модели.

Предложенная Розенблаттом нейронная сеть, представляла собой параллельно подключенные нейроны перцептроны. В 1957 году Розенблатт смоделировал работу такой сети в виде программы для универсального компьютера IBM 704. Годом позже учёный сконструировал первый [нейрокомпьютер](https://ru.wikipedia.org/wiki/Нейрокомпьютер) под названием [Mark I Perceptron](https://ru.wikipedia.org/wiki/Марк-1). 

Mark I представлял собой однослойную нейронную сеть, работающую по принципу перцептрона. Компьютер работал на аналоговых компонентах. Входное изображение поступало на матрицу из фотодетекторов размером 20x20. Сигналы с неё передавались на отдельные "нейроны". Чтобы регулировать веса входных сигналов, применялись потенциометры. Их настройки менялись в процессе обучения с помощью электромоторов. 

Mark I должен был распознавать буквы английского алфавита. Финальная версия компьютера научилась распознавать только некоторые буквы.

Работа с компьютером была очень трудоемкой. Его компоненты были ненадежны и часто выходили из строя. Чтобы поддерживать Mark I в рабочем состоянии, требовалось постоянное вмешательство оператора и замена выходящих из строя компонентов.

Иллюстрация 2-3 демонстрирует архитектуру однослойной нейронной сети под названием перцептрон.

{caption: "Иллюстрация 2-3. Архитектура нейронной сети под названием перцептрон", height: "30%"}
![Архитектура нейронной сети перцептрон](images/ArtificialIntelligence/perceptron.png)

Сеть состоит из трёх типов элементов:

1. S-элементы (сенсорные)
2. A-элементы (ассоциативные)
3. R-элементы (реагирующие)

I> Несмотря на три слоя элементов, перцептрон на иллюстрации 2-3 называется однослойным. Причина в том, что у него только один **скрытый слой** A-элементов. Скрытыми называются слои, не содержащие входных и выходных нейронов.

Перцептрон создаёт набор ассоциаций (A-элементы) между входными сигналами (S-элементы) и реакцией на них (R-элементы).

Можно провести аналогию между работой сети и мозгом. Пример обработки сигнала мозгом — реакция человека на зрительную информацию. Если человек видит опасность, физиологическим ответом на неё будет активация [двигательных нейронов](https://ru.wikipedia.org/wiki/Мотонейрон). Эти нейроны отвечают за мышечную активность. Похожим образом перцептрон обрабатывает входные сигналы: реагирующие нейроны R возбуждаются в ответ на импульсы сенсорных нейронов S, согласно ассоциациям A.

Первоначальная модель нейронной сети имела только один R-элемент. Из-за этого она могла различать только два класса объектов. Отсюда и название модели: бинарный классификатор (т.е. два класса). В более поздних моделях Розенблатт экспериментировал с несколькими R-элементами. Так ему удалось добиться распознавания нескольких классов.

В конце 1950-х годов ещё не существовало общепринятой терминологии нейронных сетей. Розенблатт вводил новые понятия, которые позднее вышли из употребления. Это приводит к ошибкам при обсуждении идей учёного сегодня.

В 1962 году Розенблатт опубликовал книгу "Принципы нейродинамики" (Principles of Neurodynamics). В ней учёный рассматривает различные архитектуры перцептронов, в том числе и многослойные. Также в книге доказана [теорема сходимости перцептрона](https://ru.wikipedia.org/wiki/Теорема_сходимости_перцептрона). Согласно теореме, перцептрон можно обучить за конечное число шагов. После такого обучения он сможет решить поставленную задачу.

Книга "Принципы нейродинамики" оказала большое влияние на развитие коннекционизма. Теорема сходимости перцептрона и её выводы позволили сформулировать требования к архитектурам нейронных сетей и методам их обучения.

#### 2.1.2.4 Экспериментальный подход

Исследователи из лаборатории ИИ Массачусетского технологического института следовали подходу, который в 1970-е годы получил название **scruffy** или "неряшливый". Его также можно назвать "экспериментальным". Идея подхода в разработке прототипов ИИ систем для небольших задач из разных областей. Затем полученные системы должны комбинироваться и совершенствоваться. Так исследователи надеялись прийти к решению реальных сложных задачи.

Противоположный подход получил название **neat**. Дословно переводится как "аккуратный". Его идею хорошо передаёт слово "теоретический". Этот подход предлагает использовать [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы), основанные на математике и логике. Таким образом получается более надёжный и научно обоснованный результат. Этого подхода придерживались исследователи из университетов Карнеги — Меллона и Стэнфордского.

В первые годы развития ИИ экспериментальный подход казался весьма плодотворным. Исследователи из МТИ разработали и продемонстрировали ряд систем для решения прикладных задач. Эти системы произвели большое впечатление на научные и политические круги, а также на инвесторов. Рассмотрим самые известные из этих разработок.

##### 2.1.2.4.1 Обработка естественного языка

Первой системой обработки естественного языка считается программа [STUDENT](https://en.wikipedia.org/wiki/STUDENT_(computer_program)). Её написал Даниэль Бобров в рамках свой докторской работы в 1964 году. Его научным руководителем был Марвин Минский.

Программа STUDENT читала и решала задачи из школьного учебника по алгебре. На вход она получала описание задачи на английском языке. На выходе система печатала решение в виде числа.

Для анализа текста STUDENT использовала запрограммированные правила и логический вывод. Функции машинного обучения у системы не было.

Другой системой обработки естественного языка была [ELIZA](https://ru.wikipedia.org/wiki/Элиза_(программа)). Её разработал профессор МТИ [Джозеф Вейценбаум](https://ru.wikipedia.org/wiki/Вейценбаум,_Джозеф) в 1966 году.

ELIZA представляет собой [виртуального собеседника](https://ru.wikipedia.org/wiki/Виртуальный_собеседник). Она обменивается с пользователем сообщениями. Направление разговора задаётся специальными сценариями. Самым популярным сценарием разговора был DOCTOR. Согласно ему, программа парадировала психотерапевта и строила вопросы на основе прошлых сообщений от пользователя.

ELIZA не понимала суть разговора. Она находила во входной фразе ключевые слова и подставляла их в шаблонные фразы. Эти фразы и были ответами системы. Для поиска ключевых слов программа использовала закодированные вручную синтаксические правила построения предложений.

ELIZA считается первой реальной программой, которая пыталась пройти тест Тьюринга.

##### 2.1.2.4.2 Микромиры

В конце 1960-х годов Марвин Минский и Сеймур Пейперт предложили сфокусировать исследования ИИ на упрощённых проблемных областях. Такие области получили название **микромиры**. Минский и Пейперт утверждали, что полученные системы ИИ смогут работать и для реальных задач.

Студенты МТИ выбирали для себя какой-то "микромир" и разрабатывали для него ИИ систему в качестве дипломной работы. Наибольшей популярностью у студентов пользовался [мир блоков](https://en.wikipedia.org/wiki/Blocks_world). Он представлял собой плоскую поверхность (table), на которой можно было размещать объекты. Изначально эти объекты находятся в коробке (box). Сами объекты представляют собой геометрические фигуры различных цветов, размеров и форм (шары, конусы, кубы и т.д).

Самым известным проектом для мира блоков была программа [SHRDLU](https://ru.wikipedia.org/wiki/SHRDLU). Её разработал [Терри Виноград](https://ru.wikipedia.org/wiki/Виноград,_Терри) в 1970 году. Программа работала на компьютере DEC PDP-6 с графическим терминалом. Терминал отрисовывал полную 3D картину текущего состояния мира блоков.

Программа представляла собой текстовый интерфейс для работы с миром блоков. Пользователь вводил команды на английском языке. SHRDLU понимал следующие типы команд:

1. Указание к действию. Например: "положи красный шар на синий блок".

2. Вопрос о состоянии мира блоков. Например: "сколько объектов находится на плоскости?".

3. Вопрос о выполненных ранее командах. Например: "перемещался ли красный куб?".

4. Вопрос о возможности выполнения действия. Например: "можно ли поставить красную пирамиду на синий куб?"

Программа вела себя так, будто понимала что имеет в виду пользователь. Это понимание достигалось благодаря простоте мира блоков. Для его полного описания хватало порядка 50 слов: существительных (названия объектов), глаголов (описание действий) и прилагательных (описание объектов). Комбинации этих слов были элементарны. Простые правила синтаксического разбора, закодированные в программе, хорошо справлялись с такими предложениями.

Кроме правил синтаксического разбора у программы была память для сохранения выполненных действий. Это позволяло SHRDLU отслеживать состояние мира блоков. Также программа имела простейшие правила физики твёрдых тел. Благодаря правилам, SHRDLU делала выводы о выполнимости команд пользователя.

В лаборатории МТИ разрабатывали не только программы для мира блоков, но и роботов. Было создано несколько версий руки-манипулятора для передвижения блоков:

* [Робот MH-1](https://www.csail.mit.edu/node/6674) был разработан Генри Эрнстом в 1961 году. Роботом [подключался к компьютеру TX-0](https://www.semanticscholar.org/paper/MH-1%2C-a-computer-operated-mechanical-hand-Ernst/06600e1ca9451d81e89d078a924184683ace9196). Через него пользователь давал команды для исполнения. MH-1 пытался выполнить введённую команду. Для обратной связи у него было несколько датчиков. MH-1 служил прототипом для изучения автономной работы подобных механизмов. Его демонстрирует иллюстрация 2-4.

* [Робот Минский-Беннета](https://cyberneticzoo.com/underwater-robotics/1968-minsky-bennett-arm-marvin-minsky-and-bill-bennett-american/) был разработан Марвином Минский и Вильямом Беннетом в 1968 году. Он [управлялся с помощью джойстика и компьютера DEC PDP-6](https://commodorez.tumblr.com/post/710801395944767488).

* Робот ["Серебряная рука"](https://www.computerhistory.org/timeline/1974/#169ebbe2ad45559efbc6eb35720d99bc) (Silver Arm) был разработан [Дэвидом Сильвером](https://en.wikipedia.org/wiki/David_Silver_(roboticist)), в 1974 году. Робот мог работать с мелкими деталями благодаря датчикам прикосновения и давления. Его демонстрирует иллюстрация 2-5.

{caption: "Иллюстрация 2-4. Рука-манипулятор MH-1", height: "40%"}
![Рука-манипулятор MH-1](images/ArtificialIntelligence/mh-1-arm-robot.jpg)

{caption: "Иллюстрация 2-5. Робот Серебряная рука", height: "60%"}
![Робот Серебряная рука](images/ArtificialIntelligence/the-silver-arm.jpeg)

### 2.1.3 Первая зима ИИ 1974 – 1980

Первые успехи конца 1950-х, начала 1960-х годов в области ИИ привлекли к себе внимание прессы. Учёные не стеснялись делать оптимистичные прогнозы. Они утверждали, что "в ближайшем будущем" машины смогут решать задачи, с которыми раньше справлялись только люди.

Громкие заявления о скором прогрессе ИИ разнесла пресса. В результате к исследованиям стали проявлять интерес лица принимающие решения о финансировании: правительственные чиновники, военные, инвесторы, руководители частных и государственных организаций.

Вокруг темы ИИ возник ажиотаж, который продолжался до середины 1970-х годов. Вслед за ним наступил спад и разочарование в достигнутых результатах. Позже этот период станут называть "первая зима ИИ". Рассмотрим её причины.

#### 2.1.3.1 Проект машинного перевода

В 1957 году СССР запустил первый искусственный спутник земли. После этого [Национальный научно-исследовательский совет США](https://ru.wikipedia.org/wiki/Национальные_академии_наук,_инженерии_и_медицины) (National Research Council или NRC) стал внимательно следить за советскими научными статьями. Чтобы ускорить их перевод на английский язык, было решено создать специальную ИИ систему. Её разработкой занимались совместно компания IBM и университет Вашингтона в Сент-Луисе.

В начале проекта считалось, что для машинного перевода достаточно простых синтаксических преобразований и замены слов по словарю. Для синтаксических преобразований нужны знания грамматики русского и английского языка, которые достаточно просто закодировать. Но скоро выяснилось, что для устранения неоднозначностей и определения смысла предложения нужные общие знания о предметной области. Позже это затруднение получит название [**проблема здравого смысла**](https://en.wikipedia.org/wiki/Commonsense_knowledge_(artificial_intelligence)).

К 1964 году NRC вложил в проект машинного перевода около 20 миллионов долларов. Но несмотря на почти десять лет разработки, заметного прогресса достигнуто не было. Тогда NRC сформировал комитет для изучения этой проблемы. В 1966 году этот комитет подготовил отчёт. В нём говорилось, что машинный перевод дороже, менее точен и медленнее, чем выполненный человеком. После этого правительство США полностью прекратило финансирование проекта. Исследования были полностью прекращены.

#### 2.1.3.2 Финансирование DARPA

В 1958 году министерство обороны США организовало [управление перспективных исследовательских проектов](https://ru.wikipedia.org/wiki/Управление_перспективных_исследовательских_проектов_Министерства_обороны_США) ARPA, которое позднее было переименовано в DARPA. Эта организация искала и финансировала перспективные научные исследования, которые могли бы применяться в военных целях.

Благодаря громким заявлениям в прессе, исследования ИИ привлекли внимание специалистов ARPA. Они посчитали, что исследования в новой области могут принести пользу для военных. Это решение привело к тому, что на протяжении 1960-х годов лаборатории ИИ в МТИ, университетах Карнеги — Меллона и Стэнфордском получали гранты в размере нескольких миллионов долларов ежегодно. Эти деньги выделялись не на конкретные проекты с жёсткими сроками. Лаборатории получали их на фундаментальные исследования, не имевшие применения на практике. Директор ARPA Джозеф Ликлайдер верил, что финансирование "людей, а не проектов" даст результаты. Однако, этого не произошло.

Отсутствие результатов и провал одного из крупных проектов заставил ARPA изменить политику финансирования. SUR был проектом голосового управления для пилотов. Над ним работала команда из университета Карнеги — Меллона. Исследователи разработали систему распознавания речи, но она оказалась очень ограниченной. Например, порядок произнесения слов был строго определён. Реальные возможности системы оказались очень далеки от обещанных. В 1974 году ARPA полностью прекратила финансирование этого проекта.

На раздутый бюджет военных исследований обратил внимание сенат США. В результате в 1969 году была принята поправка Мэнсфилда. Она требовала от ARPA финансировать только целевые исследования. Теперь учёные были обязаны доказать, что их работа связана с военными технологиями. Их заявки на финансирование рассматривались по очень строгим стандартам. Это привело к значительному сокращению бюджета лабораторий ИИ по всей стране.

#### 2.1.3.3 Отчёт Лайтхилла

В 1965 году английский учёный [Дональд Мичи](https://en.wikipedia.org/wiki/Donald_Michie) организовал лабораторию ИИ в [Эдинбургском университете](https://ru.wikipedia.org/wiki/Эдинбургский_университет). Позднее подобные лаборатории открылись в университетах Сассекс и Эссекс. В конце 1960-х и начале 1970-х они получали значительные гранты от правительства Англии.

Распределением средств на исследования ИИ в Англии занимался [совет по научным и инженерным исследованиям](https://en.wikipedia.org/wiki/Science_and_Engineering_Research_Council) (Science and Engineering Research Council или SERC). В конце 1970-х совет решил проверить достигнутые успехи исследований. В то время часто звучали утверждения о скором создании разумных машин. Но научная основа таких утверждений была неясна. Кроме этого совет хотел убедиться, что значительные инвестиции на исследования были оправданы и направлены на наиболее перспективные области.

В 1973 году SERC поручил профессору в области прикладной математики и физики [Джеймсу Лайтхиллу](https://ru.wikipedia.org/wiki/Лайтхилл,_Джеймс) оценить текущее состояние исследований в области ИИ. Лайтхилл ранее работал ректором в Имперском колледже Лондона. Он был известен своим критическим анализом научных и математических проблем и поэтому считался подходящим кандидатом.

Лайтхилл провёл всестороннее исследование: он изучил доступные материалы, побеседовал с наиболее известными экспертами в области ИИ из США и Европы, а затем классифицировал полученные данные. Результаты своей оценки он опубликовал в статье под названием "Искусственный интеллект: общий обзор" ([Artificial Intelligence: A General Survey](www.chilton-computing.org.uk/inf/literature/reports/lighthill_report/p001.htm)). Позднее она стала широко известна как [отчёт Лайтхилла](https://ru.wikipedia.org/wiki/Отчёт_Лайтхилла).

В первой части отчёта Лайтхилл описывает три основных направления исследований ИИ того времени:

* A — Advanced Automation (продвинутая автоматизация). К этой области он относит разработку систем, которые могут заменить людей для решения конкретных прикладных задач. Такие системы Лайтхилл подразделяет на два типа. Первый — для решения промышленных и военных задач. Второй — для математической и научной работы.

* C — Computer-based CNS research (исследование центральной нервной системы человека с помощью компьютера). К этому направлению относятся все теоретические исследования в области нейрофизиологии и психологии. Лайтхилл подчеркивает, что эти исследования занимаются моделированием работы мозга с помощью компьютера.

* B — Building Robots (создание роботов). Это направление связывает A и C для создания автоматических устройств, которые имитируют определённый набор человеческих функций.

Далее автор переходит ко второй части, где разбирает ожидания и реальные достижения каждого из трёх направлений: A, C и B. Лайтхилл признаёт, что исследования в областях A и C имели некоторые успехи. Однако, ни одна из заявленных целей направления B так и не была достигнута.

Чтобы оценить достижения в Advanced Automation, Лайтхилл прибегает к сравнению. Он оценивает уже существующими коммерческие системы автоматизированного управления, применяемые в авиации и космической индустрии. Эти системы оказываются значительно сложнее и эффективнее, чем системы, созданные в рамках ИИ исследований. Также автор упоминает провал систем для машинного перевода и доказательства математических теорем.

Автор рассматривает направление Computer-based CNS research больше как помощь для фундаментальных исследований в области психологии. Он утверждает, что затраты вычислительных мощностей и труда для моделирования процессов нервной системы оказываются неоправданно высоки. Основную проблему этого направления Лайтхилл видит в несовершенстве современной компьютерной техники.

Проблемы последнего направления Building Robots Лайтхилл связывает с неудачами областей A и C. Не имея надёжных систем распознавания образов, речи и логического рассуждения, нет никакой возможности построить роботов или даже узкоспециализированные машины с интеллектом близким человеческому.

В заключении статьи Лайтхилл весьма сдержанно оценивает возможные достижения ИИ исследований в последующие 25 лет.

Отчёт Лайтхилла стал причиной, по которой SERC прекратил финансирование большинства исследований ИИ в университетах. Это решение привлекло к себе внимание всех европейских стран. В итоге финансирование разработок в новой области сократились по всей Европе.

#### 2.1.3.4 Ограничения систем ИИ

Проблемы с финансированием исследований ИИ в середине 1970-х возникли по вине самих учёных. Они недооценили сложность задач, которые им предстоит решить. Поэтому их прогнозы и сроки выполнения проектов оказались слишком оптимистичными. В результате ожидания инвесторов были очень высоки.

Крупные инвестиции в область ИИ начались в середине 1960-х годов. К началу 1970-х стали ясны результаты разработок, на которые ушли несколько лет. Эти результаты оказались неудовлетворительными. Возможности реальных систем ИИ были далеки от об обещанных.

Есть мнение, что учёные умышленно вводили в заблуждение инвесторов, чтобы получить финансирование. Вполне возможно, что некоторые из них действительно делали громкие заявления, стараясь привлечь внимание прессы и подогреть оптимизм инвесторов. Но тем не менее ошибочными оказались абсолютно все прогнозы о перспективах развития ИИ, сделанные в начале 1960-х годов. Разберёмся, почему это произошло.

##### 2.1.3.4.1 Производительность компьютеров

В конце 1950-х годов сменилась технология производства компьютеров. Раньше их рабочими элементами были [электровакуумные лампы](https://ru.wikipedia.org/wiki/Электронная_лампа). В 1958-м году компания IBM выпустила первый компьютер, который работал на [транзисторах](https://ru.wikipedia.org/wiki/Транзистор). Они превосходили лампы по компактности, надежности и скорости работы.

Переход на транзисторы должен был значительно увеличить быстродействие компьютеров. Однако, конструкция самих транзисторов [продолжала развиваться](https://en.wikipedia.org/wiki/MOSFET#Commercialization) на протяжении 1960-х годов. Только в начале 1970-х годов она достигла такого уровня, который позволил наращивать производительность компьютеров. После этого момента начал действовать [закон Мура](https://ru.wikipedia.org/wiki/Закон_Мура). Он говорит о том, что число транзисторов на [интегральной схеме](https://ru.wikipedia.org/wiki/Интегральная_схема) удваивается примерно каждые два года. Соответственно растёт скорость вычислений и объём памяти.

Исследователи ИИ разрабатывали прототипы своих систем для компьютеров 1960-х годов со слабой вычислительной мощностью и ограниченной памятью. Эти прототипы могли решать относительно простые задачи. Полученные результаты позволяли исследователям сравнивать эффективность разных подходов и методов. Но оценить [**масштабируемость**]((https://ru.wikipedia.org/wiki/Масштабируемость)) прототипа системы очень сложно. Для этого её надо запустить на более мощном компьютере. На тот момент таких компьютеров просто не существовало.

I> Масштабируемость означает повышение производительности системы при добавлении ресурсов.

Вот один из примеров. Первые версии систем для машинного перевода обрабатывали небольшие специально подготовленные тексты. Памяти компьютера 1960-ого года хватало только на несколько десятков слов. Поэтому система могла переводить только маленькие тексты. Чтобы проверить насколько система универсальна, нужен был компьютер с намного большим объёмом памяти. Учёные были уверены, что более мощное оборудование решит все проблемы. Но при переводе реальных текстов в начале 1970-х неожиданно возникла "проблема здравого смысла".

Ограничением была не только память, но и быстродействие компьютеров. В 1976 году учёный [Ханс Моравек](https://ru.wikipedia.org/wiki/Моравек,_Ханс) из университета Карнеги — Меллона дал следующую оценку. Чтобы распознавать грани объектов и движение в реальном времени, система ИИ должна работать на компьютере с производительностью 10^9^ [операций в секунду](https://ru.wikipedia.org/wiki/IPS_(быстродействие)) (1000 мегаинструкций в секунду или MIPS). Однако, самый быстрый суперкомпьютер 1976 года [Cray-1](https://ru.wikipedia.org/wiki/Cray-1) выполнял всего 160 MIPS.

В 1960-е годы исследователи ИИ не смогли правильно оценить вычислительные мощности, которые понадобятся для работы их систем. Многие принципиальные проблемы обнаружились только при тестировании прототипов на более мощных компьютерах начала 1970-х годов. Для их решения требовались новые исследования и время, но инвесторы уже ждали готовых результатов.

##### 2.1.3.4.2 Комбинаторный взрыв

В отчёте Лайтхилла упоминается проблема [**комбинаторного взрыва**](https://ru.wikipedia.org/wiki/Комбинаторный_взрыв) (combinatorial explosion). Этот термин означает быстрый рост сложности задачи при увеличении размера входных данных. Именно комбинаторный взрыв стал одной из причин, помешавших развитию направления Advanced Automation.

Разберёмся в этой проблеме подробнее. Одну и ту же вычислительную задачу можно решить разными алгоритмами. Некоторые из них окажутся эффективнее, чем другие. Для выбора подходящего алгоритма, нужен надёжный способ сравнения. Самое простое решение — замерить время работы каждого алгоритма на конкретном наборе входных данных. К сожалению, такой прямолинейный подход ненадёжен. Какой-то алгоритм может быстрее других работать на большом наборе входных данных (например, обрабатывать длинные строки), но на малых наборах (коротки строки) он будет уступать другим.

Для адекватной оценки алгоритма надо учитывать зависимость его показателей от размера входных данных. Поэтому сегодня применяют две основных оценки:

* [**Временная сложность**](https://ru.wikipedia.org/wiki/Временная_сложность_алгоритма) (time complexity) — это зависимость количество итераций алгоритма от размера входных данных. Другими словами — на сколько шагов увеличится алгоритм при увеличении входных данных.

* **Пространственная сложность** — это зависимость количества занимаемой памяти от размера входных данных.

Лайтхилл демонстрирует проблему комбинаторного взрыва на системах ИИ для доказательства теорем. Такие системы следуют подходу "рассуждение как поиск". Суть подхода в применении методов поиска для выполнения логических выводов из доступной информации.

Чтобы применить эти методы, информация представляется в структурированном формате, например как граф. Его вершинами могут быть некоторые факты, а рёбрами отношения "предпосылка->вывод". Тогда система с помощью алгоритма поиска может обойти построенный граф и найти путь для доказательства какого-то факта из всего доступного набора возможных предпосылок.

Такие системы хорошо справлялись с небольшими формальными задачами, такими как теоремы из книги "Начала математики". Дерево поиска построенное для исходной информации теоремы оказывалось относительно небольшим. Когда же дело доходило до реальных прикладных задач, дерево поиска оказывалось на несколько порядков больше.

Высокая временная и пространственная сложность применявшихся в то время алгоритмов поиска приводила к тому, что вычислительные ресурсы компьютера исчерпывались задолго до нахождения решения задачи. Именно в этом и состояла проблема комбинаторного взрыва. В реальной прикладной задаче объем информации для обработки быстро увеличивался при незначительном увеличении размера входных данных. Существующие алгоритмы просто были к этому не готовы.

В своих рассуждениях Лайтхилл ссылался на [теорию вычислительной сложности](https://ru.wikipedia.org/wiki/Теория_сложности_вычислений). Как отдельное направление информатики она появилась в 1965 году. В 1970-е годы теория активно развивалась. Согласно её выводам, некоторые классы задач в принципе не имеют эффективных решений. Это значит, что не существует алгоритмов для их решения за приемлемое время. Такие задачи называются [**трудноразрешимыми**](https://www.slideshare.net/mkurnosov/12-34608847).

Концепция трудноразрешимых задач устанавливает строгие ограничения для возможностей систем ИИ. Эти системы способны решать только задачи, для которых существуют эффективные алгоритмы решения.

#### 2.1.3.5 Проблемы коннекционизма

В начале 1960-х годов модель перцептрона Розенблатта выглядела многообещающей. Группы учёных из разных университетов исследовали её возможности. Но скоро они пришли к выводу, что перцептрон хорошо справляется только  с простыми задачами. Он оказался не способен решать сложные прикладные задачи.

Понимал ограничения своей модели и Розенблатт. В книге "Принципы нейродинамики" он указал следующие недостатки однослойных перцептронов:

1. Выполнение некоторых задач требует нейронной сети с очень большим количеством элементов.

2. В некоторых случаях обучение занимает очень много времени.

3. Качество обучения сильно зависит от оценок системы во время обучения.

4. Перцептрон плохо справляется с задачей обобщения.

5. Перцептрон плохо выделяет существенные элементы в сложных входных сигналах.

Первый и второй пункт говорят о высоких требованиях перцептрона к памяти и производительности компьютера, на котором он моделируется. Реальная сложная задача требует большой сети. Каждый её элемент должен храниться в памяти компьютера. Чтобы такую сеть обучить, нужна высокая вычислительная мощность.

Третий пункт говорит о том, что обучение сети — итеративный процесс, результат которого нельзя предсказать наверняка. Если обучение не дало нужной точности работы сети, его нужно повторить снова. 

Из четвертого пункта следует, что перцептрон правильно обрабатывает только те входные данные, на которых он учился. Если условия задачи похожи на учебный пример, но полностью с ним не совпадают, перцептрон не сможет её решить.

Пятый пункт приводит к тому, что перцептрон плохо справляется со сложными задачами. Наиболее эффективный метод их решения — разделение на простые подзадачи. Но перцептрон не способен на такое разделение. Он анализирует задачу целиком как есть.

Розенблатт надеялся, что многослойные перцептроны смогут преодолеть некоторые из этих ограничений. Он начал рассматривать архитектуры таких нейронных сетей в своей книге. Но эта теория осталась недоработанной. В 1971 году Розенблатт погиб в результате несчастного случая.

Исследовать многослойные перцептроны на практике в 1960-х годах было сложно. Для моделирования их работы на универсальных компьютерах требовалось больше памяти и времени обучения, чем для однослойных перцептронов. Часто модель сети не помещалась в память компьютера или для её обучения требовалось слишком много времени.

Аппаратная реализация перцептронов в виде специальных компьютеров наподобие Марк-1 имела технические проблемы. В 1960-х годах не было надёжных и дешёвых электронных компонентов, на которых можно было бы построить нейрокомпьютер. Архитектура Марк-1 не масштабировалась. Это признал сам Розенблатт. Поэтому строить более сложные нейрокомпьютеры для многослойных перцептронов в то время было невозможно.

К середине 1960-х годов работы по развитию модели перцептрона зашли в тупик. Не было очевидных путей для продолжения исследований. Главным ограничением стала недостаточная мощность компьютеров того времени.

Начиная с 1965 года Марвин Минский и Сеймур Пейперт провели ряд экспериментов над перцептронами. Свои результаты они опубликовали в книге 1969 года под названием ["Перцептроны"](https://ru.wikipedia.org/wiki/Перцептроны_(книга)) ("Perceptrons: an introduction to computational geometry").

Книга подробно рассматривает ряд типовых задач по распознаванию образов, с которыми однослойный перцептрон не может справиться. Все эти задачи связаны с **инвариантным представлением** образов. Примеры такого представления: поворот объекта, его перенос и растяжение-сжатие. После таких действий над исходным образом перцептрон не способен его распознать.

Минский и Пейперт обобщили свои выводы. Они заявили, что рассмотренные ими ограничения справедливы для любых параллельных вычислений. Именно к этому типу вычислений относятся нейронные сети. При этом авторы подчёркивают, что последовательные вычисления могут справиться с проблемой инвариантного представления. Другими словами они заявляли превосходство своего символьного подхода над коннекционизмом.

Есть мнение, что Минский и Пейперт стремились не столько дать объективную оценку возможностей перцептрона, сколько очернить конкурирующее направление ИИ. Такое вполне возможно, особенно когда ARPA урезала финансирование и началась жесткая конкуренция за гранты.

Так или иначе, но выводы книги "Перцептроны" оказались неверными для многослойных нейронных сетей. К сожалению, многослойными сетями в те годы мало кто занимался. Поэтому ошибки авторов выявили намного позже.

Наверняка неизвестно как книга повлияла на отношение к коннекционизму в научных кругах. К моменту её выхода в 1969 году параллельные вычисления уже считались малоперспективным направлением.

На развитие коннекционизма сильно повлияла поправка Мэнсфилда. В большинстве исследований нейронные сети рассматривались как теоретическая модель для изучения мозга. Практические результаты от таких проектов ожидались редко. Поэтому ARPA прекратило спонсирование исследований в рамках коннекционизма. Не имея финансирования, учёные были вынуждены переключаться на другие проекты.

### 2.1.4 Развитие ИИ 1980 – 1987

#### 2.1.4.1 Экспертные системы

Ранние системы ИИ конца 1950-х годов, такие как General Problem Solver и Advice Taker, претендовали на универсальность. Исследователи заявляли, что их программы способны рассуждать так же, как это делают люди. Таким образом системы потенциально могли решить любую задачу.

Главной частью ранних систем ИИ считались алгоритмы поиска решения. Знания, которыми оперировали эти алгоритмы, рассматривались как нечто второстепенное. Системы могли оперировать любыми фактами, следуя одному и тому же алгоритму. Так они должны были решать задачи из разных прикладных областей. Однако, такой подход не сработал для реальных задач из-за комбинаторного взрыва.

В середине 1960-х годов появилась новая архитектура ИИ систем. Они получили название [**экспертные системы**](https://en.wikipedia.org/wiki/Expert_system).

Экспертная система — это подвид [**системы, основанной на знаниях**](https://en.wikipedia.org/wiki/Knowledge-based_systems) (knowledge-based system или KBS). Отличительная особенность KBS заключается в её архитектуре. Система состоит из двух частей: **базы знаний** и **механизма вывода**. Впервые подобную архитектуру предложил Маккарти для системы Advice Taker.

База знаний содержит факты о реальном мире или прикладной области. Эти факты представляются в наглядной форме, а не в виде программного кода. Самая простая форма представления — это утверждение на естественном языке. Например: "Земля круглая".

Механизма вывода обрабатывает информацию из базы знаний, чтобы на её основе вывести новые знания.

Экспертная система отличается от других систем, основанных на знаниях. Её особенность в том, что она имитирует процесс принятие решений человеком-экспертом в какой-то прикладной области. Для такой имитации используются знания, которые человек-эксперт предварительно заносит в базу знаний системы.

Почему экспертные системы смогли решить проблему комбинаторного взрыва? Ранние ИИ системы оперировали достаточно общими фактами. Требовались значительные вычисления, чтобы вывести из этих фактов промежуточные решения. Затем они комбинировались в конечное решение задачи.

Экспертные системы оперируют знаниями о предметной области, полученными от человека-эксперта. Эти знания уже представляют собой промежуточные решения. Таким образом экспертным системам требуется значительно меньше вычислений, чтобы из имеющихся "заготовок" составить конечный результат.

Экспертные системы можно рассматривать как дальнейшее развитие символьного подхода в ИИ. База знаний этих систем представляла собой набор символов. Причем [**уровень абстракции**](https://dou.ua/lenta/articles/level-of-abstraction/) этих символов стал значительно выше чем у ранних систем ИИ.

I> В общем смысле термин абстракция означает модель объекта реального мира. Из этой модели исключаются несущественные детали. Уровень абстракции означает количество опущенных деталей. Чем выше этот уровень, тем меньше деталей объекта учитывает модель.

Рассмотрим первые экспертные системы и их возможности.

##### 2.1.4.1.1 Dendral

В 1965 году группа учёных из Стэнфордского университета начала проект системы ИИ, основанной на знаниях. В группу входили [Эдвард Фейгенбаум](https://ru.wikipedia.org/wiki/Фейгенбаум,_Эдвард_Альберт), Брюс Бьюкенен, [Джошуа Ледерберг](https://ru.wikipedia.org/wiki/Ледерберг,_Джошуа) и [Карл Джерасси](https://ru.wikipedia.org/wiki/Джерасси,_Карл). Система получила название Dendritic Algorithm или сокращённо [Dendral](https://ru.wikipedia.org/wiki/Dendral).

Ледерберг занимался исследованиями в области [астробиологии](https://ru.wikipedia.org/wiki/Астробиология). Эта наука изучает жизнь на других планетах. Учёный задался вопросом: сможет ли компьютер помочь ему в изучении незнакомых органических соединений?

Ледерберг обратился за помощью к химику Карлу Джерасси и информатику Эдварду Фейгенбаум. Вместе они спроектировали первую версию системы Dendral. Позже к проекту присоединился программист Брюс Бьюкенен.

Система Dendral должна была определять структуру неизвестных молекул по картине их [масс-спектра](https://ru.wikipedia.org/wiki/Масс-спектрометрия). Масс-спектрометрия измеряет отношение массы фрагментов молекулы к их заряду.

Чтобы решить задачу, Dendral генерировала наборы химических соединений. Каждое соединение представлялось в виде [**графа**](https://ru.wikipedia.org/wiki/Граф_(математика)). Для генерации использовались картины масс-спектров известных молекул, общие знания по химии и теории графов.

Для каждого сгенерированного химического соединения система вычисляла ожидаемую картину масс-спектра. Далее Dendral сравнивала её с картиной неизвестной молекулы. Если картины совпадали, система делала вывод, что сгенерирована именно неизвестная молекула.

Dendral решает задачу, которую в общем виде можно сформулировать так:

*Разработать решение с учётом данного набора ограничений.*

Система успешно справилась с этой задачей. Её применяли химики в своих исследованиях. Это был первый случай, когда система ИИ смогла решать реальные задачи из прикладной области.

##### 2.1.4.1.2 Mycin

Архитектура системы Dendral доказала свою эффективность. Кроме того, она была достаточно универсальной. Поэтому учёные из Стэнфордского университета продолжили разработки экспертных систем для других прикладных областей.

В начале 1970-х годов [Эдвард Шортлифф](https://en.wikipedia.org/wiki/Edward_H._Shortliffe), Бьюкенен и генетик [Стэнли Коэн](https://ru.wikipedia.org/wiki/Коэн,_Стэнли_Норман) разработали экспертную систему [Mycin](https://ru.wikipedia.org/wiki/MYCIN). Она анализировала симптомы пациента с тяжелым инфекционным заболеванием и определяла, какие бактерии его вызвали. Затем система рекомендовала антибиотики и дозировку для лечения.

Mycin имела несколько принципиальных отличий от системы Dendral. Во-первых, пользователь работал с ней интерактивно. Система задавала вопросы о симптомах пациента. Пользователь вводил свои ответы. На основе этих ответов Mycin ставила диагноз.

Второе отличие системы Mycin заключается в характере знаний, с которыми она работала. В медицине нет такой строгой теоретической модели как в химии. Поэтому Mycin не могла точно вычислить диагноз пациента. Вместо этого система указывала вероятность того или иного диагноза.

Система оперировала базой из примерно 600 правил. Учёные с медицинского факультета Стэнфорда оценили, что система ставит правильный диагноз в 65% случаев. Точность диагноза самих учёных была в диапазоне от 42.5% до 62.5%.

Несмотря на многообещающие результаты, Mycin осталась исследовательской разработкой и не применялась в больницах. Причина этого в трудоемком процессе ввода информации. В то время больницы не имели электронного документооборота. Вся информация о пациентах хранилась в бумажном виде. Один сеанс работы с Mycin мог длиться до получаса. Для врачей такие потери времени были неприемлемы.

##### 2.1.4.1.3 XCON

Успехи экспертных систем стали известны не только в научных кругах, но и среди крупных компаний. Поэтому в конце 1970-х годов компания DEC заказала разработку экспертной системы университету Карнеги — Меллона. За разработку системы отвечал Джон Макдермотт.

Компания DEC производила компьютеры. Эти компьютеры имели много комплектующих и кабелей соединения. Поэтому при заказах часто происходили ошибки. Покупатели получали несовместимое между собой оборудование или им не хватало кабелей для его подключения. Экспертная система должна была помочь отделу продаж DEC при составлении заказов.

В 1978 году Макдермотт закончил разработку системы. Она получила название [XCON](https://en.wikipedia.org/wiki/Xcon). Компания DEC начала применять систему с 1980-ого года.

База знаний и механизм вывода системы XCON постоянны развивалась. В конце срока эксплуатации системы её база начитывала около 2500 правил. За весь срок службы система обработала около 80000 заказов. Точность её работы оценивается на уровне 95%. Благодаря XCON компания DEC экономила до 25 миллионов долларов ежегодно.

Громкий успех системы XCON привел к тому, что корпорации по всему миру начали разработку экспертных систем для внутреннего использования.

Системы Dendral и Mycin были написаны на языке Lisp. Его возможности отлично подходили для разработки экспертных систем. Поэтому Lisp стал стандартом в новой отрасли программного обеспечения.

Скоро после начала бума экспертных систем появились специальные компьютеры под названием [Lisp-машины](https://ru.wikipedia.org/wiki/Лисп-машина). Их архитектура была оптимальна для запуска программ, написанных на языке Lisp.

#### 2.1.4.2 Компьютер пятого поколения

В 1982 году правительство Японии запустило проект [компьютера пятого поколения](https://ru.wikipedia.org/wiki/Компьютеры_пятого_поколения). На проект отводилось 10 лет. За это время планировалось спроектировать производительный суперкомпьютер и запустить его в серийное производство.

Почему новый компьютер отнесли к пятому поколению?  Поколения компьютеров принято различать по рабочим элементам, которые выполняют элементарные вычисления. Таблица 2-4 демонстрирует четыре поколения компьютеров и соответствующие им рабочие элементы.

{caption: "Таблица 2-4. Поколения компьютеров", width: "100%"}
| Поколение | Рабочий элемент |
| --- | --- |
| Первое | [Электровакуумная лампа](https://ru.wikipedia.org/wiki/Электронная_лампа) |
|  | |
| Второе | [Транзистор](https://ru.wikipedia.org/wiki/Транзистор) |
|  | |
| Третье | [Интегральная схема](https://ru.wikipedia.org/wiki/Интегральная_схема) |
|  | |
| Четвёртое | [Микропроцессор](https://ru.wikipedia.org/wiki/Микропроцессор) |

До 1970-х годов Япония отставала в производстве компьютеров. Самыми передовыми технологиями в этой области владели США и Англия. Поэтому в середине 1970-х министерство международной торговли и промышленности Японии (MITI) начало исследовать перспективные компьютерные технологий. Это исследование было поручено Японскому центру развития обработки информации (JIPDEC).

Центр JIPDEC определил следующие перспективные направления:

* Технологии логического вывода для обработки знаний.
* Технологии для обработки баз знаний большого масштаба.
* Высокопроизводительные рабочие станции.
* [Параллельные вычисления](https://ru.wikipedia.org/wiki/Параллельные_вычисления).
* Суперкомпьютеры для научных вычислений.

Министерство MITI решило объединить работу по всем этим направлениям в одном проекте. Целью проекта стала разработка высокопроизводительного суперкомпьютера.

Чтобы достичь высокой производительности, разработчики решили применить многопроцессорную архитектуру. Большинство компьютеров того времени имели только процессор. Поэтому они могли выполнять только одну программу в любой момент времени.

Многопроцессорная архитектура позволяла решать несколько задач одновременно. В этом состоит суть параллельных вычислений. Также открывалась возможность делить задачу на подзадачи и выполнять их все разом на нескольких процессорах.

Ещё одним важным решением стало применение концепции логического программирования, разработанной Джоном Маккарти. Центр JIPDEC высоко оценил перспективы этого подхода. Поэтому языком программирования для суперкомпьютера стал Prolog, а не более универсальный Lisp.

На логическое программирование возлагались большие надежды. Ожидалось, что эта концепция хорошо сочетается с параллельными вычислениями. Кроме того на логическом программировании планировалось построить следующие функции ИИ для суперкомпьютера:

* Распознавание речи и автоматический набор текста.
* Машинный перевод.
* Анализ печатного текста и его категоризация.
* Распознавание образов.
* Саморазвитие системы.

Другие страны ответили на амбициозные планы Японии. В 1984 году правительство Великобритании начало спонсировать программу [Alvey](https://en.wikipedia.org/wiki/Alvey). Целью программы стали исследования по следующим направлениям:

* Сверхбольшие интегральные схемы (VLSI)
* Системы ИИ, основанные на знаниях.
* Разработка программ.
* Интерфейс взаимодействия человека и машины.

Группа американских компаний объединилась и создала [корпорацию MCC](https://en.wikipedia.org/wiki/Microelectronics_and_Computer_Technology_Corporation), также известную как Консорциум Микроэлектроники и Компьютеров. Эта корпорация должна была спонсировать фундаментальные исследования в области ИИ и информационных технологий. В то же время управление министерства обороны США DARPA утроило финансирование в области ИИ.

#### 2.1.4.3 Возрождение коннекционизма

В 1970-е и 1980-е годы исследования в рамках коннекционизма проводили учёные не связанные с ИИ. Один из них — американский физик [Джон Хопфилд](https://ru.wikipedia.org/wiki/Хопфилд,_Джон). Он использовал методы из статистической механики, чтобы изучить свойства хранения данных в нейронной сети. В результате Хопфилд разработал [новую архитектуру нейронной сети](https://ru.wikipedia.org/wiki/Нейронная_сеть_Хопфилда), которая была названа в его честь. Эта сеть стала моделью для изучения человеческой памяти. Хопфилд подробно описал свои идеи в статье 1982 года.

В начале 1980-х годов психологи [Джеффри Хинтон](https://ru.wikipedia.org/wiki/Хинтон,_Джеффри) и [Дэвид Румельхарт](https://ru.wikipedia.org/wiki/Румельхарт,_Дэвид) из университета Карнеги — Меллона исследовали процесс обучения и модель памяти на основе нейронных сетей. Они применили существующие наработки и предложили [**метод обратного распространения ошибки**](https://ru.wikipedia.org/wiki/Метод_обратного_распространения_ошибки). Этот метод позволял эффективно обучать многослойные [нейронные сети с прямой связью](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью). Именно к такому типу сетей относится перцептрон.

В 1986 году Румельхарт и [Джеймс Макклелланд](https://ru.wikipedia.org/wiki/Макклелланд,_Джеймс) опубликовали цикл статей под названием "Параллельная распределенная обработка" (Parallel Distributed Processing). В этом цикле авторы демонстрировали области применения метода обратного распространения ошибки в компьютерных науках и психологии. Благодаря статьям Румельхарта и Макклелланда, исследователи ИИ снова заинтересовались коннекционизмом.

Благодаря развитию технологии транзисторов в 1980-е годы, появилась возможность конструировать надёжные нейрокомпьютеры. Их архитектуру описали Карвер Мид и Мохаммед Исмаил в книге 1989 года "Аналоговая реализация нейронных сетей на сверхбольших интегральных схемах" ("Analog VLSI Implementation of Neural Systems").

### 2.1.5 Вторая зима ИИ 1987 — 1993

В 1984 году состоялась ежегодная встреча Американской ассоциации искусственного интеллекта (AAAI). На одном из обсуждений Марвин Минский и Роджер Шэнк обратились к предпринимателям. Они предупредили о завышенных ожиданиях от исследований в области ИИ.

На протяжении 1980-х годов инвестиции коммерческих компаний в ИИ постоянно росли. К 1985 году корпорации по всему миру потратили на разработку экспертных систем в сумме свыше миллиарда долларов. В основном это были разработки для внутренних нужд.

Разработка экспертных систем в больших масштабах вызвала спрос на услуги поддержки. На рынке появились новые компании. Они предлагали программные и аппаратные решения для экспертных систем.

Несмотря на бурный рост, в 1987 году рынок экспертных систем рухнул по сценарию [экономического пузыря](https://ru.wikipedia.org/wiki/Экономический_пузырь). Причиной кризиса стали завышенные ожидания инвесторов и невыполнимые обещания самих компаний. Новые компаний не смогли предоставить работоспособные решения в срок. В результате многие проекты были закрыты, а контракты на поддержку расторгнуты.

Такой поворот разочаровал инвесторов. Среди них появились сомнения, что разработки в области ИИ прибыльны с коммерческой точки зрения.

#### 2.1.5.1 Банкротство производителей Lisp-машин

В конце 1979-х сотрудники лаборатории ИИ Массачусетского технологического института начали работать над специальным компьютером для запуска экспертных систем. Языком для разработки этих систем был Lisp. Поэтому новые компьютеры были нацелены на исполнение только Lisp-программ и получили название Lisp-машины.

В 1979 году на базе института была создана компания [Lisp Machines](https://en.wikipedia.org/wiki/Lisp_Machines). Её первым клиентом стала компания [Control Data Corporation](https://ru.wikipedia.org/wiki/Control_Data_Corporation) — крупный производитель компьютерной периферии и суперкомпьютеров.

В 1980-ом году часть сотрудников покинули Lisp Machines чтобы организовать новую компанию [Symbolics](https://en.wikipedia.org/wiki/Symbolics). Позднее к производству Lisp-машин подключились крупные производители электроники: [Texas Instruments](https://ru.wikipedia.org/wiki/Texas_Instruments) и [Xerox](https://ru.wikipedia.org/wiki/Xerox). Рынок специализированных компьютеров выглядел перспективно и обещал долгосрочный рост. Инвестиции в разработки Lisp-машин достигли полмиллиарда долларов.

Спрос на Lisp-машины рос до 1987 года. Затем рынок неожиданно рухнул. Специализированные компьютеры стали никому не нужны. Это произошло из-за появления [**рабочих станций**](https://en.wikipedia.org/wiki/Workstation) от компании Sun Microsystems.

I> Рабочая станция отличается от персонального компьютера высокой ценой и производительностью. Её аппаратное обеспечение оптимизировано для задач визуализации, 3D моделирования и математических расчётов. При этом рабочая станция остаётся [компьютером общего назначения](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения).

Рабочие станции от Sun Microsystems имели мощное по тем временам оборудование. Их производительность была выше, чем у специализированных Lisp-машин. Несмотря на это преимущество, корпорации отказывались использовать рабочие станции. Проблема была в том, что они не поддерживали язык Lisp. Это означало, что экспертные системы на них не запускались.

В 1987 году компания [Lucid](https://en.wikipedia.org/wiki/Lucid_Inc.) разработала интерпретатор языка Lisp для операционной системы Unix. Под управлением именно этой системы работали рабочие станции Sun.

Кроме интерпретатора от компании Lucid в 1980-е годы в университете Беркли был разработан интерпретатор [Franz Lisp](https://en.wikipedia.org/wiki/Franz_Lisp). В 1982 года его портировали на компьютеры Sun.

В середине 1980-х годов относительно недорогие ПК от компаний Apple и IBM достигли производительности Lisp-машин. В скором времени на эти ПК были портированы популярные интерпретаторы языка Lisp.

Пользователям экспертных систем не осталось причин переплачивать за специальное оборудование. Корпорации стали массово отказываться от использования Lisp-машин в пользу дешёвых и универсальных компьютеров с поддержкой языка Lisp.

#### 2.1.5.2 Проблемы экспертных систем

К началу 1990-х годов компании накопили достаточно опыта в использовании экспертных систем. Опыт показал, что их обслуживание обходится слишком дорого.

Проблемы возникали при добавлении новой информации в базу знаний. Сама экспертная система не имеет функции обучения. Поэтому специалисты вносили все изменения вручную. После таких изменений всю базу знаний надо было проверять на [**согласованность**](https://ru.wikipedia.org/wiki/Согласованность_данных). Согласованность означает, что в базе нет правил противоречащих друг другу. На такую проверку и исправление найденных ошибок уходило много времени и сил.

К 1990-м годам научные круги потеряли интерес к экспертным системам. Такие системы не позволяли создать универсальный ИИ. Для работы такому ИИ требуются общие знания о реальном мире. Однако, разработки в области архитектуры баз знаний показали, что представление общих знаний — трудновыполнимая задача.

Одна из немногих попыток представить общие знания о мире в базе знаний — проект [Дугласа Лената](https://ru.wikipedia.org/wiki/Ленат,_Дуглас) под названием [Cyc](https://ru.wikipedia.org/wiki/Cyc). Этот проект неоднократно подвергался критики со стороны научного сообщества. Многие учёные считают его бесполезным.

Экспертные системы доказали свою эффективность в некоторых узкоспециализированных прикладных областях. Однако, из-за коммерческих неудач инвесторы потеряли интерес к этому направлению. Не имея финансирования и интереса со стороны научного сообщества, дальнейшая активная разработка экспертных систем прекратилась.

#### 2.1.5.3 Провал проекта компьютера пятого поколения

К 1991 году проект компьютера пятого поколения в Японии не достиг поставленных целей. В рамках проекта инженеры собрали несколько рабочих станций. Для этих станций разработали несколько [демонстрационных приложений](https://instadeq.com/blog/posts/japans-fifth-generation-computer-systems-success-or-failure/):

* Распределённую систему управления данными Kappa.
* [Правовую экспертную систему](https://ru.wikipedia.org/wiki/Правовая_экспертная_система) HELIC-II.
* Систему для доказательства теорем MGTP.
* Систему для обработки естественного языка Laputa.

На проект было потрачено много денег и усилий. Несмотря на это, рабочие станции не пошли в массовое производство и не попали на рынок. Причин этому несколько. Рассмотрим их подробнее.

Когда прототипы рабочих станций были готовы, они уже оказались устаревшими. Проект длился 10 лет. В момент его запуска исследователи предполагали, что однопроцессорные компьютеры достигли предела производительности. Специалисты пришли к выводу, что параллельные вычисления — это единственный способ увеличить мощность компьютера. Однако, этот прогноз оказался неверным. Число транзисторов на интегральной схеме продолжало увеличиваться, согласно закону Мура. В результате этого к 1991 году недорогие ПК, собранные на стандартных компонентах, превзошли по производительности рабочие станции пятого поколения.

Не только низкая производительность привела к тому, что рабочие станции устарели. Параллельно с микропроцессорами развивались и информационные технологии в целом. Так в 1984 компания Apple разработала графический интерфейс для своих ПК. В начале 1990-х появился Internet. Рабочие станции пятого поколения не поддерживали эти передовые технологии. В результате они стали неинтересны пользователям.

Другая проблема компьютера пятого поколения связана с его программами. Разработчики выбрали концепцию логического программирования и язык Prolog. Но оказалось, что эта концепция плохо совместима с параллельными вычислениями. Сам язык Prolog не предоставлял средств для выполнения программы на нескольких процессорах. Все попытки добавить такие средства в язык провалились.

Запланированные возможности ИИ потребовали более производительного оборудования, чем ожидалось. Логического программирования оказалось недостаточно для их реализации. Нужны были принципиально другие подходы разработки систем ИИ.

Провал проекта компьютера пятого поколения повлиял на развитие информационных технологий. Во-первых, проект подорвал веру разработчиков программ и учёных в логическое программирование. Недостатки этого подхода считались одной из главных причин неудачи проекта. Крупные исследования и финансирование этого направления ИИ прекратились.

Во-вторых, правительства США и Англии сократили свои инвестиции в компьютерные технологии и исследования ИИ. Эти страны остались лидерами в обоих областях. Пропала угроза того, что Япония сможет их догнать.

### 2.1.6 Развитие ИИ в 1993–2011

#### 2.1.6.1 Научный подход в ИИ

С 1970-х годов исследования в области ИИ проводились [двумя принципиально разными путями](https://en.wikipedia.org/wiki/Neats_and_scruffies). Это пути экспериментаторов (scruffy) и теоретиков (neat). Споры о преимуществах каждого подхода продолжались до 1990-х годов.

Разногласия между учёными прекратились, когда в ИИ стали применяться новейшие методы математики и статистики. Благодаря этим методам, появилось новое направление в разработке программ — [**математическая оптимизация**](https://ru.wikipedia.org/wiki/Оптимизация_(математика)). Оно занимается поиском наилучшего решения с заданными критериями между несколькими альтернативами.

 Формальные методы подстегнули развитие нейронных сетей. Такие направления как [**машинное обучение**](https://ru.wikipedia.org/wiki/Машинное_обучение) и компьютерное зрение достигли больших успехов. Это произошло благодаря пересмотру уже существующих теорий. Формальный анализ позволили лучше оценить эти теории, построить на них системы ИИ и провести надёжные эксперименты.

I> Машинное обучение — это класс методов в ИИ. Эти методы не решают поставленную задачу, а обучают систему на примерах решения аналогичных задач. После процесса обучения система решает поставленную задачу сама.

Переход к формальным методам позволили исследователям ИИ использовать достижения других наук. Среди них теория вероятностей и теория принятия решений. Использование математического аппарата ускорило обмен идеями между ИИ и смежными науками.

#### 2.1.6.2 Интеллектуальные агенты

В 1990-х годах большинство исследователей ИИ согласилось с концепцией интеллектуальных агентов. Эта концепция была заимствована из экономики и теории принятия решений. В этих науках есть понятие рационального агента. Интеллектуальный агент и есть рациональный агент в контексте ИИ.

 Интеллектуальный агент пытается максимизировать свою эффективность при решении поставленной задачи. Точно так же рациональный агент стремится максимизировать свою прибыль в экономике.

Понятие интеллектуального агента разрешило несколько философских проблем в области ИИ. Первая проблема заключается в вопросе о том, что именно считать интеллектом. Тест Тьюринга подразумевает сравнение искусственных систем с человеческим интеллектом. Понятие рационального агента устранило это сравнение. Теперь любое поведение считается интеллектуальным, если оно приводит к эффективному достижению цели.

Вторая философская проблема заключается в вопросе: может ли машина обладать сознанием и настоящим пониманием? Эти свойства оказались неважны для интеллектуального агента. Для агента важна только эффективность решения. Метод поиска решения может быть любым. Он не зависит от понятий "сознание" и "понимание".

Теперь исследователи ИИ смогли сконцентрироваться на решении конкретных практических задач. Им больше не надо было защищать свои методы с точки зрения философии ИИ. Достаточно было доказать правильность выбранных методов с помощью математики.

Концепция интеллектуального агента помогла исследователям ИИ и с практической точки зрения. Она позволила непосредственно сравнивать эффективность различных систем, основанных на разных подходах. Принцип работы системы отошёл на второй план. Раньше каждый исследователь работал только в рамках одного подхода: символьный, логическое программирование или коннекционизм. Теперь система оценивалась более объективно по своим результатам. Начались попытки совместить разные подходы, чтобы повысить эффективность систем ИИ.

#### 2.1.6.3 Восстановление репутации ИИ

Многие инвесторы разочаровались в области ИИ после краха рынка Lisp-машин, проблем с экспертными системами и провала проекта компьютера пятого поколения. Правительства стран и компании потеряли деньги, когда пузырь экспертных систем лопнул. Они больше не хотели вкладываться в исследования ИИ.

На протяжении 1990-х годов учёные избегали термина "искусственный интеллект". Считалось, что он означает невыполнимые обещания и отпугивает инвесторов. Вместо этого исследователи ИИ называли свою работу информатикой, когнитивными системами или вычислительным интеллектом. Это привело к следующим долгосрочным последствиям:

1. [Алгоритмы и концепции](https://en.wikipedia.org/wiki/Applications_of_artificial_intelligence#Historical_contributions), разработанные в рамках исследований ИИ, оказались интегрированы в обычные компьютерные системы. Эти достижения ошибочно считаются результатом развития информатики, а не ИИ.

2. Область ИИ оказалась раздробленной. Достижения учёных 1990-х годов приписываются новым, выдуманным им направлениям. На самом деле все эти достижения относятся к ИИ.

В конце 1990-х и 2000-х годах несколько систем ИИ достигли впечатляющих успехов. Эти успехи вызвали широкий резонанс в обществе. Они отчасти восстановили испорченную репутацию науки об ИИ. Вот неполный список этих систем:

* В 1997 году суперкомпьютер [DeepBlue](https://ru.wikipedia.org/wiki/Deep_Blue) от IBM смог обыграть чемпиона мира по шахматам Гарри Каспарова.

* В 2005 году робот, разработанный в Стэнфордском университете, победил в гонках [DARPA Grand Challenge](https://ru.wikipedia.org/wiki/DARPA_Grand_Challenge). Автономно управляемая машина смогла проехать весь маршрут в 211 километров по пустыне Мохаве. На это у робота ушло почти семь часов.

* В 2011 году ИИ система [Watson](https://ru.wikipedia.org/wiki/IBM_Watson) от компании IBM обыграла двух лучших игроков в телевизионной игре-викторине Jeopardy!. В этой игре участники отвечают на вопросы из области общих знаний.

Эти успехи удалось достичь благодаря увеличению производительности компьютеров и качественной разработке программ. Каждая из нашумевших ИИ систем использовала хорошо известные подходы, появившиеся ещё в 1960-х годах.

### 2.1.7 Современные направления ИИ

С развитием сети Internet становится доступно всё больше данных разного типа. Поэтому начиная с 2000-х годов в информатике и ИИ наблюдается новая тенденция. Исследователи всё чаще фокусируются на больших объемах данных, а не на алгоритмах. Они ищут способы обучения систем ИИ на этих данных без помощи человека. Такие системы после обучения способны решать прикладные задачи из разных областей.

#### 2.1.7.1 Big Data

Big data или [**большие данные**](https://ru.wikipedia.org/wiki/Большие_данные) — современное направление информатики. Изучает методы обработки наборов данных, которые слишком велики для применения традиционных подходов.

Big data занимается наборами данных, которые характеризуются "четырьмя V":

* **Volume** (объём). Количество сгенерированных и сохранённых данных. Обычно составляет от нескольких терабайт до петабайт. Объём данных определяет их ценность и полезность.

* **Velocity** (скорость). Скорость генерации и обработки данных. Big data обычно обновляются непрерывно, в режиме реального времени. Для решения задач их надо обрабатывать со скоростью близкой к реальному времени.

* **Variety** (разнообразие). Технологии big data рассчитаны на обработку плохо структурированных и неструктурированных данных разных типов: текст, изображения, видео, аудио и т.д.

* **Veracity** (достоверность). Данные должны быть надёжными и отражать истинное положение вещей. Качество собранных данных определяет точность их анализа.

Направление big data возникло по следующим причинам:

* [Компьютеризация](https://ru.wikipedia.org/wiki/Компьютеризация) общества. Все больше компаний и правительственных учреждений используют компьютеры. В результате накапливаются огромные объёмы информации. Их надо регулярно обрабатывать.

* Распространение портативных устройств, которые способны накапливать информацию. Примеры таких устройств: мобильные телефоны, телевизоры, камеры наблюдения, микрофоны. Накопленная информация используется пользователями и производителями этих устройств.

* Развитие сети Internet. Пользователи активно обмениваются информацией и оставляют историю своих действий в Internet. Эта информация интересна владельцам Web-сервисов и компаниям в сфере интернет-торговли.

Исследователи и инженеры big data используют следующие технологии:

* Машинное обучение.
* [Обработка естественных языков](https://ru.wikipedia.org/wiki/Обработка_естественного_языка).
* [Облачные вычисления](https://ru.wikipedia.org/wiki/Облачные_вычисления).
* [Базы данных](https://ru.wikipedia.org/wiki/База_данных).
* Визуализация данных.

На сегодняшний день технологии big data достаточно развиты, чтобы применяться в коммерческих целях. Наиболее активно их используют в следующих областях:

* Государственные учреждения. Они обрабатывают личную информацию граждан и ведут разного рода статистику.

* Здравоохранение. Методы big data применяются для анализа результатов клинических исследований. Также они помогают вести статистику заболеваний.

* Экономика. Для составления прогнозов и планирования крупных проектов приходится обрабатывать значительные объёмы данных.

* Страховые компании должны обрабатывать данные о своих клиентах.

* Информационные технологии. Многие информационные системы собирают статистику об их использовании. Это помогает разработчикам улучшать свои продукты.

Направление big data использует технологии ИИ: машинное обучение и обработку языков. В то же время big data разрабатывает новые подходы для обработки данных, которые применяются в передовых исследованиях ИИ. Можно сказать, что big data и ИИ — смежные направления, которые взаимно дополняют друг друга.

#### 2.1.7.2 Deep Learning

В 1986-ом году появилось новое направление коннекционизма под названием deep learning. Оно также известно как [**глубокое обучение**](https://ru.wikipedia.org/wiki/Глубокое_обучение).

Deep learning — это набор методов машинного обучения для многослойных нейронных сетей. Эти методы направлены на автоматическое [обучение признакам](https://ru.wikipedia.org/wiki/Обучение_признакам). Другими словами, нейронная сеть сама обнаруживает признаки для классификации исходных данных.

Deep learning часто противопоставляют **shallow learning** (поверхностное обучение). Второе направление считается классическим в рамках коннекционизма. Оно занимается однослойными нейронными сетям и некоторыми другими обучаемыми моделями. Многослойной сетью считается сеть, у которой два и более скрытых слоя.

Отличие между deep learning и shallow learning не только в архитектуре сетей, но и в методах обучения. В shallow learning обучающий набор данных подготавливается вручную. Из данных извлекаются признаки (feature extraction), которые актуальны для решаемой задачи. Эти признаки переводятся в формат, удобный для нейронной сети. Однослойные сети быстрее обучать, но они хуже справляются с задачей обобщения. Другими словами, однослойная сеть показывает хорошие результаты на тестовых данных, но ошибается при решении реальной задачи.

В deep learning нейронная сеть сама извлекает признаки из обучающего набора данных. При этом сеть хорошо справляется с задачей обобщения. За это приходится расплачиваться более долгим временем обучения. Кроме того многослойные сети требуют больший объём обучающих данных, чем однослойные сети.

Deep learning изучает нейронные сети со следующими архитектурами:

* [Глубокая нейронная сеть](https://en.wikipedia.org/wiki/Deep_learning#Deep_neural_networks) (deep neural networks или DNN)
* [Глубокая сеть доверия](https://ru.wikipedia.org/wiki/Глубокая_сеть_доверия) (deep belief network или DBN)
* [Рекуррентная нейронная сеть](https://ru.wikipedia.org/wiki/Рекуррентная_нейронная_сеть) (recurrent neural network или RNN)
* [Свёрточная нейронная сеть](https://ru.wikipedia.org/wiki/Свёрточная_нейронная_сеть) (convolutional neural network или CNN)

Многослойные перцептроны исследовал ещё Розенблатт в 1960-х годах. Однако, эти работы ограничивались теоретическими выкладками. В отличие от однослойных сетей, многослойные намного требовательнее к производительности компьютеров. Поэтому до 1980-х годов не удавалось построить работоспособные модели глубоких сетей.

Активные исследования по изучению многослойных сетей начались в середине 1960-х годов. Толчком к этому послужила книга Розенблатта "Принципы нейродинамики". В 1967 году советский математик [Алексей Ивахненко](https://ru.wikipedia.org/wiki/Ивахненко,_Алексей_Григорьевич) разработал первый алгоритм обучения многослойных перцептронов.

В 1980-м году японский учёный Кунихико Фукусима предложил архитектуру многослойной сети под названием [**неокогнитрон**](https://ru.wikipedia.org/wiki/Неокогнитрон). Она предназначалась для распознавания образов.

В начале 1980-х Хинтон и Румельхарт разработали метод обратного распространения ошибки. Он хорошо подходил для обучения многослойных сетей.

Исследования многослойных нейронных сетей продолжались на протяжении 1980-х годов. Однако, только в 2000-х годах глубокие сети стали широко применяться для решения практических задач. Это произошло благодаря следующим достижениям:

* Развитие теории обучения глубоких сетей.

* Рост производительности компьютеров и снижение их стоимости.

* В различных предметных областях были накоплены большие наборы данных для обучения сетей.

* Появилось специальное оборудование — [графические процессоры](https://ru.wikipedia.org/wiki/Графический_процессор) или GPU. Они на порядок ускорили обучение нейронных сетей.

На протяжении 2000-х годов глубокие нейронные сети активно развивались. Совершенствовалась теория и накапливался опыт их практического применения.

В начале 2010-х глубокие сети стали занимать призовые места на конкурсах по распознаванию образов.

Сегодня глубокие нейронные сети успешно применяются для следующих задач:

* Распознавание речи.
* Распознавание образов.
* Машинный перевод.
* Системы рекомендаций.
* Медицинская диагностика.
