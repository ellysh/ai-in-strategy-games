## История

Искусственный интеллект как направление исследований появился на стыке нескольких дисциплин. На ИИ оказали влияние идеи, открытия и методы из следующих наук:

* Неврология
* Математика
* Информатика
* Теория управления
* Кибернетика

Рассмотрим наиболее важные этапы развития ИИ.

### Появление новой науки 1943 – 1956

#### Нейронная сеть

Первые исследования в области ИИ связаны с неврологией. Американские учёные [Уолтер Питтс](https://ru.wikipedia.org/wiki/Питтс,_Уолтер) [Уоррен Мак-Каллок](https://ru.wikipedia.org/wiki/Мак-Каллок,_Уоррен) предложили модель [**искусственного нейрона**]((https://ru.wikipedia.org/wiki/Искусственный_нейрон)). Эта модель основывалась на исследованиях в области нейрофизиологии. Она могла выполнять простые логические выводы. Свои достижения учёные описали в статье "Логическое исчисление идей, относящихся к нервной активности" (A Logical Calculus of Ideas Immanent in Nervous Activity). Статья была опубликована в 1943 году.

[Нейрон](https://ru.wikipedia.org/wiki/Нейрон) — это клетка, которая является минимальным строительным блоком [нервной системы](https://ru.wikipedia.org/wiki/Нервная_система). Нейроны соединяется друг с другом в [нервную сеть](https://ru.wikipedia.org/wiki/Нервная_сеть). По этой сети передаются электрические и химические сигналы. С помощью этих сигналов передаётся информация между узлами нервной системы.

Искусственный нейрон Питтса и Мак-Каллока представлял собой упрощённую математическую модель биологического нейрона. Искусственный нейрон выполняет единственную задачу: получает на вход набор сигналов и генерирует один выходной сигнал.

В 1949 году канадский нейропсихолог [Дональд Хебб](https://ru.wikipedia.org/wiki/Хебб,_Дональд) опубликовал книгу "Организация поведения" (Organization of Behavior). В ней учёный предложил теорию обучения нейронов человеческого мозга. Эта теория получила название [правило обучения Хебба]((http://www.machinelearning.ru/wiki/index.php?title=Правило_Хэбба)). Это правило можно сформулировать так:

*Связи нейронов, которые активируются совместно, усиливаются. Связи нейронов, которые срабатывают независимо, ослабевают*

Правило Хебба легло в основу моделей первых [**нейронных сетей**](https://ru.wikipedia.org/wiki/Нейронная_сеть). Оно остаётся актуальным и сегодня.

Нейронная сеть — это соединение искусственных нейронов. Первый компьютер на основе такой сети был сконструирован аспирантами математиками [Марвином Мински](https://ru.wikipedia.org/wiki/Минский,_Марвин_Ли) и Дином Эдмондсом в 1951 году. Компьютер получил название [Snarc](https://en.wikipedia.org/wiki/Stochastic_neural_analog_reinforcement_calculator). Snarc моделировал сеть их 40 нейронов. Мински и Эдмондс пытались научить эту сеть проходить лабиринт.

#### Статья Тьюринга

Первое систематичное обсуждение искусственного интеллекта предложил [Алан Тьюринг](https://ru.wikipedia.org/wiki/Тьюринг,_Алан) в статье ["Вычислительные машины и разум"](https://ru.wikipedia.org/wiki/Вычислительные_машины_и_разум) (Computing Machinery and Intelligence). Она была опубликована в 1950 году.

В своей статье Тьюринг определяет термины "машина" и "мыслить". Он предлагает [тест](https://ru.wikipedia.org/wiki/Тест_Тьюринга) для проверки разумности машины. В этом тесте человек выполняет роль судьи. Он должен обменяться сообщениями с другим человеком и машиной. В результате этой переписки судья определяет, кто из собеседников машина. Участники теста не видят друг друга. То есть обмен сообщениями происходит вслепую. Машина проходит тест, если судья не может однозначно решить, кто из собеседников является человеком.

Тьюринг в своей работе также описывает принципы машинного обучения и генетические алгоритмы. Эти идеи намного предвосхитили соответствующие технологии.

Многие из прогнозов Тьюринга о развитии вычислительной техники и искусственного интеллекта оказались верны.

#### Logic Theorist

В 1956 году американские учёные [Аллен Ньюэлл](https://ru.wikipedia.org/wiki/Ньюэлл,_Аллен) и [Герберт Саймон](https://ru.wikipedia.org/wiki/Саймон,_Герберт_Александер) разработали программу под названием [Logic Theorist](https://en.wikipedia.org/wiki/Logic_Theorist). Эта программа выполняла [автоматические рассуждения](https://en.wikipedia.org/wiki/Automated_reasoning). Она смогла доказать 38 теорем из книги ["Начала математики"](https://ru.wikipedia.org/wiki/Principia_Mathematica) Бертрана Рассела. Эта книга считается фундаментальным трудом по [логике](https://ru.wikipedia.org/wiki/Логика).

В середине 1950-х годов считалось, что компьютеры могут оперировать только числами. Вопреки этому мнению программа Ньюэлла и Саймона работала с символами. Это позволило перейти от простых вычислений к логическим высказываниям. Разработчики Logic Theorist утверждали, что создали программу, способную "мыслить в нечисловых терминах". Их подход стал доминирующим в ИИ на следующие 30 лет.

#### Дартмутский семинар

Все описанные исследования относились к области ИИ. Однако, такой науки не существовало до лета 1956 года. Такие исследования "думающих машин" называли кибернетикой, теорией автоматов и сложной обработкой информации. Название зависело от подхода, выбранного учёными в каждом конкретном случае.

В 1955 году американский учёный в области информатики Джон Маккарти решил организовать [семинар](https://ru.wikipedia.org/wiki/Дартмутский_семинар), посвященный "думающим машинам". Задачей семинара было обсуждение достижений в этой области и разработка новых идей.

На тот момент Маккарти работал в Дартмутском колледже. Поэтому семинар стал известен как Дартмутский семинар. В заявке на проведение мероприятия Маккарти написал: "исследование искусственного интеллекта". Термин "искусственный интеллект" был выбран за свою нейтральность. Такой подход позволил отойти от принятых методов кибернетики и теории автоматов.

В семинаре принимали участие ведущие учёные, занимающиеся теорией управления, теорией автоматов, нейронными сетями, теорией игр и когнитивной психологией.

На семинаре не было предложено принципиально новых идей. Но он позволил познакомиться учёным, которые работали в области "думающих машин". Кроме того на семинаре было решено назвать новую науку искусственный интеллект.

### Символьный подход 1956 – 1974

В исследованиях по искусственному интеллекту с середины 1950-х до конца 1980-х доминировал [**символьный подход**](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект). Этот подход предлагает представлять задачи в виде понятных человеку символов. Таким способом решались задачи логического вывода и поиска.

В основе символьного подхода лежит [гипотеза Ньюэлла — Саймона](https://ru.wikipedia.org/wiki/Гипотеза_Ньюэлла_—_Саймона) о **физической символьной системе**. Согласно этой гипотезе, для выполнения интеллектуальных операций необходима и достаточна специальная система символов. Другими словами любой интеллектуальный агент должен манипулировать структурами данных, состоящими из символов.

#### Рассуждение как поиск

В этот период появился метод под названием "рассуждение как поиск" (reasoning as search). Позднее он был переименован в метод [**анализа средств и результатов**](https://en.wikipedia.org/wiki/Means–ends_analysis) (means–ends analysis). Его суть заключается в применении алгоритма поиска для решения логических задач. Этот подход напоминает поиск выхода из лабиринта. Когда программа заходит в тупик, она возвращается назад на несколько шагов и пробует другие варианты рассуждений.

Самым ярким примером применения метода "рассуждение как поиск" была программа [General Problem Solver](https://ru.wikipedia.org/wiki/Универсальный_решатель_задач) (универсальный решатель задач). Её разработали Аллен Ньюэлл и Герберт Саймон в 1959 году. Это была улучшенная версия Logic Theorist. Она могла доказывать теоремы евклидовой геометрии и логики предикатов, а также решать шахматные задачи.

#### Обработка естественного языка

В 1960-е годы начались первые исследования в области обработки естественного языка. Дэниэль Бобров разработал программу [STUDENT](https://en.wikipedia.org/wiki/STUDENT_(computer_program)) в 1964 году. Она решала алгебраические задачи, сформулированные на английском языке.

В 1966 году Джозеф Вейценбаум разработал программу [ELIZA](https://ru.wikipedia.org/wiki/Элиза_(программа)). Она была [виртуальным собеседником](https://ru.wikipedia.org/wiki/Виртуальный_собеседник), который парадирует разговор с психотерапевтом. Сегодня подобные программы называются чат-ботами.

#### Микромиры

В конце 1960-х годов Марвин Минский и Сеймур Пейперт работали в лаборатории ИИ Массачусетского технологического института (МТИ). Они предложили сфокусировать исследования ИИ на упрощённых задачах. Такие задачи получили название **микромиры**. Минский и Пейперт утверждали, что полученные в микромирах результаты будут работать и для реальных задач.

Один из примеров микромира — это [мир блоков](https://en.wikipedia.org/wiki/Blocks_world). В нём на плоской поверхности лежат блоки различных цветов и форм. Исследования в рамках мира блоков привело к нескольким инновационным разработкам:

* [Машинное зрение](https://ru.wikipedia.org/wiki/Машинное_зрение), которым занимались [Дэвид Хаффман](https://ru.wikipedia.org/wiki/Хаффман,_Дэвид), Дэвид Уолтс и [Патрик Уинстон](https://ru.wikipedia.org/wiki/Уинстон,_Патрик).

* Робот-манипулятор для перекладывания блоков. Его разработали Минский и Пейперт.

* Программа [SHRDLU](https://ru.wikipedia.org/wiki/SHRDLU). Её разработал [Терри Виноград](https://ru.wikipedia.org/wiki/Виноград,_Терри). Программа выполняла задачи над блоками. Эти задачи формулировались на английском языке.

#### Перцептрон

В 1957 году американский психолог [Фрэнк Розенблатт](https://ru.wikipedia.org/wiki/Розенблатт,_Фрэнк) предложил модель восприятия информации мозгом. Эта модель получила название [**перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон).

Перцептрон представлял собой нейронную сеть. Она состоит из трёх слоёв элементов:

1. S-элементы (сенсорные)
2. A-элементы (ассоциативные)
3. R-элементы (реагирующие)

Чтобы лучше понять структуру перцептрона, можно провести аналогию с мозгом. Перцептрон позволяет создать набор ассоциаций (A-элементы) между входными стимулами (S-элементы) и реакцией на них (R-элементы). Пример такой реакции — физиологический ответ двигательных нейронов на зрительную информацию.

В 1960 году Розенблатт сконструировал первый в мире [нейрокомпьютер](https://ru.wikipedia.org/wiki/Нейрокомпьютер) [Mark I Perceptron](https://ru.wikipedia.org/wiki/Марк-1). Этот компьютер представлял собой перцептрон, построенный на аналоговых электронных компонентах. Этими компонентами были фотодетекторы, потенцометры и электромоторы. Основной задачей компьютера было распознавание изображений.

В 1962 году Розенблатт опубликовал книгу "Принципы нейродинамики" (Principles of Neurodynamics). В ней он доказал [теорему сходимости перцептрона](https://ru.wikipedia.org/wiki/Теорема_сходимости_перцептрона). Согласно ей обучение перцептрона всегда приведёт к решению задачи за конечно число шагов.

### Первая зима ИИ 1974 – 1980

#### Финансирование DARPA

Первые успехи в области ИИ привлекли финансирование со стороны министерства обороны США. С 1963 года лаборатории ИИ в МТИ и Стэнфордском университете получали несколько миллионов долларов ежегодно. Эти деньги выделялись не на конкретные проекты, а для конкретных учёных и лабораторий. Благодаря этому, первые исследования ИИ проходили по разным направлениям.

За финансирование отвечало [управление перспективных исследовательских проектов министерства обороны США](https://ru.wikipedia.org/wiki/Управление_перспективных_исследовательских_проектов_Министерства_обороны_США) DARPA. Директор управления Джозеф Ликлайдер верил, что финансирование "людей, а не проектов" приведёт к практическим результатам. Однако, этого не произошло. Фундаментальные исследования не имели прикладных результатов для военной области. В результате сенат США принял поправку Мэнсфилда в 1969 году. Эта поправка обязывала DARPA финансировать только целевые исследования.

Управление DARPA провело собственное исследование. Оно показало, что большинство разработок в области ИИ не принесут пользы в ближайшем будущем. В результате деньги DARPA были на правлены на проекты новых военных систем.

#### Отчет Лайтхилла

В 1973 году британский парламент поручил профессору математики [Джеймсу Лайтхиллу](https://ru.wikipedia.org/wiki/Лайтхилл,_Джеймс) оценить перспективы исследований в области ИИ. Свои результаты Лайтхилл опубликовал в статье "Искусственный интеллект: общий обзор" (Artificial Intelligence: A General Survey). Позднее она стала известна как [отчёт Лайтхилла](https://ru.wikipedia.org/wiki/Отчёт_Лайтхилла).

Лайтхилл высказал пессимистичный прогноз в отношении перспектив [машинного перевода текста](https://ru.wikipedia.org/wiki/Машинный_перевод) и робототехники. Эти направления считались наиболее перспективными. При этом Лайтхилл дал положительные оценки моделированию нейрофизиологических и психических процессов.

Отчёт Лайтхилла стал причиной, по которой британское правительство прекратило финансирование большинства университетских исследований в области ИИ. Это решение привлекло к себе внимание всех европейских стран. В итоге финансирование разработок в новой области сократились по всей Европе.

#### Проблемы систем ИИ

Исследователи ИИ после первых успехов давали очень оптимистичные прогнозы. Некоторые из них сбылись. Однако, для этого новой науке понадобилось гораздо больше времени, чем ожидалось.

Первые системы ИИ успешно справлялись с простыми примерами. Но попытки применить их для реальных задач заканчивались неудачей. Причин этому было несколько. Рассмотрим их по порядку.

Первая проблема связана с ограниченной производительностью компьютеров того времени. Например, памяти компьютера не хватало для словаря программ перевода. Первые версии таких программ хранили только пару десятков слов. Это всё что помещалось в память.

Аналогичная ситуация складывалась с быстродействием. Задачи распознавания образов требовали от компьютера порядка 10^9^ [операций в секунду](https://ru.wikipedia.org/wiki/IPS_(быстродействие)) (1000 мегаинструкций в секунду или MIPS). Но самый быстрый суперкомпьютер 1976 года [Cray-1](https://ru.wikipedia.org/wiki/Cray-1) выполнял всего 160 MIPS.

Вторая проблема ИИ упоминалась в отчёте Лайтхилл. Первые системы ИИ использовали алгоритмы поиска. Эти алгоритмы перебирают все возможные шаги для достижения цели. Такой подход хорошо работал на небольших тестовых примерах и моделях микромиров. Подобные задачи решаются за короткую последовательность шагов. Найти её было очень просто.

При переходе на сложные задачи, число шагов для решения увеличивалось на порядок. Системы ИИ были способные найти решение, но время его поиска оказывалось слишком большим. Эта проблема получила название [**комбинаторный взрыв**](https://ru.wikipedia.org/wiki/Комбинаторный_взрыв). Комбинаторный взрыв означает резкий рост [**временной сложности**](https://ru.wikipedia.org/wiki/Временная_сложность_алгоритма) алгоритма при увеличении входных данных. Временная сложность — это время, которое нужно компьютеру для выполнения алгоритма.

В 1970-е годы была разработана [теория вычислительной сложности](https://ru.wikipedia.org/wiki/Теория_сложности_вычислений). Она показала, что некоторые классы задач не имеют эффективных решений. Это значит, что нет алгоритмов их решения за приемлемое время. Такие задачи называются [**тродноразрешимыми**](https://www.slideshare.net/mkurnosov/12-34608847).

Третья проблема ИИ связана с очевидными фактами об окружающем мире. Для задач компьютерного зрения и машинного перевода нужен огромный объём информации об очевидных вещах. Например, система распознавания образов должна знать очертания предметов разного типа. Если этих знаний у неё нет, система будет путать предметы. То же самое касается обработки естественного языка. Без понимания предмета обсуждения, система будет совершать смысловые ошибки при переводе.

Первые системы ИИ обошли проблему представления знаний о мире благодаря простоте тестовых примеров. Когда исследователи начали решать реальные задачи, эта проблема стала очевидной.

### Бурное развитие ИИ 1980 – 1987

### Вторая зима ИИ 1987 — 1993