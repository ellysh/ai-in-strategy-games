## История

Искусственный интеллект как направление исследований появился на стыке нескольких дисциплин. На ИИ оказали влияние идеи, достижения и методы из нескольких наук. Таблица 2-1 демонстрирует эти науки.

{caption: "Таблица 2-1. Науки, оказавшие влияние на ИИ", width: "100%"}
| Наука | Используемая в ИИ идея или метод |
| --- | --- |
| Нейрофизиология | Модель искусственного нейрона и нейронной сети |
|  | |
| Математика | Правила формальной логики и логического вывода |
|  | Статистические методы |
|  | Теория вероятностей |
|  | Теория принятия решений |
|  | |
| Информатика | Языки программирования |
|  | Теория вычислительной сложности |
|  | Высокопроизводительные компьютеры |
|  | |
| Кибернетика | Теория управления сложных систем |

Рассмотрим подробнее, как развивался ИИ и почему именно эти науки оказали на него влияние.

### Появление новой науки 1943 – 1956

#### Нейронная сеть

Первая работа в области ИИ связана с нейрофизиологией и математикой. Американские учёные [Уоррен Мак-Каллок](https://ru.wikipedia.org/wiki/Мак-Каллок,_Уоррен) и [Уолтер Питтс](https://ru.wikipedia.org/wiki/Питтс,_Уолтер) исследовали мозг человека. Используя свои знания о физиологии мозга, они разработали модель связанных между собой [**искусственных нейронов**](https://ru.wikipedia.org/wiki/Искусственный_нейрон). [Нейрон](https://ru.wikipedia.org/wiki/Нейрон) — это клетка, которая является минимальным строительным блоком [нервной системы](https://ru.wikipedia.org/wiki/Нервная_система). Нейроны соединяется друг с другом в [нервную сеть](https://ru.wikipedia.org/wiki/Нервная_сеть). По этой сети передаются электрические и химические сигналы. С помощью этих сигналов передаётся информация между узлами нервной системы.

Искусственный нейрон представляет собой упрощённую модель биологического нейрона. Эта модель имеет два состояния: возбуждённое и невозбуждённое. На вход нейрон получает сигналы от других нейронов. Он обрабатывает их с помощью [**нелинейной функции**](https://ru.wikipedia.org/wiki/Линейная_функция). Результат функции передаётся на выход нейрона, который связан со входами других нейронов.

I> График нелинейной функции не является прямой.

Соединение искусственных нейронов получило название [**нейронная сеть**](https://ru.wikipedia.org/wiki/Нейронная_сеть). Мак-Каллок и Питтс показали, что такая сеть способна выполнять числовые и логические операции. Кроме того они предположили, что сети с особенной архитектурой способны обучаться. Свои результаты учёные опубликовали в 1943 году в статье "Логическое исчисление идей, относящихся к нервной активности" (A Logical Calculus of Ideas Immanent in Nervous Activity).

Модель Мак-Каллока и Питтса была только теоретической. Свои гипотезы они подтверждали математическими выкладками. Не существовало программы или устройства, которое бы работало как нейронная сеть и подтверждало идеи учёных.

В 1949 году канадский нейропсихолог [Дональд Хебб](https://ru.wikipedia.org/wiki/Хебб,_Дональд) опубликовал книгу "Организация поведения" (Organization of Behavior). В ней учёный предложил теорию обучения нейронов человеческого мозга. Эта теория получила название [**обучение Хебба**](http://www.machinelearning.ru/wiki/index.php?title=Правило_Хэбба). Основное правило этой теории можно сформулировать в следующем виде:

*Связи нейронов, которые активируются совместно, усиливаются. Связи нейронов, которые срабатывают независимо, ослабевают*

Это **правило Хебба** стало фундаментом в теории обучения нейронных сетей. Оно применяется и сегодня.

Первая нейронная сеть была реализована в виде специального компьютера. Его сконструировали аспиранты математики [Марвином Мински](https://ru.wikipedia.org/wiki/Минский,_Марвин_Ли) и Дином Эдмондсом в 1951 году. Компьютер использовал электровакуумные лампы в качестве рабочих элементов. Он получил название [Snarc](https://en.wikipedia.org/wiki/Stochastic_neural_analog_reinforcement_calculator). Snarc моделировал сеть из 40 нейронов. Мински и Эдмондс пытались научить эту сеть проходить лабиринт. Для простоты соединения между нейронами и представляли собой этот лабиринт.

#### Статья Тьюринга

В 1950 году английский учёный [Алан Тьюринг](https://ru.wikipedia.org/wiki/Тьюринг,_Алан) опубликовал статью ["Вычислительные машины и разум"](https://ru.wikipedia.org/wiki/Вычислительные_машины_и_разум) (Computing Machinery and Intelligence). В ней Тьюринг рассуждает над вопросом о том, способны ли машины думать. Эта статья оказало влияние на исследователей в области ИИ и общественное мнение относительно возможностей ИИ. В целом статья даёт оптимистичный прогноз относительно этих возможностей.

Тьюринг начинает свою статью с определения терминов "машина" и "думать". Этим словам трудно дать однозначное определение, не вызывающее критики. Поэтому учёный предлагает заменить термин "думать" на способность машины пройти игру в имитацию. Суть игры в том, что человек и машина обмениваются с судьёй текстовыми сообщениями. Все участники игры находятся в разных комнатах и не видят друг друга. В результате судья должен определить, кто из собеседников является машиной. Если судья не может это сделать, машина выигрывает игру. Игра в имитацию получила известность как [**тест Тьюринга**](https://ru.wikipedia.org/wiki/Тест_Тьюринга).

Далее Тьюринг рассматривает объекты, которые можно отнести к категории "машина". Он предлагает ограничиться только **цифровыми компьютерами**, которые оперируют числами 0 и 1. В 1950-м году такие компьютеры уже существовали. Кроме того они стали **универсальными**. Универсальность означает, что с помощью программирования компьютер можно настроить на решение различных задач.

После определения терминов Тьюринг положительно оценивает возможность машины пройти игру в имитацию. Он предлагает модель обучающейся машины, которая была бы на это способна. Разрабатывая эту модель, Тьюринг описывает базовые принципы машинного обучения и генетических алгоритмов. Эти идеи намного опередили своё время. Намного позднее исследователи ИИ стали применять их на практике.

Многие из прогнозов Тьюринга о развитии вычислительной техники и искусственного интеллекта оказались верны.

#### Logic Theorist

В 1956 году была разработана первая система искусственного интеллекта в виде компьютерной программы. Эта система получила название [Logic Theorist](https://en.wikipedia.org/wiki/Logic_Theorist).

Logic Theorist разработали три американских учёных:

* [Герберт Саймон](https://ru.wikipedia.org/wiki/Саймон,_Герберт_Александер) был политологом. Он изучал как принимаются решения в правительственных учреждениях и компаниях. В своей работе он использовал методы теории принятия решений.

* [Аллен Ньюэлл](https://ru.wikipedia.org/wiki/Ньюэлл,_Аллен) занимался исследованиями в области логистики и [теориии организаций](https://ru.wikipedia.org/wiki/Теория_организаций). Это теория из области социологии, которая исследует взаимодействия людей в политических и коммерческих организациях.

* [Клиффорд Шоу](https://en.wikipedia.org/wiki/Cliff_Shaw) был опытным программистом из стратегического исследовательского центра [RAND](https://ru.wikipedia.org/wiki/RAND_(корпорация)).

Идею ИИ системы предложил Ньюэлл. Он предположил, что простое программируемое устройство вроде компьютера способно на сложное поведение. Чтобы доказать эту гипотезу Ньюэлл и Саймон решили разработать программу для доказательства математических теорем. Тогда к проекту присоединился Шоу, чтобы помочь с написанием этой программы.

Система Logic Theorist смогла доказать 38 теорем из книги ["Начала математики"](https://ru.wikipedia.org/wiki/Principia_Mathematica) Бертрана Рассела. Это подтвердило гипотезу Ньюэлла, что универсальный компьютер способен на "разумное" поведение.

В середине 1950-х годов считалось, что цифровые компьютеры способны оперировать только числами. Вопреки этому мнению система Logic Theorist работала с символами. Это позволило перейти от математических вычислений к логическим высказываниям. Разработчики утверждали, что создали программу, способную "мыслить в нечисловых терминах". Их подход стал доминирующим в ИИ на следующие 30 лет.

В Logic Theorist впервые были использованы следующие концепций:

* **Рассуждение как поиск**. Logic Theorist представляет доказательство гипотезы как поиск по дереву. Корень дерева соответствует начальной гипотезе. Исходящие из корня ветви — это логические операции над начальной гипотезой. Каждая ветвь приводит к определённому выводу. Один из этих выводов является целью рассуждения. Именно его и ищет система.

* [**Эвристики**]((https://ru.wikipedia.org/wiki/Эвристика)) — это дополнительные правила, которые исключают из рассмотрения некоторые ветви дерева поиска. Эвристики позволяют заранее предсказать, что какая-то ветвь не приводит к решению. Это значительно сокращает время поиска решений.

* **Обработка списков**. Чтобы написать программу Logic Theorist, был разработан специальный язык программирования [IPL](https://en.wikipedia.org/wiki/Information_Processing_Language). Для этого языка Шоу разработал специальную структур данных под названием [**связанный список**](https://ru.wikipedia.org/wiki/Связный_список). Она позволяла эффективно хранить список символов. Позднее на основе IPL и списков Джон Маккарти разработает язык Lisp. Этот язык станет доминирующим в области ИИ на два десятилетия.

Концепций, разработанные для Logic Theorist, станут ключевыми для последующих исследований в области ИИ.

#### Дартмутский семинар

В начале 1950-х годов проводились первые исследования в области ИИ. Однако, науки об ИИ не существовало до лета 1956 года. Свои исследования "думающих машин" учёные называли кибернетикой, теорией автоматов или сложной обработкой информации. Название зависело от подхода, выбранного в каждом конкретном проекте.

В 1955 году американский математик Джон Маккарти решил организовать [семинар](https://ru.wikipedia.org/wiki/Дартмутский_семинар), посвященный "думающим машинам". Маккарти хотел собрать группу исследователей в этой области, чтобы обсудить их достижения и новые подходы.

На тот момент Маккарти работал в Дартмутском колледже. Поэтому семинар получил известность как **Дартмутский семинар**.

В заявке на проведение мероприятия Маккарти написал: "исследование искусственного интеллекта". Термин "искусственный интеллект" появился здесь впервые. До этого его никто не использовал. Маккарти выбрал этот термин, чтобы предотвратить возможные споры относительно подходов. Если бы он выбрал любое из существующих названий исследований ИИ того времени, это сфокусировало бы обсуждения на конкретном подходе. Цель же семинара была в [мозговом штурме](https://ru.wikipedia.org/wiki/Метод_мозгового_штурма), т.е. в разработке совершенно новых идей.

В семинаре принимали участие ведущие учёные из следующих областей:

* Теория управления
* Теория автоматов
* Нейрофизиология
* Теорией игр
* Когнитивная психология.

В результате проведения семинара было решено создать новое научное направление под названием искусственный интеллект. Это решение оказало огромное влияние на последующие исследования. Оно позволило учёным свободно экспериментировать и искать новые подходы. Их больше не ограничивали аналоговые вычисления кибернетики и математический аппарат теории автоматов. Новая наука началась как экспериментальная дисциплина.

### Формирование основных направлений в ИИ 1956 – 1974

Дартмутский семинар дал мощный толчок для исследований в области ИИ. Некоторые из участников семинара в течении нескольких лет организовали лаборатории для изучения ИИ на базе известных учебных заведений. Эти лаборатории перечислены в таблице 2-2.

{caption: "Таблица 2-2. Лаборатории по исследованию ИИ", width: "100%"}
| Учебное заведение | Основатели лаборатории ИИ |
| --- | --- |
| [Университет Карнеги — Меллона](https://ru.wikipedia.org/wiki/Университет_Карнеги_—_Меллона) | Аллен Ньюэлл и Герберт Саймон |
|  | |
| [Стэнфордский университет](https://ru.wikipedia.org/wiki/Стэнфордский_университет) | Джон Маккарти |
|  | |
| [Массачусетский технологический институт](https://ru.wikipedia.org/wiki/Массачусетский_технологический_институт) (МТИ) | Джон Маккарти |
|  | Марвин Мински |

Каждая из лабораторий разрабатывала собственные подходы в создании интеллектуальных систем. Некоторые из этих разработок задали направления для дальнейших исследований. Таблица 2-3 демонстрирует основные подходы в ИИ.

{caption: "Таблица 2-3. Направления в ИИ", width: "100%"}
| Название | Идея | Основоположники |
| --- | --- | --- |
| [Символьный подход](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | Задача решается через действия над понятными человеку символическими обозначениями. | Аллен Ньюэлл |
|  | | Герберт Саймон |
|  | | |
| [Логическое программирование](https://ru.wikipedia.org/wiki/Логическое_программирование) | Задача решается методами формальной логики. | Джон Маккарти |
|  | | |
| [Коннекционизм](https://ru.wikipedia.org/wiki/Коннекционизм) | Задача решается сетью из связанных между собой простых элементов (нейронной сетью). | Уоррен Мак-Каллок |
|  | | Уолтер Питтс |

Эти направления сформировались в начальный период развития новой науки об ИИ. Их популярность менялась в зависимости от успехов и неудач в исследованиях. Сегодня самым многообещающим подходом считается коннекционизм.

Рассмотрим достижения каждого из направлений в первые годы науки об ИИ.

#### Символьный подход

Система Logic Theorist произвела впечатление на участников Дартмутского семинара. Она была единственным рабочим решением на 1956 год. Остальные исследования ИИ ещё находились на этапе теоретических моделей.

Следующим проектом Ньюэлла, Саймона и Шоу стала универсальная система для решения задач. Она получила название [General Problem Solver](https://ru.wikipedia.org/wiki/Универсальный_решатель_задач) (GPS). В отличие от Logic Theorist её область применения не ограничивалась математическими задачами. Вместо этого GPS должна была моделировать процесс решения задач человеком.

Система GPS была готова в 1959 году. В своей работе она использовала особенную технику поиска под названием [**анализ средств и результатов**]((https://en.wikipedia.org/wiki/Means–ends_analysis)) (means–ends analysis или MEA). Эта техника стала развитием идеи "рассуждение как поиск", впервые реализованной в Logic Theorist.

Алгоритм техники анализ средств и результатов выглядит так:

1. Система оценивает своё текущее состояние. Если поставлена задача, необходимы действия для её решения.

2. Определяется конечная цель. Она выражается в некотором состоянии системы, которое надо достигнуть. Достижение этого состояние означает решение поставленной задачи.

3. Конечная цель делится на составные части, называемые подцелями. Если подцели остаются сложными, они так же делятся на составные части.

4. Составляется список действий, выполнение которых приведёт к конечной цели, т.е. решению задачи.

5. Каждая из подцелей связывается с соответствующим ей действием из списка.

6. Выполняются все действия из списка.

7. Сравнение полученного состояния системы с тем, которое надо достигнуть для решения поставленной задачи. Если эти состояния отличаются, алгоритм повторяется начиная со второго шага.

Система GPS доказывала теоремы евклидовой геометрии и логики предикатов. Также она решала шахматные задачи.

Основываясь на опыте разработки и применения системы GPS Ньюэлл и Саймон сформулировали [**гипотезу о физической символьной системе**](https://ru.wikipedia.org/wiki/Гипотеза_Ньюэлла_—_Саймона) в 1976 году. Эта гипотеза звучит так:

*Физическая символьная система обладает необходимыми и достаточными средствами для разумного поведения.*

Это означает, что человеческое мышление заключается в манипулировании символами. Потому что без символьной системы невозможно разумное поведение. Компьютер может манипулировать символами. Следовательно, он способен на разумное поведение.

Исследования Ньюэлла и Саймона заложили основу **символьного подхода**. Этот подход предлагает создавать системы ИИ, работа которых основана на манипулировании символами. Этим символы могут быть абстрактными, но должны быть понятны человеку.

Символьный подход оставался доминирующей парадигмой в ИИ с середины 1950-х до конца 1980-х годов.

#### Логическое программирование

Джон Маккарти был не согласен с подходом Ньюэлла и Саймона. Он утверждал, что компьютеру нет необходимости рассуждать также, как это делает человек. Вместо манипулирования абстрактными символами Маккарти предлагал строить системы ИИ на правилах [**формальной**](https://ru.wikipedia.org/wiki/Формальная_логика) и [**математической**](https://ru.wikipedia.org/wiki/Математическая_логика) логики.

I> Формальная логика — это наука о высказываниях, правилах их преобразований и выводе их истинности. Математическая логика — это изучение правил логики с помощью математического аппарата.

Преимущество подхода Маккарти было в использовании математического аппарата. Благодаря ему, можно было моделировать системы ИИ и формально доказывать их работоспособность.

В 1958 году Маккарти разработал модель системы под названием [Advice Taker](https://en.wikipedia.org/wiki/Advice_taker). Он описал её принципы работы в статье "Программы со здравым смыслом" (["Programs with Common Sense"](http://www-formal.stanford.edu/jmc/mcc59.pdf)).

Согласно идее Маккарти, система Advice Taker должна использовать общие знания о мире. Благодаря им, она сможет самостоятельно делать выводы обо всём, что ей сообщают и что она уже знает. В этом случае можно утверждать, что система рассуждает с позиции [здравого смысла](https://ru.wikipedia.org/wiki/Здравый_смысл).

Маккарти предложил новый способ представления знаний в Advice Taker. Система Logic Theorist хранила все знания и эвристики в коде самой программы. Из-за этого с ними было сложно работать. Чтобы добавить новое утверждение или исправить существующее, приходилось работать на языке программирования IPL.

Система Advice Taker чётко разделяла знания и механизм рассуждений. Знания хранились в виде правил на некотором формальном языке. Эти правила помещались в списки. Благодаря этому, логический вывод сводился к операциям над списками.

Чтобы реализовать Advice Taker в виде программы, Маккарти спроектировал язык программирования [Lisp](https://ru.wikipedia.org/wiki/Лисп). Он описал этот язык в журнале Communications of the ACM в 1960 году. Первый работающий интерпретатор языка появился в 1958 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704).

В статье "Programs with Common Sense" Маккарти указывает на ряд преимуществ **декларативных** инструкций над **императивными**. Первый вариант инструкций описывает свойства результата, который должна выдать программа. Императивные инструкции задают чёткий алгоритм вычисления результата.

Несмотря на свои предпочтения, Маккарти сделал Lisp императивным. Кроме того он не встроил в язык механизмы логического вывода. Именно так поступили разработчики языка [Prolog](https://ru.wikipedia.org/wiki/Пролог_(язык_программирования)) в 1972 году. Prolog строго следует принципам логического программирования, а Lisp — нет. Благодаря решениям Маккарти, Lisp получился достаточно универсальным. Его применяли и продолжают применять в различных прикладных областях.

#### Коннекционизм

Исследования нейронных сетей Мак-Каллока и Питтса заложили основу коннекционизма. Коннекционизм — это направление [когнитивной науки](https://ru.wikipedia.org/wiki/Когнитивистика), которое моделирует и исследует психические явления с помощью искусственных нейронных сетей.

После исследований Хебба следующим значительным шагом в развитии коннекционизма стала модель под названием перцептрон.

##### Перцептрон

В 1957 году американский психолог и нейрофизиолог [Фрэнк Розенблатт](https://ru.wikipedia.org/wiki/Розенблатт,_Фрэнк) предложил модель того, как мозг человека воспринимает информацию. Эта модель получила название [**перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон).

Перцептрон представляет собой искусственную нейронную сеть с особенной архитектурой. Иллюстрация 2-1 приводит схему этой архитектуру.

{caption: "Иллюстрация 2-1. Архитектура перцептрона", height: "50%", width: "100%"}
[Архитектура перцептрона](images/ArtificialIntelligence/perceptron.png)

Сеть состоит трёх слоёв искусственных нейронов:

1. S-элементы (сенсорные)
2. A-элементы (ассоциативные)
3. R-элементы (реагирующие)

I> Несмотря на три слоя, перцептрон на иллюстрации 2-1 называется однослойным. Причина этого в том, что у него только один скрытый слой A-элементов. Скрытыми считаются слои, не содержащие входных и выходных нейронов.

Перцептрон создаёт набор ассоциаций (A-элементы) между входными сигналами (S-элементы) и реакцией на них (R-элементы).

Можно провести аналогию между работой перцептрона и мозга. Пример обработки сигнала — реакция человека на зрительную информацию. Если человек видит опасность, физиологическим ответом на неё будет активация [двигательных нейронов](https://ru.wikipedia.org/wiki/Мотонейрон). Эти нейроны отвечают за мышечную активность. Перцептрон обрабатывает входные сигналы аналогично: реагирующие нейроны R возбуждаются в ответ на входные сигналы S, согласно ассоциациям A.

Перед работой перцептрон необходимо обучить. После этого он сможет определять, к какому классу относится предъявленный ему объект. Если R-элементов больше одного, перцептрон способен различать более двух классов объектов.

Розенблатт использовал теорию Хебба и разработал методы обучения перцептрона.

В 1957 году Розенблатт смоделировал работу перцептрона в виде программы для компьютера IBM 704.

Спустя два года Розенблатт сконструировал первый в мире [нейрокомпьютер](https://ru.wikipedia.org/wiki/Нейрокомпьютер). Он получил название [Mark I Perceptron](https://ru.wikipedia.org/wiki/Марк-1). Этот компьютер представлял собой аппаратную реализацию перцептрона. Он работал на аналоговых электронных компонентах: фотодетекторах, потенциометрах и электромоторах. Основной задачей компьютера было распознавание изображений.

В 1962 году Розенблатт опубликовал книгу "Принципы нейродинамики" (Principles of Neurodynamics). В ней он рассматривает различные архитектуры перцептронов, в том числе и многослойные. Также в книге доказана [теорему сходимости перцептрона](https://ru.wikipedia.org/wiki/Теорема_сходимости_перцептрона). Согласно теореме, перцептрон можно обучить за конечное число шагов. После такого обучения он сможет решить поставленную задачу.

Книга "Принципы нейродинамики" оказала большое влияние на развитие коннекционизма. Теорема сходимости перцептрона и её выводы позволили сформулировать требования к архитектурам нейронных сетей и методам их обучения.

#### Экспериментальный подход

Исследователи из лаборатории ИИ Массачусетского технологического института следовали подходу, который в 1970-е годы получил название **scruffy** или "неряшливый". Его также можно назвать "экспериментальным". Этот подход предлагает разрабатывать прототипы систем ИИ для небольших задач из разных областей. Затем полученные системы комбинируются и усовершенствуются для более крупных задач из реального мира.

Противоположный подход в исследованиях ИИ получил название **neat**. Дословно он переводится как "аккуратный". Смысл этого подхода хорошо передаёт слово "теоретический". Он предлагает использовать [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы), основанные на математике и логике. Такой подход даёт более надёжный и научно обоснованный результат. Так работали исследователи из университетов Карнеги — Меллона и Стэнфордского.

В первые годы развития ИИ экспериментальный подход оказался самым плодотворным. Исследователи из МТИ разработали и продемонстрировали ряд систем для решения прикладных задач. Эти системы произвели большое впечатление как на научные круги, так и на инвесторов. Рассмотрим самые известные из этих разработок.

##### Обработка естественного языка

Первой системой обработки естественного языка считается программа [STUDENT](https://en.wikipedia.org/wiki/STUDENT_(computer_program)). Её написал Дэниэль Бобров в рамках свой докторской работы в 1964 году. Его научным руководителем был Марвин Минский.

Программа STUDENT читала и решала задачи из школьного учебника по алгебре. На вход она получала описание задачи на английском языке. На выходе система печатала решение в виде числа.

Для анализа текста STUDENT использовала запрограммированные правила и логический вывод. Функции машинного обучения у системы не было.

Другой системой обработки естественного языка была [ELIZA](https://ru.wikipedia.org/wiki/Элиза_(программа)). Её написал сотрудник лаборатории ИИ в МТИ [Джозеф Вейценбаум](https://ru.wikipedia.org/wiki/Вейценбаум,_Джозеф).

ELIZA представляет собой [виртуального собеседника](https://ru.wikipedia.org/wiki/Виртуальный_собеседник). Программа обменивается с пользователем сообщениями. Направление разговора задаётся специальными сценариями. Самым популярным сценарием разговора был DOCTOR. Согласно ему, программа парадировала психотерапевта и строила вопросы на основе прошлых сообщений от пользователя.

ELIZA считается первой программой, способной попытаться пройти тест Тьюринга.

##### Микромиры

В конце 1960-х годов Марвин Минский и Сеймур Пейперт предложили сфокусировать исследования ИИ на упрощённых проблемных областях. Такие области получили название **микромиры**. Минский и Пейперт утверждали, что полученные системы ИИ смогут работать и для реальных задач.

Студенты МТИ выбирали для себя микромир и выполняли для них свои дипломные работы. Наибольшей популярностью у студентов пользовался [мир блоков](https://en.wikipedia.org/wiki/Blocks_world). Он представляет собой плоскую поверхность, на которой лежат блоки различных цветов и форм.

Самым известным проектом для мира блоков считается программа [SHRDLU](https://ru.wikipedia.org/wiki/SHRDLU). Её разработал [Терри Виноград](https://ru.wikipedia.org/wiki/Виноград,_Терри) в 1970 году.

Программа SHRDLU позволяет пользователю манипулировать объектами в виртуальном пространстве. Это пространство представляет собой мир блоков. Пользователь вводит свои команды на английском языке. SHRDLU может задавать вопросы, чтобы уточнить команду. Также программа может жать ответ — выполнимо ли то или иное действие в виртуальном пространстве.

В лаборатории МТИ разрабатывали не только программы для мира блоков, но и роботов. Было создано несколько версий руки-манипулятора для передвижения блоков:

* Робот MH1, разработанный Генри Эрнстом в 1961 году.

* Робот Мински-Беннета, разработанный Марвином Мински и Вильямом Беннетом в 1968 году.

* Робот для сборки маленьких деталей от [Дэвида Сильвера](https://en.wikipedia.org/wiki/David_Silver_(roboticist)), собранный в 1974 году.

На основе мира блоков [Патрик Уинстон](https://ru.wikipedia.org/wiki/Уинстон,_Патрик) разработал программу машинного обучения ARCH. Она изучала действия над блоками из примеров.

### Первая зима ИИ 1974 – 1980

#### Финансирование DARPA

Первые успехи 1960-х годов в области ИИ привлекли к себе внимание прессы. Учёные не стеснялись делать оптимистичные прогнозы. Они утверждали, что "в ближайшем будущем" машины смогут решать задачи, с которыми раньше справлялись только люди.

В 1958 году министерство обороны США организовало [управление перспективных исследовательских проектов](https://ru.wikipedia.org/wiki/Управление_перспективных_исследовательских_проектов_Министерства_обороны_США) DARPA. Эта организация отвечала за финансирование перспективных технологий, которые могли бы применяться военными.

Исследования ИИ привлекли внимание специалистов DARPA. В результате с 1963 года лаборатории ИИ в МТИ, университетах Карнеги — Меллона и Стэнфордском получали гранты в размере нескольких миллионов долларов ежегодно. Эти деньги выделялись не на конкретные проекты с жёсткими сроками. Лаборатории их получали на фундаментальные исследования без конкретных целей.

Директор DARPA Джозеф Ликлайдер верил, что финансирование "людей, а не проектов" приведёт к практическим результатам. Однако, этого не произошло.

Несколько неудачных проектов подорвали веру в перспективность исследований ИИ среди военных. Самыми крупными среди этих проектов были следующие:

* [**Машинный перевод**](https://ru.wikipedia.org/wiki/Машинный_перевод) текстов с английского на русский язык. В период холодной войны стояла задача перевода советских научных журналов. Чтобы решить эту задачу университет Вашингтона в Сент-Луисе и компания IBM разрабатывали систему ИИ. Однако, 10 лет разработок не дали результата. Поэтому в 1964 году [Национальные академии наук](https://ru.wikipedia.org/wiki/Национальные_академии_наук,_инженерии_и_медицины) США прекратили финансирование проекта.

* Проект голосового управления для пилотов. Над ним работала команда из университета Карнеги — Меллона. Исследователи разработали систему распознавания речи, но она оказалась очень ограниченной. Например, порядок произнесения слов был строго определён. В 1974 году DARPA прекратила финансирование этого проекта.

На раздутый бюджет военных исследований обратил внимание сенат США. В результате в 1969 году была принята поправка Мэнсфилда. Она требовала от DARPA финансировать только целевые исследования. Теперь учёные были вынуждены доказывать, что их работа связана с военными технологиями. Исследователям ИИ редко удавалось обосновать свои проекты в таком ключе. Это привело к значительному сокращению бюджета лабораторий ИИ по всей стране.

#### Отчёт Лайтхилла

В 1965 году английский учёный [Дональд Мичи](https://en.wikipedia.org/wiki/Donald_Michie) организовал лабораторию ИИ в [Эдинбургском университете](https://ru.wikipedia.org/wiki/Эдинбургский_университет). Позднее подобные лаборатории открылись в университетах Сассекс и Эссекс. В конце 1960-х и начале 1970-х они получали значительные гранты от правительства Англии.

В 1973 году британский парламент поручил профессору математики [Джеймсу Лайтхиллу](https://ru.wikipedia.org/wiki/Лайтхилл,_Джеймс) оценить перспективы исследований в области ИИ. Свои результаты Лайтхилл опубликовал в статье "Искусственный интеллект: общий обзор" (Artificial Intelligence: A General Survey). Позднее она стала известна как [отчёт Лайтхилла](https://ru.wikipedia.org/wiki/Отчёт_Лайтхилла).

Лайтхилл оценил достижения в области ИИ в США и Европе. Он заметил, что учёные не выполнили многие из своих обещаний. Поэтому Лайтхилл высказал пессимистичный прогноз в отношении перспектив машинного перевода текста и робототехники. В 1973-м году эти направления считались наиболее перспективными. При этом Лайтхилл высоко оценил достижения нейронных сетей для моделирования нейрофизиологических и психических процессов.

Отчёт Лайтхилла стал причиной, по которой правительство Великобритании прекратило финансирование большинства исследований ИИ в университетах. Это решение привлекло к себе внимание всех европейских стран. В итоге финансирование разработок в новой области сократились по всей Европе.

#### Ограничения систем ИИ

Проблемы с финансированием исследований ИИ возникли по вине самих учёных. Они не смогли правильно оценить сложность задач, которые им предстоит решить. Поэтому их прогнозы и сроки выполнения проектов оказались слишком оптимистичными. В результате ожидания инвесторов были очень высокими.

Крупные инвестиции в область ИИ начались в середине 1960-х годов. К началу 1970-х стали ясны результаты разработок, на которые ушли несколько лет. Эти результаты оказались неудовлетворительными. Возможности реальных систем ИИ были далеки от того, что обещали учёные.

Почему прогнозы учёных оказались такими неточными? Рассмотрим причины этого.

##### Производительность компьютеров

В конце 1950-х годов сменилась технология производства компьютеров. До этого рабочими элементами в них были [электровакуумные лампы](https://ru.wikipedia.org/wiki/Электронная_лампа). В 1958-м году компания IBM выпустила первый компьютер, который работал на [транзисторах](https://ru.wikipedia.org/wiki/Транзистор). В отличие от ламп транзисторы компактнее, надёжнее и быстрее.

Переход на транзисторы должен был увеличить быстродействие компьютеров. Однако, конструкция самих транзисторов [продолжала развиваться](https://en.wikipedia.org/wiki/MOSFET#Commercialization) на протяжении 1960-х годов. Только в начале 1970-х годов эта конструкция достигла уровня, достаточного для роста производительности компьютеров. После этого момента начал действовать [закон Мура](https://ru.wikipedia.org/wiki/Закон_Мура). Он говорит о том, что число транзисторов на [интегральной схеме](https://ru.wikipedia.org/wiki/Интегральная_схема) удваивается примерно каждые два года. Соответственно растёт скорость вычислений и объём памяти.

Исследователи ИИ разрабатывали прототипы своих систем для решения относительно простых задач. Такие задачи позволяли быстро сравнить разные подходы и методы. Однако, [**масштабируемость**]((https://ru.wikipedia.org/wiki/Масштабируемость)) полученных прототипов было сложно оценить. Для этого их надо было запустить на более мощных компьютерах. Но таких компьютеров просто не существовало.

I> Масштабируемость означает повышение производительности системы при добавлении ресурсов.

Вот один из примеров. Первые версии систем для машинного перевода обрабатывали небольшие специально подготовленные тексты. Памяти компьютера 1960-ого года хватало только на несколько десятков слов. Поэтому система могла переводить только маленькие тексты. Чтобы проверить насколько система универсальна, нужен был компьютер с намного большим объёмом памяти.

Быстродействие компьютеров тоже было проблемой. В 1976 году учёный [Ханс Моравек](https://ru.wikipedia.org/wiki/Моравек,_Ханс) из университета Карнеги — Меллона дал следующую оценку. Чтобы распознавать грани объектов и движение в реальном времени, система ИИ должна работать на компьютере с производительностью 10^9^ [операций в секунду](https://ru.wikipedia.org/wiki/IPS_(быстродействие)) (1000 мегаинструкций в секунду или MIPS). Однако, самый быстрый суперкомпьютер 1976 года [Cray-1](https://ru.wikipedia.org/wiki/Cray-1) выполнял всего 160 MIPS.

В 1960-е годы исследователи ИИ не смогли правильно оценить вычислительные мощности, которые понадобятся для их систем. Прототипы, решающие простые задачи, не помогали в такой оценке.

##### Комбинаторный взрыв

В своём отчёте Лайтхилл говорит о [**комбинаторном взрыве**](https://ru.wikipedia.org/wiki/Комбинаторный_взрыв). Комбинаторный взрыв означает быстрый рост сложности задачи при увеличении размера входных данных.

Алгоритмы решения задач оцениваются по двум параметрам:

* [**Временная сложность**](https://ru.wikipedia.org/wiki/Временная_сложность_алгоритма) — это время, которое нужно компьютеру для выполнения алгоритма. Обычно, оно считается как число элементарных шагов для нахождения решения.

* **Память** — это объём данных, которые алгоритм должен хранить в течении своей работы.

Лайтхилл пишет о системах, которые используют подход "рассуждение как поиск". У них возникли проблемы с решением реальных задач. Причина была в том, что дерево поиска для таких задач на несколько порядков больше, чем у демонстрационных примеров. Быстрый рост дерева поиска приводит к большем числу шагов для нахождения решения. В результате система тратит дни и даже недели для решения одной задачи.

Системы, основанные на поиске, используют эвристики. Эти эвристики хранятся в памяти компьютера как база знаний. При решение простых задач набор эвристик небольшой. Когда задача становится сложной, число эвристик и их взаимосвязи быстро растут. Опять происходит комбинаторный взрыв, но на этот раз с точки зрения используемой памяти.

Исходя из этих выводов Лайтхилл заключает, что существующие на 1973 год системы ИИ не смогут решать реальные задачи даже при увеличении мощности компьютеров.

[Теория вычислительной сложности](https://ru.wikipedia.org/wiki/Теория_сложности_вычислений), которую использовал Лайтхилл, появилась в 1965 году. В 1970-е годы она активно развивалась. Теория показала, что некоторые классы задач в принципе не имеют эффективных решений. Это значит, что нет алгоритмов для их решения за приемлемое время. Такие задачи называются [**трудноразрешимыми**](https://www.slideshare.net/mkurnosov/12-34608847).

Концепция трудноразрешимых задач означает, что возможности систем ИИ строго ограничены.

#### Проблемы коннекционизма

В начале 1960-х годов модель перцептрона Розенблатта выглядела многообещающей. Группы учёных из разных университетов исследовали возможности этой модели. Скоро стало ясно, что перцептрон хорошо справляется с простыми задачами. Однако, сложные задачи он решить не мог.

Розенблатт перечисляет следующие недостатки однослойных перцептронов в своей книге "Принципы нейродинамики":

1. Выполнение некоторых задач требует нейронной сети с очень большим количеством элементов.

2. Обучение занимает очень много времени в некоторых случаях.

3. Качество обучения сильно зависит от оценок системы во время обучения.

4. Перцептрон плохо справляется с задачей обобщения.

5. Перцептрон плохо выделяет существенные элементы в сложных входных сигналах.

Из четвертого пунка следует, что перцептрон не способен обработать ситуации, с которыми он не сталкивался во время обучения. Если условия задачи похожи на учебный пример, но полностью с ним не совпадают, перцептрон не сможет её решить.

Пятый пункт приводит к тому, что перцептрон плохо справляется со сложными задачами. Наиболее эффективный метод их решения: разделение на простые подзадачи. Однако, перцептрон не способен на такое разделение. Он анализирует всю задачу целиком, как она есть.

Розенблатт надеялся, что многослойные перцептроны смогут решить некоторые из этих проблем. Он начал рассматривать такие архитектуры нейронных сетей в своей книге. Однако, теория осталась недоработанной. В 1971 году Розеблатт погиб в результате несчастного случая.

Исследовать многослойные перцептроны на практике в 1960-х годах было сложно. Для их эмуляции на универсальных компьютерах требовалось больше памяти и времени обучения, чем для однослойных перцептронов. Часто модель сети не помещалась в память компьютера или для её обучения требовалось слишком много времени.

Аппаратная реализация нейросетей в виде специальных компьютеров наподбоие Марк-1 имела технические проблемы. В 1960-х годах не было надёжных и дешёвых электронных компонентов, на которых можно было бы построить нейрокомпьютер. Архитектура Марк-1 не масштабировалась. Это признал сам Розенблатт.

Начиная с 1965 года Марвин Мински и Сеймур Пейперт провели ряд экспериментов над перцептронами. Свои результаты они опубликовали в книге 1969 года под названием ["Перцептроны"](https://ru.wikipedia.org/wiki/Перцептроны_(книга)) ("Perceptrons: an introduction to computational geometry").

Книга подробно рассматривает ряд типовых задач по распознованию образов, с которыми однослойный перцептрон не может справиться. Все эти задачи связаны с **инвариантным представлением** образов. Примеры такого представления: поворот объекта, перенос и растяжение-сжатие.

Мински и Пейперт обобщают свои выводы. Они утверждают, что рассмотренные ими ограничения справедливы для любых параллельных вычислений. Именно к этому типу вычислений относятся нейронные сети. При этом последовательные вычисления могут справиться с проблемой инвариантного представления.

Выводы книги "Перцептроны" оказались неверными для многослойных нейронных сетей. Однако, книга получила широкую известность в научных кругах. Её пессиместичный тон в отношении перцептрона повлиял на отношение к коннекционизму в целом.

Кроме критики в научных кругах на коннекционизм сильно повлияла поправка Мэнсфилда. В большинстве исследований нейронные сети рассматривались как теоретическая модель для изучения мозга. Практические результаты от таких проектов ожидались редко. Поэтому государство практически приекратило спонсирование исследований в рамках коннекцинизма.

### Развитие ИИ 1980 – 1987

#### Экспертные системы

Ранние системы ИИ конца 1950-х годов, такие как General Problem Solver и Advice Taker, претендовали на универсальность. Исследователи заявляли, что их программы способны рассуждать так же, как это делают люди. Таким образом системы потенциально могли решить любую задачу.

Главной частью ранних систем ИИ считались алгоритмы поиска решения. Знания, которыми оперировали эти алгоритмы, рассматривались как нечто второстепенное. Системы могли оперировать любыми фактами, следуя одному и тому же алгоритму. Так они должны были решать задачи из разных прикладных областей. Однако, такой подход не сработал для реальных задач из-за комбинаторного взрыва.

В середине 1960-х годов появилась новая архитектура ИИ систем. Они получили название [**экспертные системы**](https://en.wikipedia.org/wiki/Expert_system).

Экспертная система — это подвид [**системы, основанной на знаниях**](https://en.wikipedia.org/wiki/Knowledge-based_systems) (knowledge-based system или KBS). Отличительная особенность KBS заключается в её архитектуре. Система состоит из двух частей: **базы знаний** и **механизма вывода**. Впервые подобную архитектуру предложил Маккарти для системы Advice Taker.

База знаний содержит факты о реальном мире или прикладной области. Эти факты представляются в наглядной форме, а не в виде программного кода. Самая простая форма представления — это утверждение на естественном языке. Например: "Земля круглая".

Механизма вывода обрабатывает информацию из базы знаний, чтобы на её основе вывести новые знания.

Экспертная система отличается от других систем, основанных на знаниях. Её особенность в том, что она имитирует процесс принятие решений человеком-экспертом в какой-то прикладной области. Для такой имитации используются знания, которые человек-эксперт предварительно заносит в базу знаний системы.

Почему экспертные системы смогли решить проблему комбинаторного взрыва? Ранние ИИ системы оперировали достаточно общими фактами. Требовались значительные вычисления, чтобы вывести из этих фактов промежуточные решения. Затем они комбинировались в конечное решение задачи.

Экспертные системы оперируют знаниями о предметной области, полученными от человека-эксперта. Эти знания уже представляют собой промежуточные решения. Таким образом экспертным системам требуется значительно меньше вычислений, чтобы из имеющихся "заготовок" составить конечный результат.

Экспертные системы можно рассматривать как дальнейшее развитие символьного подхода в ИИ. База знаний этих систем представляла собой набор символов. Причем [**уровень абстракции**](https://dou.ua/lenta/articles/level-of-abstraction/) этих символов стал значительно выше чем у ранних систем ИИ.

I> В общем смысле термин абстракция означает модель объекта реального мира. Из этой модели исключаются несущественные детали. Уровень абстракции означает количество опущенных деталей. Чем выше этот уровень, тем меньше деталей объекта учитывает модель.

Рассмотрим первые экспертные системы и их возможности.

##### Dendral

В 1965 году группа учёных из Стэнфордского университета начала проект системы ИИ, основанной на знаниях. В группу входили [Эдвард Фейгенбаум](https://ru.wikipedia.org/wiki/Фейгенбаум,_Эдвард_Альберт), Брюс Бьюкенен, [Джошуа Ледерберг](https://ru.wikipedia.org/wiki/Ледерберг,_Джошуа) и [Карл Джерасси](https://ru.wikipedia.org/wiki/Джерасси,_Карл). Система получила название Dendritic Algorithm или сокращённо [Dendral](https://ru.wikipedia.org/wiki/Dendral).

Ледерберг занимался исследованиями в области [астробиологии](https://ru.wikipedia.org/wiki/Астробиология). Эта наука изучает жизнь на других планетах. Учёный задался вопросом: сможет ли компьютер помочь ему в изучении незнакомых органических соединений?

Ледерберг обратился за помощью к химику Карлу Джерасси и информатику Эдварду Фейгенбаум. Вместе они спроектировали первую версию системы Dendral. Позже к проекту присоединился программист Брюс Бьюкенен.

Система Dendral далжна была определять структуру неизвестных молекул по картине их [масс-спектра](https://ru.wikipedia.org/wiki/Масс-спектрометрия). Масс-спектрометрия измеряет отношение массы фрагментов молекулы к их заряду.

Чтобы решить задачу, Dendral генерировала наборы химических соединений. Каждое соединение представлялось в виде [**графа**](https://ru.wikipedia.org/wiki/Граф_(математика)). Для генерации использовались картины масс-спектров известных молекул, общие знания по химии и теории графов.

Для каждого сгенерированного химического соединения система вычисляла ожидаемую картину масс-спектра. Далее Dendral сравнивала её с картиной неизвестной молекулы. Если картины совпадали, система делала вывод, что сгенерирована именно неизвестная молекула.

Dendral решает задачу, которую в общем виде можно сформулировать так:

*Разработать решение с учётом данного набора ограничений.*

Система успешно справилась с этой задачей. Её применяли химики в своих исследованиях. Это был первый случай, когда система ИИ смогла решать реальные задачи из прикладной области.

##### Mycin

Архитектура системы Dendral доказала свою эффективность. Кроме того, она была достаточно универсальной. Поэтому учёные из Стэнфордского университета продолжили разработки экспертных систем для других прикладных областей.

В начале 1970-х годов [Эдвард Шортлифф](https://en.wikipedia.org/wiki/Edward_H._Shortliffe), Бьюкенен и генетик [Стэнли Коэн](https://ru.wikipedia.org/wiki/Коэн,_Стэнли_Норман) разработали экспертную систему [Mycin](https://ru.wikipedia.org/wiki/MYCIN). Она анализировала симптомы пациента с тяжелым инфекционным заболеванием и определяла, какие бактерии его вызвали. Затем система рекомендавала антибиотики и дозировку для лечения.

Mycin имела несколько принципиальных отличий от системы Dendral. Во-первых, пользователь работал с ней интерактивно. Система задавала вопросы о симптомах пациента. Пользователь вводил свои ответы. На основе этих ответов Mycin ставила диагноз.

Второе отличие системы Mycin заключается в характере знаний, с которыми она работала. В медицине нет такой строгой теоретической модели как в химии. Поэтому Mycin не могла точно вычислить диагноз пациента. Вместо этого система указывала вероятность того или иного диагноза.

Система оперировала базой из примерно 600 правил. Учёные с медицинского факультета Стэнфорда оценили, что система ставит правильный диагноз в 65% случаев. Точность диагноза самих учёных была в диапазоне от 42.5% до 62.5%.

Несмотря на многообщающие результаты, Mycin осталась исследовательной разработкой и не применялась в больницах. Причина этого в трудоемком процессе ввода информации. В то время больницы не имели электронного документооборота. Вся информация о пациентах хранилась в бумажном виде. Один сеанс работы с Mycin мог длиться до получаса. Для врачей такие потери времени были неприемлемы.

##### XCON

Успехи экспертных систем стали известны не только в научных кругах, но и среди крупных компаний. Поэтому в конце 1970-х годов компания DEC заказала разработку экспертной системы университету Карнеги — Меллона. За разработку системы отвечал Джон Макдермотт.

Компания DEC производила компьютеры. Эти компьютеры имели много комплектующих и кабелей соединения. Поэтому при заказах часто происходили ошибки. Покупатели получали несовместимое между собой оборудование или им не хватало кабелей для его подключения. Экспертная система должна была помочь отделу продаж DEC при составлении заказов.

В 1978 году Макдермотт закончил разработку системы. Она получила название [XCON](https://en.wikipedia.org/wiki/Xcon). Компания DEC начала применять систему с 1980-ого года.

База знаний и механизм вывода системы XCON постоянны развивалась. В конце срока эксплуатации системы её база начитывала около 2500 правил. За весь срок службы система обработала около 80000 заказов. Точность её работы оцениватся на уровне 95%. Благодаря XCON компания DEC экономила до 25 миллионов долларов ежегодно.

Громкий успех системы XCON привел к тому, что корпорации по всему миру начали разработку экспертных систем для внутреннего использования.

Системы Dendral и Mycin были написаны на языке Lisp. Его возможности отлично подходили для разработки экспертных систем. Поэтому Lisp стал стандартом в новой отрасли программного обеспечения.

Скоро после начала бума экспертных систем появились специальные компьютеры под названием [Lisp-машины](https://ru.wikipedia.org/wiki/Лисп-машина). Их архитектура была оптимальна для запуска программ, написанных на языке Lisp.

#### Компьютер пятого поколения

В 1982 году правительство Японии запустило проект [компьютера пятого поколения](https://ru.wikipedia.org/wiki/Компьютеры_пятого_поколения). На проект отводилось 10 лет. За это время планировалось спроектировать производительный суперкомпьютер и запустить его в серийное производство.

Почему новый компьютер отнесли к пятому поколению?  Поколения компьютеров принято различать по рабочим элментам, которые выполняют  элементарные вычисления. Таблица 2-4 демонстрирует четыре поколения компьютеров и соответствующие им рабочие элементы.

{caption: "Таблица 2-4. Поколения компьютеров", width: "100%"}
| Поколение | Рабочий элемент |
| --- | --- |
| Первое | [Электровакуумная лампа](https://ru.wikipedia.org/wiki/Электронная_лампа) |
|  | |
| Второе | [Транзистор](https://ru.wikipedia.org/wiki/Транзистор) |
|  | |
| Третье | [Интегральная схема](https://ru.wikipedia.org/wiki/Интегральная_схема) |
|  | |
| Четвёртое | [Микропроцессор](https://ru.wikipedia.org/wiki/Микропроцессор) |

До 1970-х годов Япония отставала в производстве компьютеров. Самыми передовыми технологиями в этой области владели США и Англия. Поэтому в середине 1970-х министерство международной торговли и промышленности Японии (MITI) начало исследовать перспективные компьютерные технологий. Это исследование было поручено Японскому центру развития обработки информации (JIPDEC).

Центр JIPDEC определил следующие перспективные направления:

* Тенологии логического вывода для обработки знаний.
* Технологии для обработки баз знаний большого масштаба.
* Высокопроизводительные рабочие станции.
* [Параллельные вычисления](https://ru.wikipedia.org/wiki/Параллельные_вычисления).
* Суперкомпьютеры для научных вычислений.

Министерство MITI решило объединить работу по всем этим направлениям в одном проекте. Целью проекта стала разработка высокопроизводительного суперкомпьютера.

Чтобы достич высокой производительности, разработчики решили применить многопроцессорную архитектуру. Большинство компьютеров того времени имели только процессор. Поэтому они могли выполнять только одну программу в любой момент времени.

Многопроцессорная архитектура позволяла решать несколько задач одновременно. В этом состоит суть параллельных вычислений. Также открывалась возможность делить задачу на подзадачи и выполнять их все разом на нескольких процессорах.

Ещё одним важным решеним стало применение концепции логического программирования, разработанной Джоном Маккарти. Центр JIPDEC высоко оценил перспективы этого подхода. Поэтому языком программирования для суперкомпьютера стал Prolog, а не более универсальный Lisp.

На логическое программирование возлагались большие надежды. Ожидалось, что эта концепция хорошо сочетается с параллельными вычислениями. Кроме того на логическом программировании планировалось построить следующие функции ИИ для суперкомпьютера:

* Распознавание речи и автоматический набор текста.
* Машинный перевод.
* Анализ печатного текста и его категоризация.
* Распознавание образов.
* Саморазвитие системы.

Другие страны ответили на амбициозные планы Японии. В 1984 году правительство Великобритании начало спонсировать программу [Alvey](https://en.wikipedia.org/wiki/Alvey). Целью программы стали исследования по следующим направлениям:

* Сверхбольшие интегральные схемы (VLSI)
* Системы ИИ, основанные на знаниях.
* Разработка программ.
* Интерфейс взаимодействия человека и машины.

Группа американских компаний объединилась и создала [корпорацию MCC](https://en.wikipedia.org/wiki/Microelectronics_and_Computer_Technology_Corporation), также известную как Консорциум Микроэлектрони и Компьютеров. Эта корпорация должна была спонсировать фундаментальные исследования в области ИИ и информационных технологий. В то же время управление министерства обороны США DARPA утроило финансирование в области ИИ.

#### Возрождение коннекционизма

В 1970-е и 1980-е годы исследования в рамках коннекционизма проводили учёные не связанные с ИИ. Один из них — американский физик [Джон Хопфилд](https://ru.wikipedia.org/wiki/Хопфилд,_Джон). Он использовал методы из статистической механики, чтобы изучить свойства хранения данных в нейронной сети. В результате Хопфилд разработал [новую архитектуру нейронной сети](https://ru.wikipedia.org/wiki/Нейронная_сеть_Хопфилда), которая была названа в его честь. Эта сеть стала моделью для изучения человеческой памяти. Хопфилд подробно описал свои идеи в статье 1982 года.

В начале 1980-х годов психологи [Джеффри Хинтон](https://ru.wikipedia.org/wiki/Хинтон,_Джеффри) и [Дэвид Румельхарт](https://ru.wikipedia.org/wiki/Румельхарт,_Дэвид) из университета Карнеги — Меллона исследовали процесс обучения и модель памяти на основе нейронных сетей. Они применили существующие наработки и предложили [**метод обратного распространения ошибки**](https://ru.wikipedia.org/wiki/Метод_обратного_распространения_ошибки). Этот метод позволял эффективно обучать многослойнные [нейронные сети с прямой связью](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью). Именно к такому типу сетей относится перцептрон.

В 1986 году Румельхарт и [Джеймс Макклелланд](https://ru.wikipedia.org/wiki/Макклелланд,_Джеймс) опубликовали цикл статей под названием "Параллельная распределенная обработка" (Parallel Distributed Processing). В этом цикле авторы демонстрировали области применения метода обратного распространения ошибки в компьютерных науках и психологии. Благодаря статьям Румельхарта и Макклелланда, исследователи ИИ снова заинтересовались коннекционизмом.

Благодаря развитию технологии транзисторов в 1980-е годы, появилась возможность конструировать надёжные нейрокомпьютеры. Их архитектуру описали Карвер Мид и Мохаммед Исмаил в книге 1989 года "Аналоговая реализация нейронных сетей на сверхбольших интегральных схемах" ("Analog VLSI Implementation of Neural Systems").

### Вторая зима ИИ 1987 — 1993

В 1984 году состоялась ежегодная встреча Американской ассоциации искусственного интеллекта (AAAI). На одном из обсуждений Марвин Мински и Роджер Шэнк обратились к предпринимателям. Они предупредили о завышенных ожиданиях от исследований в области ИИ.

На протяжении 1980-х годов инвестиции коммерческих компаний в ИИ постоянно росли. К 1985 году корпорации по всему миру потратили на разработку экспертных систем в сумме свыше миллиарда долларов. В основном это были разработки для внутренних нужд.

Разработка экспертных систем в больших масштабах вызвала спрос на услуги поддержки. На рынке появились новые компании. Они предлагали программные и аппаратные решения для экспертных систем.

Несмотря на бурный рост, в 1987 году рынок экспертных систем рухнул по сценарию [экономического пузыря](https://ru.wikipedia.org/wiki/Экономический_пузырь). Причиной кризиса стали завышенные ожидания инвесторов и невыполнимые обещания самих компаний. Новые компаний не смогли предоставить работоспособные решения в срок. В результате многие проеты были закрыты, а контракты на поддержку расторгнуты.

Такой поворот разочаровал инвесторов. Среди них появились сомнения, что разработки в области ИИ прибыльны с коммерческой точки зрения.

#### Банкротство производителй Lisp-машин

В конце 1979-х сотрудники лаборатории ИИ Массачусетского технологического института начали работать над специальным компьютером для запуска экспертных систем. Языком для разработки этих систем был Lisp. Поэтому новые компьютеры были нацелены на исполнение только Lisp-программ и получили название Lisp-машины.

В 1979 году на базе института была создана компания [Lisp Machines](https://en.wikipedia.org/wiki/Lisp_Machines). Её первым клиентом стала компания [Control Data Corporation](https://ru.wikipedia.org/wiki/Control_Data_Corporation) — крупный производитель компьютерной переферии и суперкомпьютеров.

В 1980-ом году часть сотрудников покинули Lisp Machines чтобы организовать новую компанию [Symbolics](https://en.wikipedia.org/wiki/Symbolics). Позднее к производству Lisp-машин подключились крупные производители электроники: [Texas Instruments](https://ru.wikipedia.org/wiki/Texas_Instruments) и [Xerox](https://ru.wikipedia.org/wiki/Xerox). Рынок специализированных компьютеров выглядел перспективно и обещал долгосрочный рост. Инвестиции в разработки Lisp-машин достигли полмилииарда долларов.

Спрос на Lisp-машины рос до 1987 года. Затем рынок неожиданно рухнул. Специализированные компьютеры стали никому не нужны. Это произошло из-за появления [**рабочих станций**](https://en.wikipedia.org/wiki/Workstation) от компании Sun Microsystems.

I> Рабочая станция отличается от персонального компьютера высокой ценой и производительностью. Её аппаратное обеспечение оптимизированно для задач визуализации, 3D моделирования и математических рассчётов. При этом рабочая станция остаётся [компьютером общего назначения](https://ru.wikipedia.org/wiki/Компьютер_общего_назначения).

Рабочие станции от Sun Microsystems имели мощное по тем временам оборудование. Их производительность была выше, чем у специализированных Lisp-машин. Несмотря на это преимущество, корпорации отказывались использовать рабочие станции. Проблема была в том, что они не поддерживали язык Lisp. Это означало, что экспертные системы на них не запускались.

В 1987 году компания [Lucid](https://en.wikipedia.org/wiki/Lucid_Inc.) разработала интерпретатор языка Lisp для операционной системы Unix. Под управлением именно этой системы работали рабочие станции Sun.

Кроме интерпретатора от компании Lucid в 1980-е годы в университете Беркли был разработан интерпретатор [Franz Lisp](https://en.wikipedia.org/wiki/Franz_Lisp). В 1982 года его портировали на компьютеры Sun.

В середине 1980-х годов относительно недорогие ПК от компаний Apple и IBM достигли производительности Lisp-машин. В скором времени на эти ПК были портированы популярные интерпретаторы языка Lisp.

Пользователям экспертных систем не осталось причин переплачивать за специальное оборудование. Корпорации стали массово отказываться от использования Lisp-машин в пользу дешёвых и универсальных компьютеров с поддержкой языка Lisp.

#### Проблемы экспертных систем

К началу 1990-х годов компании накопили достаточно опыта в использовании экспертных систем. Опыт показал, что их обслуживание обходится слишком дорого.

Проблемы возникали при добавлении новой информации в базу знаний. Сама экспертная система не имеет функции обучения. Поэтому специалисты вносили все изменения вручную. После таких изменений всю базу знаний надо было проверять на [**согласованность**](https://ru.wikipedia.org/wiki/Согласованность_данных). Согласованность означает, что в базе нет правил противоречащих друг другу. На такую проверку и исправление найденных ошибок уходило много времени и сил.

К 1990-м годам научные круги потеряли интерес к экспертным системам. Такие системы не позволяли создать универсальный ИИ. Для работы такому ИИ требуются общие знания о реальном мире. Однако, разработки в области архитектуры баз знаний показали, что представление общих знаний — трудновыполнимая задача.

Одна из немногих попыток представить общие знания о мире в базе знаний — проект [Дугласа Лената](https://ru.wikipedia.org/wiki/Ленат,_Дуглас) под названием [Cyc](https://ru.wikipedia.org/wiki/Cyc). Этот проект неоднократно подвергался критики со стороны научного сообщества. Многие учёные считают его бесполезным.

Экспертные системы доказали свою эффективность в некоторых узкоспециализированных прикладных областях. Однако, из-за коммерческих неудач инвесторы потеряли интерес к этому направлению. Не имея финансирования и интереса со стороны научного сообщества, дальнейшая активная разработка экспертных систем прекратилась.

#### Проблемы с компьютером пятого поколения

К 1991 году проект компьютера пятого поколения в Японии не достиг поставленных целей. В рамках проекта инженеры собрали несколько рабочих станций. Для этих станций разработали [несколько демонстрационных приложений](https://instadeq.com/blog/posts/japans-fifth-generation-computer-systems-success-or-failure/):

* Распределённую систему управления данными Kappa.
* [Правовую экспертную систему](https://ru.wikipedia.org/wiki/Правовая_экспертная_система) HELIC-II.
* Систему для доказательства теорем MGTP.
* Систему для обработки естественного языка Laputa.

На проекты было потрачено огромное количество денег и усилий. Несмотря на это, рабочие станции не пошли в массовое производство и не попали на рынок. Причин этому несколько. Рассмотрим их подробнее.

К моменту своего появления рабочие станции оказались устаревшими. Проект длился 10 лет. В момент его запуска исследователи предполагали, что однопроцессорные компьютеры достигли предела производительности. Специалисты пришли к выводу, что параллельные вычисления — это единственный способ увеличить мощность компьютера. Однако, этот прогноз оказался неверным. Число транзисторов на интегральной схеме продолжало увеличиваться, согласно закону Мура. В результате этого к 1991 году недорогие ПК, собранные на стандартных компонентах, превзошли по производительности рабочие станции пятого поколения.

Устаревание рабочих станций было связано не только с их производительностью. Параллельно с микропроцессорами развивались информационные технологим. Так в 1984 ПК от компании Apple получили графический интерфейс. В начале 1990-х появился Internet. Рабочие станции пятого поколения не поддерживали эти передовые технологии. В результате они стали неинтересны пользователям.

Другая проблема компьютера пятого поколения связана с его программами. Разработчики выбрали концепцию логического программирования и язык Prolog. Но оказалось, что эта концепция плохо совместима с параллельными вычислениями. Сам язык Prolog не предоставлял средств для выполнения программы на нескольких процессорах. Все попытки добавить такие средства в язык провалились.

Запланированные возможности ИИ оказались намного более требовательными к оборудованию, чем ожидалось. Логического программирования оказалось недостаточно для их реализации. Эти возможности требовали других подходов и более производительной аппаратуры.

Провал проекта компьютера пятого поколения имел несколько последствий для информационных технологий в целом. Во-первых, проект подорвал веру разработчиков программ и учёных в логическое программирование. Недостатки этого подхода рассматривались как одна из главных причин неудачи проекта. Крупные исследования и финансирование этого направления ИИ прекратились.

Во-вторых, правительства США и Англии сократили свои инвестиции в компьютерные технологии и исследования ИИ. Эти страны оставались лидерами в обоих областях. Пропала угроза того, что Япония сможет их догнать.

### Развитие ИИ в 1993–2011

#### Научный подход в ИИ

С 1970-х годов ииследования в области ИИ проводились [двумя принципиально разными путями](https://en.wikipedia.org/wiki/Neats_and_scruffies).

Первый подход назывался **neat**, что по-английски означает "аккуратный". Лучше всего смысл этого подхода передаёт слово "теоретический". Исследователь-теоретик применяет только [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы). Эти методы основаны на математике и логике. Такой подход даёт более надёжный и научно обоснованный результат. Ожидается, что такой путь приведёт к идее или методу, который можно обобщить и на его основе создать ИИ.

Второй подход называется **scruffy** или "неряшливый". Его лучше назвать "экспериментальным" или "практическим". Исследователи-практики пробуют разные алгоритмы и методы, чтобы добиться от системы нужного поведения. Они утверждают, что для создания ИИ необходимо решить ряд несвязанных между собой задач. При этом ни одна программа не сможет стать интеллектуальной самостоятельно.

Споры между теоретиками и практиками продолжались до 1990-х годов. Они прекратились, когда новейшие подходы математики и статистики стали применяться в ИИ. Благодаря им, появилось новое направление в разработке программ — [**математическая оптимизация**](https://ru.wikipedia.org/wiki/Оптимизация_(математика)). Кроме того эти подходы подстегнули развитие нейронных сетей. Такие направления как [**машинное обучение**](https://ru.wikipedia.org/wiki/Машинное_обучение) и компьютерное зрение достигли больших успехов.

I> Машинное обучение — это класс методов в ИИ. Эти методы не решают поставленную задачу, а обучают систему на примерах решения аналогичных задач. После процесса обучения система решает поставленную задачу сама.

Переход к формальным методам позволили исследователям ИИ использовать достижения других наук. Среди них теория вероятностей и теория принятия решений. Использование математического аппарата ускорилоло обмен идеями между ИИ и смежными с ним науками.

#### Интеллектуальные агенты

В 1990-х годах концепция интеллектуальных агентов получила признание среди исследователей ИИ. Эта концепция пришла в ИИ из экономики и теории принятия решений. Её прототипом стало понятие рацинального агента из экономики. Главная особенность интеллектуального агента в том, что он пытается максимизировать свою эффективность при решении поставленной задачи.

Понятие интеллектуального агента разрешило несколько философских проблем в области ИИ. Первая из них заключалась в спорах о том, что считается интеллектом. Тест Тьюринга подчёркивал сравнение искусственных систем с человеческим интеллектом. Понятие рационального агента устранило это сравнение. Теперь интеллектуальным стало считаться любое поведение, которое ведеёт к эффективному достижению цели.

Кроме того теперь потеряли смысл обсуждения о том, может ли машина обладать сознанием и настоящим пониманием. Эти свойства стали неважны для интеллектуального агента. Исследователи ИИ смогли сконцентрироваться на решении конкретных практических задач. Формальные методы позволили им находить решения, правильность которых можно было доказать.

Новая концепция помогла исследователям ИИ и с практической точки зрения. Она позволила непосредственно сравнивать эффективность различных систем, основанных на разных подходах. Принцип работы системы отошёл на второй план. Раньше каждый исследователь работал только в рамках одного подхода: символьный или коннекционизм. Теперь система оценивалась более объективно по своим результатам. Начались попытки совмещения разных подходов для повышения эффективности.

#### Восстановление репутации ИИ

Многие инвесторы разочаровались в области ИИ после краха рынка Lisp-машин, проблем с экспертными системами и провала проекта компьютера пятого поколения. Это вызвало сокращение финансирования фундаментальных исследований и разработок.

На протяжении 1990-х годов многие исследователи избегали термина ИИ, когда описывали свою работу. Вместо этого они говорили об информатике, когнитивных системах и вычислительном интеллекте. Так исследователи имели больше шансов найти финансирование. В результате многие достижения в области ИИ стали считаться частью информатики. Например, к этим достижениям относятся алгоритмы поиска и способы представления данных.

В конце 1990-х и начале 2000-х годах исследователи ИИ смогли продемонстрировать несколько впечатляющих успехов. Эти успехи вызвали широкий резонанс в обществе. Они частично восстановили испорченную репутацию науки об ИИ.

В 1997 году суперкомпьютер [DeepBlue](https://ru.wikipedia.org/wiki/Deep_Blue) от IBM смог обыграть чемпиона мира по шахматам Гарри Каспарова.

В 2005 году робот, разработанный в Стэнфордском университете, победил в гонках [DARPA Grand Challenge](https://ru.wikipedia.org/wiki/DARPA_Grand_Challenge). Автономно управляемая машина смогла проехать весь маршрут в 211 километров по пустыне Мохаве. На это у робота ушло почти семь часов.

В 2011 году ИИ ситема [Watson](https://ru.wikipedia.org/wiki/IBM_Watson) от компании IBM смогла обыграть двух лучших игроков в телевизионной игре-викторине Jeopardy!. В этой игре участники отвечают на вопросы из области общих знаний.

Эти успехи удалось достичь благодаря увеличению производительности компьютеров и качеству разработки программ в 1990-х годах. Каждая из нашумевших ИИ систем использовала хорошо известные подходы, разработанные ещё в 1960-х годах.

### Современные направления в ИИ

#### Big Data

Big data или [**большие данные**](https://ru.wikipedia.org/wiki/Большие_данные) — это одно из современных направлений в ИИ. Оно изучает методы обработки наборов данных, которые слишком велики для применения традиционных подходов.

Направление big data возникло по двум причинам:

* [Компьютеризация](https://ru.wikipedia.org/wiki/Компьютеризация) общества. Все больше компаний и правительственных учреждений используют компьютеры. В результате накапливаются огромные объёмы информации.

* Распространение портативных устройств, которые способны накапливать информацию. Примеры таких устройств: мобильные телефоны, телевизоры, камеры наблюдения, микрофоны.

Исследователи big data используют следующие технологии:

* Машинное обучение.
* [Обработка естсественных языков](https://ru.wikipedia.org/wiki/Обработка_естественного_языка).
* [Облачные вычисления](https://ru.wikipedia.org/wiki/Облачные_вычисления).
* [Базы данных](https://ru.wikipedia.org/wiki/База_данных).
* Визуализация данных.

Сегодня big data активно применяется в следующих областях:

* Государственные учреждения. Они обрабатывают личную информацию граждан и ведут разного рода статистику.

* Здравоохранение. Методы big data применяются для анализа результатов клинических исследований. Также они помогают вести статистику заболеваний.

* Экономика. Для составления прогнозов и планирования крупных проектов приходится обрабатывать значительные объёмы данных.

* Страховые компании должны обрабатываеть данные о своих клиентах.

* Информационные технологии. Многие информационные системы собирают стсатистику об их использовании. Это помогает разработчикам улучшать свои продукты.

#### Deep Learning

Перцептрон Розенблатта и нейронные сети 1980-х годов моделировали работу мозга. Для этого исследователи ИИ применяли знания из области нейрофизиологии. Низкая производительность компьютеров ограничивала размеры этих сетей. Число нейронов в них было на несколько порядков меньше, чем в мозге мыши. Это привело к скромным достижениям коннекционизма в 1980-е годы по сравнению с символьным подходом.

В 1986-ом году в машинном обучении появилось новое направление под названием deep learning. Оно также известно как [**глубокое обучение**](https://ru.wikipedia.org/wiki/Глубокое_обучение). Отличительная особенность этого подхода в архитектуре нейронных сетей. Эти сети называются **глубокими** или **многослойными**. В отличие от перцептрона Розенблатта они имеют более трёх слоёв. Благодаря такой архитектуре, алгоритм обучения может извлекать признаки разного уровня асбтракции из входных данных. Например, алгоритм машинного зрения может различать на низком уровне отдельные линии, а на более высоком цифры и буквы.

Активные исследования по изучению многослойных сетей начались в середине 1960-х годов. В 1967 году советский математик [Алексей Ивахненко](https://ru.wikipedia.org/wiki/Ивахненко,_Алексей_Григорьевич) разработал первый алгоритм обучения многослойных перцептронов.

В 1980-м году японский учёный Кунихико Фукусима предложил архитектуру многослойной сети под названием [**неокогнитрон**](https://ru.wikipedia.org/wiki/Неокогнитрон). Она предназначалась для распознавания образов.

Исследования многослойных нейронных сетей продолжались на протяжении 1980-х годов. Однако, только в 2000-х годах глубокие сети стали широко использоваться. Причин этому несколько:

* Недостаточно проработанная теория обучения глубоких сетей.

* Возросла общая производительность компьютеров.

* В различных предметных областях были накоплены большие наборы данных для обучения сетей.

* Появилось специальное оборудование ([графические процессоры](https://ru.wikipedia.org/wiki/Графический_процессор) или GPU), которое на порядок ускорило обучение сетей.

Все эти проблемы удалось преодолеть к концу 2000-х годов. Поэтому в начале 2010-х глубокие нейронные сети стали занимать призовые места на конкурсах по распознованию образов.

Сегодня глубокие нейронные сети показывают хоршие результаты в следующих областях:

* Распознавание речи.
* Распознавание образов.
* Машинный перевод.
* Системы рекомендаций.
* Медицинская диагностика.
