## 2.1 История

История искусственного интеллекта (ИИ) — это большая и сложная тема для отдельной книги. Наука об ИИ относительно молода, но несмотря на это, она успела пережить несколько взлётов и падений. Очередные успехи исследователей вызывали неоправданный ажиотаж и завышенные ожидания инвесторов. Затем наступало разочарование и сокращение финансирования.

Здесь мы рассмотрим только события и теории, которые относятся к теме книги. Кратко мы познакомимся с некоторыми ключевыми концепциями, которые пригодятся нам в дальнейшем.

Искусственный интеллект как направление исследований появился на стыке нескольких дисциплин. Он перенял некоторые теории, идеи и методы из других наук. Эти науки приводит таблица 2-1.

{caption: "Таблица 2-1. Науки, оказавшие влияние на ИИ", width: "100%"}
| Наука | Применяемая в ИИ теория, идея или метод |
| --- | --- |
| Нейрофизиология | Модель искусственного нейрона и нейронной сети |
|  | |
| Математика | Правила формальной логики и логического вывода |
|  | Статистические методы |
|  | Теория вероятностей |
|  | Теория принятия решений |
|  | |
| Информатика | Языки программирования |
|  | Теория вычислительной сложности |
|  | Высокопроизводительные компьютеры |
|  | |
| Кибернетика | Теория управления сложных систем |

### 2.1.1 Дартмутский семинар

В начале 1950-х годов учёные проводили первые исследования в области искусственного интеллекта. Свою работу они относили к сложной обработке информации, кибернетике или теории автоматов. Название зависело от подхода, выбранного в каждом конкретном проекте.

Термин "искусственный интеллект" впервые появился в заявке на проведение семинара в Дартмутском колледже в Хановере (штат Нью-Гэмпшир). Семинар состоялся в 1956 году. В группу его организаторов входили:

* Джон Маккарти
* Клод Шеннон
* Марвин Мински
* Натаниэль Рочестер

В мероприятии приняли участие ведущие учёные из разных областей. Самыми обсуждаемыми темами стали следующие:

* Обработка естественных языков.
* Ориентированные на прикладные области системы (ранние экспертные системы). 
* Дедуктивные и индуктивные системы логического вывода.

Участники семинара решили объединить эти темы в единое научное направление. Оно получило название "искусственный интеллект". Это решение повлияло на последующие исследования. Во-первых, в 1960-е и 1970-е годы доминирующими направлениями стали именно те, которые активно обсуждались на семинаре. Во-вторых, учёные получили возможность свободно экспериментировать и искать новые подходы к построению интеллектуальных машин. Их больше не ограничивали методы существующих наук: аналоговые вычисления кибернетики и математический аппарат теории автоматов. Новое научное направление началось как экспериментальная дисциплина.

### 2.1.2 Основные направления ИИ

Дартмутский семинар дал мощный толчок для развития ИИ. Он задал несколько перспективных направлений для исследований и определил их методологию. После семинара его участники смогли найти поддержку в правительственных кругах. Таким образом они получили финансирование для своей работы.

Правительство США выделило огромные средства на исследования в новой области. На базе известных учебных заведений были созданы специальные лаборатории. Руководящие роли в них заняли некоторые из участников Дартмутского семинара.

Таблице 2-2 приводит первые лаборатории по исследованию ИИ.

{caption: "Таблица 2-2. Лаборатории по исследованию ИИ", width: "100%"}
| Учебное заведение | Основатели лаборатории ИИ |
| --- | --- |
| [Университет Карнеги — Меллона](https://ru.wikipedia.org/wiki/Университет_Карнеги_—_Меллона) | Аллен Ньюэлл и Герберт Саймон |
|  | |
| [Стэнфордский университет](https://ru.wikipedia.org/wiki/Стэнфордский_университет) | Джон Маккарти |
|  | |
| [Массачусетский](https://ru.wikipedia.org/wiki/Массачусетский_технологический_институт) |  Марвин Минский |
| технологический институт (МТИ) | Джон Маккарти (впоследствии покинул МТИ) |

Новые лаборатории специализировались на исследованиях в области вычислительной техники и ИИ. Каждая из них разрабатывала собственные подходы для создания интеллектуальных систем.

Исследователи из Массачусетского технологического института следовали подходу, который в 1970-е годы получил название [**scruffy**](https://en.wikipedia.org/wiki/Neats_and_scruffies). Дословно его название переводится как "неряшливый". Но лучше его характеризует слово "экспериментальный". Идея подхода следующая: разрабатывать прототипы интеллектуальных систем для небольших задач из разных областей. Затем комбинировать и совершенствовать полученные системы. Так исследователи надеялись прийти к решению реальных сложных задач.

Противоположный подход получил название **neat**. Дословно его название переводится как "аккуратный". Его идею хорошо передаёт слово "теоретический". Этот подход предлагает использовать [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы) для разработки интеллектуальных систем. Эти методы основаны на математике и логике. Они дают более надёжный и научно обоснованный результат. Этого подхода придерживались исследователи из университетов Карнеги — Меллона и Стэнфордского.

Некоторые направления исследований оказались особенно успешными. Большинство учёных в своих работах стало ориентироваться на них. Таблица 2-3 приводит три основных направления, которые стали доминирующими к началу 1960-х годов.

{caption: "Таблица 2-3. Направления в ИИ", width: "100%"}
| Название | Идея | Основоположники |
| --- | --- | --- |
| [Символьный](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | Задача решается | Аллен Ньюэлл |
| [подход](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | через действия над понятными человеку символическими обозначениями. | Герберт Саймон |
|  | | |
| [Логическое программирование](https://ru.wikipedia.org/wiki/Логическое_программирование) | Задача решается методами формальной логики. | Джон Маккарти |
|  | | |
| [Коннекционизм](https://ru.wikipedia.org/wiki/Коннекционизм) | Задача решается | Уоррен Мак-Каллок |
| | сетью из связанных между собой простых элементов (нейронной сетью). | Уолтер Питтс |

Популярность этих направлений менялась на протяжении десятилетий. Она зависела от успехов и неудач в исследованиях. Сегодня самым многообещающим подходом считается машинное обучение. Его можно считать наследником коннекционизма.

Рассмотрим подробнее истоки и наиболее важные открытия каждого из направлений ИИ.

### 2.1.3 Символьный подход

#### 2.1.3.1 Logic Theorist

Первую интеллектуальную систему в виде компьютерной программы разработала группа американских учёных в 1956 году. Система получила название [Logic Theorist](https://en.wikipedia.org/wiki/Logic_Theorist). Её авторы работали в корпорации [RAND](https://ru.wikipedia.org/wiki/RAND_(корпорация)). С 1948 года RAND выполняла стратегические исследования для правительства США.

Разработчиков Logic Theorist было трое:

* [Герберт Саймон](https://ru.wikipedia.org/wiki/Саймон,_Герберт_Александер) — учёный в области экономических, социальных и политических наук. Одна из его научных работ была посвящена принятию решений в правительственных учреждениях и компаниях. В своих исследованиях он использовал методы теории принятия решений.

* [Аллен Ньюэлл](https://ru.wikipedia.org/wiki/Ньюэлл,_Аллен) — учёный в области логистики и [теории организаций](https://ru.wikipedia.org/wiki/Теория_организаций). Это теория из области социологии, которая исследует взаимодействия людей в политических и коммерческих организациях.

* [Клиффорд Шоу](https://en.wikipedia.org/wiki/Cliff_Shaw) — опытный программист корпорации RAND, который реализовал замыслы Саймона и Ньюэлла.

Идею системы предложил Аллен Ньюэлл. Он утверждал, что простое программируемое устройство, вроде компьютера, способно на сложное поведение. Чтобы проверить эту гипотезу Ньюэлл и Саймон решили разработать систему для [**доказательства математических теорем**](https://en.wikipedia.org/wiki/Automated_theorem_proving) (automated theorem proving). Тогда к проекту присоединился Клиффорд Шоу, чтобы помочь с программированием.

Система Logic Theorist смогла доказать 38 теорем из книги ["Начала математики"](https://ru.wikipedia.org/wiki/Principia_Mathematica) Бертрана Рассела. Учёные решили, что это подтверждает гипотезу Аллена Ньюэлла. Их рассуждение было следующим. Универсальный компьютер доказал математические теоремы. Поэтому он способен к разумному поведению.

В середине 1950-х годов считалось, что цифровые компьютеры могут оперировать только числами. Вопреки этому мнению, система Logic Theorist работала с символами. Её разработчики утверждали, что создали программу, способную мыслить в нечисловых терминах. Операции над символами позволили перейти от математических вычислений к логическим высказываниям. Этот подход стал доминирующим в области ИИ в течение следующих 30 лет.

Разработчики Logic Theorist впервые применили следующие концепций:

* **Рассуждение как поиск**. Logic Theorist выполняет поиск по дереву для доказательства гипотезы. Корень дерева соответствует известным фактам. Исходящие из корня ветви — это логические операции над фактами. Каждая ветвь приводит к определённому выводу. Один из этих выводов является целью рассуждения. Именно его ищет система.

* [**Эвристика**](https://ru.wikipedia.org/wiki/Эвристика) — это дополнительное правило, которое исключает из рассмотрения некоторые ветви дерева. Эвристика без проверки предсказывает, что какая-то ветвь не приведёт к решению. Удаление таких ветвей значительно сокращает время поиска.

* **Обработка списков**. Чтобы написать программу Logic Theorist, был разработан специальный язык программирования [IPL](https://en.wikipedia.org/wiki/Information_Processing_Language). Для него Клиффорд Шоу впервые применил структуру данных под названием [**связанный список**](https://ru.wikipedia.org/wiki/Связный_список). Она хранит список символов в эффективном формате. Позднее на основе IPL и списков Джон Маккарти разработает язык Lisp.

Новаторские идеи, заложенные в Logic Theorist, во многом определили дальнейшее развитие области ИИ.

#### 2.1.3.2 General Problem Solver

Система Logic Theorist произвела впечатление на участников Дартмутского семинара. Она была единственным работающим решением среди всех представленных проектов. Остальные исследования находились только на этапе теоретических моделей.

Аллен Ньюэлл, Герберт Саймон и Клиффорд Шоу продолжили работать с операциями над символами. Их следующим проектом стала универсальная система для решения задач. Она получила название [General Problem Solver](https://ru.wikipedia.org/wiki/Универсальный_решатель_задач) (GPS). В отличие от Logic Theorist её область применения не ограничивалась математическими задачами. GPS была намного мощнее и универсальнее. Авторы утверждали, что она моделирует процесс принятия решений человеком.

Система GPS была готова в 1959 году. Для решения поставленной задачи она использовала новую технику поиска под названием [**анализ средств и результатов**](https://en.wikipedia.org/wiki/Means–ends_analysis) (means–ends analysis или MEA). Эта техника стала развитием концепции "рассуждение как поиск", на которой был построен Logic Theorist.

Алгоритм анализа средств и результатов выглядит так:

1. Оценить текущее состояние системы. Если поставлена задача, необходимы действия для её решения.

2. Определить конечную цель. Она выражается в некотором состоянии системы, которое надо достигнуть. Достижение этого состояния означает решение поставленной задачи.

3. Разделить конечную цель на составные части, называемые подцелями. Если подцели остаются сложными, они так же делятся на составные части.

4. Составить список действий, выполнение которых приведёт к конечной цели. Достижение этой цели означает решение поставленной задачи.

5. Связать каждую из подцелей с соответствующим ей действием из списка.

6. Выполнить все действия из списка.

7. Сравнить полученное состояние системы с тем, которое надо достигнуть для решения поставленной задачи. Если эти состояния отличаются, повторить алгоритм начиная с шага 2.

Система GPS успешно доказывала теоремы [евклидовой геометрии](https://ru.wikipedia.org/wiki/Евклидова_геометрия) и логики предикатов. Также она могла решать шахматные задачи.

Эксперимент с системой GPS дал Аллену Ньюэллу и Герберту Саймону полезный опыт. Опираясь на него, в 1976 году учёные сформулировали [**гипотезу о физической символьной системе**](https://ru.wikipedia.org/wiki/Гипотеза_Ньюэлла_—_Саймона). Она звучит так:

> Физическая символьная система обладает необходимыми и достаточными средствами для разумного поведения.

Учёные обосновали свою гипотезу следующими рассуждениями:

1. Без символьной системы невозможно разумное поведение.

2. Следовательно, мышление человека основано на символьной системе и заключается в манипулировании символами.

3. Универсальный компьютер также может манипулировать символами.

4. Следовательно, он теоретически способен на разумное поведение.

Исследования Аллена Ньюэлла и Герберта Саймона заложили основу **символьного подхода** (symbolic approach). Его идея заключается в создании интеллектуальных систем, работа которых основана на манипулировании символами. Символы могут быть абстрактными, но должны быть понятны человеку. Саму систему надо программировать вручную, как и любую другую компьютерную программу.

Символьный подход, как идея и метод, доминировал в области ИИ с середины 1950-х до конца 1980-х годов.

### 2.1.4 Логическое программирование

В 1958 году Джон Маккарти разработал модель системы под названием [Advice Taker](https://en.wikipedia.org/wiki/Advice_taker). Принцип её работы учёный описал в статье "Программы со здравым смыслом" (["Programs with Common Sense"](http://www-formal.stanford.edu/jmc/mcc59.pdf)).

Advice Taker использовал концепцию рассуждение как поиск, предложенную Алленом Ньюэллом и Клиффордом Шоу. Главное отличие новой системы от Logic Theorist было в том, что Advice Taker работал с логическими высказываниями, а не с абстрактными символами.

На вход система Advice Taker получала от пользователя условия задачи. Эти условия представляли собой логические утверждения на некотором формальном языке. Далее система искала решение поставленной задачи путём логических рассуждений. В основе этих рассуждений был поиск.

Джон Маккарти выдвинул следующую гипотезу: 

> Система станет универсальной, если сообщить ей общую информацию об окружающем мире.

Если эта гипотеза верна, то Advice Taker смог бы самостоятельно делать выводы обо всём, что ему сообщают и что он уже знает. Это означало бы, что система рассуждает с позиции [здравого смысла](https://ru.wikipedia.org/wiki/Здравый_смысл).

Разработчики Logic Theorist делали ставку на продвинутые алгоритмы поиска по множеству высказываний. Джон Маккарти предложил другой путь улучшения работы системы. Advice Taker использовал [**формальную**](https://ru.wikipedia.org/wiki/Формальная_логика) и [**математическую**](https://ru.wikipedia.org/wiki/Математическая_логика) логику. По мнению учёного, это более точный подход для моделирования интеллектуальных систем. Главное его преимущество в том, что работоспособность системы можно формально доказать.

I> **Формальная логика** — это раздел логики, в котором применяется формальный язык и строгие правила для операций над высказываниями. **Математическая логика** — это направление формальной логики, в которой активно применяется математический аппарат.

Джон Маккарти предложил новый способ представления знаний для Advice Taker. Система Logic Theorist хранила все знания и эвристики в коде самой программы. Из-за этого их было сложно редактировать. Чтобы добавить новое утверждение или исправить существующее, приходилось исправлять программный код на языке IPL.

В системе Advice Taker знания и механизм рассуждений чётко разделялись. Знания хранились в виде правил на некотором формальном языке. Эти правила помещались в списки. В результате их стало проще редактировать. Теперь с этой задачей мог справиться оператор без навыков программирования.

Для логического вывода Advice Taker выполнял поиск по спискам. Джон Маккарти искал способ вынести алгоритм поиска из кода самой системы. Учёный решил сделать поиск одним из механизмов языка программирования. Тогда на таком языке стало бы значительно проще и быстрее создавать новые специализированные интеллектуальные системы.

Джон Маккарти начал работать над новым языком программирования. Он рассматривал это как первый шаг для реализации Advice Taker. Так появился язык LISt Processing более известный как [Lisp](https://ru.wikipedia.org/wiki/Лисп). Учёный описал Lisp в статье для журнала Communications of the ACM в 1960 году. Первый работающий интерпретатор языка появился в 1958 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704).

Некоторые идеи языка Lisp Джон Маккарти высказал ещё в статье "Программы со здравым смыслом". В ней учёный рассуждал над преимуществами декларативных и императивных инструкций. **Декларативные инструкции** описывают свойства результата, который должна выдать программа. **Императивные инструкции** — задают чёткий алгоритм вычисления результата. Джон Маккарти утверждал, что декларативные инструкции лучше подходят для разработки интеллектуальных систем и упрощают работу с логическими правилами.

Главный механизм Lisp — это операции над списками. В отличие от других языков Lisp не различает данные и код программы. Вся программа записывается в виде списков, заключенных в круглые скобки. Такие структуры в терминологии языка называются **S-выражениями** (s-expressions).

Изначально Джон Маккарти задумывал Lisp как чисто декларативный язык. Но в процессе реализации учёный добавил такие конструкции императивного языка как циклы и переменные. Благодаря им, Lisp стал универсальным языком. Он подходит для широкого круга задач, которые не относятся к ИИ. Сегодня его [продолжают применять](https://habr.com/ru/companies/typeable/articles/581488/) в разных прикладных областях.

Система Advice Taker так никогда и не была реализована. Когда Джон Маккарти довел язык Lisp до стабильного состояния, она уже потеряла актуальность. Тем не менее Advice Taker оказалась полезна как модель типичной интеллектуальной системы. Она помогла учёному лучше понять нужды разработчиков. Благодаря этому, Джон Маккарти создал язык, который стал основным инструментом для исследователей ИИ на протяжении десятилетий.

### 2.1.5 Коннекционизм

#### 2.1.5.1 Искусственный нейрон

Первая исследовательская работа в области ИИ связана с нейрофизиологией и математикой. Её выполнили американские учёные [Уоррен Мак-Каллок](https://ru.wikipedia.org/wiki/Мак-Каллок,_Уоррен) и [Уолтер Питтс](https://ru.wikipedia.org/wiki/Питтс,_Уолтер), когда изучали мозг человека.

Уоррен Мак-Каллок был известным нейрофизиком. Он изучал медицину в колледже врачей и хирургов Колумбийского университета в Нью-Йорке, где в 1927 году получил степень доктора медицины. После этого он занимался медицинской практикой до 1937 года. Закончив её, Мак-Каллок работал в лаборатории нейрофизиологии Йельского университета. В 1941 году он переехал в Чикаго и поступил на кафедру психиатрии Иллинойского университета, где был профессором психиатрии.

Уолтер Питтс был самоучкой из бедной семьи. В 1935 году в возрасте 12 лет Питтс прочитал "Основания математики" Бертрана Рассела. Он нашёл в книге несколько ошибок и написал о них автору. Благодаря этой переписке с известным английским математиком, Уолтер Питтс смог получить образование в Иллинойсском университете в Чикаго. Его специальностью была математическая логика.

Уоррен Мак-Каллок и Уолтер Питтс познакомились в Иллинойсском университете. Они решили объединить свои знания и усилия, чтобы найти логические закономерности в работе мозга. Вместе учёные разработали математическую модель связанных между собой [**искусственных нейронов**](https://ru.wikipedia.org/wiki/Искусственный_нейрон). Эта модель впоследствии стала известна как **бинарный пороговый нейрон** ([binary threshold neuron](https://www.youtube.com/watch?v=iKKfoP-naN8)).

[**Нейрон**](https://ru.wikipedia.org/wiki/Нейрон) — это узкоспециализированная электрически возбудимая клетка. В организме человека и животных нейроны соединяются друг с другом в [**нервную сеть**](https://ru.wikipedia.org/wiki/Нервная_сеть). По этой сети проходят электрические и химические сигналы. С их помощью передаётся информация между узлами нервной системы.

Бинарный пороговый нейрон представляет собой упрощённую модель биологического нейрона. Эта модель имеет два состояния: возбуждённое и невозбуждённое. На вход нейрон получает сигналы от других нейронов. Их обрабатывает [**функция активации**](https://ru.wikipedia.org/wiki/Функция_активации). Результат функции передаётся на выход нейрона, который связан со входами других нейронов.

Функция активации бинарного порогового нейрона называется **ступенчатой** ([step function](https://en.wikibooks.org/wiki/Artificial_Neural_Networks/Activation_Functions#Step_Function)). Её формула выглядит следующим образом:
{width: "50%"}
![](images/ArtificialIntelligence/step-function-formula.png)

В этой формуле используются следующие обозначения:

* f(x) — результат функции
* m — число входных сигналов нейрона
* x~i~ — значение i-ого входного сигнала
* θ — пороговое значение для входных сигналов.

Иллюстрация 2-1 демонстрирует график ступенчатой функции активации. Результат функции f(x) отображается на оси Y, а сумма входных сигналов — на оси X. Пока эта сумма меньше θ, нейрон находится в невозбуждённом состоянии. Его выходной сигнал равен нулю. Когда сумма входных сигналов превышает θ, нейрон возбуждается. Его выходной сигнал становится равен единице.

{caption: "Иллюстрация 2-1. Ступенчатая функция активации бинарного порогового нейрона", height: "30%"}
![Ступенчатая функция активации бинарного порогового нейрона](images/ArtificialIntelligence/step-function-graph.png)

Мак-Каллок и Питтс связали между собой несколько искусственных нейронов. При этом выходы одних нейронов соединялись со входами других. Такая структура получила название [**нейронная сеть**](https://ru.wikipedia.org/wiki/Нейронная_сеть).

Мак-Каллок и Питтс доказали, что нейронная сеть может выполнять числовые и логические операции. Кроме того они предположили, что сети с особенной архитектурой способны обучаться. В 1943 году учёные опубликовали свои результаты в статье "Логическое исчисление идей, присущих нервной деятельности" (A Logical Calculus of Ideas Immanent in Nervous Activity).

Модель нейронной сети Мак-Каллока и Питтса была только теоретической. Учёные подтверждали свои гипотезы только математическими выкладками. На тот момент не существовало программы или устройства, которое работало как нейронная сеть. Поэтому работоспособность модели нельзя было проверить на практике.

#### 2.1.5.2 Обучение нейронной сети

Модель Мак-Каллока и Питтса была полноценным вычислительным механизмом. В своей статье учёные описали её работу с числовыми и логическими выражениями. Но чтобы решать реальные задачи с помощью нейронной сети, нужны были средства управления. Для универсальных компьютеров такими средствами стали программы. Это решение не подходило для нейронных сетей. Для них нужен был принципиально иной подход.

Прототип средства управления нейронной сетью разработал канадский нейропсихолог [Дональд Хебб](https://ru.wikipedia.org/wiki/Хебб,_Дональд). Он изучал влияние хирургии и травм головного мозга человека на его функции. Также учёный проводил эксперименты на животных. Он выяснял, как обучение в детском возрасте влияет на поведение взрослых животных. Результаты своих исследований и их трактовку Дональд Хебб привёл в книге "Организация поведения: нейропсихологическая теория" (The Organization of Behavior: A Neuropsychological Theory). Она была опубликована в 1949 году.

Книга Дональда Хебба посвящена не искусственным нейронным сетям, а нейробиологии. На момент её написания существовало несколько теорий поведения человека: [**бихевиоризм**](https://ru.wikipedia.org/wiki/Бихевиоризм), [**гештальтпсихология**](https://ru.wikipedia.org/wiki/Гештальтпсихология) и другие. Каждая из теорий хорошо объясняла некоторые психические функции, но имела трудности с другими. Дональд Хебб объединил существующие данные о поведении и мозге в единую теорию. Она связала биологические функции мозга как органа с высшими функциями разума.

Центральная идея книги — зависимость поведения человека от способа обработки информации мозгом. Учёный ввёл понятие **сборка клеток** (cell assembly), которое означает взаимосвязанные нейроны. Дональд Хебб утверждает, что обучение и память основаны на формировании сборок клеток. Входящие в одну сборку нейроны активируются вместе в результате обучения. Именно такие взаимосвязанные нейроны являются основными единицами мышления. Их организация определяет поведение человека.

Согласно Дональду Хеббу, поведение человека определяется двумя фундаментальными процессами: физиологическими процессами мозга и переживаниями. Учёный предположил, что эти два фактора неразрывно связаны. Мозг постоянно приспосабливается к окружающей среде. Для этого между нейронами образуются новые связи.

Предложенная Дональдом Хеббом теория обучения нейронов человеческого мозга получила название **обучение Хебба**. Основное правило этой теории учёный сформулировал так:

> Пусть аксон клетки А находится достаточно близко, чтобы возбуждать клетку B. Он неоднократно или постоянно принимает участие в ее возбуждении. Тогда наблюдается процесс роста или метаболических изменений в одной или обеих клетках. Этот процесс увеличивает эффективность А, как одной из клеток возбуждающих В

I> **Аксон** — это длинный цилиндрический отросток нервной клетки, по которому нервные импульсы идут от её тела к органам и другим нервным клеткам.

Этот постулат стал известен как [**правило Хебба**](https://habr.com/ru/articles/102305/). Он объясняет, как связи между нейронами меняются в зависимости от их активности. Простыми словами его можно переформулировать так:

> Если за активацией нейрона А последовательно следует активация нейрона Б, связь между ними усиливается. С другой стороны, если за активацией нейрона А не следует активация нейрона Б, связь ослабевает.

Правило Хебба заложило основу теории обучения искусственных нейронных сетей. Именно разработанные в рамках этой теории алгоритмы стали средствами управления для нейронных сетей.

#### 2.1.5.3 Перцептрон

В середине 1950-х годов американский психолог и нейрофизиолог [Фрэнк Розенблатт](https://ru.wikipedia.org/wiki/Розенблатт,_Фрэнк) изучал организацию памяти в биологических системах. Он пришел к выводу, что механизм памяти неразрывно связан с процессом восприятия. Тогда учёный сменил направление исследований и начал изучать этот процесс.

В конце 1950-х годов Фрэнк Розенблатт разработал модель восприятия информации мозгом человека. Она получила название [**перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон). Позднее модель такого типа стала называться [**двоичным классификатором**](https://ru.wikipedia.org/wiki/Двоичная_классификация) ([binary classifier](https://www.youtube.com/watch?v=mI6jTc-8sUY)).

Термин "перцептрон" часто вызывает путаницу. Причина в том, что им обозначают следующие понятия:

1. Алгоритм обучения с учителем для двоичных классификаторов.

2. Модель отдельного нейрона.

3. Модель однослойной нейронной сети.

4. Модель многослойной нейронной сети.

I> С алгоритмами обучения мы познакомимся в разделе "2.6 Машинное обучение".

Для начала рассмотрим модель отдельного нейрона под названием перцептрон. Такой нейрон получает на вход несколько сигналов. Каждый входной сигнал имеет свой вес. **Вес** — это вещественное число, которое пропорционально важности сигнала. Чем важнее сигнал, тем больше его вес и наоборот. Вес нужен для расчёта **взвешенной суммы входных сигналов**. Она рассчитывается по следующей формуле:
{height: "10%"}
![](images/ArtificialIntelligence/perceptron-dot-product.png)

В этой формуле используются следующие обозначения:

* Y — взвешенная сумма входных сигналов
* m — число входных сигналов перцептрона
* w~i~ — вес i-ого входного сигнала
* x~i~ — значение i-ого входного сигнала.

Иногда к взвешенной сумме входных сигналов прибавляют константу. Она называется **смещением** (bias). Благодаря ей, результат функции активации смещается в область положительных или отрицательных значений. Это решает некоторые проблемы при обучении нейронных сетей.

Обозначим смещение буквой b. Тогда функция активации перцептрона выглядит так:
{height: "10%"}
![](images/ArtificialIntelligence/perceptron-activation-function.png)

Здесь f(x) означает результат функции активации. Функция равна 1, если взвешенная сумма входных сигналов плюс смещение больше нуля. В противном случае, она равна 0. Функция активации определяет величину выходного сигнала перцептрона.

Функция активации перцептрона, как и бинарного порогового нейрона, является ступенчатой. Её график демонстрирует иллюстрация 2-2. Единственное отличие этого графика от иллюстрации 2-1 — это смещение перехода функции от 0 к 1 в начало оси X.

{caption: "Иллюстрация 2-2. Ступенчатая функция активации перцептрона", height: "30%"}
![Ступенчатая функция активации перцептрона](images/ArtificialIntelligence/perceptron-step-function-graph.png)

Функция активации перцептрона f(x) отображается на оси Y, а взвешенная сумма входных сигналов — на оси X. Пока эта сумма меньше 0, перцептрон находится в невозбуждённом состоянии. Когда сумма превышает 0, перцептрон возбуждается. Его выходной сигнал становится равен единице.

Сравним перцептрон с бинарным пороговым нейроном. Это поможет нам понять их особенности. Ключевые различия между моделями следующие:

1. Бинарный пороговый нейрон получает на вход сигналы, которые представляются двоичными числами (0 или 1). Входные сигналы перцептрона представляются вещественными числами.

2. В отличие от бинарного порогового нейрона, каждый входной сигнал перцептрона имеет вес.

3. Функция активации бинарного порогового нейрона рассчитывает сумму входных сигналов. Функция активации перцептрона рассчитывает взвешенную сумму входных сигналов.

4. Бинарный пороговый нейрон не предусматривает алгоритма обучения. В отличие от него перцептрон может обучаться. Этот процесс заключается в автоматическом подборе значений весов для каждого входного сигнала. Алгоритм обучения перцептрона основан на теории Дональда Хебба.

5. Бинарный пороговый нейрон был только теоретической моделью. Он не решал какую-то практическую задачу. Перцептрон разрабатывался как инструмент для распознавания изображений.

I> [**Распознавание образов**](https://en.wikipedia.org/wiki/Pattern_recognition) (pattern recognition) в общем смысле — это задача обнаружения шаблонов и закономерностей во входных данных. Если говорить об обработке изображений, то распознавание образов означает обнаружение определённых объектов (например, лиц людей). Такая частная задача называется **распознавание изображений** (image recognition).

Теперь рассмотрим модель [однослойной нейронной сети под названием перцептрон](https://en.wikipedia.org/wiki/Feedforward_neural_network#Single-layer_perceptron). Впоследствии класс подобных моделей стал называться [**нейронные сети с прямой связью**](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью) (feedforward neural network или FNN).

Фрэнк Розенблатт разработал модель нейрона для изучения процессов восприятия в биологических системах. Чтобы проверить её достоверность на практике, учёный обратился к задаче распознавания образов. Для её решения отдельному нейрону не хватало вычислительных возможностей. Поэтому Фрэнк Розенблатт объединил несколько перцептронов в нейронную сеть. Это увеличило вычислительную мощность модели.

В 1957 году Фрэнк Розенблатт смоделировал работу нейронной сети в виде программы для универсального компьютера IBM 704. Годом позже учёный сконструировал первый [**нейрокомпьютер**](https://ru.wikipedia.org/wiki/Нейрокомпьютер) под названием [Mark I Perceptron](https://ru.wikipedia.org/wiki/Марк-1). 

Mark I представлял собой однослойную нейронную сеть. Она работала по тому же принципу, что и отдельный перцептрон. Компьютер состоял только из аналоговых компонентов. Входное изображение поступало на матрицу из фотодетекторов размером 20x20. Сигналы с неё передавались на электромеханические устройства, которые моделировали отдельные нейроны. Чтобы регулировать веса входных сигналов, применялись потенциометры. В процессе обучения их настройки менялись автоматически с помощью электромоторов.

Mark I должен был распознавать все буквы английского алфавита. Но финальная версия компьютера научилась распознавать только некоторые буквы.

Работа с аналоговым компьютером была очень трудоёмкой. Его компоненты были ненадёжны и часто выходили из строя. Чтобы поддерживать Mark I в рабочем состоянии, нужен был специалист оператор. Он следил за компьютером и заменял отказавшие компоненты.

Иллюстрация 2-3 демонстрирует архитектуру однослойной нейронной сети под названием перцептрон.

{caption: "Иллюстрация 2-3. Архитектура нейронной сети под названием перцептрон", height: "30%"}
![Архитектура нейронной сети перцептрон](images/ArtificialIntelligence/perceptron.png)

Сеть состоит из элементов трёх типов:

1. S-элементы (сенсорные)
2. A-элементы (ассоциативные)
3. R-элементы (реагирующие)

Несмотря на три слоя элементов, перцептрон на иллюстрации 2-3 называется однослойным. Причина в том, что у него только один скрытый слой A-элементов. **Скрытым** называется слой, не содержащий входных и выходных нейронов сети.

Проведём аналогию между работой нейронной сети и мозгом. Пример обработки сигнала мозгом — реакция человека на зрительную информацию. Если человек видит опасность, физиологическим ответом на неё будет активация [двигательных нейронов](https://ru.wikipedia.org/wiki/Мотонейрон). Эти нейроны отвечают за мышечную активность. Похожим образом перцептрон обрабатывает входные сигналы. Реагирующие нейроны R возбуждаются в ответ на импульсы сенсорных нейронов S, согласно ассоциациям A.

Кратко работу перцептрона можно описать так:

> Перцептрон создаёт набор ассоциаций (A-элементы) между входными сигналами (S-элементы) и реакцией на них (R-элементы).

Первая версия нейронной сети имела только один R-элемент. Из-за этого она могла различать только два класса объектов. Отсюда происходит название модели: двоичный классификатор. В более поздних моделях Фрэнк Розенблатт экспериментировал с несколькими R-элементами. Так ему удалось добиться распознавания нескольких классов. Каждый класс соответствовал одной из букв английского алфавита.

В конце 1950-х годов ещё не существовало общепринятой терминологии для нейронных сетей. Фрэнк Розенблатт вводил новые понятия, которые позднее вышли из употребления. Это часто приводит к ошибкам при обсуждении идей учёного.

В 1962 году Фрэнк Розенблатт опубликовал книгу "Принципы нейродинамики" (Principles of Neurodynamics). В ней учёный описал различные архитектуры перцептронов, в том числе и многослойные. Также в книге доказана [теорема сходимости перцептрона](https://ru.wikipedia.org/wiki/Теорема_сходимости_перцептрона). Согласно ей, перцептрон можно обучить за конечное число шагов. После такого обучения он сможет решить поставленную задачу.

Книга "Принципы нейродинамики" оказала большое влияние на развитие коннекционизма. Последователи этого направления использовали теорему сходимости перцептрона в своих исследованиях. С помощью теоремы сходимости и её выводов, они сформулировали общие требования к архитектурам нейронных сетей и методам их обучения.

#### 2.1.5.4 Сеть Хопфилда

В 1972 году японский математик Шуничи Амари работал с [**моделью Изинга**](https://ru.wikipedia.org/wiki/Модель_Изинга). Эта модель статистической физики описывает процесс намагничивания материала. Её разработали для изучения спиновых стёкол. **Спиновые стёкла** — это сплавы немагнитных материалов с магнитными примесями. Их поведение намного сложнее чем у обычных магнитов. Шуничи Амари первым применил модель Изинга для обучения нейронных сетей.

Идеи Шуничи Амари продолжил развивать Уильям Литтл из Стэнфордского университета. В своей статье 1974 года ["Существование устойчивых состояний в мозгу"](https://www.sciencedirect.com/science/article/abs/pii/0025556474900315?via%3Dihub) (The existence of persistent states in the brain) он рассматривает возможность математического моделирования деятельности мозга. В следующей статье 1980 года ["Модель Изинга для нейронных сетей"](https://link.springer.com/chapter/10.1007/978-3-642-61850-5_18) (An Ising Model of a Neural Network) Уильям Литтл подробно разбирает, как применить модель Изинга для нейронных сетей.

Следующий шаг сделал американский физик [Джон Хопфилд](https://ru.wikipedia.org/wiki/Хопфилд,_Джон). Он изучал способы хранения данных в нейронной сети. Учёный применил модель Изинга и наработки Уильяма Литтла. В результате Джон Хопфилд разработал новую архитектуру нейронной сети, которая была названа в его честь.

[**Сеть Хопфилда**](https://ru.wikipedia.org/wiki/Нейронная_сеть_Хопфилда) стала моделью для изучения человеческой памяти. На вход она получает новый образец данных. Затем сеть ищет похожий образец из уже известных. Таким образом модель выполняет функцию ассоциативной памяти. 

Сеть Хопфилда решает следующие задачи:

 1. Распознавание образов.

 2. Восстановление повреждённых изображений.
 
 3. [Комбинаторные задачи оптимизации](https://ru.wikipedia.org/wiki/Комбинаторная_оптимизация).

Джон Хопфилд подробно описал свои идеи в статье 1982 года под названием ["Нейронные сети и физические системы с возникающими коллективными вычислительными способностями"](https://www.pnas.org/doi/10.1073/pnas.79.8.2554) (Neural networks and physical systems with emergent collective computational abilities).

Сеть Хопфилда была полезна как новая модель с перспективными возможностями. Но намного важнее оказалась стоящая за ней идея: применить хорошо проработанный математический аппарат модели Изинга к нейронным сетям. Именно эта идея подтолкнула дальнейшие исследования в рамках коннекционизма.

#### 2.1.5.5 Машина Больцмана

Примеру Джона Хопфилда последовали другие учёные. Они искали альтернативные математические модели для новых архитектур нейронных сетей. Одной из таких моделей стала [**машина Больцмана**](https://ru.wikipedia.org/wiki/Машина_Больцмана). Её разработала группа учёных: психолог [Джеффри Хинтон](https://ru.wikipedia.org/wiki/Хинтон,_Джеффри), математик Дэвид Окли и биолог Терри Сейновски. В 1985 году они описали устройство новой модели в статье "Обучающий алгоритм для машины Больцмана" (A Learning Algorithm for Boltzmann Machines).

Учёные представили машину Больцмана как модель нейронного компьютера, выполняющего параллельные вычисления. Такой компьютер состоит из соединённых в сеть процессоров. На эту идею учёных подтолкнуло развитие технологии транзисторов и сверхбольших интегральных схем (СБИС) в начале 1980-х.

Машина Больцмана строится на одном из вариантов модели Изинга, который известен как стохастический. Применительно к нейронным сетям, стохастический означает, что функция активации нейронов недетерминирована. Нейроны такой сети находятся в состоянии "включено" или "выключено" с некоторой вероятностью. Это одно из основных отличий машины Больцмана от детерминированной сети Хопфилда.

Создатели машины Больцмана предложили применять её для следующих задач:

1. Генерация данных (в том числе изображений). Машина способна производить данные похожие на те, что применялись в процессе обучения.

2. Дополнение неполных входных данных по обучающим примерам.

3. Обнаружение во входных данных общих признаков и шаблонов.

Над созданием надёжного нейрокомпьютера на основе СБИС продолжили работать Карвер Мид и Мохаммед Исмаил. В 1989 году они опубликовали книгу "Аналоговая реализация нейронных сетей на сверхбольших интегральных схемах" (Analog VLSI Implementation of Neural Systems). В ней они предложили возможную архитектуру нейрокомпьютера.

#### 2.1.5.6 Метод обратного распространения ошибки

В 1962 году Фрэнк Розенблатт впервые ввёл термин **исправление ошибки обратным распространением** (back-propagating error correction). Так он назвал способ обучения сети перцептрон, при котором корректируются веса соединений нейронов. В начале 1960-х годов этот способ оставался только теоретической идеей. Фрэнк Розенблатт не смог реализовать его на практике.

В 1970 году финский математик Сеппо Линнайнмаа защитил магистерскую диссертацию. В ней он описал, как эффективно применить [**метод обратного распространения ошибки**](https://en.wikipedia.org/wiki/Backpropagation) (backpropagation) к сетям произвольной архитектуры, которые похожи на нейронные. В диссертации нейронные сети не упоминаются явно. Но разработанный Сеппо Линнайнмаа математический аппарат применяется в современных алгоритмах обучения практически без изменений.

Американский учёный Пол Вербос был первым, кто подробно описал обучение именно нейронной сети методом обратного распространения ошибки. Это стало темой его диссертации в 1974 году. К сожалению, сообщество исследователей ИИ не обратило внимание на работу молодого учёного.

В 1982 году Пол Вербос опубликовал статью "Применение достижений в нелинейном анализе чувствительности" (Applications of advances in nonlinear sensitivity analysis). В ней он применил метод обратного распространения ошибки к многослойным сетям с прямой связью.

Спустя четыре года эту же тему подняли Джеффри Хинтон и психолог [Дэвид Румельхарт](https://ru.wikipedia.org/wiki/Румельхарт,_Дэвид). В 1986 году они опубликовали статью "Изучение представлений путем обратного распространения ошибок" (Learning representations by back-propagating errors). Статья описывает обучение [**многослойного перцептрона Румельхарта**](https://ru.wikipedia.org/wiki/Многослойный_перцептрон_Румельхарта) методом обратного распространения ошибки. Эта нейронная сеть является частным случаем перцептрона Розенблатта.

Алгоритм обратного распространения ошибки выглядит так:

1. **Инициализация**. Весам всех соединений нейронной сети присваиваются случайные числа.

2. **Прямой проход**. Нейронная сеть получает на вход обучающий пример. Сигналы распространяются по сети от входных нейронов к выходам. Каждый нейрон вычисляет взвешенную сумму своих входов и с помощью функции активации рассчитывает выходной сигнал.

3. **Ошибка вычисления**. После прямого прохода выход сети сравнивается с желаемым результатом. Разница между реальным выходом и ожидаемым — это ошибка вычисления.

4. **Обратный проход**. При обратном проходе ошибка распространяется по сети в направлении от выходов к входам. Начиная с выходного слоя, алгоритм вычисляет вклад каждого веса в общую ошибку вычисления.

5. **Обновление веса**. Учитывая вклад каждого веса в общую ошибку вычисления, алгоритм обучения обновляет веса сети. Они корректируются в направлении, которое минимизирует ошибку вычисления. Для этого применяется алгоритм оптимизации, например **градиентный спуск**.

6. **Повторение процесса**. Шаги со второго по пятый повторяются для каждого обучающего примера. Алгоритм продолжает корректировать веса сети итеративно. Тем самым он постепенно уменьшает ошибку вычисления.

7. **Критерий остановки**. Процесс обучения продолжает до тех пор, пока не выполнен критерий остановки. Обычно критерий — это заданное значение, ниже которого должна упасть ошибка вычисления. Другой вариант — максимально допустимое число итераций алгоритма обучения.

В 1986 году Дэвид Румельхарт и [Джеймс Макклелланд](https://ru.wikipedia.org/wiki/Макклелланд,_Джеймс) опубликовали цикл статей под названием "Параллельная распределенная обработка" (Parallel Distributed Processing). В нём авторы продемонстрировали области применения метода обратного распространения ошибки в компьютерных науках и психологии.

#### 2.1.5.7 Байесовская сеть

В начале 1990-х годов в исследованиях ИИ начал доминировать подход теоретиков (neat). Этому способствовали достижения коннекционизма в 1980-е годы. Учёные убедились в важности хорошо проработанных математических моделей. Они неоднократно становились отправной точкой при разработке новых архитектур нейронных сетей.

Учёный в области информатики Джудиа Перл занимался поиском и разработкой перспективных математических моделей. В 1988 году он опубликовал книгу "Вероятностное рассуждение в интеллектуальных системах" (Probabilistic Reasoning in Intelligent Systems). В ней автор предложил теоретические основы и вычислительные методы для создания интеллектуальных систем, которые принимают решения в условиях неопределённости. Книга получила признание среди специалистов. Она убедила многих учёных в том, что теория вероятности и теория принятия решений применимы в области ИИ.

Используя математический аппарат теории вероятностей, Джудиа Перл разработал модель [**байесовской сети**](https://ru.wikipedia.org/wiki/Байесовская_сеть). Эта модель отражает связи между множеством переменных и их вероятностными зависимостями по теореме Байеса. Эта теорема определяет вероятность события при условии, что произошло другое статистически взаимозависимое с ним событие.

Байесовская сеть представляет собой ориентированный ациклический граф. Его узлы — это некоторые переменные. Ребра графа соответствуют вероятностным взаимосвязям между узлами. Для примера допустим, что система медицинской диагностики построена на Байесовской сети. Тогда узлы графа — это симптомы и вызвавшие их заболевания. Ребра графа показывают причинно-следственную связь между ними.

Для каждого ребра определяется условная вероятность. Она отражает вероятность переменной в данном узле с учётом его родителей. Родитель — это узел из которого выходит ребро, входящее в данный узел. В медицинской системе диагностики условная вероятность определяется экспертами, клиническими испытаниями и статистическими данными.

Готовая байесовская сеть получает на вход данные. Для системы диагностики данные — это симптомы пациента. По ним сеть выдаёт наиболее вероятный диагноз.

Мы рассмотрели **причинно-следственную байесовскую сеть** (causal bayesian network). Кроме неё есть и другие виды байесовских сетей:

1. **Статическая** (Static Bayesian Network) — в ней отношения между переменными фиксированы и не меняются.

2. **Динамическая** (Dynamic Bayesian Network) — может моделировать временные зависимости и изменения во времени. Используется, когда моделируемая система подвержена динамическим процессам.

3. **Гибридная** (Hybrid Bayesian Network) — объединяет разные типы переменных: дискретные и непрерывные. Используется, когда переменные имеют разные типы данных.

4. **Временные** (Temporal Bayesian Network) — обобщённая версия динамической сети. Может обрабатывать данные временных рядов. [**Временной ряд**](https://ru.wikipedia.org/wiki/Временной_ряд) — это замеры каких-либо параметров в разные моменты времени.

5. **Скрытая марковская модель** (Hidden Markov Model или HMM) — особый вид динамической сети, который используют для моделирования последовательностей наблюдаемых событий со скрытыми состояниями. HMM решает задачи распознавания речи, обработки естественного языка и последовательного анализа данных.

6. **Диаграмма влияния** (Influence Diagram) — представляют собой единую графическую модель, которая включает неопределённость и данные для принятия решений. Используются в задачах анализа решений и оптимизации.

7. **Полидеревья и цепные графы** (Polytrees and Chain Graphs). Байесовская сеть представляет собой направленный ациклический граф. Полидеревья и цепные графы ослабляют это ограничение. Полидеревья допускают не более одного цикла. Цепные графы могут содержать как ориентированные, так и неориентированные ребра.

Алгоритмы машинного обучения применимы ко всем видам байесовских сетей. Структура и параметры этих сетей зависят от конкретной задачи. Их выбирают исходя из обучающих данных.

### 2.1.6 Интеллектуальные агенты

В 1995 году Стюарт Рассел и Питер Норвиг опубликовали книгу "Искусственный интеллект: современный подход". В ней авторы предложили концепцию интеллектуального агента. Она заимствована из экономики и теории принятия решений. В этих науках есть понятие рационального агента. **Интеллектуальный агент** — это тот же рациональный агент только в контексте ИИ. В экономике рациональный агент стремится максимизировать свою прибыль. Точно так же интеллектуальный агент пытается максимизировать свою эффективность при решении поставленной задачи.

Большинство исследователей согласилось с концепцией интеллектуального агента. Она разрешила несколько философских проблем в области ИИ. Первой проблемой были разногласия учёных о том, что именно считать интеллектом. Тест Тьюринга подразумевает сравнение с человеческим интеллектом. Понятие рационального агента устранило это сравнение. Любое поведение агента считается интеллектуальным, если оно приводит к эффективному достижению цели.

I> **Тест Тьюринга** — эксперимент, в котором человек и машина обмениваются с судьёй текстовыми сообщениями. Все три участника эксперимента находятся в разных комнатах и не видят друг друга. В результате переписки судья должен определить, кто из собеседников является машиной.

Вторая философская проблема заключалась в вопросе: может ли машина обладать сознанием и настоящим пониманием? Учёные давали разные ответы на этот вопрос. В зависимости от своей точки зрения, они выбирали соответствующее направление исследований. Для интеллектуального агента сознание и понимание оказались совершенно не важны. Новая концепция ставит на первое место эффективность решения. Метод поиска решения может быть любым.

Теперь исследователи могли сконцентрироваться на решении конкретных практических задач. Им больше не надо было защищать свои методы с философской точки зрения. Достаточно было математически доказать их эффективность.

Концепция интеллектуального агента помогла исследователям не только с философской точки зрения, но и на практике. Она дала надёжный способ сравнивать системы, основанные на разных подходах. Принцип их работы отошёл на второй план. Теперь главным показателем стала **функция полезности** (value function). Если агент лучше максимизирует эту функцию, он эффективнее справляется с поставленной задачей. Благодаря новому методу оценки, учёные стали быстрее достигать результатов на практике.

Раньше каждый исследователь работал в рамках только одного подхода (например, коннекционизма). Когда приоритетом стала измеряемая эффективность, учёные начали совмещать разные подходы в одной системе. В некоторых случаях такие эксперименты приводили к положительным результатам.

Формальные методы оценки дали исследователям ИИ средство для обмена идеями с другими научными направлениями. Математическая оптимизация, теория вероятностей и теория принятия решений внесли свой вклад в развитие ИИ. Использование общего математического аппарата усилило связь ИИ со смежными науками.

### 2.1.7 Современные направления ИИ

С середины 2010-х годов вокруг исследований в области ИИ начался очередной ажиотаж. Журналисты назвали этот период "Возрождением ИИ" (AI Renaissance).

Новый бум ИИ стал следствием быстрого прогресса и повышенным вниманием СМИ. Прогресс стал возможным благодаря удачному стечению ряда событий:

1. Американский учёный [Эндрю Ын](https://ru.wikipedia.org/wiki/Ын,_Эндрю) предложил использовать [графические процессоры](https://ru.wikipedia.org/wiki/Графический_процессор) (GPU) для моделирования нейронных сетей. Это позволило эффективно обучать более крупные и сложные модели, чем раньше.

2. Повсеместное распространение цифровых данных в различных форматах (изображения, текст, видео, показания датчиков). Это стало источником огромного объёма исходных данных для обучения моделей.

3. Исследователи ИИ разработали эффективные алгоритмы глубокого обучения (deep learning) для нейронных сетей. Их применение на практике увеличило производительность моделей в задачах распознавания образов и обработки естественного языка.

4. Доступность [фреймворков](https://ru.wikipedia.org/wiki/Фреймворк) (программных платформ) и библиотек для работы с нейронными сетями. Например, [TensorFlow](https://ru.wikipedia.org/wiki/TensorFlow) от Google и [PyTorch](https://ru.wikipedia.org/wiki/PyTorch) от Facebook. Эти инструменты стали распространяться с открытым исходным кодом. Так разработчики, исследователи и просто энтузиасты получили возможность экспериментировать и внедрять модели ИИ в свои приложения.

5. Корпорации Amazon, Microsoft и Google предоставили сервис облачных платформ. Через него организации и частные лица получили доступ к мощным вычислительным ресурсам. Это позволило всем желающим экспериментировать с ИИ без значительных инвестиций в специальное оборудование.

6. Правительства и инвесторы снова поверили в потенциал ИИ. Они начали вкладывать значительные средства в исследования.

Эти события привели к крупным успехам интеллектуальных систем в областях распознавания образов и обработки естественного языка. Эти достижения вдохновили учёных на дальнейшие исследования.

Рассмотрим предпосылки периода возрождения ИИ.

#### 2.1.7.1 Платформа для моделирования нейронных сетей

В конце 1990-х и начале 2000-х годов нейронные сети и машинное обучение были малопопулярными направлениями. Над ними продолжали работать несколько групп учёных. Их немногочисленные публикации читали только коллеги, работавшие в той же области.

В те годы проблема подходящей аппаратной платформы для моделирования нейронных сетей по-прежнему оставалась нерешенной. Это сильно тормозило их исследование и применение на практике. В начале 2000-х годов обучаемые модели стали очень сложными. Работа с ними на обычных компьютерах требовала слишком много времени.

Эндрю Ын вел курс "Machine Learning" в Стэнфордском университете в 2011 году. На одной из лекций он рассказал о преимуществах использования графических процессоров для обучения нейронных сетей. Видео этих лекции стало доступно через интернет. Так идея Эндрю Ына стала широко известна. Примерно в это же время группы исследователей и компании производители оборудования уже экспериментировали с GPU и машинным обучением.

В 2007 году компания Nvidia выпустила платформу [CUDA](https://ru.wikipedia.org/wiki/CUDA) (Compute Unified Device Architecture). Она позволяла разработчикам программ переносить часть своих вычислений с процессора (CPU) на GPU. Изначально Nvidia рассматривала свой продукт, как средство ускорения работы обычных пользовательских приложений.

Основное преимущество GPU перед CPU заключается в параллельной обработке больших блоков данных. Современный графический процессор имеет от нескольких сотен до нескольких тысяч ядер. Каждое из них работает независимо. Поэтому GPU отлично справляется с параллельными вычислениями. Они встречаются в алгоритмах шифрования и сортировки, программах моделирования физики и научных вычислениях. Моделирование нейронных сетей — это тоже обработка больших блоков данных, которую можно распараллелить.

Благодаря работе Эндрю Ына и других исследователей, CUDA и GPU от Nvidia стали основной программно-аппаратной платформой для работы с нейронными сетями.

#### 2.1.7.2 Особенности deep learning

Термин deep learning появился в конце 1980-х годов. Его употребляли только специалисты машинного обучения. Широкую известность он получил в 2000-х годах. [**Deep learning**](https://ru.wikipedia.org/wiki/Глубокое_обучение) дословного переводится как "глубокое обучение". Это собирательное название для семейства методов машинного обучения, которые работают с нейронными сетями. Главное отличие этих методов — высокая сложность обучаемых моделей. Они работают с нейронными сетями, имеющими несколько скрытых слоёв и сотни параметров.

Для методов, которые не относятся к deep learning, появился новый термин **shallow learning** (поверхностное обучение). Это собирательное название для относительно простых алгоритмов обучения нейронных сетей с одним скрытым слоем. Примеры shallow learning алгоритмов: метод опорных векторов, дерево решений, линейная регрессия и т.д.

Вот ключевые различия deep learning и shallow learning:

1. Высокая сложность обучаемой модели в deep learning.

2. [**Конструирование признаков**](https://habr.com/ru/companies/ruvds/articles/680498/) (feature engineering) в deep learning — это извлечение важных для модели признаков (входных параметров) из исходных данных.

* Deep learning модели автоматически извлекают признаки из исходных данных. Это происходит благодаря способности сети распознавать сложные закономерности.

* Для shallow learning моделей необходимо ручное конструирование признаков. Из всего множества признаков, встречающихся в исходных данных, разработчик должен определить самые важные для решаемой задачи. Затем отобранные признаки надо преобразовать в удобный для выбранной модели формат. Конечный результат алгоритма обучения зависит от качества конструирования признаков.

3. [**Обучение представлению**](https://analyticsindiamag.com/a-comprehensive-guide-to-representation-learning-for-beginners/) (representation learning) — это способность модели интерпретировать исходные данные.

* Deep learning модель эффективно представляет исходные данные в виде иерархии абстракций. Таким образом она учитывает сложные закономерности в данных. Каждый слой или набор слоев нейронной сети распознаёт отдельный уровень абстракций. Вот пример уровней абстракций на изображении в порядке возрастания сложности: отдельные линии, геометрические фигуры (треугольник, квадрат и т.д.), объекты (дом, автомобиль и т.д.).

* Shallow learning модель не способна самостоятельно строить сложные иерархии абстракций. Она полностью полагается на ручное конструирование признаков и заложенные в них простые абстракции.

4. Требования к исходным данным.

* Deep learning: для качественного обучения сложных моделей нужны исходные данные большого объёма.

* Shallow learning: для обучения моделей достаточно небольших наборов исходных данных. Качество обучения зависит от качества конструирования признаков.

5. Требования к вычислительным ресурсам.

* Обучение deep learning моделей требует значительных вычислительных ресурсов и специализированного оборудования (например, GPU). Даже используя большие вычислительные мощности, алгоритм обучения может выполниться несколько дней или недель.

* Shallow learning модели можно обучать на стандартных процессорах. Работа алгоритмов обучения, как правило, не занимает много времени.

6. Интерпретируемость результатов модели

* Deep learning модели из-за своей сложности работают по принципу "чёрного ящика". Разработчикам очень сложно понять, почему модель приходит к тому или иному выводу.

* Shallow learning модели проще анализировать. Разработчики обычно знают, как именно модель принимает решения.

#### 2.1.7.3 История deep learning

История deep learning началась в 1960-е годы. Фрэнк Розенблатт был первым, кто исследовал многослойные нейронные сети. Его работа ограничивалась только теоретическими выводами. Для моделирования многослойной сети нужно высокопроизводительное оборудование. Поэтому до 1980-х годов не было технических возможностей для такого моделирования.

В 1979 году японский учёный [Кунихико Фукусима](https://en.wikipedia.org/wiki/Kunihiko_Fukushima) разработал новую архитектуру нейронной сети [**неокогнитрон**](https://en.wikipedia.org/wiki/Neocognitron). Её прообразом стала модель, которую предложили нейрофизиологи Дэвид Хьюбел и Торстен Визель в 1959 году. Эта модель описывает устройство зрительной коры мозга человека, в которой два типа клеток (простая и сложная) расположены каскадно. Кунихико Фукусима спроектировал неокогнитрон для распознавания рукописных японских иероглифов.

Неокогнитрон стал прототипом новой архитектуры, получившей название [**свёрточная нейронная сеть**](https://ru.wikipedia.org/wiki/Свёрточная_нейронная_сеть) (convolutional neural network или CNN). Она является подвидом сети с прямой связью (FNN) и оптимизирована для обработки изображений.

В 1989 году французский учёный [Ян Лекун](https://ru.wikipedia.org/wiki/Лекун,_Ян) решал задачу распознания рукописных почтовых индексов на конвертах. Он применил метод backpropagation для свёрточной нейронной сети (CNN). После трёх дней обучения сеть смогла распознавать индексы. Свои результаты учёный описал в статье "Применение обратного распространение ошибки к распознаванию рукописного почтового индекса" (Backpropagation Applied to Handwritten Zip Code Recognition). В 1998 году на основе этого решения Ян Лекун разработал сеть LeNet-5. Она распознавала любые рукописные цифры. Несколько банков использовали её для автоматической обработки чеков.

В 1980-х годах исследователи начали экспериментировать со сложными моделями нейронных сетей. Попытки обучить их методом обратного распространения ошибки привели к проблеме исчезающего градиента.

I> В машинном обучении **градиентом** (gradient) называется скорость изменения функции по отношению к её входным параметрам. Градиент даёт информацию о том, как небольшие изменения входных параметров влияют на результат функции.

[**Проблема исчезающего градиента**](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) (vanishing gradient problem) связана с процессом присвоения кредитов в ходе обучения модели. **Присвоение кредитов** (credit assignment) означает расчёт вклада отдельных нейронов и их соединений в конечный результат работы сети.

В многослойных сетях активация отдельного нейрона имеет долгосрочное влияние на конечный результат. Другими словами, эффект активации нейрона может распространяться через несколько слоев сети, прежде чем внести свой вклад. Во время обучения информация в модели распространяется в обратном направлении через множество слоёв. Это может привести к тому, что градиенты становятся чрезвычайно малыми (исчезающий градиент), либо чрезвычайно большими (**взрывающийся градиент**). В результате обучение идёт медленно или оказывается неэффективным.

Первую попытку решить проблему исчезающего градиента предпринял [Юрген Шмидхубер](https://ru.wikipedia.org/wiki/Шмидхубер,_Юрген) в 1992 году. Он предложил обучать каждый слой нейронной сети отдельно. Затем обученную иерархию слоёв надо свернуть в единую нейронную сеть. Так получалась законченная модель.

Работа с отдельными слоями решала не только проблему исчезающего градиента, но и недостаток вычислительной мощности. Обучение сложной модели целиком требовало слишком много времени в 1990-е годы. Этот процесс проходил быстрее при разделении его на отдельные шаги: обучение только одного слоя за раз.

Юрген Шмидхубер работал с рекуррентными нейронными сетями. К ним относятся и модель Изинга, и сеть Хопфилда. В чём их особенность? Информационный поток в нейронных сетях с прямой связью (FNN) однонаправленный. Это означает, что информация распространяется только в одном направлении — вперёд: от входных узлов через скрытые узлы к выходным узлам без циклов и петель. [**Рекуррентные нейронные сети**](https://ru.wikipedia.org/wiki/Рекуррентная_нейронная_сеть) (recurrent neural network или RNN) в отличие от FNN имеют замыкающиеся связи. Такие связи позволяют двунаправленный поток информации: вперёд от входных узлов через скрытые узлы к выходным узлам и в обратном направлении.

Благодаря двунаправленному потоку информации, RNN используют результаты предыдущего временного шага в качестве входных данных для текущего временного шага. Таким образом сеть эффективно изучает и фиксирует закономерности в последовательностях. Поэтому архитектура RNN хорошо подходит для обработки естественного языка, распознавания речи, анализа временных рядов и подобных задач.

В 1991 году Зепп Хохрайтер посвятил свою дипломную работу проблеме исчезающего градиента при обучении рекуррентных нейронных сетей. Он предложил добавить так называемые **остаточные соединения** (residual connections) в архитектуру сети. Эти соединения работают как короткий путь между не соседними, удалёнными друг от друга слоями. Таким образом поток информации проходит мимо одного или нескольких слоёв. Благодаря остаточным соединениям, алгоритм обучения лучше оценивает разницу между входом и желаемым выходом модели.

В 1997 году Зепп Хохрайтер и Юрген Шмидхубер развили идею остаточных соединений. Они разработали архитектуру нейронной сети, названную [**длинная цепь элементов краткосрочной памяти**](https://habr.com/ru/companies/wunderfund/articles/331310/) (long short-term memory или LSTM). Это особая разновидность рекуррентных сетей, которая может обучаться долговременным зависимостям. Тем самым в ней решается проблема исчезающего градиента.

LSTM использует специальную структуру ячеек, вентилей и модулей памяти. **Ячейки** (cell) — это элементарные строительные блоки LSTM сети. Они содержат в себе вентили и модули памяти. Механизм **вентилей** (gate) управляет потоком информации и памятью внутри сети. Благодаря ему, LSTM способна собирать и сохранять информацию в течении нескольких временных шагов.

В 2006 году Джеффри Хинтон, [Руслан Салахутдинов](https://ru.wikipedia.org/wiki/Салахутдинов,_Руслан_(учёный)), Саймон Осиндеро и [Йи Вай Тех](https://en.wikipedia.org/wiki/Yee_Whye_Teh) опубликовали несколько статей. Учёные повторили подход Юргена Шмидхубера с обучением каждого слоя отдельно. Отличие нового исследования было в том, что команда Джеффри Хинтона работала не с RNN, а с сетями с прямой связью (FNN). Теперь исследователи могли эффективно обучать модели любого типа (RNN и FNN) на обычных компьютерах за приемлемое время.

Исследователи нейронных сетей были вынуждены обучать свои модели послойно до 2010-х годов. В 2011 году значительно выросла производительность GPU. Благодаря идеям Эндрю Ына и усилиям Nvidia, CUDA стала надёжной платформой для разработки алгоритмов обучения нейронных сетей. Теперь сложные модели можно было обучать целиком, а не послойно. Это упростило и ускорило эксперименты с нейронными сетями. При этом проблема исчезающего градиента решалась специальными архитектурами сетей, например LSTM.

В 2009 году Фей-Фей Ли из Принстонского университета представила свой проект [**ImageNet**](https://ru.wikipedia.org/wiki/ImageNet) на конференции, посвященной компьютерному зрению. Проект заключался в подготовке огромной базы изображений. Для каждого изображения вручную составлялась аннотация с перечислением попавших на него объектов и их координат. Чтобы подготовить аннотацию изображений, Фей-Фей Ли воспользовалась краудсорсинговой платформой Amazon Mechanical Turk.

Начиная с 2010 года Фей-Фей Ли запустила проект ILSVRC (ImageNet Large Scale Visual Recognition Challenge). Это открытое соревнование между исследовательскими группами. В ходе соревнования обученные модели распознают и классифицирую объекты на изображениях из базы ImageNet.

Ежегодное соревнование ILSVRC привлекло внимание специалистов и СМИ со всего мира. Это событие стало престижным, благодаря известности его участников. База ImageNet свободно доступна через интернет. Любой желающий может её скачать и начать экспериментировать с моделями. Это привело к быстрому прогрессу в задаче распознавания образов.

В 2011 году пятёрка лучших моделей распознавала образы с 25% ошибок. В 2012 году глубокая свёрточная сеть AlexNet достигла результата в 16% ошибок. Эту сеть разработали Джеффри Хинтон, [Алексей Крижевский](https://en.wikipedia.org/wiki/Alex_Krizhevsky) и [Илья Суцкевер](https://ru.wikipedia.org/wiki/Суцкевер,_Илья). К 2014 году процент ошибок у лучших моделей упал до нескольких процентов. В 2015 году появились модели, превосходящие способности человека. Но эти модели могли распознавать изображения примерно из тысячи категорий. Человек же способен различать намного больше категорий изображений и лучше оценивать их контекст.

Соревнование ILSVRC было не единственным в своём роде. Также проводились и менее известные ежегодные соревнования. Например, по распознаванию рукописного китайского текста (ICDAR), выявлению раковых опухолей на медицинских изображениях (ICPR), распознаванию речи (Interspeech). Модели на глубоких свёрточных сетях доминировали во всех соревнованиях по распознаванию образов. В распознавании речи лучшие результаты показывали LSTM модели.

Успехи глубоких нейронных сетей в престижных соревнованиях сделали этот подход трендом в современных исследованиях. С 2010-х годов началась так называемая ["революция глубокого обучения"](https://en.wikipedia.org/wiki/Deep_learning#Deep_learning_revolution) в ИИ.

{pagebreak}
