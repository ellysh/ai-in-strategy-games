## История

Искусственный интеллект как направление исследований появился на стыке нескольких дисциплин. На ИИ оказали влияние идеи, достижения и методы из нескольких наук. Таблица 2-1 демонстрирует эти науки.

{caption: "Таблица 2-1. Науки, оказавшие влияние на ИИ", width: "100%"}
| Наука | Используемая в ИИ идея или метод |
| --- | --- |
| Нейрофизиология | Модель искусственного нейрона и нейронной сети |
|  | |
| Математика | Правила формальной логики и логического вывода |
|  | Статистические методы |
|  | Теория вероятностей |
|  | Теория принятия решений |
|  | |
| Информатика | Языки программирования |
|  | Теория вычислительной сложности |
|  | Высокопроизводительные компьютеры |
|  | |
| Кибернетика | Теория управления сложных систем |

Рассмотрим подробнее, как развивался ИИ и почему именно эти науки оказали на него влияние.

### Появление новой науки 1943 – 1956

#### Нейронная сеть

Первая работа в области ИИ связана с нейрофизиологией и математикой. Американские учёные [Уоррен Мак-Каллок](https://ru.wikipedia.org/wiki/Мак-Каллок,_Уоррен) и [Уолтер Питтс](https://ru.wikipedia.org/wiki/Питтс,_Уолтер) исследовали мозг человека. Используя свои знания о физиологии мозга, они разработали модель связанных между собой [**искусственных нейронов**](https://ru.wikipedia.org/wiki/Искусственный_нейрон). [Нейрон](https://ru.wikipedia.org/wiki/Нейрон) — это клетка, которая является минимальным строительным блоком [нервной системы](https://ru.wikipedia.org/wiki/Нервная_система). Нейроны соединяется друг с другом в [нервную сеть](https://ru.wikipedia.org/wiki/Нервная_сеть). По этой сети передаются электрические и химические сигналы. С помощью этих сигналов передаётся информация между узлами нервной системы.

Искусственный нейрон представляет собой упрощённую модель биологического нейрона. Эта модель имеет два состояния: возбуждённое и невозбуждённое. На вход нейрон получает сигналы от других нейронов. Он обрабатывает их с помощью [**нелинейной функции**](https://ru.wikipedia.org/wiki/Линейная_функция). Результат функции передаётся на выход нейрона, который связан со входами других нейронов.

I> График нелинейной функции не является прямой.

Соединение искусственных нейронов получило название [**нейронная сеть**](https://ru.wikipedia.org/wiki/Нейронная_сеть). Мак-Каллок и Питтс показали, что такая сеть способна выполнять числовые и логические операции. Кроме того они предположили, что сети с особенной архитектурой способны обучаться. Свои результаты учёные опубликовали в 1943 году в статье "Логическое исчисление идей, относящихся к нервной активности" (A Logical Calculus of Ideas Immanent in Nervous Activity).

Модель Мак-Каллока и Питтса была только теоретической. Свои гипотезы они подтверждали математическими выкладками. Не существовало программы или устройства, которое бы работало как нейронная сеть и подтверждало идеи учёных.

В 1949 году канадский нейропсихолог [Дональд Хебб](https://ru.wikipedia.org/wiki/Хебб,_Дональд) опубликовал книгу "Организация поведения" (Organization of Behavior). В ней учёный предложил теорию обучения нейронов человеческого мозга. Эта теория получила название [**обучение Хебба**](http://www.machinelearning.ru/wiki/index.php?title=Правило_Хэбба). Основное правило этой теории можно сформулировать в следующем виде:

*Связи нейронов, которые активируются совместно, усиливаются. Связи нейронов, которые срабатывают независимо, ослабевают*

Это **правило Хебба** стало фундаментом в теории обучения нейронных сетей. Оно применяется и сегодня.

Первая нейронная сеть была реализована в виде специального компьютера. Его сконструировали аспиранты математики [Марвином Мински](https://ru.wikipedia.org/wiki/Минский,_Марвин_Ли) и Дином Эдмондсом в 1951 году. Компьютер использовал электровакуумные лампы в качестве рабочих элементов. Он получил название [Snarc](https://en.wikipedia.org/wiki/Stochastic_neural_analog_reinforcement_calculator). Snarc моделировал сеть из 40 нейронов. Мински и Эдмондс пытались научить эту сеть проходить лабиринт. Для простоты соединения между нейронами и представляли собой этот лабиринт.

#### Статья Тьюринга

В 1950 году английский учёный [Алан Тьюринг](https://ru.wikipedia.org/wiki/Тьюринг,_Алан) опубликовал статью ["Вычислительные машины и разум"](https://ru.wikipedia.org/wiki/Вычислительные_машины_и_разум) (Computing Machinery and Intelligence). В ней Тьюринг рассуждает над вопросом о том, способны ли машины думать. Эта статья оказало влияние на исследователей в области ИИ и общественное мнение относительно возможностей ИИ. В целом статья даёт оптимистичный прогноз относительно этих возможностей.

Тьюринг начинает свою статью с определения терминов "машина" и "думать". Этим словам трудно дать однозначное определение, не вызывающее критики. Поэтому учёный предлагает заменить термин "думать" на способность машины пройти игру в имитацию. Суть игры в том, что человек и машина обмениваются с судьёй текстовыми сообщениями. Все участники игры находятся в разных комнатах и не видят друг друга. В результате судья должен определить, кто из собеседников является машиной. Если судья не может это сделать, машина выигрывает игру. Игра в имитацию получила известность как [**тест Тьюринга**](https://ru.wikipedia.org/wiki/Тест_Тьюринга).

Далее Тьюринг рассматривает объекты, которые можно отнести к категории "машина". Он предлагает ограничиться только **цифровыми компьютерами**, которые оперируют числами 0 и 1. В 1950-м году такие компьютеры уже существовали. Кроме того они стали **универсальными**. Универсальность означает, что с помощью программирования компьютер можно настроить на решение различных задач.

После определения терминов Тьюринг положительно оценивает возможность машины пройти игру в имитацию. Он предлагает модель обучающейся машины, которая была бы на это способна. Разрабатывая эту модель, Тьюринг описывает базовые принципы машинного обучения и генетических алгоритмов. Эти идеи намного опередили своё время. Намного позднее исследователи ИИ стали применять их на практике.

Многие из прогнозов Тьюринга о развитии вычислительной техники и искусственного интеллекта оказались верны.

#### Logic Theorist

В 1956 году была разработана первая система искусственного интеллекта в виде компьютерной программы. Эта система получила название [Logic Theorist](https://en.wikipedia.org/wiki/Logic_Theorist).

Logic Theorist разработали три американских учёных:

* [Герберт Саймон](https://ru.wikipedia.org/wiki/Саймон,_Герберт_Александер) был политологом. Он изучал как принимаются решения в правительственных учреждениях и компаниях. В своей работе он использовал методы теории принятия решений.

* [Аллен Ньюэлл](https://ru.wikipedia.org/wiki/Ньюэлл,_Аллен) занимался исследованиями в области логистики и [теориии организаций](https://ru.wikipedia.org/wiki/Теория_организаций). Это теория из области социологии, которая исследует взаимодействия людей в политических и коммерческих организациях.

* [Клиффорд Шоу](https://en.wikipedia.org/wiki/Cliff_Shaw) был опытным программистом из стратегического исследовательского центра [RAND](https://ru.wikipedia.org/wiki/RAND_(корпорация)).

Идею ИИ системы предложил Ньюэлл. Он предположил, что простое программируемое устройство вроде компьютера способно на сложное поведение. Чтобы доказать эту гипотезу Ньюэлл и Саймон решили разработать программу для доказательства математических теорем. Тогда к проекту присоединился Шоу, чтобы помочь с написанием этой программы.

Система Logic Theorist смогла доказать 38 теорем из книги ["Начала математики"](https://ru.wikipedia.org/wiki/Principia_Mathematica) Бертрана Рассела. Это подтвердило гипотезу Ньюэлла, что универсальный компьютер способен на "разумное" поведение.

В середине 1950-х годов считалось, что цифровые компьютеры способны оперировать только числами. Вопреки этому мнению система Logic Theorist работала с символами. Это позволило перейти от математических вычислений к логическим высказываниям. Разработчики утверждали, что создали программу, способную "мыслить в нечисловых терминах". Их подход стал доминирующим в ИИ на следующие 30 лет.

В Logic Theorist впервые были использованы следующие концепций:

* **Рассуждение как поиск**. Logic Theorist представляет доказательство гипотезы как поиск по дереву. Корень дерева соответствует начальной гипотезе. Исходящие из корня ветви — это логические операции над начальной гипотезой. Каждая ветвь приводит к определённому выводу. Один из этих выводов является целью рассуждения. Именно его и ищет система.

* [**Эвристики**]((https://ru.wikipedia.org/wiki/Эвристика)) — это дополнительные правила, которые исключают из рассмотрения некоторые ветви дерева поиска. Эвристики позволяют заранее предсказать, что какая-то ветвь не приводит к решению. Это значительно сокращает время поиска решений.

* **Обработка списков**. Чтобы написать программу Logic Theorist, был разработан специальный язык программирования [IPL](https://en.wikipedia.org/wiki/Information_Processing_Language). Для этого языка Шоу разработал специальную структур данных под названием [**связанный список**](https://ru.wikipedia.org/wiki/Связный_список). Она позволяла эффективно хранить список символов. Позднее на основе IPL и списков Джон Маккарти разработает язык Lisp. Этот язык станет доминирующим в области ИИ на два десятилетия.

Концепций, разработанные для Logic Theorist, станут ключевыми для последующих исследований в области ИИ.

#### Дартмутский семинар

В начале 1950-х годов проводились первые исследования в области ИИ. Однако, науки об ИИ не существовало до лета 1956 года. Свои исследования "думающих машин" учёные называли кибернетикой, теорией автоматов или сложной обработкой информации. Название зависело от подхода, выбранного в каждом конкретном проекте.

В 1955 году американский математик Джон Маккарти решил организовать [семинар](https://ru.wikipedia.org/wiki/Дартмутский_семинар), посвященный "думающим машинам". Маккарти хотел собрать группу исследователей в этой области, чтобы обсудить их достижения и новые подходы.

На тот момент Маккарти работал в Дартмутском колледже. Поэтому семинар получил известность как **Дартмутский семинар**.

В заявке на проведение мероприятия Маккарти написал: "исследование искусственного интеллекта". Термин "искусственный интеллект" появился здесь впервые. До этого его никто не использовал. Маккарти выбрал этот термин, чтобы предотвратить возможные споры относительно подходов. Если бы он выбрал любое из существующих названий исследований ИИ того времени, это сфокусировало бы обсуждения на конкретном подходе. Цель же семинара была в [мозговом штурме](https://ru.wikipedia.org/wiki/Метод_мозгового_штурма), т.е. в разработке совершенно новых идей.

В семинаре принимали участие ведущие учёные из следующих областей:

* Теория управления
* Теория автоматов
* Нейрофизиология
* Теорией игр
* Когнитивная психология.

В результате проведения семинара было решено создать новое научное направление под названием искусственный интеллект. Это решение оказало огромное влияние на последующие исследования. Оно позволило учёным свободно экспериментировать и искать новые подходы. Их больше не ограничивали аналоговые вычисления кибернетики и математический аппарат теории автоматов. Новая наука началась как экспериментальная дисциплина.

### Формирование основных направлений в ИИ 1956 – 1974

Дартмутский семинар дал мощный толчок для исследований в области ИИ. Некоторые из участников семинара в течении нескольких лет организовали лаборатории для изучения ИИ на базе известных учебных заведений. Эти лаборатории перечислены в таблице 2-2.

{caption: "Таблица 2-2. Лаборатории по исследованию ИИ", width: "100%"}
| Учебное заведение | Основатели лаборатории ИИ |
| --- | --- |
| [Университет Карнеги — Меллона](https://ru.wikipedia.org/wiki/Университет_Карнеги_—_Меллона) | Аллен Ньюэлл и Герберт Саймон |
|  | |
| [Стэнфордский университет](https://ru.wikipedia.org/wiki/Стэнфордский_университет) | Джон Маккарти |
|  | |
| [Массачусетский технологический институт](https://ru.wikipedia.org/wiki/Массачусетский_технологический_институт) (МТИ) | Джон Маккарти |
|  | Марвин Мински |

Каждая из лабораторий разрабатывала собственные подходы в создании интеллектуальных систем. Некоторые из этих разработок задали направления для дальнейших исследований. Таблица 2-3 демонстрирует основные подходы в ИИ.

{caption: "Таблица 2-3. Направления в ИИ", width: "100%"}
| Название | Идея | Основоположники |
| --- | --- | --- |
| [Символьный подход](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) | Задача решается через действия над понятными человеку символическими обозначениями. | Аллен Ньюэлл |
|  | | Герберт Саймон |
|  | | |
| [Логическое программирование](https://ru.wikipedia.org/wiki/Логическое_программирование) | Задача решается методами формальной логики. | Джон Маккарти |
|  | | |
| [Коннекционизм](https://ru.wikipedia.org/wiki/Коннекционизм) | Задача решается сетью из связанных между собой простых элементов (нейронной сетью). | Уоррен Мак-Каллок |
|  | | Уолтер Питтс |

Эти направления сформировались в начальный период развития новой науки об ИИ. Их популярность менялась в зависимости от успехов и неудач в исследованиях. Сегодня самым многообещающим подходом считается коннекционизм.

Рассмотрим достижения каждого из направлений в первые годы науки об ИИ.

#### Символьный подход

Система Logic Theorist произвела впечатление на участников Дартмутского семинара. Она была единственным рабочим решением на 1956 год. Остальные исследования ИИ ещё находились на этапе теоретических моделей.

Следующим проектом Ньюэлла, Саймона и Шоу стала универсальная система для решения задач. Она получила название [General Problem Solver](https://ru.wikipedia.org/wiki/Универсальный_решатель_задач) (GPS). В отличие от Logic Theorist её область применения не ограничивалась математическими задачами. Вместо этого GPS должна была моделировать процесс решения задач человеком.

Система GPS была готова в 1959 году. В своей работе она использовала особенную технику поиска под названием [**анализ средств и результатов**]((https://en.wikipedia.org/wiki/Means–ends_analysis)) (means–ends analysis или MEA). Эта техника стала развитием идеи "рассуждение как поиск", впервые реализованной в Logic Theorist.

Алгоритм техники анализ средств и результатов выглядит так:

1. Система оценивает своё текущее состояние. Если поставлена задача, необходимы действия для её решения.

2. Определяется конечная цель. Она выражается в некотором состоянии системы, которое надо достигнуть. Достижение этого состояние означает решение поставленной задачи.

3. Конечная цель делится на составные части, называемые подцелями. Если подцели остаются сложными, они так же делятся на составные части.

4. Составляется список действий, выполнение которых приведёт к конечной цели, т.е. решению задачи.

5. Каждая из подцелей связывается с соответствующим ей действием из списка.

6. Выполняются все действия из списка.

7. Сравнение полученного состояния системы с тем, которое надо достигнуть для решения поставленной задачи. Если эти состояния отличаются, алгоритм повторяется начиная со второго шага.

Система GPS доказывала теоремы евклидовой геометрии и логики предикатов. Также она решала шахматные задачи.

Основываясь на опыте разработки и применения системы GPS Ньюэлл и Саймон сформулировали [**гипотезу о физической символьной системе**](https://ru.wikipedia.org/wiki/Гипотеза_Ньюэлла_—_Саймона) в 1976 году. Эта гипотеза звучит так:

*Физическая символьная система обладает необходимыми и достаточными средствами для разумного поведения.*

Это означает, что человеческое мышление заключается в манипулировании символами. Потому что без символьной системы невозможно разумное поведение. Компьютер может манипулировать символами. Следовательно, он способен на разумное поведение.

Исследования Ньюэлла и Саймона заложили основу **символьного подхода**. Этот подход предлагает создавать системы ИИ, работа которых основана на манипулировании символами. Этим символы могут быть абстрактными, но должны быть понятны человеку.

Символьный подход оставался доминирующей парадигмой в ИИ с середины 1950-х до конца 1980-х годов.

#### Логическое программирование

Джон Маккарти был не согласен с подходом Ньюэлла и Саймона. Он утверждал, что компьютеру нет необходимости рассуждать также, как это делает человек. Вместо манипулирования абстрактными символами Маккарти предлагал создавать ИИ системы на основе правил [**формальной**](https://ru.wikipedia.org/wiki/Формальная_логика) и [**математической**](https://ru.wikipedia.org/wiki/Математическая_логика) логики.

I> Формальная логика — это наука о высказываниях, правилах их преобразований и выводе их истинности. Математическая логика — это изучение правил логики с помощью математического аппарата.

Преимущество подхода Маккарти было в использовании математического аппарата. Благодаря ему, можно было строить модели систем ИИ и формально доказывать их работоспособность.

В 1958 году Маккарти разработал модель системы под названием [Advice Taker](https://en.wikipedia.org/wiki/Advice_taker). Он описал её принципы работы в статье "Программы со здравым смыслом" (["Programs with Common Sense"](http://www-formal.stanford.edu/jmc/mcc59.pdf)).

В своей статье Маккарти рассматривает о преимуществах [**императивного**](https://ru.wikipedia.org/wiki/Императивное_программирование) и [**декларативного**](https://ru.wikipedia.org/wiki/Декларативное_программирование) программирования. Он приходит к выводу, что декларативный подход лучше для работы с накопленными ранее знаниями. Кроме того он позволяет выстраивать логические связи между высказываниями.

Согласно идее Маккарти, система Advice Taker должна использовать общие знания о мире. Благодаря им, она сможет самостоятельно делать выводы обо всём, что её сообщают и что она уже знает. В этом случае можно утверждать, что система расуждает с позиции [здравого смысла](https://ru.wikipedia.org/wiki/Здравый_смысл).

Для хранения знаний Маккарти предлагает использовать списки. Тогда логический вывод сводится к операциям над этими списками.

Чтобы реализовать Advice Taker в виде программы, Маккарти спроектировал язык программирования [Lisp](https://ru.wikipedia.org/wiki/Лисп). Он описал этот язык в журнале Communications of the ACM в 1960 году. Первый работающий интерпретатор языка появился в 1958 году для компьютера [IBM 704](https://ru.wikipedia.org/wiki/IBM_704).

Язык Lisp следует декларативному подходу. Его ключевой особенность в представлении и данных, и кода программы в виде списков. Таким образом идеи Маккарти о том, как должна работать система Advice Taker отразились на дизайне его языка. Также на язык Lisp оказал сильное влияние язык IPL, разработанный Ньюэллом, Саймоном и Шоу для системы Logic Theorist.

#### Коннекционизм

Исследования нейронных сетей Мак-Каллока и Питтса заложили основу коннекционизма. Коннекционизм — это направление [когнитивной науки](https://ru.wikipedia.org/wiki/Когнитивистика), которое моделирует и исследует психические явления с помощью искусственных нейронных сетей.

После исследований Хебба следующим значительным шагом в развитии коннекционизма стала модель под названием перцептрон.

##### Перцептрон

В 1957 году американский психолог и нейрофизиолог [Фрэнк Розенблатт](https://ru.wikipedia.org/wiki/Розенблатт,_Фрэнк) предложил модель того, как мозг человека воспринимает информацию. Эта модель получила название [**перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон).

Перцептрон представляет собой искусственную нейронную сеть с особенной архитектурой. Иллюстрации 2-1 приводит схему этой архитектуру.

{caption: "Иллюстрация 2-1. Архитектура перцептрона", height: "50%", width: "100%"}
[Архитектура перцептрона](images/ArtificialIntelligence/perceptron.png)

Сеть состоит трёх слоёв искусственных нейронов:

1. S-элементы (сенсорные)
2. A-элементы (ассоциативные)
3. R-элементы (реагирующие)

Перцептрон создаёт набор ассоциаций (A-элементы) между входными сигналами (S-элементы) и реакцией на них (R-элементы).

Можно провести аналогию между работой перцептрона и мозга. Пример обработки сигнала — реакция человека на зрительную информацию. Если человек видит опасность, физиологическим ответом на неё будет активация [двигательных нейронов](https://ru.wikipedia.org/wiki/Мотонейрон). Эти нейроны отвечают за мышечную активность. Перцептрон обрабатывает входные сигналы аналогично: реагирующие нейроны R возбуждаются в ответ на входные сигналы S, согласно ассоциациям A.

Перед работой перцептрон необходимо обучить. После этого он сможет определять к какому классу относится предъявленный ему объект. Розенблатт использовал теорию Хебба и разработал два метода обучения перцептрона.

В 1957 году Розенблатт смоделировал работу перцептрона в виде программы для компьютера IBM 704. 

Спустя два года Розенблатт сконструировал первый в мире [нейрокомпьютер](https://ru.wikipedia.org/wiki/Нейрокомпьютер). Он получил название [Mark I Perceptron](https://ru.wikipedia.org/wiki/Марк-1). Этот компьютер представлял собой аппаратную реализацию перцептрона. Он работал на аналоговых электронных компонентах: фотодетекторах, потенцометрах и электромоторах. Основной задачей компьютера было распознавание изображений.

В 1962 году Розенблатт опубликовал книгу "Принципы нейродинамики" (Principles of Neurodynamics). В ней он рассматривает различные архитектуры перцептронов, в том числе и многослойные. Также в книге доказана [теорему сходимости перцептрона](https://ru.wikipedia.org/wiki/Теорема_сходимости_перцептрона). Согласно теореме, перцептрон можно обучить за конечное число шагов. После такого обучения он сможет решить поставленную задачу.

Книга "Принципы нейродинамики" оказала большое влияние на развитие коннекционизма. Теорема сходимости перцептрона и её выводы позволили сформулировать требования к архитектурам нейронных сетей и методам их обучения.

#### Экспериментальный подход

Исследователи из лаборатории ИИ Массачусетского технологического института следовали подходу, который в 1970-е годы получил название **scruffy** или "неряшливый". Его также можно назвать "экспериментальным". Этот подход предлагает разрабатывать прототипы систем ИИ для небольших задач из разных областей. Затем полученные системы комбинируются и усовершенствуются для более крупных задач из реального мира.

Противоположный подход в исследованиях ИИ получил название **neat**. Дословно он переводится как "аккуратный". Смысл этого подхода хорошо передаёт слово "теоретический". Он предлагает использовать [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы), основанные на математике и логике. Такой подход даёт более надёжный и научно обоснованный результат. Так работали исследователи из университетов Карнеги — Меллона и Стэнфордского.

В первые годы развития ИИ экспериментальный подход оказался самым плодотворным. Исследователи из МТИ разработали и продемонстрировали ряд систем для решения прикладных задач. Эти системы произвели большое впечатление как на научные круги, так и на инвесторов. Рассмотрим самые известные из этих разработок.

##### Обработка естественного языка

Первой системой обработки естественного языка считается программа [STUDENT](https://en.wikipedia.org/wiki/STUDENT_(computer_program)). Её написал Дэниэль Бобров в рамках свой докторской работы в 1964 году. Его научным руководителем был Марвин Минский.

Программа STUDENT читала и решала задачи из школьного учебника по алгебре. На вход она получала описание задачи на английском языке. На выходе система печатала решение в виде числа.

Для анализа текста STUDENT использовала запрограммированные правила и логический вывод. Функции машинного обучения у системы не было.

Другой системой обработки естественного языка была [ELIZA](https://ru.wikipedia.org/wiki/Элиза_(программа)). Её написал сотрудник лаборатории ИИ в МТИ [Джозеф Вейценбаум](https://ru.wikipedia.org/wiki/Вейценбаум,_Джозеф).

ELIZA представляет собой [виртуального собеседника](https://ru.wikipedia.org/wiki/Виртуальный_собеседник). Программа обменивается с пользователем сообщениями. Направление разговора задаётся специальными сценариями. Самым популярным сценарием разговора был DOCTOR. Согласно ему, программа парадировала психотерапевта и строила вопросы на основе прошлых сообщений от пользователя.

ELIZA считается первой программой, способной попытаться пройти тест Тьюринга.

##### Микромиры

В конце 1960-х годов Марвин Минский и Сеймур Пейперт предложили сфокусировать исследования ИИ на упрощённых проблемных областях. Такие области получили название **микромиры**. Минский и Пейперт утверждали, что полученные системы ИИ смогут работать и для реальных задач.

Студенты МТИ выбирали для себя микромир и выполняли для них свои дипломные работы. Наибольшей популярностью у студентов пользовался [мир блоков](https://en.wikipedia.org/wiki/Blocks_world). Он представляет собой плоскую поверхность, на которой лежат блоки различных цветов и форм.

Самым известным проектом для мира блоков считается программа [SHRDLU](https://ru.wikipedia.org/wiki/SHRDLU). Её разработал [Терри Виноград](https://ru.wikipedia.org/wiki/Виноград,_Терри) в 1970 году.

Программа SHRDLU позволяет пользователю манипулировать объектами в виртуальном пространстве. Это пространство представляет собой мир блоков. Пользователь вводит свои команды на английском языке. SHRDLU может задавать вопросы, чтобы уточнить команду. Также программа может жать ответ — выполнимо ли то или иное действие в виртуальном пространстве.

В лаборатории МТИ разрабатывали не только программы для мира блоков, но и роботов. Было создано несколько версий руки-манипулятора для передвижения блоков:

* Робот MH1, разработанный Генри Эрнстом в 1961 году.

* Робот Мински-Беннета, разработанный Марвином Мински и Вильямом Беннетом в 1968 году.

* Робот для сборки маленьких деталей от [Дэвида Сильвера](https://en.wikipedia.org/wiki/David_Silver_(roboticist)), собранный в 1974 году.

На основе мира блоков [Патрик Уинстон](https://ru.wikipedia.org/wiki/Уинстон,_Патрик) разработал программу машинного обучения ARCH. Она изучала действия над блоками из примеров.

### Первая зима ИИ 1974 – 1980

#### Финансирование DARPA

Первые успехи 1960-х годов в области ИИ привлекли к себе внимание прессы. Учёные не стеснялись делать оптимистичные прогнозы. Они утверждали, что "в ближайшем будущем" машины смогут решать задачи, с которыми раньше справлялись только люди.

В 1958 году министерство обороны США организовало [управление перспективных исследовательских проектов](https://ru.wikipedia.org/wiki/Управление_перспективных_исследовательских_проектов_Министерства_обороны_США) DARPA. Эта организация отвечала за финансирование перспективных технологий, которые могли бы применяться военными.

Исследования ИИ привлекли внимание специалистов DARPA. В результате с 1963 года лаборатории ИИ в МТИ, университетах Карнеги — Меллона и Стэнфордском получали гранты в размере нескольких миллионов долларов ежегодно. Эти деньги выделялись не на конкретные проекты с жёсткими сроками. Лаборатории их получали на фундаментальные исследования без конкретных целей.

Директор DARPA Джозеф Ликлайдер верил, что финансирование "людей, а не проектов" приведёт к практическим результатам. Однако, этого не произошло.

Несколько неудачных проектов подорвали веру в перспективность исследований ИИ среди военных. Самыми крупными среди этих проектов были следующие:

* [**Машинный перевод**](https://ru.wikipedia.org/wiki/Машинный_перевод) текстов с английского на русский язык. В период холодной войны стояла задача перевода советских научных журналов. Чтобы решить эту задачу университет Вашингтона в Сент-Луисе и компания IBM разрабатывали систему ИИ. Однако, 10 лет разработок не дали результата. Поэтому в 1964 году [Национальные академии наук](https://ru.wikipedia.org/wiki/Национальные_академии_наук,_инженерии_и_медицины) США прекратили финансирование проекта.

* Проект голосового управления для пилотов. Над ним работала команда из университета Карнеги — Меллона. Исследователи разработали систему распознавания речи, но она оказалась очень ограниченной. Например, порядок произнесения слов был строго определён. В 1974 году DARPA прекратила финансирование этого проекта.

На раздутый бюджет военных исследований обратил внимание сенат США. В результате в 1969 году была принята поправка Мэнсфилда. Она требовала от DARPA финансировать только целевые исследования. Теперь учёные были вынуждены доказывать, что их работа связана с военными технологиями. Исследователям ИИ редко удавалось обосновать свои проекты в таком ключе. Это привело к значительному сокращению бюджета лабораторий ИИ по всей стране.

#### Отчет Лайтхилла

В 1965 году английский учёный [Дональд Мичи](https://en.wikipedia.org/wiki/Donald_Michie) организовал лабораторию ИИ в [Эдинбургском университете](https://ru.wikipedia.org/wiki/Эдинбургский_университет). Позднее подобные лаборатории открылись в университетах Сассекс и Эссекс. В конце 1960-х и начале 1970-х они получали значительные гранты от правительства Англии.

В 1973 году британский парламент поручил профессору математики [Джеймсу Лайтхиллу](https://ru.wikipedia.org/wiki/Лайтхилл,_Джеймс) оценить перспективы исследований в области ИИ. Свои результаты Лайтхилл опубликовал в статье "Искусственный интеллект: общий обзор" (Artificial Intelligence: A General Survey). Позднее она стала известна как [отчёт Лайтхилла](https://ru.wikipedia.org/wiki/Отчёт_Лайтхилла).

Лайтхилл оценил достижения в области ИИ в США и Европе. Он заметил, что учёные не выполнили многие из своих обещаний. Поэтому Лайтхилл высказал пессимистичный прогноз в отношении перспектив машинного перевода текста и робототехники. В 1973-м году эти направления считались наиболее перспективными. При этом Лайтхилл высоко оценил достижения нейронных сетей для моделирования нейрофизиологических и психических процессов.

Отчёт Лайтхилла стал причиной, по которой правительство Великобритании прекратило финансирование большинства исследований ИИ в университетах. Это решение привлекло к себе внимание всех европейских стран. В итоге финансирование разработок в новой области сократились по всей Европе.

#### Проблемы систем ИИ

Проблемы с финансированием исследований ИИ возникли по вине самих учёных. Они не смогли правильно оценить сложность задач, которые им предстоит решить. Поэтому их прогнозы и сроки выполнения проектов оказались слишком оптимистичными. В результате ожидания инвесторов были очень высокими.

Крупные инвестиции в область ИИ начались в середине 1960-х годов. К началу 1970-х стали ясны результаты многолетних разработок. Они оказались неудовлетворительны. Возможности реальных систем ИИ были далеки от того, что обещали учёные.

Почему прогнозы учёных оказались такими неточными? Рассмотрим причины этого по порядку.

##### Производительность компьютеров

В конце 1950-х годов сменилась технология производства компьютеров. До этого рабочими элементами в них были [электровакуумные лампы](https://ru.wikipedia.org/wiki/Электронная_лампа). В 1958-м году компания IBM выпустила первый компьютер, который работал на [транзисторах](https://ru.wikipedia.org/wiki/Транзистор). В отличие от ламп транзисторы компактнее, надёжнее и быстрее.

Переход на новые технологии обещал рост быстродействия компьютеров. Однако, эти технологии оставались несовершенными на протяжении 1960-х годов. Только в начале 1970-х годов транзисторы и интегральные схемы достигли уровня развития, достаточного для роста производительности компьютеров. После этого момента начал действовать [закон Мура](https://ru.wikipedia.org/wiki/Закон_Мура). Он говорит о том, что число транзисторов на [интегральной схеме](https://ru.wikipedia.org/wiki/Интегральная_схема) удваивается примерно каждые два года.

Исследователи ИИ разрабатывали прототипы своих систем для решения относительно простых задач. Решая такие задачи, можно было быстро сравнить разные подходы и методы. Однако, решив простую задачу сложно оценить насколько система окажется масштабируемой.

Например, первые версии систем для машинного перевода обрабатывали небольшие специально подготовленные тексты. Памяти компьютера 1960-ого года хватало только на несколько десятков слов. Поэтому система могла справиться с переводом маленького текста. Чтобы сделать её универсальной, нужен был компьютер на порядок мощнее существующего.

Быстродействие компьютеров тоже было проблемой. В 1976 году учёный [Ханс Моравек](https://ru.wikipedia.org/wiki/Моравек,_Ханс) из университета Карнеги — Меллона дал следующую оценку. Чтобы распознавать грани объектов и движение в реальном времени, система ИИ должна работать на компьютере с производительностью 10^9^ [операций в секунду](https://ru.wikipedia.org/wiki/IPS_(быстродействие)) (1000 мегаинструкций в секунду или MIPS). Однако, самый быстрый суперкомпьютер 1976 года [Cray-1](https://ru.wikipedia.org/wiki/Cray-1) выполнял всего 160 MIPS.

В 1960-е годы исследователи ИИ не смогли правильно оценить вычислительные мощности, которые понадобятся для их систем. Прототипы, решающие простые задачи, не помогали в такой оценке.

##### Комбинаторный взрыв

В своём отчёте Лайтхилл говорит о [**комбинаторном взрыве**](https://ru.wikipedia.org/wiki/Комбинаторный_взрыв). Комбинаторный взрыв означает быстрый рост сложности задачи при увеличении размера входных данных.

Алгоритмы решения задач оцениваются по двум параметрам:

* [**Временная сложность**](https://ru.wikipedia.org/wiki/Временная_сложность_алгоритма) — это время, которое нужно компьютеру для выполнения алгоритма. Обычно, оно считается как число элементарных шагов для нахождения решения.

* **Память** — это объём данных, которые алгоритм должен хранить в течении своей работы.

Лайтхилл рассматривает системы, которые используют подход "рассуждение как поиск". Дерево поиска реальной задачи на несколько порядков больше, чем дерево поиска простой задачи. Поэтому примеры для демонстраций таких систем оказались неадекватно упрощёнными. Для реальной задачи временная сложность алгоритма поиска растёт слишком быстро. Поэтому системе ИИ требуются дни и даже недели на её решение.

Системы, основанные на поиске, используют эвристики. Эти эвристики хранятся в памяти компьютера как база знаний. При решение простых задач набор эвристик небольшой. Когда задача становится сложной, число эвристик и их взаимосвязи быстро растут. Опять происходит комбинаторный взрыв, но на этот раз с точки зрения используемой памяти.

Исходя из этих выводов Лайтхилл заключает, что существующие на 1973 год системы ИИ не смогут решать реальные задачи даже при увеличении мощности компьютеров.

[Теория вычислительной сложности](https://ru.wikipedia.org/wiki/Теория_сложности_вычислений), которую использовал Лайтхилл, появилась в 1965 году. В 1970-е годы она начала активно развиваться. Теория показала, что некоторые классы задач в принципе не имеют эффективных решений. Это значит, что нет алгоритмов для их решения за приемлемое время. Такие задачи называются [**тродноразрешимыми**](https://www.slideshare.net/mkurnosov/12-34608847).

Концепция тродноразрешимых задач означала, что возможности систем ИИ строго ограничены.

##### Общие знания

Третья проблема ИИ связана с очевидными фактами об окружающем мире. Для задач компьютерного зрения и машинного перевода нужен огромный объём информации об очевидных вещах. Например, система распознавания образов должна знать очертания предметов разного типа. Если этих знаний у неё нет, система будет путать предметы. То же самое касается обработки естественного языка. Без понимания предмета обсуждения, система будет совершать смысловые ошибки при переводе.

Первые системы ИИ обошли проблему представления знаний о мире благодаря простоте тестовых примеров. Когда исследователи начали решать реальные задачи, эта проблема стала очевидной.

### Развитие ИИ 1980 – 1987

#### Экспертные системы

В 1960-е годы большинство исследователей придерживалось символьного подхода. "Рассуждение как поиск" было доминирующим методом решения задач. Этот метод предлагал общий механизм для решения задач любого типа. Однако, он плохо [**масштабировался**](https://ru.wikipedia.org/wiki/Масштабируемость). Масштабируемость означает повышение производительности системы при добавлении ресурсов. Другими словами поиск не мог решить сложные задачи за приемлемое время из-за комбинаторного взрыва.

В 1965 году группа учёных из Стэнфордского университета начала проект системы ИИ, основанной на знаниях. В группу входили [Эдвард Фейгенбаум](https://ru.wikipedia.org/wiki/Фейгенбаум,_Эдвард_Альберт), Брюс Бьюкенен, [Джошуа Ледерберг](https://ru.wikipedia.org/wiki/Ледерберг,_Джошуа) и [Карл Джерасси](https://ru.wikipedia.org/wiki/Джерасси,_Карл). Система получила название [Dendral](https://ru.wikipedia.org/wiki/Dendral).

Группа Фейгенбаума решала практическую задачу из области органической химии. Химикам часто приходится определять неизвестные органические соединения, анализируя их [масс-спектр](https://ru.wikipedia.org/wiki/Масс-спектрометрия). Масс-спектрометрия измеряет отношение массы фрагментов молекулы к их заряду.

Система Dendral принимала на вход масс-спектр вещества. В ходе анализа, она должна была определить его химический состав. Первая версия системы использовала метод поиска. Она генерировала предполагаемые картины масс-спектра для проверяемого вещества. Затем система сравнивала эти картины с реальными наблюдениями. Этот подход работал для небольших молекул. Однако для сложных органических веществ он оказался неприменим.

Проблема заключалась в том, что системе приходилось проверять много вариантов картин масс-спектра. Разработчики Dendral обсудили это затруднение с химиками. Вместе они пришли к идее, как сократить число потенциальных решений. Для этого в систему добавили знания о типичных картинах пиков в масс-спектре вещества. Эти пики указывают на наличие определённых фрагментов молекул. Такое решение позволило системе успешно различать большие органические молекулы.

Знания о картинах пиков в масс-спектре вещества в Dendral стали первыми эвристиками, основанными на знаниях из предметной области. До этого эвристики строились на правилах формальной логики, как в программе Logic Theorist.

Системы ИИ, которые используют в своей работе знания из предметной области, стали называться **экспертными системами**. Опыт Dendral показал, что этот подход позволяет решать реальные сложные задачи.

В 1972 году Фейгенбаум, Бьюкенен и генетик [Стэнли Коэн](https://ru.wikipedia.org/wiki/Коэн,_Стэнли_Норман) разработали экспертную систему [MYCIN](https://ru.wikipedia.org/wiki/MYCIN). Она диагностировала инфекционные заболевания и давала рекомендации для их лечения.

В 1978 году Джон Макдермотт из университета из университета Карнеги — Меллона разработал первую коммерческую экспертную систему [XCON](https://en.wikipedia.org/wiki/Xcon). Заказчиком системы был производитель компьютеров — компания DEC. Система XCON помогала сотрудникам DEC составлять конфигурации компьютеров, согласно требованиям заказчиков. Экспертная система экономила компании до 40 миллионов долларов в год.

Громкий успех системы XCON привел к тому, что корпорации по всему миру начали разработку экспертных систем для внутреннего использования. В эти разработки включились производители оборудования. Начали появляться специальные компьютеры под названием [Lisp-машины](https://ru.wikipedia.org/wiki/Лисп-машина). Они предназначались для запуска программ на языке [Lisp](https://ru.wikipedia.org/wiki/Лисп). Этот язык стал основным для разработки экспертных систем.

#### Компьютеры пятого поколения

В 1981 году правительство Японии начало спонсировать проект [компьютера пятого поколения](https://ru.wikipedia.org/wiki/Компьютеры_пятого_поколения). В рамках проекта за 10 лет планировалось спроектировать производительный суперкомпьютер и запустить его в серийное производство.

Компьютер должен был решать ряд задач с применением ИИ. Среди этих задач были следующие:

* Распознавание речи и автоматический набор текста.
* Машинный перевод.
* Анализ печатного текста и его категоризация.
* Распознавание образов.
* Саморазвитие системы.

Чтобы реализовать возможности ИИ, разработчики компьютера предложили несколько инновационных для того времени решений. Прежде всего, все вычисления должны были выполняться [параллельно](https://ru.wikipedia.org/wiki/Параллельные_вычисления). Для такого режима работы была разработана многопроцессорная архитектура. Компьютеры того времени имели только один процессор. Он выполнял только одну задачу в каждый момент времени. Многопроцессорная архитектура позволяла решать несколько задач одновременно. Также появлялась возможность делить задачу на подзадачи и выполнять их все разом на нескольких процессорах.

Вторым важным решением стало применение концепции **логического программирования**. Она предлагает представлять программу в виде предложений. Эти предложения сообщают факты и правила о некоторой предметной области. С помощью формальной логики из этих фактов выводится нужная информация. Данные для логического вывода хранились не в файловой системе, а в базе данных.

Таблица 2-4 объясняет отличительные черты разных поколений компьютеров.

{caption: "Таблица 2-4. Поколения компьютеров", width: "100%"}
| Поколение | Рабочий элемент |
| --- | --- |
| Первое | [Электровакуумная лампа](https://ru.wikipedia.org/wiki/Электронная_лампа) |
|  | |
| Второе | [Транзистор](https://ru.wikipedia.org/wiki/Транзистор) |
|  | |
| Третье | [Интегральная схема](https://ru.wikipedia.org/wiki/Интегральная_схема) |
|  | |
| Четвёртое | [Микропроцессор](https://ru.wikipedia.org/wiki/Микропроцессор) |

Другие страны ответили на амбициозные планы Японии. В 1984 году правительство Великобритании начало спонсировать программу [Alvey](https://en.wikipedia.org/wiki/Alvey). Целью программы было не создание суперкомпьютера, а исследования в области информационных технологий. Среди направлений исследований были следующие:

* Сверхбольшие интегральные схемы (VLSI)
* Системы ИИ, основанные на знаниях.
* Разработка программ.
* Интерфейс взаимодействия человека и машины.

Группа американских компаний объединилась и создала [корпорацию MCC](https://en.wikipedia.org/wiki/Microelectronics_and_Computer_Technology_Corporation), также известную как Консорциум Микроэлектрони и Компьютеров. Эта корпорация должна была спонсировать фундаментальные исследования в области ИИ и информационных технологий. В то же время управление министерства обороны США DARPA утроило финансирование в области ИИ.

#### Возвращение коннекционизма

Модель перцептрона выглядела многообещающей. Она успешна справлялась с простыми задачами распознавания образов. Однако, скоро исследователи обнаружили её ограничения.

Основная задача перцептрона — это распознавание. В результате распознования нейронная сеть относит воспринимаемый образ к какому-то классу объектов. Перцептрон с одним слоем A-элементов различает только два класса объектов. При этом шаблоны образов должны быть [линейно разделимыми](https://ru.wikipedia.org/wiki/Линейная_сепарабельность).

Простейший пример линейной раздилимости — два набора точек на плоскости. Эти наборы называются линейно разделимыми, если между ними можно провести прямую линию.

В случае нейронных сетей, количество измерений простаранства соответствует числу признаков классификации. Каждая точка пространства соответстует набору этих признаков. Классы объектов представляют собой наборы этих точек. Линейная разделимость в этом случае означает возможность разделить наборы точек [гиперплоскостью](https://ru.wikipedia.org/wiki/Гиперплоскость).

I> Гиперплоскость это подпространство с размерностью на 1 меньше, чем объемлющее её пространство. Например, гиперплоскость для двумерного пространства — это прямая.

В 1969 году Марвин Мински и Сеймур Пейперт опубликовали книгу ["Перцептроны"](https://ru.wikipedia.org/wiki/Перцептроны_(книга)) ("Perceptrons: an introduction to computational geometry"). В ней авторы рассмотрели ограничения перцептрона. В целом тон книги пессиместичен относительно перспектив такой архитектуры нейронных сетей. Книга получила широкую известность и повлияла на отношение к коннективизму в научных кругах.

В 1970-е и 1980-е годы исследования в рамках коннекционизма проводили учёные не связанные с ИИ. Один из них — американский физик Джон Хопфилд. Он использовал методы из статистической механики, чтобы изучить свойства хранения данных в нейронной сети. В результате Хопфилд разработал [новую архитектуру нейронной сети](https://ru.wikipedia.org/wiki/Нейронная_сеть_Хопфилда), которая была названа в его честь. Эта сеть стала моделью для изучения человеческой памяти.

В начале 1980-х годов психологи [Джеффри Хинтон](https://ru.wikipedia.org/wiki/Хинтон,_Джеффри) и [Дэвид Румельхарт](https://ru.wikipedia.org/wiki/Румельхарт,_Дэвид) из университета Карнеги — Меллона исследовали процесс обучения и модель памяти на основе нейронных сетей. Они применили существующие наработки и предложили **метод обратного распространения ошибки**. Этот метод позволял эффективно обучать [нейронные сети с прямой связью](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью).

В 1986 году Румельхарт и [Джеймс Макклелланд](https://ru.wikipedia.org/wiki/Макклелланд,_Джеймс) опебликовали цикл статей под названием "Параллельная распределенная обработка" (Parallel Distributed Processing). В этом цикле авторы демонстрировали области применения метода обратного распространения ошибки в компьютерных науках и психологии. Благодаря статьям Румельхарта и Макклелланд, исследователи ИИ снова заинтересовались коннекционизмом.

### Вторая зима ИИ 1987 — 1993

В 1984 году состоялась ежегодная встреча Американской ассоциации искусственного интеллекта (AAAI). На одном обсужденийй Марвин Мински и Роджер Шэнк обратились к предпринимателям. Они предупредили о завышенных ожиданиях от исследований в области ИИ.

На протяжении 1980-х годов инвестиции коммерческих компаний в ИИ постоянно росли. К 1985 году корпорации по всему миру тратили на разработку экспертных систем свыше миллиарда долларов. Появилось много новых компаний, который предлагали программные и аппаратные решения для нового направления в ИИ. Однако, в 1987 году этот рынок рухнул по сценарию [экономического пузыря](https://ru.wikipedia.org/wiki/Экономический_пузырь). Большинство компаний не смогли выполнить свои обещания и предоставить рабочие решения в срок. Это разочаровало инвесторов и поставило под сомнение, что разработки в области ИИ прибыльны с коммерческой точки зрения.

#### Банкротство производителй Lisp-машин

В конце 1979-х сотрудники лаборатории ИИ Массачусетского технологического института начали работать над специальным компьютером для запуска экспертных систем. Языком для разработки этих систем был Lisp. Поэтому новые компьютеры были нацелены на исполнение только Lisp-программ и получили название Lisp-машины.

На базе института была создана компания [Lisp Machines](https://en.wikipedia.org/wiki/Lisp_Machines) в 1979 году. Её первым клиентом стала компания [Control Data Corporation](https://ru.wikipedia.org/wiki/Control_Data_Corporation) — крупный производитель компьютерной переферии и суперкомпьютеров.

В 1980-ом году часть сотрудников покинули Lisp Machines чтобы организовать новую компанию [Symbolics](https://en.wikipedia.org/wiki/Symbolics). Позднее к производству Lisp-машин подключились крупные производители электроники: [Texas Instruments](https://ru.wikipedia.org/wiki/Texas_Instruments) и [Xerox](https://ru.wikipedia.org/wiki/Xerox). Рынок специализированных компьютеров выглядел перспективно и обещал долгосрочный рост. Инвестиции в разработки Lisp-машин достигли полмилииарда долларов.

Однако, в 1987 году рынок Lisp-машин неожиданно рухнул. Причиной этого стало появление [рабочих станций](https://en.wikipedia.org/wiki/Workstation) от компании Sun Microsystems. Рабочая станция отличается от персонального компьютера высокой ценой и производительностью. Её аппаратное обеспечение оптимизированно для задач визуализации, 3D моделирования и математических рассчётов.

[Рабочие станции Sun Microsystems](https://ru.wikipedia.org/wiki/Sun-1) изначально не поддерживали язык Lisp. Это останавливало пользователей экспертных систем от перехода на более мощное оборудование. Но компания [Lucid](https://en.wikipedia.org/wiki/Lucid_Inc.) разработала интерпретатор языка Lisp для операционной системы Unix. Под управлением этой системы работали компьютеры Sun.

Кроме интерпретатора от компании Lucid в 1980-е годы в университете Беркли был разработан интерпретатор [Franz Lisp](https://en.wikipedia.org/wiki/Franz_Lisp). В 1982 года его портировали на компьютеры Sun.

В середине 1980-х годов относительно недорогие ПК от компаний Apple и IBM достигли производительности Lisp-машин. В скором времени на ПК были портированы популярные интерпретаторы языка Lisp. С этого момента пользователям не было никакого смысла переплачивать за специальное оборудование. Компании стали массово отказываться от использования Lisp-машин.

#### Проблемы экспертных систем

К началу 1990-х годов компании накопили достаточно опыта в использовании экспертных систем. Этот опыт показал, что обслуживание таких систем обходится дорого. Основная проблема заключалась в обновлении больших баз знаний. Сама система не имела функции обучения. Поэтому изменения делались вручную специалистами. Во время этих изменений требовалось проверять всю базу знаний на согласованность. Это требовало много времени и значительных усилий.

Научные круги к этому времени потеряли интерес к экспертным системам. Разработки в области архитектуры баз знаний показали, что представление общих знаний о реальном мире — трудновыполнимая задача. Один из примеров таких разработок — проект [Cyc](https://ru.wikipedia.org/wiki/Cyc) под руководством [Дугласа Лената](https://ru.wikipedia.org/wiki/Ленат,_Дуглас). Этот проект неоднократно подвергался критики со стороны научного сообщества. Многие считают его бесполезным.

Экспертные системы показали свою полезность в некоторых узкоспециализированных областях. Однако, разработчики этих систем не смогли выполнить своих обещаний по созданию ИИ. Это разочаровало инвесторов. В результате многие научные исследования и компании потеряли финансирование.

#### Провал разработки компьютеров пятого поколения

К 1991 году разработка компьютера пятого поколения в Японии не достигла поставленных целей. В ходе проекта были созданы несколько рабочих станций. Они использовали специальное аппаратное обеспечение с многопроцессорной архитектурой.

К моменту своего появления рабочие станции оказались устаревшими. Причиной этого стало появление мощных ПК. Проект длился 10 лет. В момент его начала исследователи предполагали, что однопроцессорные компьютеры достигли предела производительности. Поэтому, по их мнению, увеличить мощность могли только параллельные вычисления. Однако, эти прогнозы оказались ошибочными. В результате к 1991 году производительность недорогих ПК, собранных на стандартных компонентах, превзошла производительность рабочих станций пятого поколения.

Кроме роста производительности процессоров появилось несколько новых технологий. В 1984 ПК от компании Appl начали использовать графический интерфейс. В начале 1990-х появился Internet. Компьютер пятого поколения не поддерживал эти передовые технологии. В результате он стал неинтересен пользователям.

Другая проблема компьютера пятого поколения связана с программным обеспечением. Разработчики выбрали язык [Prolog](https://ru.wikipedia.org/wiki/Пролог_(язык_программирования)) для написания программ. Этот язык следует концепции логического программирования. Эта концепция была ключевой в новом компьютере. Однако, Prolog не использует преимущества параллельных вычислений. Все попытки добавить поддержку параллельности в язык не дали ожидаемого результата.

Возможности ИИ, которые планировалось реализовать в компьютере пятого поколения, были переоценены. Производительности оборудования и уровня исследования ИИ того времени не хватило для задач распознавания образов и машинного перевода текстов. Идея саморазвития системы оказалась непродуктивной. После нескольких самостоятельных изменений система теряла надёжность и становилась неработоспособной.

Провал проекта вызвал реакцию в США и Англии. Эти страны прекратили разработки суперкомпьютеров и сократили инвестиции в исследования ИИ.

### Развитие ИИ в 1993–2011

#### Научный подход в ИИ

С 1970-х годов ииследования в области ИИ проводились [двумя принципиально разными путями](https://en.wikipedia.org/wiki/Neats_and_scruffies).

Первый подход назывался **neat**, что по-английски означает "аккуратный". Лучше всего смысл этого подхода передаёт слово "теоретический". Исследователь-теоретик применяет только [**формальные методы**](https://ru.wikipedia.org/wiki/Формальные_методы). Эти методы основаны на математике и логике. Такой подход даёт более надёжный и научно обоснованный результат. Ожидается, что такой путь приведёт к идее или методу, который можно обобщить и на его основе создать ИИ.

Второй подход называется **scruffy** или "неряшливый". Его лучше назвать "экспериментальным" или "практическим". Исследователи-практики пробуют разные алгоритмы и методы, чтобы добиться от системы нужного поведения. Они утверждают, что для создания ИИ необходимо решить ряд несвязанных между собой задач. При этом ни одна программа не сможет стать интеллектуальной самостоятельно.

Споры между теоретиками и практиками продолжались до 1990-х годов. Они прекратились, когда новейшие подходы математики и статистики стали применяться в ИИ. Благодаря им, появилось новое направление в разработке программ — [**математическая оптимизация**](https://ru.wikipedia.org/wiki/Оптимизация_(математика)). Кроме того эти подходы подстегнули развитие нейронных сетей. Такие направления как [**машинное обучение**](https://ru.wikipedia.org/wiki/Машинное_обучение) и компьютерное зрение достигли больших успехов.

I> Машинное обучение — это класс методов в ИИ. Эти методы не решают поставленную задачу, а обучают систему на примерах решения аналогичных задач. После процесса обучения система решает поставленную задачу сама.

Переход к формальным методам позволили исследователям ИИ использовать достижения других наук. Среди них теория вероятностей и теория принятия решений. Использование математического аппарата ускорилоло обмен идеями между ИИ и смежными с ним науками.

#### Интеллектуальные агенты

В 1990-х годах концепция интеллектуальных агентов получила признание среди исследователей ИИ. Эта концепция пришла в ИИ из экономики и теории принятия решений. Её прототипом стало понятие рацинального агента из экономики. Главная особенность интеллектуального агента в том, что он пытается максимизировать свою эффективность при решении поставленной задачи.

Понятие интеллектуального агента разрешило несколько философских проблем в области ИИ. Первая из них заключалась в спорах о том, что считается интеллектом. Тест Тьюринга подчёркивал сравнение искусственных систем с человеческим интеллектом. Понятие рационального агента устранило это сравнение. Теперь интеллектуальным стало считаться любое поведение, которое ведеёт к эффективному достижению цели.

Кроме того теперь потеряли смысл обсуждения о том, может ли машина обладать сознанием и настоящим пониманием. Эти свойства стали неважны для интеллектуального агента. Исследователи ИИ смогли сконцентрироваться на решении конкретных практических задач. Формальные методы позволили им находить решения, правильность которых можно было доказать.

Новая концепция помогла исследователям ИИ и с практической точки зрения. Она позволила непосредственно сравнивать эффективность различных систем, основанных на разных подходах. Принцип работы системы отошёл на второй план. Раньше каждый исследователь работал только в рамках одного подхода: символьный или коннекционизм. Теперь система оценивалась более объективно по своим результатам. Начались попытки совмещения разных подходов для повышения эффективности.

#### Восстановление репутации ИИ

Многие инвесторы разочаровались в области ИИ после краха рынка Lisp-машин, проблем с экспертными системами и провала проекта компьютера пятого поколения. Это вызвало сокращение финансирования фундаментальных исследований и разработок.

На протяжении 1990-х годов многие исследователи избегали термина ИИ, когда описывали свою работу. Вместо этого они говорили об информатике, когнитивных системах и вычислительном интеллекте. Так исследователи имели больше шансов найти финансирование. В результате многие достижения в области ИИ стали считаться частью информатики. Например, к этим достижениям относятся алгоритмы поиска и способы представления данных.

В конце 1990-х и начале 2000-х годах исследователи ИИ смогли продемонстрировать несколько впечатляющих успехов. Эти успехи вызвали широкий резонанс в обществе. Они частично восстановили испорченную репутацию науки об ИИ.

В 1997 году суперкомпьютер [DeepBlue](https://ru.wikipedia.org/wiki/Deep_Blue) от IBM смог обыграть чемпиона мира по шахматам Гарри Каспарова.

В 2005 году робот, разработанный в Стэнфордском университете, победил в гонках [DARPA Grand Challenge](https://ru.wikipedia.org/wiki/DARPA_Grand_Challenge). Автономно управляемая машина смогла проехать весь маршрут в 211 километров по пустыне Мохаве. На это у робота ушло почти семь часов.

В 2011 году ИИ ситема [Watson](https://ru.wikipedia.org/wiki/IBM_Watson) от компании IBM смогла обыграть двух лучших игроков в телевизионной игре-викторине Jeopardy!. В этой игре участники отвечают на вопросы из области общих знаний.

Эти успехи удалось достичь благодаря увеличению производительности компьютеров и качеству разработки программ в 1990-х годах. Каждая из нашумевших ИИ систем использовала хорошо известные подходы, разработанные ещё в 1960-х годах.

### Современные направления в ИИ

#### Big Data

Big data или [**большие данные**](https://ru.wikipedia.org/wiki/Большие_данные) — это одно из современных направлений в ИИ. Оно изучает методы обработки наборов данных, которые слишком велики для применения традиционных подходов.

Направление big data возникло по двум причинам:

* [Компьютеризация](https://ru.wikipedia.org/wiki/Компьютеризация) общества. Все больше компаний и правительственных учреждений используют компьютеры. В результате накапливаются огромные объёмы информации.

* Распространение портативных устройств, которые способны накапливать информацию. Примеры таких устройств: мобильные телефоны, телевизоры, камеры наблюдения, микрофоны.

Исследователи big data используют следующие технологии:

* Машинное обучение.
* [Обработка естсественных языков](https://ru.wikipedia.org/wiki/Обработка_естественного_языка).
* [Облачные вычисления](https://ru.wikipedia.org/wiki/Облачные_вычисления).
* [Базы данных](https://ru.wikipedia.org/wiki/База_данных).
* Визуализация данных.

Сегодня big data активно применяется в следующих областях:

* Государственные учреждения. Они обрабатывают личную информацию граждан и ведут разного рода статистику.

* Здравоохранение. Методы big data применяются для анализа результатов клинических исследований. Также они помогают вести статистику заболеваний.

* Экономика. Для составления прогнозов и планирования крупных проектов приходится обрабатывать значительные объёмы данных.

* Страховые компании должны обрабатываеть данные о своих клиентах.

* Информационные технологии. Многие информационные системы собирают стсатистику об их использовании. Это помогает разработчикам улучшать свои продукты.

#### Deep Learning

Перцептрон Розенблатта и нейронные сети 1980-х годов моделировали работу мозга. Для этого исследователи ИИ применяли знания из области нейрофизиологии. Низкая производительность компьютеров ограничивала размеры этих сетей. Число нейронов в них было на несколько порядков меньше, чем в мозге мыши. Это привело к скромным достижениям коннекционизма в 1980-е годы по сравнению с символьным подходом.

В 1986-ом году в машинном обучении появилось новое направление под названием deep learning. Оно также известно как [**глубокое обучение**](https://ru.wikipedia.org/wiki/Глубокое_обучение). Отличительная особенность этого подхода в архитектуре нейронных сетей. Эти сети называются **глубокими** или **многослойными**. В отличие от перцептрона Розенблатта они имеют более трёх слоёв. Благодаря такой архитектуре, алгоритм обучения может извлекать признаки разного уровня асбтракции из входных данных. Например, алгоритм машинного зрения может различать на низком уровне отдельные линии, а на более высоком цифры и буквы.

Активные исследования по изучению многослойных сетей начались в середине 1960-х годов. В 1967 году советский математик [Алексей Ивахненко](https://ru.wikipedia.org/wiki/Ивахненко,_Алексей_Григорьевич) разработал первый алгоритм обучения многослойных перцептронов.

В 1980-м году японский учёный Кунихико Фукусима предложил архитектуру многослойной сети под названием [**неокогнитрон**](https://ru.wikipedia.org/wiki/Неокогнитрон). Она предназначалась для распознавания образов.

Исследования многослойных нейронных сетей продолжались на протяжении 1980-х годов. Однако, только в 2000-х годах глубокие сети стали широко использоваться. Причин этому несколько:

* Недостаточно проработанная теория обучения глубоких сетей.

* Возросла общая производительность компьютеров.

* В различных предметных областях были накоплены большие наборы данных для обучения сетей.

* Появилось специальное оборудование ([графические процессоры](https://ru.wikipedia.org/wiki/Графический_процессор) или GPU), которое на порядок ускорило обучение сетей.

Все эти проблемы удалось преодолеть к концу 2000-х годов. Поэтому в начале 2010-х глубокие нейронные сети стали занимать призовые места на конкурсах по распознованию образов.

Сегодня глубокие нейронные сети показывают хоршие результаты в следующих областях:

* Распознавание речи.
* Распознавание образов.
* Машинный перевод.
* Системы рекомендаций.
* Медицинская диагностика.
