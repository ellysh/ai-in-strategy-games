## Машинное обучение

Мы рассмотрели методы формальной логики и алгоритмы поиска, которые применяются в программах интеллектуальных агентов. Теперь познакомимся с более сложными подходами, разработанными в рамках машинного обучения.

### Механизм обучения

Начнём с основных понятий, которые применяются в машинном обучении.

**Механизм обучения** это набор методов, который автоматически создаёт программу интеллектуального агента. Любой механизм обучения состоит из двух компонентов:

* **Алгоритм обучения**
* **Обучаемая модель**

Чтобы воспользоваться механизмом обучения, нужен **обучающий набор данных** (training set). Этот набор состоит из **обучающих примеров** (training sample).

 Алгоритм обучения получает на вход обучающий набор данных. Далее алгоритм находит в них закономерности и строит обучаемую модель. Эта модель учитывает все найденные закономерности.

Для разных типов обучаемых моделей применяются разные алгоритмы обучения. Алгоритм обучения определят требования к обучающему набору данных.

По принципу работы алгоритмы обучения делятся на три больших класса:

* [**Обучение с учителем**](https://ru.wikipedia.org/wiki/Обучение_с_учителем) или контролируемое (supervised learning)

* [**Обучение без учителя**](https://ru.wikipedia.org/wiki/Обучение_без_учителя) или неконтролируемое (unsupervised learning)

* [**Обучение с подкреплением**](https://ru.wikipedia.org/wiki/Обучение_с_подкреплением) (reinforcement learning)

Каждый класс представляет собой отдельную **парадигму**. Парадигма — это система предположений, концепций и практических приёмов для решения какой-то задачи.

Один и тот же алгоритм обучения можно представить в разных формах:

* С помощью математических формул.
* В виде псевдокода.
* В виде запускаемой программы.
* В виде программной библиотеки.

Форма представления выбирается исходя из задачи. Первые две формы чаще применяются в образовательных целях. Последние две — на практике.

Обучаемая модель — это то, что строит алгоритм обучения после обработки обучающего набора данных. Модель хранит результаты процесса обучения. Она состоит из правил и наборов данных, которые необходимы для прогнозирования. По-сути модель — это программа. Она имеет данные и машинные инструкции для их обработки. Инструкции используют данные, чтобы выполнять прогнозы для новых наборов данных. Эти наборы представляют собой восприятие агента в процессе его работы.

Можно сказать, что обучаемая модель состоит из двух компонентов:

* **Данные модели**
* **Алгоритм для прогнозирования**

Цель машинного обучения — автоматически получить обучаемую модель. Алгоритм обучения используется как средство достижения этой цели. Он влияет на качество обучаемой модели. При этом конечная программа агента никак не использует алгоритм обучения.

### Алгоритмы обучения

Теперь познакомимся с парадигмами алгоритмов обучения.

Таблица 2-18 для каждой парадигмы обучения демонстрирует решаемые с её помощью задачи

{caption: "Таблица 2-18. Парадигмы алгоритмов обучения", width: "100%"}
| Парадигма обучения | Задачи |
| --- | --- |
| Обучение с учителем | Регрессия |
|  | Классификация |
|  | Структурный вывод |
|  | |
| Обучение без учителя | Кластеризация |
|  | Обнаружение аномалий |
|  | Сокращение размерности |
|  | Поиск ассоциативных правил |
|  | |
| Обучение с подкреплением | Машинный перевод |
|  | Задача управления |

#### Обучение с учителем

Алгоритмы обучения с учителем принимают на вход **размеченные данные**. Можно применить терминологию интеллектуальных агентов и описать размеченный обучающий пример так:

*Обучающий пример содержит акт восприятия агента и ожидаемое действие на него.*

Продолжим пользоваться этой же терминологией, чтобы описать алгоритм обучения с учителем. Алгоритм принимает на вход размеченные данные. Эти данные содержат примеры работы желаемой функции агента. В результате обучения алгоритм строит модель. Она реализует функцию агента, поведение которой близко к желаемой.

Теперь перейдём к терминологии, принятой в машинном обучении. Она более точна, но в то же время сложнее для понимания. Для начала дадим определение размеченному обучающему примеру:

*Обучающий пример представляет собой пару векторов X = (x~1~, x~2~,..., x~n~) и Y = (y~1~, y~2~,..., y~n~). X – это вектор входных значений, а Y – вектор выходных значений. Вектор Y должна вернуть обучаемая модель при получении на вход вектора X.*

I> **Вектором** в контексте машинного обучения называют упорядоченный набор чисел.

Теперь рассмотрим общий алгоритм обучения с учителем. Алгоритм передаёт на вход модели вектор входных значений X очередного примера из обучающего набора. Модель в ответ на эти входные значения возвращает вектор выходных значений Y'.

Далее алгоритм обучения сравнивает вектора Y из обучающего примера и Y', полученный от модели. Если эти вектора не совпадают, это называется [**ошибкой обучения**](https://wiki.loginom.ru/articles/training-error.html) (training error). При возникновении такой ошибки алгоритм обучения автоматически изменяет параметры модели. Если вектора Y и Y' совпали, алгоритм обучения переходит к следующему примеру.

Когда обучаемая модель готова, её точность можно оценить с помощью размеченного **тестового набора данных**. Эти данные не входят в обучающий набор, поэтому модель никогда с ними не встречалась. Для каждого **тестового примера** модель возвращает вектор выходных значений Y'. Если он не совпадает с вектором Y из примера, это называется [**ошибкой обобщения**](https://wiki.loginom.ru/articles/generalization-error.html) (generalization error). При высокой частоте таких ошибок, говорят что **производительность** модели низка.

Чтобы улучшить производительность модели, есть целый [ряд методов](https://machinelearningmastery.com/improve-deep-learning-performance/). Некоторые из них меняют конфигурацию модели. В результате она подгоняется под обучающий и тестовый набор данных. Эта проблема называется [**переобучением**](https://wiki.loginom.ru/articles/overtraining.html) (overtraining или overfitting). Из-за переобучения модель хорошо работает на обучающих и тестовых наборах, но часто ошибается на реальных данных. В этом случае говорят о плохой **обобщающей способности модели** (generalization ability).

Обобщающая способность — это способность обучаемой модели выдавать правильные выходные значения не только для обучающих и тестовых примеров, но и для любых данных, с которыми модель ранее не сталкивалась.

Чтобы оценить обобщающую способность модели применяют, её проверяют на **валидационном наборе данных** (validation set). Примеры из этого набора не входят ни в обучающий, ни в тестовый наборы. Такая проверка модели называется **валидацией**. Она нужна, чтобы оценить предсказательную способность модели.

Обучение с учителем эффективно для решения следующих задач:

* **Классификация** — определение категории, к которой принадлежит некоторый объект.

* **Регрессия** — предсказание числового значения по входным данным.

* **Структурный вывод** — порождение вектора выходных значений, между элементами которого существуют важные связи.

Рассмотрим подробнее первые две задачи и примеры к ним. Это даст нам общее представление об алгоритмах и моделях обучения с учителем.

##### Классификация

Задача классификации заключается в определении класса объекта по его параметры. Параметры объекта в терминологии машинного обучения называются **признаками**. Пример объекта — автомобиль. Его признаки: габариты, мощность двигателя, расход топлива и т.д.

Для обучения модели, которая решает задачу классификации, применяется набор обучающих данных специального формата. В каждом примере вектор входных значений X представляет собой все проверяемые признаки конкретного объекта. Выходной вектор Y состоит из единственного скалярного значения y. Оно определяет номер класса, к которому следует отнести объект из примера. Этот номер класса называется **меткой**.

При решении задачи классификации обучаемая модель возвращает дискретные значения. Обычно это номер класса, к которому относится переданный на вход модели объект.

Каноничным примером для демонстрации задачи классификации считается набор данных под названием [**ирисы Фишера**](https://ru.wikipedia.org/wiki/Ирисы_Фишера). С его помощью английский статистик и биолог Роналд Фишер продемонстрировал разработанный им метод статистического анализа в 1936 году.

Набор данных ирисы Фишера представляет собой таблицу со следующей информацией:

1. Длина чашелистника (sepal) цветка.
2. Ширина чашелистника (sepal) цветка.
3. Длина лепестка (petal) цветка.
4. Ширина лепестка (petal) цветка.
5. Вид ириса.

Всего в таблице 150 записей для трёх типов ириса. Для каждого типа есть по 50 записей с разными разными параметрами цветка.

Для простоты мы рассмотрим только два параметра цветка: длина и ширина чашелистника. По этим признакам модель должна определить, относится ли растение к виду Iris setosa или к другому виду.

В ходе обучения на наборе данных, алгоритм строит модель. Простейшая модель для классификации представляет собой формулу для расчёта выходного значения y по вектору входных значений X. Модели такого типа называются [**линейными классификаторами**](https://ru.wikipedia.org/wiki/Линейный_классификатор).

Формула линейного классификатора в общем виде выглядит так:

![Формула линейного классификатора](images/ArtificialIntelligence/linear-classifier-formula.png)

В этой формуле используются следующие обозначения:

* y — выходное значение модели
* f — пороговая функция
* w~i~ — вес признака под номером i
* x~i~ — значение признака под номером i

**Пороговая функция** f отображает все возможные суммы (w~i~ * x~i~) на два дискретных значения. Обычно это значения 0 и 1. Они соответствуют двум классам объектов. Допустим, что в нашем случае значение 0 соответствует виду Iris setosa, а 1 — другим видам ирисов.

**Вес** признаков w~i~ — это некоторые коэффициенты, которые подбирает алгоритм обучения. Благодаря правильно подобранным весам, пороговая функция может однозначно различать классы объектов.

Теперь вернёмся к нашему примеру с ирисами. Мы рассматриваем только два признака: ширина и длина чашелистника цветка. Поэтому формулу линейного классификатора можно упростить до такого вида:

![Формула классификатора ирисов](images/ArtificialIntelligence/iris-classifier-formula.png)

Обозначения в формуле следующие:

* y — выходное значение модели
* f — пороговая функция
* w~1~ — вес признака ширина чашелистника
* x~1~ — ширина чашелистника
* w~2~ — вес признака длина чашелистника
* x~2~ — длина чашелистника

Возникает вопрос: какая именно пороговая функция f используется в формуле? Эта функция зависит от конкретной обучаемой модели, которую мы решим использовать. Вот некоторые из моделей, которые применяют на практике для линейной классификации:

* [**Машина поддерживающих векторов**](https://ru.wikipedia.org/wiki/Метод_опорных_векторов) (support vector machine или SVM).

* [**Логистическая регрессия**](https://ru.wikipedia.org/wiki/Логистическая_регрессия) или логит-модель (logit model).

* [Нейронная сеть перцептрон](https://www.mathematik.uni-muenchen.de/~deckert/teaching/SS18/sec-steps.html).

Для наглядности модель линейного классификатора удобно представлять в виде графика. Этот график строится на **пространстве признаков**. Размерность пространства совпадает с количеством проверяемых признаков объекта.

В нашем случае признаков два, поэтому график строится в двумерном пространстве. Его демонстрирует иллюстрация 2-14.

{caption: "Иллюстрация 2-14. Модель для классификации ирисов", height: "50%", width: "100%"}
![Классификация ирисов](images/ArtificialIntelligence/fisher-iris-classification.png)

На горизонтальной оси откладывается длина чашелистника в сантиметрах для каждого примера из обучающего набора данных. На вертикальной оси — ширина чашелистника. Фиолетовые точки в левой верхней части графика обозначают ирисы вида Iris setosa. Зелёные и жёлтые точки справ внизу — это ирисы видов Iris virginica и Iris versicolor. Синяя пунктирная линия соответствует границе между классами, которую построил алгоритм обучения.

Наклон линии границы между классами определяют веса w~1~ и w~2~, которые подобрал алгоритм обучения.

Рассмотрим, как работает обученная и проверенная модель. На вход она получает вектор X. Элементы вектора: ширина и длина чашелистника ириса, вид которого надо определить. Модель подставляет полученные признаки x~1~ и x~2~ в формулу и вычисляет значение y. Если y равно 0, то проверяемый ирис относится к виду Iris setosa. Если y равно 1, то мы столкнулись с ирисом какого-то другого вида.

Работу модели можно наглядно представить, если обратиться к графику на иллюстрации 2-14. Предположим, что модель получила входные данные: ширина и длина чашелистника неизвестного ириса. Отложим на горизонтальной и вертикальной оси значения этих признаков. Если точка оказалась выше границы классов, проверяемый ирис относится к виду Iris setosa. В противном случае, этот ирис относится к другому виду.

Остаётся открытым один вопрос: как именно алгоритм обучения подбирает веса w~1~ и w~2~ в нашем примере с ирисами? Для моделей линейных классификаторов часто применятся [**стохастический градиентный спуск**](https://ru.wikipedia.org/wiki/Стохастический_градиентный_спуск).

Python скрипт для классификации ирисов Фишера приводится в приложении 3.1 и на [Github](https://github.com/ellysh/ai-in-strategy-games/blob/master/manuscript/resources/code/ArtificialIntelligence/linear-classifier.py).

##### Регрессия

Задача регрессии — это прогноз значений некоторой **зависимой переменной** y от вектора **независимых переменных** X. Связь между зависимыми и независимыми переменными математическая: изменение значений независимых переменных систематически меняет значение зависимой.

Рассмотрим обучающий набор данных для модели, решающей задачу регрессии. Пример состоит из вектора независимых переменных X и единственного зависимого от них значения y. В отличие от задачи классификации y является вещественным числом. В этом случае говорят, что модель возвращает непрерывные значения.

Вот пример задачи регрессии. Нам нужно оценить стоимость автомобиля Volkswagen Golf в зависимости от его пробега. В этом случае мы учитываем единственный признак объекта — пробег в километрах.

Чтобы обучить модель, нам нужен набор данных. Каждый пример этого набора представляет собой пару значений: цена и пробег. Пробег будет единственным элементом вектора X независимых переменных. Цена будет зависимой переменной y.

Предположим, что мы проверили рынок поддержанных автомобилей и нашли несколько предложений Volkswagen Golf. Цены и пробег этих машин мы заносим в таблицу. Далее переводим эти данные в формат, подходящий для алгоритма обучения. Алгоритм обрабатывает эти данные и строит обучаемую модель.

Полученная модель принимает на вход пробег автомобиля. По этому признаку она предсказывает примерную стоимость автомобиля. Модели такого типа называются **линейными регрессорами**.

Формула линейного регрессора в общем виде выглядит так:

![Формула линейного регрессора](images/ArtificialIntelligence/linear-regressor-formula.png)

В ней используются следующие обозначения:

* y — выходное значение модели
* w~i~ — вес признака под номером i
* x~i~ — значение признака под номером i
* ε — случайная ошибка модели

Линейный регрессор в отличие от классификатора не использует пороговую функцию f. Модель регрессора представляет собой указанную выше формулу с правильно подобранными весами w~i~.

Вернёмся к нашей задаче определения цены на поддержанные Volkswagen Golf. Мы рассматриваем только один признак машины — её пробег. Поэтому в формуле регрессора остаётся только одна независимая переменная x~1~ и её вес w~1~. Таким образом формула принимает следующий вид:

![Формула регрессора стоимости](images/ArtificialIntelligence/cost-regressor-formula.png)

Здесь используются следующие обозначения:

* y — выходное значение модели
* w~1~ — вес признака пробег автомобиля
* x~1~ — пробег автомобиля в километрах
* ε — случайная ошибка модели.

Модель линейного регрессора можно представить в виде графика. В отличии от линейного классификатора к пространству признаков надо добавить ещё одно измерение — значение зависимой переменной y. Поскольку в нашем примере используется один признак, пространство графика будет двумерным. Первое измерение — это пробег автомобиля в километрах x~1~, а второе — цена y.

Иллюстрация 2-15 демонстрирует модель линейного регрессора для определения цены Volkswagen Golf.

{caption: "Иллюстрация 2-15. Модель для вычисления стоимости автомобиля", height: "50%", width: "100%"}
![Стоимость автомобиля](images/ArtificialIntelligence/car-cost-regression.png)

На горизонтальной оси отображается пробег автомобиля в километрах. На вертикальной оси — его цена. Чёрные точки обозначают тестовый набор данных. На графике изображены 15 крестиков — это машины с разным пробегом и их актуальные цены. Мы получили их из анализа рынка поддержанных машин. Синяя линия отображает зависимость между пробегом и ценой автомобиля. Это и есть наша модель, которую построил алгоритм обучения.

Вес w~1~ определяет наклон линии на иллюстрации 2-15.

Рассмотрим, как работает полученная нами модель. На вход она получает вектор независимых переменных X. Он состоит из единственного значения x~1~ — пробег автомобиля, цену которого надо определить. Модель подставляет это значение x~1~ в формулу и вычисляет y. Значение y — это искомая цена автомобиля.

Работу модели можно наглядно представить с помощью иллюстрации 2-15. Для этого надо отложить пробег автомобиля по горизонтальной оси. Для примера допустим, что это 2000 км. Этому значению соответствует одна точка на синей линии. По вертикальной оси этой точке соответствует цена 20000$. Это и есть ожидаемая цена автомобиля с пробегом 2000 км.

Чтобы подобрать веса w~i~ линейного регрессора, на практике часто применяется [**метод наименьших квадратов**](http://www.machinelearning.ru/wiki/index.php?title=Метод_наименьших_квадратов) (МНК). Этот метод является алгоритмом обучения для модели.

Python скрипт для линейной регрессии цен на автомобили приводится в приложении 3.2 и на [Github](https://github.com/ellysh/ai-in-strategy-games/blob/master/manuscript/resources/code/ArtificialIntelligence/linear-regression.py).

#### Обучение без учителя

Обучение с учителем хорошо работает, когда есть большой объём размеченных данных. Однако подготавливать такие данные — трудоёмкий и дорогой процесс. Обычно это приходится делать вручную. Из-за сложной подготовки наборы обучающих данных получаются небольшими. Поэтому обучить на них удаётся только относительно простые модели. Для сложных моделей требуется больше данных.

Обученная модель нужна для решения какой-то прикладной задачи. Чем сложнее задача, тем сложнее должна быть модель. Если модель проще чем функция, которую она должна реализовать, возникает проблема [**недообучения**](https://wiki.loginom.ru/articles/underfitting.html) (underfitting). В случае недообучения обобщающая способность модели оказывается неприемлемо низкой.

Обучение без учителя решает проблему трудоёмкой подготовки обучающих данных. Такие алгоритмы обучения принимают на вход **неразмеченные данные**. Каждый обучающий пример таких данных содержит только вектор входных значений X = (x~1~, x~2~,..., x~n~).

Может возникнуть вопрос: если данные не размечены, как алгоритм обучения поймёт что с ними делать? Цели обучения с учителем и без принципиально отличаются. Цели обучения без учителя можно сформулировать так:

* Найти повторяющиеся закономерности в данных.
* Сгруппировать примеры по их сходству.
* Представить набор данных в сжатом формате.

Алгоритмы обучения без учителя строятся с учётом этих целей. Они работают не так, как алгоритмы обучения с учителем.

Вот несколько задач, которые решаются обучением без учителя:

* **Кластеризация** — объединение объектов в непересекающиеся группы на основе близости значений их признаков.

* **Обнаружение аномалий** — анализ множества объектов. Объекты с отличительными признаками помечаются как нетипичные.

* [**Сокращение размерности**](https://wiki.loginom.ru/articles/data-reduction.html) — преобразование данных в более удобную форму для их анализа и интерпретации.

* [**Поиск ассоциативных правил**](https://en.wikipedia.org/wiki/Association_rule_learning) — обнаружение неявных закономерностей в больших наборах данных.

Рассмотрим на примере кластеризации алгоритмы и модели обучения без учителя.

##### Кластеризация

Задача кластеризации заключается в том, чтобы разбить множество объектов на группы. В одну группу попадают объекты со сходными признаками.

Обучающие алгоритмы кластеризации работают с неразмеченными данными. Поэтому у разработчика нет возможности явно задать группы объектов. Алгоритм должен определить их сам в зависимости от признаков объектов.

Важное условие кластеризации: полученные группы объектов не должны пересекаться. Другими словами, каждый объект должен относится только к одной группе.

I> **Кластером** называется объединение набора объектов на основе их сходства.

Обучающий пример из набор данных для решения задачи кластеризации состоит из вектора входных значений X. В этом примере нет вектора выходных значений Y, которые ожидаются от модели. Алгоритм обучения выводит его самостоятельно для каждого примера и закладывает полученную зависимость вектора Y от X в модель.

Рассмотрим задачу кластеризации на примере. Предположим, что онлайн магазину нужно сгруппировать пользователей по интересом. Это позволит показывать каждому пользователю только интересную ему рекламу о новых товарах.

У магазина есть статистика о том, сколько раз каждый пользователь просматривал разные категории товаров. Для простоты предположим, что в магазине есть только две категории товаров: велозапчасти и автозапчасти.

Алгоритм обучения должен подготовить модель, которая относит пользователя к некоторому классу. В зависимости от этого класса магазин выбирает, какую рекламу показывать пользователю. Варианты могут быть следующие:

* Показывать рекламу только велозапчастей.
* Показывать рекламу только автозапчастей.
* Показывать рекламу и велозапчастей, и автозапчастей.
* Не показывать рекламу велозапчастей и автозапчастей.

Идея в том, чтобы пользователи получали рекламу только интересной им категории товаров. Другими словами, пользователи с большим числом просмотров велозапчастей должны получать рекламу новых велозапчастей. Аналогично для пользователей, предпочитающих автозапчасти, — они получают рекламу автозапчастей. Рекламу товаров обоих категорий получают те, кому интересны эти обе категории.

Применим один из популярных алгоритмов обучения для задачи кластеризации под названием [**метод k-средних**](https://en.wikipedia.org/wiki/K-means_clustering) (k-means). Среди прочих параметров этому алгоритму нужно указать число ожидаемых кластеров. В нашем примере это число равно четырём. Именно столько вариантов показа рекламы есть у онлайн магазина.

Метод k-средних в ходе обучения находит [**геометрический центр**](https://ru.wikipedia.org/wiki/Барицентр) (centroid) каждого кластера на пространстве признаков. Геометрический центр множества точек представляет собой среднее арифметическое координат этих точек. То есть координата геометрического центра по каждой оси равна сумме координат всех точек по этой оси, разделённая на количество точек.

Найденные геометрические центры кластеров являются обучаемой моделью. Готовая модель может определить к какому кластеру относится каждый из объектов в обучающем наборе данных. Для этого она вычисляет расстояние от объекта до центра каждого кластера на пространстве признаков. Ближайший к объекту центр определит, к какому кластеру его отнести.

Модель кластеризации также может определить кластер незнакомого ей объекта. Однако, такое использование модели нетипично. Правильнее будет добавить новый объект в обучающий набор и перезапустить алгоритм обучения.

Для наглядности представим обученную модель для нашего примера с онлайн магазином на графике. У каждого пользователя мы учитываем только два признака: посещения двух категорий товаров.Поэтому пространство признаков на графике будет двумерным. Его демонстрирует иллюстрация 2-16.

{caption: "Иллюстрация 2-16. Модель для кластеризации пользователей онлайн магазина", height: "50%", width: "100%"}
![Кластеризация пользователей](images/ArtificialIntelligence/online-shop-clustering.png)

Горизонтальная ось показывает количество посещений пользователями категории товаров автозапчасти. Вертикальная ось — количество посещений категории велозапчасти. Большие серые круги обозначают центры кластеров, которые нашел алгоритм k-средних. Ближайшие к этим центрам точки попали в соответствующий кластер.

Интерпретируем полученную модель для нашей задачи. Алгоритм k-средних выделил следующие четыре кластера пользователей:

* Жёлтые точки — пользователи с небольшим числом посещений обоих категорий товаров. Эти категории им не особенно интересны. Поэтому показывать рекламу им не нужно.

* Синие точки — пользователи, которые интересуются автозапчастями. Им нужно показывать рекламу новинок этой категории товаров.

* Фиолетовые точки — пользователи, которые интересуются велозапчастями. Им нужно показывать рекламу новинок этой категории товаров.

* Зелёные точки — пользователи, которые интересуются обоими категориями товаров. Им нужно показывать рекламу новинок из обоих категорий.

Благодаря нашей модели, онлайн магазин может учесть предпочтения каждого своего постоянного посетителя и показать интересную ему рекламу.

Если у магазина появился новый посетитель, по нему сначала надо собрать статистику: какие категории товаров он чаще посещает. Затем нового посетителя надо добавить в обучающий набор данных и повторить алгоритм k-средних. Так обученная модель учтёт предпочтения нового пользователя.

Python скрипт для кластеризации методом k-средних  случайно сгенерированного набора данных приведён в приложении 3.3 и на [Github](https://github.com/ellysh/ai-in-strategy-games/blob/master/manuscript/resources/code/ArtificialIntelligence/k-mean-clustering.py).

#### Обучение с подкреплением

Обучение с подкреплением принципиально отличается от обучения с учителем и без учителя. В последних двух парадигмах алгоритм обучения получает на вход заранее собранные и представленные в специальном формате данные. В обучении с подкреплением таких данных нет.

Обратимся к терминологии теории интеллектуальных агентов. Именно её применяют в обучении с подкреплением.

Алгоритмы обучения с учителем и без учителя создают модели, которые работают в эпизодических средах. Обучение происходит на несвязанных между собой примерах входных данных. Готовые модели обрабатывают такие же несвязанные новые данные. В этом случае прошлые решения агента никак не влияют на его последующие решения. Поэтому агент не отслеживает долгосрочные последствия своих действий. Как следствие, он не может эффективно работать в последовательной среде. В такой среде действия, успешные в краткосрочной перспективе, могут привести к негативным результатам в будущем. Чтобы учесть такие долгосрочные последствия, нужна иная парадигма обучения. Именно для таких задач применяется обучение с подкреплением.

Алгоритм обучения с подкреплением строит агента, который выбирает действия для различных наблюдаемых состояний среды. Выполняя эти действия, агент максимизирует числовой **сигнал вознаграждения** (reward signal). В процессе обучения агент не получает инструкций о том, какие действия следует выполнять. Вместо этого он должен самостоятельно пробовать разные действия и искать среди них те, которые дают максимальный сигнал вознаграждения.

Обучение с подкреплением отличают от других парадигм обучения две особенности:

1. Поиск [методом проб и ошибок](https://en.wikipedia.org/wiki/Trial_and_error) (trial-an-error).
2. Отсроченное по времени вознаграждение.

Главные компоненты обучения с подкреплением — это агент и среда. Каждое действие агента меняет состояние среды. В ответ на это, среда посылает сигнал вознаграждения. Величина этого сигнала позволяет агенту отличить успешные действия от неуспешных.

Кроме агента и среды в обучении с подкреплением есть четыре второстепенных элемента:

* **Стратегия** (policy) означает функцию агента в терминологии обучения с подкреплением. Эта функция определяет действие агента, как ответ на конкретное наблюдаемое состояние среды. Функция может представлять собой как простую таблицу соответствий состояние-действие, так и более сложный вычислительный процесс (например, алгоритм поиска). Поведение агента полностью определяется его функцией.

* **Сигнал вознаграждения** (reward signal) определяет цель обучения с подкреплением. Среда посылает агенту этот сигнал в ответ на каждое выполненное им действие. Вознаграждение представляет собой число. За успешные действия агент получает большее вознаграждение, чем за менее успешные. Главная цель агента — максимизировать своё суммарное вознаграждение в долгосрочной перспективе. Ориентируясь на вознаграждение, агент меняет свою стратегию. Таким образом он избегает действий с низким вознаграждением.

* **Функция полезности** (value function) для указанного состояния среды возвращает общую сумму вознаграждения. Эту сумму агент потенциально получит в будущем, если начнёт действовать с указанного состояния среды. Функция полезности определяет долгосрочную перспективу действий агента. Она учитывает вознаграждения от будущих состояний среды, которые станут доступны из указанного состояния. Это отличает функцию полезности от вознаграждения. Вознаграждение определяет желательность только текущего состояния среды без учёта доступных из него состояний.

* **Модель среды** (model) имитирует поведение среды. Используя модель, агент прогнозирует результат своих действий. Вот пример того, как работает модель. Она получает на вход текущее состояние среды и выбранное агентом действие. Исходя из этого, модель вычисляет следующее состояние среды и ожидаемый сигнал вознаграждения за выполненное действие. Благодаря модели, агент может планировать свои действия до их исполнения.

Алгоритмы обучения с подкреплением делятся на два типа в зависимости от использования модели среды:

1. **Основанные на модели** (model-based)
2. **Без модели** (model-free)

I> Обратите внимание на различие между терминами "модель среды" и "обучаемая модель". Вместо обучаемой модели в терминологии обучения с подкреплением применяется понятие "агент".

Перед тем, как обратиться к примеру обучения с подкреплением, разберёмся с двумя вопросами.

Первый вопрос: что означает термин "подкрепление"? Этот термин ввёл российский физиолог Иван Павлов в начале XX века. Подкреплением он назвал стимул, который усиливает модель поведения животного. Психологи расширили термин "подкрепление". Они обратили внимание на то, что модель поведение можно не только усиливать, но и ослаблять. Важная особенность "подкрепления" в том, что после устранения стимула, животное сохраняет выученное им поведение.

Теперь вернёмся к машинному обучению. Агент всегда действует в какой-то среде. Эта среда некоторым образом реагирует на каждое совершённое действие. Такую реакцию в численном виде представляет функция полезности. Для успешного действия функция вернёт большее значение, чем для менее успешного. Агент воспринимает это значение как поощрение или наказание. Он стремится повторять успешные действия и избегать неудачные. Такое воздействие среды на агента и называется "подкреплением".

Подкрепление бывает двух типов:

* **Положительное подкрепление** увеличивает склонность агента к успешному поведению.

* **Отрицательное подкрепление** уменьшает склонность агента совершать неудачные действия. Таким образом поведение агента в целом становится успешнее, поскольку он избегает состояния среды с низкими показателями функции полезности.

Второй вопрос: что означает поиск методом проб и ошибок в машинном обучении? Прежде всего это врождённый метод мышления человека и животных. Он заключается в повторении различных действий до тех пор, пока задача не будет решена. Например, именно этот метод использует мышь, которая ищет выход из лабиринта. Она пробует первый возможный путь. Если он заканчивается тупиком, мышь возвращается назад и пробует следующий вариант.

В обучении с подкреплением поведение агента напоминает поведение мыши в лабиринте. Изначально он ничего не знает о среде. Он пробует первое случайно выбранное действие. Если в ответ на него среда посылает положительный сигнал вознаграждения, агент запоминает это действие как успешное. Если сигнал вознаграждения отрицательный — агент будет избегать этого действия в дальнейшем.

После ряда попыток агент составляет список успешных действий. Благодаря функции полезности, эти действия можно объединить в последовательности <TODO: проверить эту идею>. Некоторые последовательности действий будут более успешными чем другие. Таким образом агент находит алгоритм решения задачи.

У метода проб и ошибок есть ряд особенностей. Допустим, что решается сложная задача. Её решение состоит из нескольких шагов, причем каждый шаг можно выполнить разными способами. В этом случае метод не найдёт эффективное решение. Вместо этого он даст первое сработавшее решение. Это означает, что интеллектуальный агент так же не сможет найти наилучшее возможное решение для сложной задачи.

Метод проб и ошибок приводит к поиску компромисса между исследованием и эксплуатированием (exploration and exploitation). Суть компромисса заключается в следующем: чтобы максимизировать вознаграждение, агенту лучше повторять уже знакомые успешные действия. Однако, чтобы найти их агент вынужден пробовать новые ещё неизвестные действия. Таким образом агент должен эксплуатировать знания, которые у него уже есть. Это позволит ему максимизировать вознаграждение в краткосрочной перспективе. В то же время агент вынужден исследовать новые действия, чтобы постараться улучшить вознаграждение в будущем.

Хорошей демонстрацией компромисса исследования и эксплуатировании является [проблема многорукого бандита](https://en.wikipedia.org/wiki/Multi-armed_bandit). Одноруким бандитом называется [игровой автомат](https://ru.wikipedia.org/wiki/Слот-машина). Пользователь должен бросить монету и дёрнуть за рычаг. После этого вращается барабан, который показывает комбинацию символов. Некоторые комбинации являются выигрышными.

В проблеме многорукого бандита у игрока есть набор игровых автоматов. У каждого автомата своё соотношение затрат к выигрышу. Изначально игрок не знает этих соотношений, но может их выяснить после нескольких попыток игры на автомате.

Задача игрока — максимизировать свой выигрыш, имея на руках ограниченное количество монет. Для этого он должен решить для себя следующее:

1. На каких автоматах ему играть?
2. Сколько раз играть на каждом автомате и в какой последовательности?
3. Стоит ли продолжать играть на текущем автомате или перейти к следующему?

Полное решение проблемы многорукого бандита требует большой объём вычислений. Однако, есть ряд приблизительных решений, которые дают не наилучший, но приемлемый результат.

##### Алгоритм обучения

Чтобы реализовать обучение с подкреплением на практике, применяют следующие подходы:

1. **Подход, основанный на полезности** (value-based) находит оптимальную функцию полезности. Используя эту функцию, агент выбирает действие с наилучшей полезностью в изученных состояниях среды. Таким образом он вычисляет долгосрочный результат своих действий в этих состояниях.

2. **Подход, основанный на стратегии** (policy-based) ищет оптимальную стратегию без использования функции полезности. Для такого поиска применяются [эволюционные алгоритмы](https://ru.wikipedia.org/wiki/Эволюционные_алгоритмы). Найденная оптимальная стратегия позволяет агенту получить максимально возможное итоговое вознаграждение за свои действия. Сами оптимальные стратегии бывают двух типов:

    * **Детерминированная стратегия** — предписывает агенту выполнять одни и те же действия в каждом состоянии среды.

    * **Вероятностная (стохастическая) стратегия** — агент выбирает случайно одно из нескольких возможных действий в каждом состоянии среды.

3. **Подход, основанный на модели** (model-based). Заключается в создании виртуальной модели среды. Агент исследует эту модель для того, чтобы изучить среду. После обучения агент использует полученную стратегию для выбора действий в среде.

Рассмотрим подходы обучения с подкреплением на примере. Допустим, что мы создаём агента для игры в крестики-нолики. Этот агент будет соревноваться с несовершенным игроком. Такой игрок допускает ошибки и иногда выбирает не лучший из своих возможных ходов.

Применим обучение с подкреплением для нашей задачи. Наш агент будет многократно играть с оппонентом. То каким образом агент получит свою финальную стратегию, будет зависеть от выбранного нами подхода.

Предположим, что мы выбрали подход, основанный на стратегии (policy-based). В этом случае мы применяем эволюционный алгоритм. Такой алгоритм генерирует набор случайных стратегий. В нашем случае стратегия — это правила, которые определяют следующий ход агента для любого возможного состояния поля игры крестики-нолики. Сгенерированные в начале стратегии называются первым поколением. Агент исполняет их, играя оппонентом. Каждая стратегия приводит к победе, поражению или ничьей.

Далее эволюционный алгоритм отбирает стратегии, которые привели к победе. Каждая из них модифицируется несколькими случайными способами. В результате получается набор стратегий второго поколения. Агент снова их исполняет и получает для каждой результат: ничья, поражение или победа. Этот процесс повторяется снова и снова до тех пор, пока алгоритм не найдёт стратегию, которая побеждает оппонента в большинстве игр. <TODO: проверить другие методы policy-based подхода>