## Машинное обучение

Мы рассмотрели методы формальной логики и алгоритмы поиска, которые применяются в программах интеллектуальных агентов. Теперь познакомимся с более сложными подходами, разработанными в рамках машинного обучения.

### Механизм обучения

Начнём с основных понятий, которые применяются в машинном обучении.

**Механизм обучения** это набор методов, который автоматически создаёт программу интеллектуального агента. Любой механизм обучения состоит из двух компонентов:

* **Алгоритм обучения**
* **Обучаемая модель**

Чтобы воспользоваться механизмом обучения, нужен **обучающий набор данных** (training set). Этот набор состоит из **обучающих примеров** (training sample).

 Алгоритм обучения получает на вход обучающий набор данных. Далее алгоритм находит в них закономерности и строит обучаемую модель. Эта модель учитывает все найденные закономерности.

Для разных типов обучаемых моделей применяются разные алгоритмы обучения. Алгоритм обучения определят требования к обучающему набору данных.

По принципу работы алгоритмы обучения делятся на три больших класса:

* [**Обучение с учителем**](https://ru.wikipedia.org/wiki/Обучение_с_учителем) или контролируемое (supervised learning)

* [**Обучение без учителя**](https://ru.wikipedia.org/wiki/Обучение_без_учителя) или неконтролируемое (unsupervised learning)

* [**Обучение с подкреплением**](https://ru.wikipedia.org/wiki/Обучение_с_подкреплением) (reinforcement learning)

Каждый класс представляет собой отдельную **парадигму**. Парадигма — это система предположений, концепций и практических приёмов для решения какой-то задачи.

Один и тот же алгоритм обучения можно представить в разных формах:

* С помощью математических формул.
* В виде псевдокода.
* В виде запускаемой программы.
* В виде программной библиотеки.

Форма представления выбирается исходя из задачи. Первые две формы чаще применяются в образовательных целях. Последние две — на практике.

Обучаемая модель — это то, что строит алгоритм обучения после обработки обучающего набора данных. Модель хранит результаты процесса обучения. Она состоит из правил и наборов данных, которые необходимы для прогнозирования. По-сути модель — это программа. Она имеет данные и машинные инструкции для их обработки. Инструкции используют данные, чтобы выполнять прогнозы для новых наборов данных. Эти наборы представляют собой восприятие агента в процессе его работы.

Можно сказать, что обучаемая модель состоит из двух компонентов:

* **Данные модели**
* **Алгоритм для прогнозирования**

Цель машинного обучения — автоматически получить обучаемую модель. Алгоритм обучения используется как средство достижения этой цели. Он влияет на качество обучаемой модели. При этом конечная программа агента никак не использует алгоритм обучения.

### Алгоритмы обучения

Теперь познакомимся с парадигмами алгоритмов обучения.

Таблица 2-18 для каждой парадигмы обучения демонстрирует решаемые с её помощью задачи

{caption: "Таблица 2-18. Парадигмы алгоритмов обучения", width: "100%"}
| Парадигма обучения | Задачи |
| --- | --- |
| Обучение с учителем | Регрессия |
|  | Классификация |
|  | Структурный вывод |
|  | |
| Обучение без учителя | Кластеризация |
|  | Обнаружение аномалий |
|  | Визуализация |
|  | Сокращение размерности |
|  | Поиск ассоциативных правил |
|  | |
| Обучение с подкреплением | Машинный перевод |
|  | Задача управления |

#### Обучение с учителем

Алгоритмы обучения с учителем принимают на вход **размеченные данные**. Можно применить терминологию интеллектуальных агентов и описать размеченный обучающий пример так:

*Обучающий пример содержит акт восприятия агента и ожидаемое действие на него.*

Продолжим пользоваться этой же терминологией, чтобы описать алгоритм обучения с учителем. Алгоритм принимает на вход размеченные данные. Эти данные содержат примеры работы желаемой функции агента. В результате обучения алгоритм строит модель. Она реализует функцию агента, поведение которой близко к желаемой.

Теперь перейдём к терминологии, принятой в машинном обучении. Она более точна, но в то же время сложнее для понимания. Для начала дадим определение размеченному обучающему примеру:

*Обучающий пример представляет собой пару векторов X = (x~1~, x~2~,..., x~n~) и Y = (y~1~, y~2~,..., y~n~). X – это вектор входных значений, а Y – вектор выходных значений. Вектор Y должна вернуть обучаемая модель при получении на вход вектора X.*

I> **Вектором** в контексте машинного обучения называют упорядоченный набор чисел.

Теперь рассмотрим общий алгоритм обучения с учителем. Алгоритм передаёт на вход модели вектор входных значений X очередного примера из обучающего набора. Модель в ответ на эти входные значения возвращает вектор выходных значений Y'.

Далее алгоритм обучения сравнивает вектора Y из обучающего примера и Y', полученный от модели. Если эти вектора не совпадают, это называется [**ошибкой обучения**](https://wiki.loginom.ru/articles/training-error.html) (training error). При возникновении такой ошибки алгоритм обучения автоматически изменяет параметры модели. Если вектора Y и Y' совпали, алгоритм обучения переходит к следующему примеру.

Когда обучаемая модель готова, её точность можно оценить с помощью размеченного **тестового набора данных**. Эти данные не входят в обучающий набор, поэтому модель никогда с ними не встречалась. Для каждого **тестового примера** модель возвращает вектор выходных значений Y'. Если он не совпадает с вектором Y из примера, это называется [**ошибкой обобщения**](https://wiki.loginom.ru/articles/generalization-error.html) (generalization error). При высокой частоте таких ошибок, говорят что **производительность** модели низка.

Чтобы улучшить производительность модели, есть целый [ряд методов](https://machinelearningmastery.com/improve-deep-learning-performance/). Некоторые из них меняют конфигурацию модели. В результате она подгоняется под обучающий и тестовый набор данных. Эта проблема называется [**переобучением**](https://wiki.loginom.ru/articles/overtraining.html) (overtraining или overfitting). Из-за переобучения модель хорошо работает на обучающих и тестовых наборах, но часто ошибается на реальных данных. В этом случае говорят о плохой **обобщающей способности модели** (generalization ability).

Обобщающая способность — это способность обучаемой модели выдавать правильные выходные значения не только для обучающих и тестовых примеров, но и для любых данных, с которыми модель ранее не сталкивалась.

Чтобы оценить обобщающую способность модели применяют, её проверяют на **валидационном наборе данных** (validation set). Примеры из этого набора не входят ни в обучающий, ни в тестовый наборы. Такая проверка модели называется **валидацией**. Она нужна, чтобы оценить предсказательную способность модели.

Обучение с учителем эффективно для решения следующих задач:

* Классификация
* Регрессия
* Структурный вывод

Рассмотрим подробнее первые две задачи и примеры к ним. Это даст нам общее представление об алгоритмах и моделях обучения с учителем.

##### Классификация

Задача **классификации** заключается в определении класса объекта по его параметры. Параметры объекта в терминологии машинного обучения называются **признаками**. Пример объекта — автомобиль. Его признаки: габариты, мощность двигателя, расход топлива и т.д.

Для обучения модели, которая решает задачу классификации, применяется набор обучающих данных специального формата. В каждом примере вектор входных значений X представляет собой все проверяемые признаки конкретного объекта. Выходной вектор Y состоит из единственного скалярного значения y. Оно определяет номер класса, к которому следует отнести объект из примера. Этот номер класса называется **меткой**.

Говорят, что при решении задачи классификации обучаемая модель возвращает дискретные значения.

Каноничным примером для демонстрации задачи классификации считается набор данных под названием [**ирисы Фишера**](https://ru.wikipedia.org/wiki/Ирисы_Фишера). С его помощью английский статистик и биолог Роналд Фишер продемонстрировал разработанный им метод статистического анализа в 1936 году.

Набор данных представляет собой таблицу со следующей информацией:

1. Длина чашелистника (sepal) цветка.
2. Ширина чашелистника (sepal) цветка.
3. Длина лепестка (petal) цветка.
4. Ширина лепестка (petal) цветка.
5. Вид ириса.

Всего в таблице 150 записей для трёх типов ириса. Для каждого типа есть по 50 записей с разными разными параметрами цветка.

Для простоты мы рассмотрим только два параметра цветка: длина и ширина чашелистника. По этим признакам агент должен определить, относится ли растение к виду Iris setosa или к другому виду.

В ходе обучения на наборе данных, алгоритм строит модель. Простейшая модель для классификации представляет собой формулу для расчёта выходного значения y по вектору входных значений X. Модели такого типа называются [**линейными классификаторами**](https://ru.wikipedia.org/wiki/Линейный_классификатор).

Формула линейного классификатора в общем виде выглядит так:

![Формула линейного классификатора](images/ArtificialIntelligence/linear-classifier-formula.png)

В этой формуле используются следующие обозначения:

* y — выходное значение функции агента
* f — пороговая функция
* w~i~ — вес признака под номером i
* x~i~ — значение признака под номером i

**Пороговая функция** f отображает все возможные суммы (w~i~ * x~i~) на два дискретных значения. Обычно это значения 0 и 1. Они соответствуют двум классам объектов. Допустим, что в нашем случае значение 0 соответствует виду Iris setosa, а 1 — другому виду ирисов.

**Вес** признаков w~i~ — это некоторые коэффициенты, которые подбирает алгоритм обучения. Благодаря правильно подобранным весам, пороговая функция может однозначно различать классы объектов.

Теперь вернёмся к нашему примеру с ирисами. Мы рассматриваем только два признака: ширина и длина чашелистника цветка. Поэтому формулу линейного классификатора можно упростить до такого вида:

![Формула классификатора ирисов](images/ArtificialIntelligence/iris-classifier-formula.png)

Обозначения в формуле следующие:

* y — выходное значение функции агента
* f — пороговая функция
* w~1~ — вес признака ширина чашелистника
* x~1~ — ширина чашелистника
* w~2~ — вес признака длина чашелистника
* x~2~ — длина чашелистника

Возникает вопрос: какая именно пороговая функция f используется в формуле? Эта функция зависит от конкретной обучаемой модели, которую мы решим использовать. Вот некоторые из моделей, которые применяют на практике для линейной классификации:

* [**Машина поддерживающих векторов**](https://ru.wikipedia.org/wiki/Метод_опорных_векторов) (support vector machine или SVM).

* [**Логистическая регрессия**](https://ru.wikipedia.org/wiki/Логистическая_регрессия) или логит-модель (logit model).

* [Нейронная сеть перцептрон](https://www.mathematik.uni-muenchen.de/~deckert/teaching/SS18/sec-steps.html).

Для наглядности модель линейного классификатора удобно представлять в виде графика. Этот график строится на **пространстве признаков**. Размерность этого пространства совпадает с количеством проверяемых признаков объекта.

В нашем случае признаков два, поэтому график строится в двумерном пространстве. Его демонстрирует иллюстрация 2-14.

{caption: "Иллюстрация 2-14. Модель для классификации ирисов", height: "50%", width: "100%"}
![Классификация ирисов](images/ArtificialIntelligence/fisher-iris-classification.png)

На горизонтальной оси откладывается ширина чашелистника в сантиметрах для каждого примера из обучающего набора данных. На вертикальной оси — длина чашелистника. Фиолетовые крестики в правой нижней части обозначают ирисы вида Iris setosa. Зелёные крестики слева вверху — это ирисы видов Iris virginica и Iris versicolor. Синяя линия соответствует границе между классами, которую построил алгоритм обучения.

Наклон линии границы между классами определяют веса w~1~ и w~2~, которые подобрал алгоритм обучения.

Рассмотрим, как работает обученная и проверенная модель. На вход она получает вектор X. Элементы вектора: ширина и длина чашелистника ириса, вид которого надо определить. Модель подставляет полученные признаки x~1~ и x~2~ в формулу и вычисляет значение y. Если y равно 0, то проверяемый ирис относится к виду Iris setosa. Если y равно 1, то мы столкнулись с ирисом какого-то другого вида.

Работу модели можно наглядно представить, если обратиться к графику на иллюстрации 2-14. Предположим, что модель получила входные данные: ширина и длина чашелистника неизвестного ириса. Отложим на горизонтальной и вертикальной оси значения этих признаков. Если точка оказалась ниже границы классов, проверяемый ирис относится к виду Iris setosa. В противном случае, этот ирис относится к другому виду.

Остаётся открытым один вопрос: как именно алгоритм обучения подбирает веса w~1~ и w~2~ в нашем примере с ирисами? Для моделей линейных классификаторов часто применятся [**стохастический градиентный спуск**](https://ru.wikipedia.org/wiki/Стохастический_градиентный_спуск).

##### Регрессия

Задача **регрессии** — это прогноз значений некоторой **зависимой переменной** y от вектора **независимых переменных** X. Связь между зависимыми и независимыми переменными математическая: изменение значений независимых переменных систематически меняет значение зависимой.

Рассмотрим обучающий набор данных для модели, решающей задачу регрессии. Пример состоит из вектора независимых переменных X и единственного зависимого от них значения y. В отличие от задачи классификации y является вещественным числом. В этом случае говорят, что модель возвращает непрерывные значения.

Вот пример задачи регрессии. Нам нужно оценить стоимость автомобиля Volkswagen Golf в зависимости от его пробега. В этом случае мы учитываем единственный признак объекта — пробег в километрах.

Чтобы обучить модель, нам нужен набор данных. Каждый пример этого набора представляет собой пару значений: цена и пробег. Пробег будет единственным элементом вектора X независимых переменных. Цена будет зависимой переменной y.

Предположим, что мы проверили рынок поддержанных автомобилей и нашли там несколько Volkswagen Golf с пробегом. Цены и пробег этих машин мы заносим в таблицу. Теперь эти данные мы передаём алгоритму обучения, который строит модель.

Наша модель принимает на вход пробег автомобиля. По этому признаку она предсказывает примерную стоимость автомобиля. Модели такого типа называются **линейными регрессорами**.

Формула линейного регрессора в общем виде выглядит так:

![Формула линейного регрессора](images/ArtificialIntelligence/linear-regressor-formula.png)

В ней используются следующие обозначения:

* y — выходное значение функции агента
* w~i~ — вес признака под номером i
* x~i~ — значение признака под номером i
* ε — случайная ошибка модели

Линейный регрессор в отличие от классификатора не использует пороговую функцию f. Это значит, модель регрессора представляет собой формулу с правильно подобранными весами w~i~.

Вернёмся к нашей задаче определения цены на поддержанный Volkswagen Golf. Мы рассматриваем только один признак машины — её пробег. Поэтому в формуле регрессора остаётся только независимая переменная x~1~ и её вес w~1~. Таким образом формула принимает следующий вид:

![Формула регрессора стоимости](images/ArtificialIntelligence/cost-regressor-formula.png)

Обозначения в формуле следующие:

* y — выходное значение функции агента
* w~1~ — вес признака пробег автомобиля
* x~1~ — пробег автомобиля в километрах
* ε — случайная ошибка модели

Модель линейного регрессора можно представить в виде графика. В отличии от линейного классификатора к пространству признаков надо добавить ещё одно измерение — значение зависимой переменной y. Поскольку в нашем примере рассматривается только один признак, пространство для изображения модели будет двумерным. Первое измерение в нём — пробег автомобиля в километрах x~1~, а второе — цена y.

Иллюстрация 2-15 демонстрирует модель линейного регрессора для определения цены Volkswagen Golf.

{caption: "Иллюстрация 2-15. Модель для вычисления стоимости автомобиля", height: "50%", width: "100%"}
![Стоимость автомобиля](images/ArtificialIntelligence/car-cost-regression.png)

На горизонтальной оси отображается пробег автомобиля в километрах. На вертикальной оси — его цена. Фиолетовые крестики обозначают обучающий набор данных. На графике изображены шесть крестиков — это шесть машин с разным пробегом и их актуальные цены. Мы получили их из анализа рынка поддержанных машин. Зелёная линия отображает зависимость между пробегом и ценой автомобиля. Это и есть наша модель, которую построил алгоритм обучения.

Наклон линии на иллюстрации 2-15 определяется весом w~1~.

Рассмотрим, как работает полученная нами модель. На вход она получает вектор независимых переменных X. Он состоит из единственного значения x~1~ — пробег автомобиля, цену которого надо определить. Модель подставляет это значение x~1~ в формулу и вычисляет y. Значение y — это искомая цена автомобиля.

Работу модели можно наглядно представить с помощью иллюстрации 2-15. Для этого надо отложить пробег неизвестного автомобиля по горизонтальной оси. Пусть это будет 3500 км. Этому значению соответствует одна точка на зелёной линии. По вертикальной оси этой точке соответствует цена 17050$. Это и будет искомой ценой автомобиля.

Чтобы подобрать веса w~i~ линейного регрессора, на практике часто применяется [**метод наименьших квадратов**](http://www.machinelearning.ru/wiki/index.php?title=Метод_наименьших_квадратов) (МНК). Этот метод и есть алгоритм обучения для модели.

#### Обучение без учителя

Обучение с учителем хорошо работает, когда есть достаточный объём размеченных данных. Однако подготавливать такие данные — трудоёмкий и дорогой процесс. Обычно это приходится делать вручную. Из-за сложной подготовки наборы обучающих данных получаются небольшими. Это приводит к тому, что обучить на них удаётся только относительно простые модели. Сложные модели требуют больший объем обучающих данных.

Обученная модель нужна для решения какой-то прикладной задачи. Чем сложнее задача, тем сложнее должна быть модель. Если модель проще чем функция, которую она должна реализовать, возникает проблема [**недообучения**](https://wiki.loginom.ru/articles/underfitting.html) (underfitting). В случае недообучения обобщающая способность модели оказывается неприемлемо низкой.

Обучение без учителя решает проблему трудоёмкой подготовки обучающих данных. Такие алгоритмы обучения принимают на вход **неразмеченные данные**. Каждый обучающий пример таких данных содержит только вектор входных значений X = (x~1~, x~2~,..., x~n~).

Может возникнуть вопрос: если данные не размечены, как алгоритм обучения поймёт что с ними делать? Цели обучения с учителем и без принципиально отличаются. Цели обучения без учителя можно сформулировать так:

* Найти повторяющиеся закономерности в данных.
* Сгруппировать примеры по их сходству.
* Представить набор данных в сжатом формате.

Алгоритмы обучения без учителя строятся с учётом этих целей. Они работают не так, как алгоритмы обучения с учителем.

Вот несколько задач, которые решаются обучением без учителя:

* Кластеризация
* Обнаружение аномалий
* Визуализация
* Сокращение размерности
* Поиск ассоциативных правил

Рассмотрим на примере кластеризации алгоритмы и модели обучения без учителя.

##### Кластеризация

#### Обучение с подкреплением

// TODO: Удалить следующий раздел

### Обучаемые модели

Чаще всего применяются следующие обучаемые модели:

* **Нейронная сеть** (artificial neural network) состоит их искусственных нейронов. Нейроны соединяются направленными связями. Через эти связи по сети распространяются сигналы. Каждая связь имеет числовой вес, который определяет силу и знак связи. Веса входных связей нейрона определяют, какие сигналы приведут к его активации. Нейрон после активации посылает выходной сигнал. В процессе обучения агент подбирает правильные числовые веса для всех связей в сети.

* [**Дерево решений**](https://ru.wikipedia.org/wiki/Обучение_дерева_решений) (decision tree learning). В результате обучения агент строит дерево решений. Построенное дерево реализует функцию агента: получает на вход последовательность актов восприятия и на их основе выбирает подходящее действие. Чтобы выбрать действие, над входными данными выполняется серия проверок. Каждый узел дерева соответствует условию проверки, а исходящие из него ветви — результатам проверки.

* [**Машина поддерживающих векторов**](https://ru.wikipedia.org/wiki/Метод_опорных_векторов) (support vector machine или SVM) представляет собой модель и набор алгоритмов для работы с ней. Машина обучается с учителем на примерах. Для каждого примера указано, к какому из двух классов он относится. После обучения машина определяет класс полученного на вход примера. SVM решает задачи **линейной** и **нелинейной классификации**.

I> [Линейная классификация](https://ru.wikipedia.org/wiki/Линейный_классификатор) сводится к разделению множества точек в пространстве признаков одной гиперплоскостью. **Гиперплоскость** имеет на одну размерность меньше, чем объемлющее её пространство. Например, гиперплоскость для двумерного пространства — это прямая.

* [**Байесовская сеть**](https://ru.wikipedia.org/wiki/Байесовская_сеть) (Bayesian network) представляет собой направленный граф. Его вершины — это переменные произвольного типа (признаки, теории и т.д.). Граф отображает [условные зависимости](https://en.wikipedia.org/wiki/Conditional_dependence) между переменными. Пример использования сети: вычисление вероятности той или иной болезни у пациента по её симптомам.

* [**Генетический алгоритм**](https://ru.wikipedia.org/wiki/Генетический_алгоритм) (genetic algorithm) — это модель, которая имитирует процесс естественного отбора. В процессе обучения такой модели применяются методы мутации, скрещивания и отбора. Эти методы производят новые версии модели, которые обладают нужными характеристиками.

Таблица 2-18 демонстрирует какие алгоритмы обучения применяются для разных моделей. Кроме того в таблице указан класс модели: deep learning или shallow learning.

{caption: "Таблица 2-18. Соответствие алгоритмов обучения и моделей", width: "100%"}
| Модель | Класс модели | Алгоритм обучения |
| --- | --- | --- |
| Однослойная нейронная сеть | Shallow learning | Обучение с учителем |
|  | | |
| Глубокая нейронная сеть (DNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Глубокая сеть доверия (DBN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | |
| Рекуррентная нейронная сеть (RNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Свёрточная нейронная сеть (CNN) | Deep learning | Обучение с учителем |
|  | | |
| Дерево решений | Shallow learning | Обучение с учителем |
|  | | |
| Машина поддерживающих векторов | Shallow learning | Обучение с учителем |
|  | | |
| Байесовская сеть | Shallow learning | Обучение с учителем |
|  | | |
| Генетический алгоритм | Shallow learning | Обучение с учителем |

#### Дерево решений

#### Нейронная сеть