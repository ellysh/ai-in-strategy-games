## Машинное обучение

Мы рассмотрели методы формальной логики и алгоритмы поиска, которые применяются в программах интеллектуальных агентов. Теперь познакомимся с более сложными подходами, разработанными в рамках машинного обучения.

### Алгоритмы обучения

Механизм обучения автоматически создаёт программу интеллектуального агента.

Любой механизм обучения состоит из двух компонентов:

* **Алгоритм обучения**
* **Обучаемая модель**

Чтобы воспользоваться механизмом обучения, нужен **обучающий набор данных**. Этот набор получает на вход алгоритм обучения. Он находит в данных закономерности и строит обучаемую модель. Эта модель учитывает все найденные закономерности.

Для разных типов обучаемых моделей применяются разные алгоритмы обучения. По принципу работы все эти алгоритмы делят на три больших класса:

* [**Обучение с учителем**](https://ru.wikipedia.org/wiki/Обучение_с_учителем) или контролируемое (supervised learning)

* [**Обучение без учителя**](https://ru.wikipedia.org/wiki/Обучение_без_учителя) или неконтролируемое (unsupervised learning)

* [**Обучение с подкреплением**](https://ru.wikipedia.org/wiki/Обучение_с_подкреплением) (reinforcement learning)

#### Обучение с учителем

Обучение с учителем считается самым простым классом алгоритмов. При этом такое обучение предъявляет самые высокие требования к обучающему набору данных. Этот набор состоит из примеров последовательностей актов восприятия и соответствующих им действий агента. Такие данные называются **размеченными**.

Пример размеченных данных — набор картинок животных. У каждой картинки есть метка с названием изображённого животного: "кот", "собака" и т.д.

Алгоритм обучения получает на вход размеченные данные. Таким образом он наблюдает за примерами работы функции агента, которую надо получить. В результате обучения алгоритм строит модель. Она реализует функцию агента, близкую к ожидаемой.

Обучение с учителем эффективно для решения двух классов задач:

* Классификация
* Регрессия

Задача **классификации** заключается в разделении заданного множества объектов на классы. При решении этой задачи функция агента возвращает дискретные значения, которые соответствуют определённым классам.

Вот простой пример классификации. На датчики агента поступает картинка с животным. Агент должен определить, что за животное на картинке: кошка или собака.

Задача **регрессии** — это прогноз значений некоторой **зависимой переменной** от одной или более **независимых переменных**. Связь между зависимыми и независимыми переменными математическая: изменение значений независимых переменных систематически меняет значение зависимой.

При решении задачи регрессии функция агента возвращает непрерывные значения (вещественное число). Пример такого значения: стоимость одной акции какой-то компании. Эта стоимость представляет собой зависимую переменную. Она может определяться такими независимыми переменными как прибыль компании, её репутация, доходность и надёжность.

Достоинства:

Недостатки:

#### Обучение без учителя

Обучение без учителя — это более сложный подход.

#### Обучение с подкреплением

### Обучаемые модели

Обучаемая модель — это то, что построил алгоритм обучения посоле обработки конкретных входных данных. Модель представляет собой правила и набор данных, которые необходимы для прогнозирования.

Вот несколько примеров обучаемой модели:

* Алгоритм линейной регрессии строит модель, которая состоит из вектора коэффициентов с определёнными значениями.

* Алгоритм дерева решений генерирует последовательность условных операторов. Они проверяют факты относительно какого-то объекта.

* Алгоритм обратного распространения ошибки для нейронной сети создаёт модель, которая представляет собой направленный граф. Пути между вершинами этого графа имеют веса.

Обучаемая модель представляет собой программу агента, которую автоматически создаёт алгоритм обучения.

Чаще всего применяются следующие обучаемые модели:

* **Нейронная сеть** (artificial neural network) состоит их искусственных нейронов. Нейроны соединяются направленными связями. Через эти связи по сети распространяются сигналы. Каждая связь имеет числовой вес, который определяет силу и знак связи. Веса входных связей нейрона определяют, какие сигналы приведут к его активации. Нейрон после активации посылает выходной сигнал. В процессе обучения агент подбирает правильные числовые веса для всех связей в сети.

* [**Дерево решений**](https://ru.wikipedia.org/wiki/Обучение_дерева_решений) (decision tree learning). В результате обучения агент строит дерево решений. Построенное дерево реализует функцию агента: получает на вход последовательность актов восприятия и на их основе выбирает подходящее действие. Чтобы выбрать действие, над входными данными выполняется серия проверок. Каждый узел дерева соответствует условию проверки, а исходящие из него ветви — результатам проверки.

* [**Машина поддерживающих векторов**](https://ru.wikipedia.org/wiki/Метод_опорных_векторов) (support vector machine или SVM) представляет собой модель и набор алгоритмов для работы с ней. Машина обучается с учителем на примерах. Для каждого примера указано, к какому из двух классов он относится. После обучения машина определяет класс полученного на вход примера. SVM решает задачи **линейной** и **нелинейной классификации**.

I> [Линейная классификация](https://ru.wikipedia.org/wiki/Линейный_классификатор) сводится к разделению множества точек в пространстве признаков одной гиперплоскостью. **Гиперплоскость** имеет на одну размерность меньше, чем объемлющее её пространство. Например, гиперплоскость для двумерного пространства — это прямая.

* [**Байесовская сеть**](https://ru.wikipedia.org/wiki/Байесовская_сеть) (Bayesian network) представляет собой направленный граф. Его вершины — это переменные произвольного типа (признаки, теории и т.д.). Граф отображает [условные зависимости](https://en.wikipedia.org/wiki/Conditional_dependence) между переменными. Пример использования сети: вычисление вероятности той или иной болезни у пациента по её симптомам.

* [**Генетический алгоритм**](https://ru.wikipedia.org/wiki/Генетический_алгоритм) (genetic algorithm) — это модель, которая имитирует процесс естественного отбора. В процессе обучения такой модели применяются методы мутации, скрещивания и отбора. Эти методы производят новые версии модели, которые обладают нужными характеристиками.

Таблица 2-18 демонстрирует какие алгоритмы обучения применяются для разных моделей. Кроме того в таблице указан класс модели: deep learning или shallow learning.

{caption: "Таблица 2-18. Соответствие алгоритмов обучения и моделей", width: "100%"}
| Модель | Класс модели | Алгоритм обучения |
| --- | --- | --- |
| Однослойная нейронная сеть | Shallow learning | Обучение с учителем |
|  | | |
| Глубокая нейронная сеть (DNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Глубокая сеть доверия (DBN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | |
| Рекуррентная нейронная сеть (RNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Свёрточная нейронная сеть (CNN) | Deep learning | Обучение с учителем |
|  | | |
| Дерево решений | Shallow learning | Обучение с учителем |
|  | | |
| Машина поддерживающих векторов | Shallow learning | Обучение с учителем |
|  | | |
| Байесовская сеть | Shallow learning | Обучение с учителем |
|  | | |
| Генетический алгоритм | Shallow learning | Обучение с учителем |

#### Дерево решений

#### Нейронная сеть