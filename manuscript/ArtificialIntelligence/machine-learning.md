## Машинное обучение

Мы рассмотрели методы формальной логики и алгоритмы поиска, которые применяются в программах интеллектуальных агентов. Теперь познакомимся с более сложными подходами, разработанными в рамках машинного обучения.

### Механизм обучения

Начнём с основных понятий, которые применяются в машинном обучении.

**Механизм обучения** это набор методов, который автоматически создаёт программу интеллектуального агента.

Любой механизм обучения состоит из двух компонентов:

* **Алгоритм обучения**
* **Обучаемая модель**

Чтобы воспользоваться механизмом обучения, нужен **обучающий набор данных**. Алгоритм обучения получает на вход этот набор. Далее алгоритм находит в данных закономерности и строит обучаемую модель. Эта модель учитывает все найденные закономерности.

Для разных типов обучаемых моделей применяются разные алгоритмы обучения. По принципу работы эти алгоритмы делятся на три больших класса:

* [**Обучение с учителем**](https://ru.wikipedia.org/wiki/Обучение_с_учителем) или контролируемое (supervised learning)

* [**Обучение без учителя**](https://ru.wikipedia.org/wiki/Обучение_без_учителя) или неконтролируемое (unsupervised learning)

* [**Обучение с подкреплением**](https://ru.wikipedia.org/wiki/Обучение_с_подкреплением) (reinforcement learning)

Каждый класс представляет собой отдельную **парадигму**. Парадигма — это система предположений, концепций и практических приёмов для решения какой-то задачи.

Алгоритмы обучения можно представить в разных формах:

* С помощью математических формул.
* В виде псевдокода.
* В виде запускаемой программы.
* В виде программной библиотеки.

Обучаемая модель — это то, что строит алгоритм обучения после обработки обучающего набора данных. Модель хранит результаты процесса обучения.

Обучаемая модель состоит из правил и наборов данных, которые необходимы для прогнозирования. По-сути модель — это программа. Она имеет данные и машинные инструкции для их обработки. Инструкции используют данные, чтобы выполнять прогнозы для новых наборов данных. Эти наборы представляют собой восприятие агента в процессе его работы.

Можно сказать, что обучаемая модель состоит из двух компонентов:

* **Данные модели**
* **Алгоритм для прогнозирования**

Цель машинного обучения — автоматически получить обучаемую модель. Алгоритм обучения используется как средство достижения этой цели. Он влияет на качество обучаемой модели. При этом конечная программа агента никак не использует алгоритм обучения.

### Алгоритмы обучения

#### Обучение с учителем

Проще всего понять парадигму обучения с учителем. Она предъявляет самые высокие требования к обучающему набору данных. Этот набор должен состоять из примеров последовательностей актов восприятия и соответствующих им действий агента. Такие данные называются **размеченными**.

Пример размеченных данных — набор картинок животных. У каждой картинки есть **метка** с названием изображённого животного: "кот", "собака" и т.д.

Алгоритм обучения получает на вход размеченные данные. Таким образом он наблюдает за примерами работы функции агента, которую надо получить. В результате обучения алгоритм строит модель. Она реализует функцию агента, близкую к ожидаемой.

Обучение с учителем эффективно для решения двух классов задач:

* Классификация
* Регрессия

##### Классификация

Задача **классификации** заключается в разделении заданного множества объектов на классы. При решении этой задачи функция агента возвращает дискретные значения, которые соответствуют определённым классам.

Каноничным примером для демонстрации задачи классификации считается набор данных под названием [**ирисы Фишера**](https://ru.wikipedia.org/wiki/Ирисы_Фишера). С его помощью английский статистик и биолог Роналд Фишер продемонстрировал разработанный им метод статистического анализа в 1936 году.

Набор данных представляет собой таблицу со следующей информацией:

1. Длина чашелистника (sepal) цветка.
2. Ширина чашелистника (sepal) цветка.
3. Длина лепестка (petal) цветка.
4. Ширина лепестка (petal) цветка.
5. Вид ириса.

Всего в таблице 150 записей для трёх типов ириса. К каждому типу относится по 50 записей.

Для простоты мы рассмотрим только два параметра цветка: длина и ширина чашелистника. Эти параметры объектов в терминологии машинного обучения называются **признаками**. По признакам агент должен определить, относится ли растение к виду Iris setosa.

В ходе обучения на наборе данных, алгоритм строит функцию агента. Её график на **пространстве признаков** демонстрирует иллюстрация 2-14. Поскольку признаков только два, пространство признаков двумерное в нашем случае. В общем случае размерность пространства соответствует количеству проверяемых признаков объекта.

{caption: "Иллюстрация 2-14. Функция агента для классификации ирисов", height: "50%", width: "100%"}
![Классификация ирисов](images/ArtificialIntelligence/fisher-iris-classification.png)

На горизонтальной оси отображается ширина чашелистника. На вертикальной оси — длина чашелистника. Синим крестикам соответствуют ирисы вида Iris setosa, а красным крестикам — виды Iris virginica и Iris versicolor. Синяя линия соответствует границе между классами, которую построил алгоритм обучения.

Допустим, агент получает длину и ширину чашелистника неизвестного вида ириса. Этому виду будет соответствовать новая точка в пространстве признаков. Агент вычисляет положение этой точки относительно линии границы между классами. Если точка оказалась выше линии границы, то агент отнесёт растение к виду Iris setosa. В противном случае агент сделает вывод, что растение относится к другому виду ирисов.

Полученный нами агент называется [**линейным классификатором**](https://ru.wikipedia.org/wiki/Линейный_классификатор). При принятии решения такой классификатор использует формулу, которую можно записать в общем виде:

![Формула линейного классификатора](images/ArtificialIntelligence/linear-classifier-formula.png)

В этой формуле используются следующие обозначения:

* y — выходное значение функции агента
* f — пороговая функция
* w~i~ — вес признака под номером i
* x~i~ — значение признака под номером i

**Пороговая функция** отображает все возможные суммы w~i~ * x~i~ на два дискретных значения. Обычно это значения 0 и 1. Они соответствуют двум классам объектов. В нашем случае эти классы: вид Iris setosa и другие виды.

Вес признаков w~i~ — это некоторые коэффициенты, которые подбирает алгоритм обучения. Благодаря правильно подобранным весам, пороговая функция может однозначно различать классы объектов.

Для линейного классификатора ирисов из нашего примера формула выглядит так:

![Формула классификатора ирисов](images/ArtificialIntelligence/iris-classifier-formula.png)

Обозначения в формуле следующие:

* y — выходное значение функции агента
* f — пороговая функция
* w~1~ — вес признака ширина чашелистника
* x~1~ — ширина чашелистника
* w~2~ — вес признака длина чашелистника
* x~2~ — длина чашелистника

##### Регрессия

Задача **регрессии** — это прогноз значений некоторой **зависимой переменной** y от одной или более **независимых переменных** x~1~, x~2~, x~3~... Связь между зависимыми и независимыми переменными математическая: изменение значений независимых переменных систематически меняет значение зависимой.

При решении задачи регрессии функция агента принимает на вход набор независимых переменных. По этим переменным функция вычисляет значение, которое является вещественным числом. В этом случае говорят, что функция агента возвращает непрерывные значения.

Рассмотрим пример задачи регрессии. Нам нужно оценить стоимость автомобиля в зависимости от его пробега. В этом случае мы имеем единственный признак объекта — пробег в километрах. Иллюстрация 2-15 демонстрирует нужную нам зависимость для машины Volkswagen Golf.

{caption: "Иллюстрация 2-15. Функция агента для вычисления стоимости автомобиля", height: "50%", width: "100%"}
![Стоимость автомобиля](images/ArtificialIntelligence/car-cost-regression.png)

На горизонтальной оси отображается пробег машины в километрах. На вертикальной оси — цена машины с соответствующим пробегом. Фиолетовые крестики обозначают обучающий набор данных. На графике изображены шесть крестиков — это шесть машин с разным пробегом и их актуальные цены. Зелёная линия отображает зависимость между пробегом и ценой автомобиля, которую нашёл алгоритм обучения.

Предположим, что обученный агент получает на вход величину пробега машины. Он должен определить её рыночную цену. Эта цена будет равна точке зелёной линии, которая находится над значением пробега, отложенном на горизонтальной оси (см иллюстрации 2-15). Например, для машины с пробегом 3500 км, функция агента вычислит цену 17050$.

Полученный нами агент называется **регрессором**. Для вычисления зависимого значения он использует следующую формулу:

![Формула линейного регрессора](images/ArtificialIntelligence/linear-regressor-formula.png)

-------

Достоинства обучения с учителем:

Недостатки обучения с учителем:

#### Обучение без учителя

Обучение без учителя — это более сложный подход.

#### Обучение с подкреплением

### Обучаемые модели

Чаще всего применяются следующие обучаемые модели:

* **Нейронная сеть** (artificial neural network) состоит их искусственных нейронов. Нейроны соединяются направленными связями. Через эти связи по сети распространяются сигналы. Каждая связь имеет числовой вес, который определяет силу и знак связи. Веса входных связей нейрона определяют, какие сигналы приведут к его активации. Нейрон после активации посылает выходной сигнал. В процессе обучения агент подбирает правильные числовые веса для всех связей в сети.

* [**Дерево решений**](https://ru.wikipedia.org/wiki/Обучение_дерева_решений) (decision tree learning). В результате обучения агент строит дерево решений. Построенное дерево реализует функцию агента: получает на вход последовательность актов восприятия и на их основе выбирает подходящее действие. Чтобы выбрать действие, над входными данными выполняется серия проверок. Каждый узел дерева соответствует условию проверки, а исходящие из него ветви — результатам проверки.

* [**Машина поддерживающих векторов**](https://ru.wikipedia.org/wiki/Метод_опорных_векторов) (support vector machine или SVM) представляет собой модель и набор алгоритмов для работы с ней. Машина обучается с учителем на примерах. Для каждого примера указано, к какому из двух классов он относится. После обучения машина определяет класс полученного на вход примера. SVM решает задачи **линейной** и **нелинейной классификации**.

I> [Линейная классификация](https://ru.wikipedia.org/wiki/Линейный_классификатор) сводится к разделению множества точек в пространстве признаков одной гиперплоскостью. **Гиперплоскость** имеет на одну размерность меньше, чем объемлющее её пространство. Например, гиперплоскость для двумерного пространства — это прямая.

* [**Байесовская сеть**](https://ru.wikipedia.org/wiki/Байесовская_сеть) (Bayesian network) представляет собой направленный граф. Его вершины — это переменные произвольного типа (признаки, теории и т.д.). Граф отображает [условные зависимости](https://en.wikipedia.org/wiki/Conditional_dependence) между переменными. Пример использования сети: вычисление вероятности той или иной болезни у пациента по её симптомам.

* [**Генетический алгоритм**](https://ru.wikipedia.org/wiki/Генетический_алгоритм) (genetic algorithm) — это модель, которая имитирует процесс естественного отбора. В процессе обучения такой модели применяются методы мутации, скрещивания и отбора. Эти методы производят новые версии модели, которые обладают нужными характеристиками.

Таблица 2-18 демонстрирует какие алгоритмы обучения применяются для разных моделей. Кроме того в таблице указан класс модели: deep learning или shallow learning.

{caption: "Таблица 2-18. Соответствие алгоритмов обучения и моделей", width: "100%"}
| Модель | Класс модели | Алгоритм обучения |
| --- | --- | --- |
| Однослойная нейронная сеть | Shallow learning | Обучение с учителем |
|  | | |
| Глубокая нейронная сеть (DNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Глубокая сеть доверия (DBN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | |
| Рекуррентная нейронная сеть (RNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Свёрточная нейронная сеть (CNN) | Deep learning | Обучение с учителем |
|  | | |
| Дерево решений | Shallow learning | Обучение с учителем |
|  | | |
| Машина поддерживающих векторов | Shallow learning | Обучение с учителем |
|  | | |
| Байесовская сеть | Shallow learning | Обучение с учителем |
|  | | |
| Генетический алгоритм | Shallow learning | Обучение с учителем |

#### Дерево решений

#### Нейронная сеть