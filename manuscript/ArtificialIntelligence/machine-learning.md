## Машинное обучение

Мы рассмотрели методы формальной логики и алгоритмы поиска, которые применяются в программах интеллектуальных агентов. Теперь познакомимся с более сложными подходами, разработанными в рамках машинного обучения.

### Алгоритмы обучения

Механизм обучения автоматически создаёт программу интеллектуального агента.

Любой механизм обучения состоит из двух компонентов:

* **Алгоритм обучения**
* **Обучаемая модель**

Чтобы воспользоваться механизмом обучения, нужен **обучающий набор данных**. Этот набор получает на вход алгоритм обучения. Он находит в данных закономерности и строит обучаемую модель. Эта модель учитывает все найденные закономерности.

Для разных типов обучаемых моделей применяются разные алгоритмы обучения. По принципу работы все эти алгоритмы делят на три больших класса:

* [**Обучение с учителем**](https://ru.wikipedia.org/wiki/Обучение_с_учителем) или контролируемое (supervised learning)

* [**Обучение без учителя**](https://ru.wikipedia.org/wiki/Обучение_без_учителя) или неконтролируемое (unsupervised learning)

* [**Обучение с подкреплением**](https://ru.wikipedia.org/wiki/Обучение_с_подкреплением) (reinforcement learning)

Каждый класс представляет собой отдельную **парадигму**. Парадигма — это система предположений, концепций и практических приёмов для решения какой-то задачи.

#### Обучение с учителем

Проще всего понять парадигму обучения с учителем. Она предъявляет самые высокие требования к обучающему набору данных. Этот набор должен состоять из примеров последовательностей актов восприятия и соответствующих им действий агента. Такие данные называются **размеченными**.

Пример размеченных данных — набор картинок животных. У каждой картинки есть **метка** с названием изображённого животного: "кот", "собака" и т.д.

Алгоритм обучения получает на вход размеченные данные. Таким образом он наблюдает за примерами работы функции агента, которую надо получить. В результате обучения алгоритм строит модель. Она реализует функцию агента, близкую к ожидаемой.

Обучение с учителем эффективно для решения двух классов задач:

* Классификация
* Регрессия

##### Классификация

Задача **классификации** заключается в разделении заданного множества объектов на классы. При решении этой задачи функция агента возвращает дискретные значения, которые соответствуют определённым классам.

Каноничным примером для демонстрации задачи классификации считается набор данных под названием [**ирисы Фишера**](https://ru.wikipedia.org/wiki/Ирисы_Фишера). С его помощью английский статистик и биолог Роналд Фишер продемонстрировал разработанный им метод статистического анализа в 1936 году.

Набор данных представляет собой таблицу со следующей информацией:

1. Длина чашелистника (sepal) цветка.
2. Ширина чашелистника (sepal) цветка.
3. Длина лепестка (petal) цветка.
4. Ширина лепестка (petal) цветка.
5. Вид ириса.

Всего в таблице 150 записей для трёх типов ириса. К каждому типу относится по 50 записей.

Для простоты мы рассмотрим только два параметра цветка: длина и ширина чашелистника. Эти параметры в терминологии машинного обучения называются **признаками**. По признакам агент должен определить, относится ли растение к виду Iris setosa.

В ходе обучения на наборе данных, алгоритм строит функцию агента. Её график представлен на иллюстрации 2-14.

{caption: "Иллюстрация 2-14. Функция агента для классификации ирисов", height: "50%", width: "100%"}
![Классификация ирисов](images/ArtificialIntelligence/fisher-iris-classification.png)

На горизонтальной оси отображается ширина чашелистника. На вертикальной оси — длина чашелистника. Синим крестикам соответствуют ирисы вида Iris setosa, а красным крестикам — виды Iris virginica и Iris versicolor. Синяя линия соответствует границе между классами, которую построил алгоритм обучения.

Допустим, агент получает длину и ширину чашелистника неизвестного вида ириса. Агент представляет эти признаки как новую точку пространства. Если точка оказалась выше линии границы между классами, то агент отнесёт растение к виду Iris setosa. В противном случае агент сделает вывод, что растение относится к другому виду ирисов.

Полученный нами агент называется [**линейным классификатором**](https://ru.wikipedia.org/wiki/Линейный_классификатор). При принятии решения такой классификатор использует формулу, которую можно записать в общем виде:

![Формула линейного классификатора](images/ArtificialIntelligence/linear-classifier-formula.png)

В этой формуле используются следующие обозначения:

* y — выходное значение функции агента
* f — пороговая функция
* w~i~ — вес признака под номером i
* x~i~ — значение признака под номером i

**Пороговая функция** отображает все возможные суммы w~i~ * x~i~ на два дискретных значения. Обычно это значения 0 и 1. Они соответствуют двум классам объектов. В нашем случае эти классы: вид Iris setosa и другие виды.

Вес признаков w~i~ — это некоторые коэффициенты, которые подбирает алгоритм обучения. Благодаря правильно подобранным весам, пороговая функция может однозначно различать классы объектов.

Для линейного классификатора ирисов из нашего примера формула выглядит так:

![Формула классификатора ирисов](images/ArtificialIntelligence/iris-classifier-formula.png)

Обозначения в формуле следующие:

* y — выходное значение функции агента
* f — пороговая функция
* w~1~ — вес признака ширина чашелистника
* x~1~ — ширина чашелистника
* w~2~ — вес признака длина чашелистника
* x~2~ — длина чашелистника

##### Регрессия

Задача **регрессии** — это прогноз значений некоторой **зависимой переменной** от одной или более **независимых переменных**. Связь между зависимыми и независимыми переменными математическая: изменение значений независимых переменных систематически меняет значение зависимой.

При решении задачи регрессии функция агента возвращает непрерывные значения (вещественное число). Пример такого значения: стоимость одной акции какой-то компании. Эта стоимость представляет собой зависимую переменную. Она может определяться такими независимыми переменными как прибыль компании, её репутация, доходность и надёжность.

-------

Достоинства:

Недостатки:

#### Обучение без учителя

Обучение без учителя — это более сложный подход.

#### Обучение с подкреплением

### Обучаемые модели

Обучаемая модель — это то, что построил алгоритм обучения посоле обработки конкретных входных данных. Модель представляет собой правила и набор данных, которые необходимы для прогнозирования.

Вот несколько примеров обучаемой модели:

* Алгоритм линейной регрессии строит модель, которая состоит из вектора коэффициентов с определёнными значениями.

* Алгоритм дерева решений генерирует последовательность условных операторов. Они проверяют факты относительно какого-то объекта.

* Алгоритм обратного распространения ошибки для нейронной сети создаёт модель, которая представляет собой направленный граф. Пути между вершинами этого графа имеют веса.

Обучаемая модель представляет собой программу агента, которую автоматически создаёт алгоритм обучения.

Чаще всего применяются следующие обучаемые модели:

* **Нейронная сеть** (artificial neural network) состоит их искусственных нейронов. Нейроны соединяются направленными связями. Через эти связи по сети распространяются сигналы. Каждая связь имеет числовой вес, который определяет силу и знак связи. Веса входных связей нейрона определяют, какие сигналы приведут к его активации. Нейрон после активации посылает выходной сигнал. В процессе обучения агент подбирает правильные числовые веса для всех связей в сети.

* [**Дерево решений**](https://ru.wikipedia.org/wiki/Обучение_дерева_решений) (decision tree learning). В результате обучения агент строит дерево решений. Построенное дерево реализует функцию агента: получает на вход последовательность актов восприятия и на их основе выбирает подходящее действие. Чтобы выбрать действие, над входными данными выполняется серия проверок. Каждый узел дерева соответствует условию проверки, а исходящие из него ветви — результатам проверки.

* [**Машина поддерживающих векторов**](https://ru.wikipedia.org/wiki/Метод_опорных_векторов) (support vector machine или SVM) представляет собой модель и набор алгоритмов для работы с ней. Машина обучается с учителем на примерах. Для каждого примера указано, к какому из двух классов он относится. После обучения машина определяет класс полученного на вход примера. SVM решает задачи **линейной** и **нелинейной классификации**.

I> [Линейная классификация](https://ru.wikipedia.org/wiki/Линейный_классификатор) сводится к разделению множества точек в пространстве признаков одной гиперплоскостью. **Гиперплоскость** имеет на одну размерность меньше, чем объемлющее её пространство. Например, гиперплоскость для двумерного пространства — это прямая.

* [**Байесовская сеть**](https://ru.wikipedia.org/wiki/Байесовская_сеть) (Bayesian network) представляет собой направленный граф. Его вершины — это переменные произвольного типа (признаки, теории и т.д.). Граф отображает [условные зависимости](https://en.wikipedia.org/wiki/Conditional_dependence) между переменными. Пример использования сети: вычисление вероятности той или иной болезни у пациента по её симптомам.

* [**Генетический алгоритм**](https://ru.wikipedia.org/wiki/Генетический_алгоритм) (genetic algorithm) — это модель, которая имитирует процесс естественного отбора. В процессе обучения такой модели применяются методы мутации, скрещивания и отбора. Эти методы производят новые версии модели, которые обладают нужными характеристиками.

Таблица 2-18 демонстрирует какие алгоритмы обучения применяются для разных моделей. Кроме того в таблице указан класс модели: deep learning или shallow learning.

{caption: "Таблица 2-18. Соответствие алгоритмов обучения и моделей", width: "100%"}
| Модель | Класс модели | Алгоритм обучения |
| --- | --- | --- |
| Однослойная нейронная сеть | Shallow learning | Обучение с учителем |
|  | | |
| Глубокая нейронная сеть (DNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Глубокая сеть доверия (DBN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | |
| Рекуррентная нейронная сеть (RNN) | Deep learning | Обучение с учителем |
|  | | Обучение без учителя |
|  | | Обучение с подкреплением |
|  | | |
| Свёрточная нейронная сеть (CNN) | Deep learning | Обучение с учителем |
|  | | |
| Дерево решений | Shallow learning | Обучение с учителем |
|  | | |
| Машина поддерживающих векторов | Shallow learning | Обучение с учителем |
|  | | |
| Байесовская сеть | Shallow learning | Обучение с учителем |
|  | | |
| Генетический алгоритм | Shallow learning | Обучение с учителем |

#### Дерево решений

#### Нейронная сеть