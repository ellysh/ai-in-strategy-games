# 6 Список терминов

## 6.1 Теория игр

### Б

[**Беспристрастная игра**](https://ru.wikipedia.org/wiki/Беспристрастная_игра) — игра, в которой допустимые ходы зависят только от текущей позиции. При этом неважно, какой игрок выполняет ход.

### В

**Внешняя неопределённость** — независящие от игроков обстоятельства, которые влияют на исход игры. Такими обстоятельствами могут быть случайные события.

**Выбор** — действие игрока в конкретной ситуации.

### Д

**Дерево игры** отображает все возможные действия игроков и исходы игры, к которым они приводят.

[**Детерминированная игра**](https://ru.wikipedia.org/wiki/Игра_с_полной_информацией##Свойства) — игра, в которой нет внешней неопределённости.

**Дискретная игра** — игра, в которой у каждого участника есть конечное число чистых стратегий.

### И

**Игра** — 1) способ получения и развития навыков у животных и людей. 2) Совокупность правил, описывающих игру.

[**Игра с ненулевой суммой**](https://lopatnikov.pro/slovar/i/igry-s-nenulevoj-summoj/) допускает разные суммы выигрышей участников в зависимости от исхода. Возможны исходы, когда все участники проигрывают или выигрывают.

[**Игра с неполной информацией**](https://ru.wikipedia.org/wiki/Игра_с_неполной_информацией) или **байесовская игра** — участники не имеют полной информации друг о друге. Могут быть неизвестны стратегии игроков, их функции полезности или выигрыши при разных исходах.

[**Игра с несовершенной информацией**](https://ru.wikipedia.org/wiki/Игра_с_неполной_информацией) — некоторые её аспекты скрыты от участников. Например, произошедшие события или предыдущие ходы игроков могут быть неизвестны.

[**Игра с нулевой суммой**](https://ru.wikipedia.org/wiki/Антагонистическая_игра) или **антагонистическая игра** — сумма выигрышей всех участников не зависит от исхода игры. Другими словами, выигрыш одного участника означает проигрыш всех остальных.

[**Игра с полной информацией**](https://ru.wikipedia.org/wiki/Игра_с_полной_информацией) — в ней вся информация об участниках является общим знанием. Эта информацию включает: стратегии участников, их функции полезности и выигрыши при любом возможном исходе.

[**Игра с совершенной информацией**](https://ru.wikipedia.org/wiki/Игра_с_совершенной_информацией) — в ней каждый участник на момент своего хода знает обо всех предыдущих событиях и действиях других игроков. Если игра параллельная, игроки знают все происходящие действия.

### К

[**Комбинаторная теория игр**](https://ru.wikipedia.org/wiki/Комбинаторная_теория_игр) — раздел математики, который изучает последовательные игры с полной информацией.

[**Концепция решения**](https://ru.wikipedia.org/wiki/Концепция_решения) — это правило, предсказывающее по какому сценарию пройдёт игра.

[**Кооперативная игра**](https://ru.wikipedia.org/wiki/Кооперативная_теория_игр) — в ней участники действуют согласованно в группах. При этом есть внешнее принуждение к такому согласованному поведению.

### Н

**Наилучший ответ** ([best response](https://en.wikipedia.org/wiki/Best_response)) — это стратегия, которая даёт наилучший исход с учётом стратегий других игроков.

[**Недетерминированная игра**](https://ru.wikipedia.org/wiki/Игра_с_полной_информацией##Свойства) — в ней есть внешняя неопределённость (например, элемент случайности).

[**Некооперативная игра**](https://ru.wikipedia.org/wiki/Некооперативная_теория_игр) — в ней каждый участник действует самостоятельно. При этом нет внешних стимулов для выполнения договорённостей между игроками.

[**Непрерывная игра**](https://ru.knowledgr.com/06448520/НепрерывнаяИгра) — в ней каждый участник имеет бесконечное число чистых стратегий. В частном случае стратегия может быть некоторым числом, выбранным из непрерывного диапазона.

### О

**Обещание** — условный стратегический ход. Игрок А заявляет, что даст игроку Б вознаграждение при совершении им определённого действия.

[**Обратная индукция**](https://ru.wikipedia.org/wiki/Обратная_индукция) (обратные рассуждения) — метод поиска лучшей стратегии в игре. Он предлагает рассматривать ходы игроков в обратном порядке, начиная с последнего. Так определяется последний лучший ход, затем предпоследний лучший ход и т.д. В конце анализа определяется первый лучший ход в игре.

[**Общее знание**](https://ru.wikipedia.org/wiki/Общее_знание) — особый вид информации, которой владеют несколько или все участники игры. Факт X является общим знанием для игроков A и B, если оба о нём знают. Также A знает, что B знает о факте X и наоборот. Далее B знает, что A знает о его осведомленности насчёт факта X и наоборот. Эта цепочка продолжается до бесконечности.

**Обязательство** — это заявление одного из участников о том, какой ход он намерен сделать независимо от действий других игроков. Обязательство является безусловным стратегическим ходом.

[**Одновременная_игра**](https://ru.wikipedia.org/wiki/Одновременная_игра) — игра, в которой каждый участник делает свой ход, не зная о действиях других игроков. Пример — камень-ножницы-бумага.

[**Оптимум по Парето**](https://ru.wikipedia.org/wiki/Эффективность_по_Парето) — состояние системы при котором суммарное благосостояние её участников достигает максимума. Любое изменение этого состояние ухудшает благосостояние хотя бы одного участника.

### П

**Партия** — каждый случай разыгрывания игры определённым способом от начала и до конца.

**Платёжная матрица** (payoff matrix) — таблица, размерность которой равна числу участников игры. По каждой размерности (строка, столбец) расположены стратегии соответствующего игрока. В каждой ячейки таблицы отображаются выигрыши всех игроков. Следующие термины означают то же самое: **матрица игры**, **таблица платежей**, **таблица выигрышей**.

**Подыгра** — это часть многоходовой игры, представленной в развёрнутой форме. Дерево подыгры является частью дерева исходной игры. При этом их начальные узлы не совпадают. Начальный узел подыгры является одним из узлов действия дерева полной игры.

[**Последовательная игра**](https://ru.wikipedia.org/wiki/Последовательная_игра) — игра, в которой каждый участник выбирает свой действие до того, как другие участники сделают свой ход. Делающий ход игрок имеет информацию обо всех предыдущих ходах. Пример — шахматы.

[**Пристрастная игра**](https://ru.wikipedia.org/wiki/Беспристрастная_игра) — игра, в которой в каждой позиции каждый игрок имеет свой набор возможных ходов. Пример: шахматы, шашки, нарды.

### Р

[**Равновесие Нэша**](https://ru.wikipedia.org/wiki/Равновесие_Нэша) — стабильное состояние системы из нескольких участников. В нём игроки не могут увеличить свой выигрыш, изменив свою стратегию.

### С

[**Сложность дерева игры**](https://en.wikipedia.org/wiki/Game_complexity#Game-tree_complexity) — это количество терминальных узлов в полном дереве игры. Полное дерево игры включает все узлы на любой возможной глубине.

**Смешанная стратегия** — игрок выбирает одну из нескольких чистых стратегий. Выбор делается случайным образом с заданной вероятностью. Принятая чистая стратегия не меняется до окончания партии.

**Стратегическая неопределённость** — недостаток информации у одного из участников о прошлых или происходящих игровых событиях, в том числе о действиях других игроков.

[**Стратегическая игра**](https://ru.wikipedia.org/wiki/Игра##Теория_игр) — борьба двух и более сторон за достижение своих целей. При этом действия участников влияют на результаты друг друга. Это влияние общеизвестно, т.е. является общим знанием.

**Стратегический ход** — действие участника игры, которое меняет её правила.

### Т

[**Теория вероятностей**](https://ru.wikipedia.org/wiki/Теория_вероятностей) — раздел математики, который изучает случайные события и величины, а также их свойства

[**Теория игр**](https://ru.wikipedia.org/wiki/Теория_игр) — наука, которая изучает математические модели стратегического взаимодействия между [**рациональными агентами**](https://ru.wikipedia.org/wiki/Рациональный_агент). В некоторых источниках называется **математической теорией игр** или **теорией стратегических игр**.

### У

**Убеждение** — мнение игрока о том, какие стратегии выбрали другие игроки.

**Угроза** — условный стратегический ход. Игрок А заявляет, что причинит игроку Б вред при совершении им определённого действия.

### Ф

**Фактор ветвления** — это среднее количество вариантов действий у игроков на каждом ходу.

**Функция выигрыша** ([payoff function](https://en.wikipedia.org/wiki/Normal-form_game)) — отображение сочетаний стратегий всех игроков на множество выигрышей одного конкретного игрока.

[**Функция полезности**](https://ru.wikipedia.org/wiki/Нормальная_форма_игры##Функция_полезности) ([utility function](https://en.wikipedia.org/wiki/Utility##Utility_function)) — в теории игр это отображение исходов игры на некоторые числа. Эти числа отражают предпочтения игрока. Теория игр предполагает, что игрок всегда выбирает более предпочтительный для себя исход.

### Х

**Ход** — возможность выбора игрока между несколькими вариантами действий.

### Ч

[**Чистая стратегия**](https://ru.wikipedia.org/wiki/Стратегия_(теория_игр)##Типы_стратегий) однозначно определяет действия игрока во всех возможных игровых ситуациях.

## 6.2 Искусственный интеллект

### А

**Агент** — объект, который воспринимает свою окружающую среду через датчики и воздействует на эту среду через исполнительные механизмы.

**Ансамбль моделей** — комбинация нескольких алгоритмов машинного обучения. Совместная работа этих алгоритмов строит более эффективную и точную модель.

**Аппроксимация** или приближение — это замена сложного объекта более простыми. При этом важные аспекты заменяющего и исходного объекта похожи. В контексте ИИ аппроксимация часто выполняется для функций и моделей.

### Б

[**Большие данные**](https://ru.wikipedia.org/wiki/Большие_данные) (big data) — направление информатики. Оно изучает методы обработки наборов данных, которые слишком велики для применения традиционных подходов.

### В

[**Валидационный набор данных**](https://wiki.loginom.ru/articles/validation-set.html) (validation set) нужен для оценки предсказательной способности модели. Примеры этого набора не входят ни в обучающий, ни в тестовый наборы.

[**Валидация**](https://help.loginom.ru/userguide/processors/validation.html) (validation) — оценка предсказательной способности модели.

**Вес входного сигнала нейрона** — это вещественное число, которое пропорционально   важности сигнала: чем важнее сигнал, тем больше вес и наоборот.

**Восприятие** — набор входных данных, поступающий на датчики агента в любой момент времени.

**Временная сложность** (time complexity) — это зависимость количества итераций алгоритма от размера входных данных. Другими словами — на сколько шагов увеличится алгоритм при увеличении входных данных.

### Г

**Гиперпараметр** (hyperparameter) — это некоторое значение, которое используется для управления процессом машинного обучения.

[**Глубокое обучение**](https://ru.wikipedia.org/wiki/Глубокое_обучение) (deep learning) — это набор методов машинного обучения нейронных сетей. Эти методы направлены на обучение признакам. [**Обучение признакам**](https://ru.wikipedia.org/wiki/Обучение_признакам) означает, что нейронная сеть автоматически обнаруживает признаки для классификации исходных данных.

**Градиент** (gradient) — в машинном обучении это скорость изменения функции по отношению к её входным параметрам. Градиент даёт информацию о том, как небольшие изменения входных параметров влияют на результат функции.

[**Граф**](https://ru.wikipedia.org/wiki/Граф_(математика)) — структура, представляющая собой набор связанных между собой объектов. Эти объекты называются вершинами графа, а связи между ними — рёбрами.

### Д

**Дерево** — это связный ациклический граф. **Связный** означает, что между любой парой вершин есть минимум один путь. **Ациклический** граф не содержит циклов.

**Динамический диапазон** — диапазон значений, который слой нейронной сети может принимать на вход.

[**Длинная цепь элементов краткосрочной памяти**](https://habr.com/ru/companies/wunderfund/articles/331310/) (long short-term memory или LSTM) — это особая разновидность рекуррентных сетей (RNN), которая может обучаться долговременным зависимостям. LSTM использует специальную структуру ячеек (cell), вентилей (gate) и модулей памяти для управления потоком информации и её хранением.

### З

[**Задача поиска аномалий**](https://dyakonov.org/2017/04/19/поиск-аномалий-anomaly-detection/) (anomaly detection) — поиск редких элементов или наблюдений, которые значительно отклоняются от остальных данных и не соответствуют представлению о нормальном поведении.

[**Задача поиска ассоциативных правил**](https://en.wikipedia.org/wiki/Association_rule_learning) — обнаружение неявных закономерностей в больших наборах данных.

**Задача сокращения размерности** (data reduction) — преобразование данных в более удобную форму для их анализа и интерпретации.

**Задача структурного вывода** (structural inference problem) — порождение вектора выходных значений, между элементами которого существуют важные связи.

[**Задача классификации**](https://wiki.loginom.ru/articles/classification-problem.html) (classification problem) — определение категории, к которой принадлежит некоторый объект. Категория выбирается исходя из признаков объекта.

[**Задача кластеризации**](https://wiki.loginom.ru/articles/clustering.html) (clustering problem) — объединение объектов в непересекающиеся группы на основе близости значений их признаков.

**Задача регрессии** (regression problem) — это прогноз значений некоторой зависимой переменной от вектора независимых переменных. Связь между зависимыми и независимыми переменными математическая: изменение значений независимых переменных систематически меняет значение зависимой.

### И

[**Извлечение признаков**](https://ru.wikipedia.org/wiki/Выделение_признаков) (feature extraction) — процесс абстрагирования и снижения размерности входных данных модели машинного обучения.

[**Импликация**](https://ru.wikipedia.org/wiki/Импликация) — это логическая операция, которая означает связь "если ..., то ...". Обозначается символом →.

[**Интеллектуальный агент**](https://ru.wikipedia.org/wiki/Интеллектуальный_агент) — это объект или система, которая воспринимает окружающую среду и выполняет действия, увеличивающие её шансы на достижение поставленной цели.

**Информационное множество** — набор узлов действия на дереве игры. Когда игрок принимает в них решения, он не может различить узлы этого набора. Поэтому выбор игрока в пределах одного информационного множества означает один и тот же ход для всех узлов этого множества.

[**Информированный поиск**](https://ru.wikipedia.org/wiki/Информированный_метод_поиска) — поиск с использованием дополнительной информации о решаемой задаче. Благодаря такой информации, агент исключает проверки некоторых ветвей дерева или графа.

[**Искусственная нейронная сеть**](https://ru.wikipedia.org/wiki/Нейронная_сеть) — соединение искусственных нейронов. Представляет собой математическую модель нервной сети живого организма. Также нейронной сетью называют программную или аппаратную реализацию этой модели.

[**Искусственный интеллект**](https://ru.wikipedia.org/wiki/Искусственный_интеллект) (ИИ) — наука о проектировании **интеллектуальных агентов**.

### К

[**Квантор**](https://ru.wikipedia.org/wiki/Квантор) — это логическая операция, которая ограничивает область истинности переменной. Чаще всего применяются кванторы всеобщности (∀ означает "каждый") и существования (∃ означает "существует такой, что...").

**Классический поиск** — собирательное название алгоритмов [поиска в пространстве состояний](https://ru.wikipedia.org/wiki/Поиск_в_пространстве_состояний) одноагентной среды. Такие алгоритмы представляют все возможные состояния среды в виде вершин графа. Его рёбра соответствуют действиям агента. В результате работы алгоритмы находят путь для перехода из корня графа к искомой вершине.

**Кластер** — набор объектов, схожих по какому-то признаку.

**Комбинаторный взрыв** (combinatorial explosion) — быстрый рост сложности задачи при увеличении размера входных данных.

[**Коннекционизм**](https://ru.wikipedia.org/wiki/Коннекционизм) (connectionism) — подход в области ИИ, который моделирует процесс мышления с помощью сетей из связанных между собой простых элементов. Обычно это искусственные нейронные сети.

**Конструирование признаков** (feature engineering) — в машинном обучении это извлечение важных для модели признаков (входных параметров) из исходных данных.

[**Конъюнкция**](https://ru.wikipedia.org/wiki/Конъюнкция) — это логическая операция, близкая по смыслу к союзу "и". Также называется логическим И. Операция даёт результат истина, если все её операнды истины.

### Л

[**Линейный классификатор**](http://www.machinelearning.ru/wiki/index.php?title=Линейный_классификатор) (linear classifier) — алгоритм классификации, который строит линейную разделяющую поверхность на пространстве признаков. Если классов два, то разделяющая поверхность представляет собой гиперплоскость.

**Линейный слой** (linear layer) — слой нейронной сети, нейроны которого связаны с нейронами предыдущего слоя напрямую без замыканий. При такой связи информация распространяется в одном направлении: от входов нейронов слоя к их выходам.

[**Логика**](https://ru.wikipedia.org/wiki/Логика) — наука о рассуждениях и истинности высказываний.

[**Логика первого порядка**](https://ru.wikipedia.org/wiki/Логика_первого_порядка) — это расширение пропозициональной логики. В нём применяются переменные с ограниченной областью истинности и логические операторы.

[**Логическое программирование**](https://ru.wikipedia.org/wiki/Логическое_программирование) — парадигма программирования, которая предлагает решать задачи методами формальной логики.

[**Логический оператор**](https://ru.wikipedia.org/wiki/Логическая_операция) — операция над логическими выражениями или формулами. Результат операции зависит от значений исходных выражений, к которым она применяется.

### М

**Масштабируемость системы** — повышение производительности системы при увеличении доступных ей аппаратных ресурсов.

[**Математическая логика**](https://ru.wikipedia.org/wiki/Математическая_логика) — это направление формальной логики в которой активно применяет математический аппарат.

[**Машинное обучение**](https://ru.wikipedia.org/wiki/Машинное_обучение) — это класс методов ИИ. Эти методы не решают поставленную задачу, а обучают систему на примерах решения аналогичных задач. После процесса обучения система решает поставленную задачу сама.

**Метод Монте-Карло** (Monte Carlo method) —  широкий класс вычислительных алгоритмов, которые полагаются на повторную случайную выборку и статистический анализ для получения численных результатов.

**Метод обратного распространения ошибки** (backpropagation) — алгоритм машинного обучения, при котором автоматически корректируются параметры модели. Таким образом постепенно минимизируется ошибка её работы.

**Механизм обучения** — набор методов, который автоматически создаёт программу интеллектуального агента. Сам механизм состоит из двух компонентов: алгоритм обучения и обучаемая модель.

**Модель среды** (model) имитирует поведение среды при обучении с подкреплением. 

### Н

[**Недообучение**](https://wiki.loginom.ru/articles/underfitting.html) (underfitting) — одна из проблем машинного обучения. Она возникает, когда алгоритм обучения создаёт слишком грубую модель. Эта модель оказывается проще чем функция, которую она должна реализовать. В результате её обобщающая способность неприемлемо низка.

[**Неинформированный поиск**](https://ru.wikipedia.org/wiki/Неинформированный_метод_поиска) — поиск без использования дополнительной информации о решаемой задаче.

[**Нейрон**](https://ru.wikipedia.org/wiki/Нейрон) — электрически возбудимая клетка, которая передаёт информацию соседним клеткам с помощью электрических и химических сигналов.

[**Нейронная сеть с прямой связью**](https://ru.wikipedia.org/wiki/Нейронная_сеть_с_прямой_связью) (feedforward neural network или FNN) — сеть с однонаправленным потоком информации. Он распространяется только в одном направлении — вперёд: от входных узлов через скрытые узлы к выходным узлам без циклов и петель.

**Нормализация** — это приведение числа к некоторому заданному диапазону.

### О

[**Обобщающая способность**](https://wiki.loginom.ru/articles/generalization-ability.html) (generalization ability) — эффективность работы обучаемой модели с новыми данными, с которыми она не встречалась в процессе обучения.

[**"О" большое**](https://ru.wikipedia.org/wiki/«O»_большое_и_«o»_малое) — нотация (обозначение) характера изменения функции, когда её аргумент стремится к бесконечности. Эта нотация даёт представление о том, как быстро растёт функция в зависимости от её входных данных.

[**Обучаемая модель**](https://wiki.loginom.ru/articles/taught-model.html) — программа, которую строит алгоритм обучения после обработки обучающего набора данных. Для новых наборов данных модель может выполнять следующие действия: обнаруживать неизвестные закономерности, извлекать правила, классифицировать объекты, устанавливать связи между ними и т.д.

[**Обучающий набор данных**](https://wiki.loginom.ru/articles/training-set.html) (training set) — структурированные данные, которые получает на вход алгоритм обучения. Алгоритм находит в данных закономерности и строит обучаемую модель. Эта модель учитывает все найденные закономерности.

[**Обучение без учителя**](https://wiki.loginom.ru/articles/unsupervised-learning.html) (unsupervised learning) — класс алгоритмов машинного обучения. Эти алгоритмы получают на вход неразмеченные наборы данных. Такие наборы содержат входные значения для модели, но не её ожидаемую реакцию.

[**Обучение с подкреплением**](https://wiki.loginom.ru/articles/reinforcement-learning.html) (reinforcement learning) — класс алгоритмов машинного обучения, которые строят агента, способного действовать в последовательной среде. Такой агент выбирает свои действия, ориентируясь на наблюдаемые состояния среды.

[**Обучение с учителем**](https://wiki.loginom.ru/articles/supervised-learning.html) (supervised learning) — класс алгоритмов машинного обучения, которые строят модели на основе наборов данных типа "известный вход — известный выход". Данные такого типа называются размеченными.

**Обучение представлению** (representation learning) — в машинном обучении это способность модели интерпретировать исходные данные.

[**Операнд**](https://ru.wikipedia.org/wiki/Операнд) — объект математической или логической операции, над которым выполняется действие.

**Остаточное соединение** (residual connection) — соединение между двумя не соседними, удалёнными друг от друга слоями нейронной сети. Оно работает как короткий путь между ними и позволяет потоку информации проходить мимо одного или нескольких слоев.

[**Ошибка обобщения**](https://wiki.loginom.ru/articles/generalization-error.html) (generalization error) — разность между желаемым и фактическим выходом модели при обработке примеров из тестового набора данных.

[**Ошибка обучения**](https://wiki.loginom.ru/articles/training-error.html) (training error) — разность между желаемым и фактическим выходом модели при обработке примеров из обучающего набора данных.

### П

[**Переобучение**](https://wiki.loginom.ru/articles/overtraining.html) (overtraining или overfitting) — одна из проблем обучения модели. Заключается в том, что модель хорошо работает на обучающем наборе данных, но часто ошибается на тестовых и реальных данных.

[**Перцептрон**](https://ru.wikipedia.org/wiki/Перцептрон) — модель восприятия информации человеческим мозгом. Перцептроном также называют алгоритм обучения с учителем для двоичных классификаторов.

**Поверхностное обучение** (shallow learning)  — собирательное название для относительно простых алгоритмов обучения. Эти алгоритмы работают с небольшими моделями, например нейронные сети с одним скрытым слоем.

**Показатели производительности** — критерии для оценки успешности действий агента.

**Полносвязный слой** (fully connected) — слой нейронной сети, каждый нейрон которого связан с каждым нейроном предыдущего слоя.

**Последовательность актов восприятия** — это полный набор всех входных данных, которые когда-либо поучил агент.

**Правило Хебба** — связи нейронов, которые активируются совместно, усиливаются. Связи нейронов, которые срабатывают независимо, ослабевают.

**Предсказательная способность** — эффективность обучаемой модели при решении задачи, для которой она была разработан.

**Признаки объекта** — в машинном обучении это параметры объекта, которые рассматриваются в контексте поставленной задачи.

**Присвоение кредитов** (credit assignment) — расчёт вклада отдельных нейронов и их соединений в конечный результат работы сети.

**Проблема здравого смысла** (commonsense knowledge problem) — необходимость в общих знаниях о предметной области для устранения неоднозначности при машинном переводе.

**Проблемная среда** — описание задачи, которое включает в себя информацию об исполнительных механизмах и датчиках агента, его показателях производительности и окружающей среде.

**Программа агента** — это реализация функции агента конкретными методами ИИ в виде программы, работающей на физическом устройстве.

[**Пропозициональная логика**](https://ru.wikipedia.org/wiki/Логика_высказываний) — это раздел математической логики, который изучает высказывания и методы вывода их истинности.

**Пространственная сложность** (space complexity) — это зависимость количества используемой алгоритмом памяти от размера входных данных.

**Пространство признаков** — в машинном обучении это многомерное пространство, каждое измерение которого соответствует одному из признаков объекта. Каждый объект представляется точкой в этом пространстве. Его координаты соответствует величине каждого его признака. 

[**Пространство состояний**](https://en.wikipedia.org/wiki/State_space) — набор всех возможных состояний среды интеллектуального агента.

### Р

**Распознавание образов** (pattern recognition) — это задача обнаружения шаблонов и закономерностей во входных данных.

**Распознавание изображений** (image recognition) — частная задача распознавания образов применительно к изображениям. Она заключается в обнаружении на них определённых объектов (например, лиц людей).

[**Рекуррентная нейронная сеть**](https://ru.wikipedia.org/wiki/Рекуррентная_нейронная_сеть) (recurrent neural network или RNN) — сеть с замыкающимися связями. Такие связи позволяют двунаправленный поток информации: вперёд от входных узлов через скрытые узлы к выходным узлам и в обратном направлении.

### С

[**Свёрточная нейронная сеть**](https://ru.wikipedia.org/wiki/Свёрточная_нейронная_сеть) (convolutional neural network или CNN) — это подвид многослойной нейронной сети с прямой связью (FNN). Её архитектура повторяет особенность зрительной коры человека: чередование двух типов слоёв. Эта сеть оптимизирована для обработки изображений.

**Сигнал вознаграждения** (reward signal) — сигнал среды в ответ на каждое действие агента. Представляет собой число. За успешные действия агент получает большее вознаграждение, чем за менее успешные. 

[**Символьный подход**](https://ru.wikipedia.org/wiki/Символический_искусственный_интеллект) (symbolic approach) — направление в области ИИ, которое предлагает решать задачи через действия над понятными человеку символическими обозначениями.

**Состязательный поиск** (adversarial search) — поиск в мультиагентной среде, когда агенты конкурируют друг с другом.

**Скрытый слой нейронов** (hidden layer) — слой, не содержащий входных и выходных нейронов сети.

**Стратегия** (policy) — это функция агента в терминологии обучения с подкреплением.

**Сходимость алгоритма обучения** — свойство достигать оптимума целевой функции или подходить достаточно близко к нему за конечное число шагов.

### Т

**Терминальный узел** — узел дерева, который не имеет дочерних узлов. В случае состязательного поиска, он соответствует состоянию среды, в котором игра окончена.

**Тест Тьюринга** — эксперимент, в котором человек и машина обмениваются с судьёй текстовыми сообщениями. Все три участника эксперимента находятся в разных комнатах и не видят друг друга. В результате переписки судья должен определить, кто из собеседников является машиной.

[**Тестовый набор данных**](https://wiki.loginom.ru/articles/test-set.html) (test set) — подмножество обучающего набора данных. Алгоритм обучения не получает эти данные на этапе создания модели. Вместо этого тестовый набор используют для проверки точности и обобщающей способности готовой модели.

[**Темп обучения**](https://en.wikipedia.org/wiki/Learning_rate) (learning rate) — настраиваемый параметр алгоритма обучения, который определяет размер шага на каждой итерации при движении к минимуму **функции потерь** (loss function). Функция потерь отображает стоимость неправильного принятия решений на основе наблюдаемых данных.

### Ф

[**Формальная логика**](https://ru.wikipedia.org/wiki/Формальная_логика) — это раздел логики, в котором применяется формальный язык и строгие правила для операций над высказываниями.

[**Формальный язык**](https://ru.wikipedia.org/wiki/Формальный_язык) состоит из слов, буквы которого взяты из алфавита естественного языка. Эти слова формируются согласно определённому набору правил.

**Функция агента** отображает последовательности актов восприятия на действия агента. Представляет собой внешнее описание агента.

**Функция активации нейрона** (activation function) определяет выходной сигнал нейрона по набору его входных сигналов.

**Функция полезности** (value function) — в ИИ это отображение состояний среды на вещественные числа. Эти числа означают степень удовлетворённости агента от состояния среды.

### Ц

**Цикл** в теории графов — это путь, который начинается и заканчивается в одной и той же вершине.

### Э

[**Эвристика**](https://ru.wikipedia.org/wiki/Эвристика) — метод для нахождения приближённого решения или ближайшей краткосрочной цели. Он применяется тогда, когда невозможно найти оптимальное решение. В случае поиска по дереву, эвристика исключает из рассмотрения некоторые его ветви.

**Эвристическая функция** оценивает альтернативные направления в алгоритмах поиска. Простейший пример оценки — это расчёт расстояния по прямой линии от проверяемого узла до целевого.

[**Экспертная система**](https://en.wikipedia.org/wiki/Expert_system) (expert system) — основанная на знаниях система, которая имитирует процесс принятия решения человеком-экспертом в какой-то прикладной области.

## 6.3 Шахматы

### А

**Армагеддон** (armageddon) — это контроль времени, при котором игрок за чёрные фигуры выигрывает в случае ничьей. Ему отводится на 1 минуту меньше времени, чем игроку за белые фигуры. Обычно, белые имеют 6 или 5 минут на все ходы. Соответственно чёрные имеют 5 или 4 минуты.

### Б

**Битборд** (bitboard) — оптимальный способ представления состояния шахматной доски в программе. Это состояние хранится в виде 64-разрядного числа. Каждый его бит соответствует одному из 64-х полей шахматной доски. Если бит равен единице, поле занято фигурой. Если бит равен нулю, то поле свободно.

**Блиц** (blitz) — это контроль времени, при котором игрокам отводится от 3 до 10 минут на ходы.

**Буллит** (bullet) — это контроль времени, при котором игроки имеют менее 3-х минут на ходы.

### В

**Вариант** — серия ходов, логически связанных между собой.

### Д

**Дебют** (opening) — начало партии. К дебюту относятся первые 15-20 ходов.

### Е

**Единственный хороший ход** — единственный ход, который значительно лучше альтернатив.

### З

**Закрытый дебют** — начинается с хода белых d4 и любого ответа чёрных кроме d5. В таких началах стороны избегают раннего размена пешек и лёгких фигур. В результате складываются **закрытые позиции**, в которых центр доски заблокирован пешками и мобильность фигур ограничена.

**Зевок** — грубая ошибка, которая чаще всего делается по невнимательности.

### К

**Классический контроль времени** — на первые 40 ходов каждому игроку отводится 90 минут. После 40-го хода каждому игроку добавляется 30 минут. К этим 30 минутам добавляется по 30 секунд за каждый ход, сделанный с начала партии.

**Кольцо короля** — восемь клеток вокруг короля.

**Комбинация** — форсированный вариант с использованием различных тактических приёмов. Обычно комбинации сопутствует жертва материала.

### Л

**Ловушка** — попытка спровоцировать соперника на внешне выгодное продолжение, которое в действительности оказывается ошибочным. Так называют любой хитрый ход, содержащий скрытую угрозу и рассчитанный на промах противника.

### М

**Материал** — фигуры, которыми располагает игрок.

**Миттельшпиль** (middlegame) — середина партии. Миттельшпиль начинается примерно с 20-25 хода.

### Н

**Новинка** —  новый ход или новая схема развития в известных вариантах.

### О

**Опровержение** — это ход или серия ходов, доказывающих несостоятельность действий противника.

**Открытая линия** — это свободная от пешек вертикаль.

**Открытый дебют** — начинается с хода белых e4 и ответа чёрных e5. Такие начала приводят к раннему размену пешек и лёгких фигур. В результате складываются открытые позиции, в которых центр доски относительно свободен от пешек.

### П

 **План** — общая идея, которой руководствуется игрок при выборе ходов.

**Позиционный перевес** — лучшая пешечная структура, более подвижные фигуры или защищённость короля.

**Полуоткрытый дебют** — начинается с хода белых e4 и любого ответа чёрных кроме e5. В них одна сторона получает открытый центр (не занятый пешками), а другая — закрытый. Такие начала приводят к позиционной игре в дебюте и переносят комбинационную игру в миттельшпиль.

**Полуход** — ход одной из сторон: белых или чёрных. Два полухода составляют один полный ход.

**Проблема компьютерных шахмат** — задача разработки программы или компьютера, способного обыграть действующего чемпиона мира по шахматам.

### Р

**Рапид** (rapid) — это контроль времени, при котором каждому игроку отводится от 10 до 60 минут на все ходы.

**Развитие фигур** — планомерное передвижение фигур к средней линии доски.

### С

[**Скользящие фигуры**](https://www.chessprogramming.org/Sliding_Pieces) (sliding pieces) — фигуры, которы могут ходить через всю доску: слон, ладья и ферзь.

**Сложное окончание** — эндшпиль в котором у каждой стороны кроме короля осталось две или больше фигур.

**Спокойная позиция** — позиция, в которой нет взятий, шахов и единственных ходов.

**Средняя линия доски** — это горизонтальная граница между рядами полей 4 и 5.

**Статическая оценка позиции** — функция шахматной программы, которая присваивает заданной позиции числовое значение. Чем позиция выгоднее, тем это значение больше.

**Стратегия** — в шахматах долговременный план, на реализацию которого направлены конкретные ходы и комбинации.

### Т

**Таблица транспозиций** — это структура данных в шахматной программе, которая хранит ранее проверенные позиции и результаты оценочной функции для них. Она используется для ускорения поиска.

**Тактика** — система приёмов и комбинаций, которые позволяют достичь преимущества или свести партию к ничьей.

**Техническое окончание** — эндшпиль с минимальным количеством фигур: от 3 до 5. Причём этого набора фигур достаточно, чтобы игрок с преимуществом гарантированно ставил мат.

**Транспозиция** — последовательности ходов, которые приводят к одному и тому же результату.

### Ф

**Форсированный  ход** — ход, на который противник вынужден отвечать только определённым образом (например, размен или шах).

### Ц

**Цепочка лучших ходов** — это последовательность из лучших ходов в текущей позиции. Это могут быть и единственные хорошие ходы спасающие от поражения.

### Ш

[**Шахматный движок**](https://ru.wikipedia.org/wiki/Шахматный_движок) — программа, которая анализирует заданные позиции и генерирует список лучших ходов в них.

### Э

**Эндшпиль** (endgame) — конец партии. Эндшпиль начинается, когда на доске осталось мало фигур.

{pagebreak}
