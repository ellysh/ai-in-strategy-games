## 3.8 Человек против шахматной программы

Последний крупный матч человека против шахматной программы состоялся в ноябре 2006 года. Действующий на тот момент чемпион мира Владимир Крамник играл против движка Deep Fritz. Матч закончился победой Deep Fritz со счётом 4-2: четыре ничьи и две победы программы. Шахматист не смог выиграть ни одной партии.

Во время матча Deep Fritz работал на мощном по меркам того времени персональном компьютере. Но его вычислительные ресурсы значительно уступали шахматному суперкомпьютеру Deep Blue. Скорость работы программы и суперкомпьютера отличалась на два порядка:

* Deep Fritz просчитывал около 8 миллионов позиций в секунду.

* Deep Blue — от 100 до 300 миллионов в зависимости от конфигурации.

Несмотря на скромную производительность, Deep Fritz одержал уверенную победу над чемпионом мира. Этот матч показал, насколько выросло качество шахматных программ спустя 10 лет после противостояния Гарри Каспарова и Deep Blue.

В условиях матча современные шахматные движки не оставляют шансов лучшим игрокам. Ведущие шахматисты единогласно признают, что человек уже давно не может конкурировать с машиной. Этот вопрос считается решённым однозначно и окончательно.

Можно ли сказать что-то новое о противостоянии человека и шахматной программы? Что если посмотреть на него под несколько непривычным углом?

### 3.8.1 Ошибки в программах

Матчи гроссмейстеров с шахматными программами комментируют профессионалы. Они — эксперты в предметной области и знают тонкости шахматной игры. Опираясь на свой опыт, комментатор рассказывает о позициях, ходах, вариантах, комбинациях и ошибках. Точка зрения именно этих экспертов звучит в репортажах со всех шахматных событий. Но когда речь заходит о программах, эта точка зрения не единственно возможная.

Шахматные движки разрабатывают профессиональные программисты. Это другой вид экспертов, который имеет отношение к компьютерным шахматам. К сожалению, эти эксперты редко высказываются о поединке человека и машины. Одну из самых известных попыток предпринял Фэн Сюн Сю. Он опубликовал книгу "Behind Deep Blue" о поединке суперкомпьютера IBM и Гарри Каспарова.

Что может рассказать разработчик шахматной программы? В своей книге Фэн Сюн Сю знакомит читателя с техническими задачами и проблемами, которые решала его команда. Комментируя партии, он часто говорит о программных и аппаратных ошибках. Именно из-за них Deep Blue делал слабые ходы, терял позиционное преимущество и проигрывал. Означает ли это, что ключ к победе над шахматной программой кроется в ошибках её реализации? Если да, то изменилось ли что-то со времён Deep Blue?

Управляющая программа для Deep Blue была разработана почти 30 лет назад. Методология программирования продвинулась далеко вперёд за это время. Но проблема ошибок никуда не делась. Современные программы аварийно завершаются, теряют данные пользователей и зависают точно так же, как и 30 лет назад. Так происходит потому, что разработка программного обеспечения — это компромисс между функциональностью, стоимостью, временем и качеством. Чем-то всегда приходится жертвовать. Разработка шахматной программы в этом плане ничем не отличается.

Чтобы найти и исправить ошибки в программах, разработчики используют разные методы тестирования. Например, это может быть ручная проверка самых важный функций программы. Какие-то шаги тестирования можно автоматизировать. Специальные системы могут запускать программу и выполнять в ней стандартные действия. Тем самым они проверяют, что она по-прежнему работает.

В истории шахматных программ можно заметить некоторую закономерность. Метод поиска ошибок в них постоянно развивался. Одновременно с этим рос их уровень игры. Значительные скачки в силе программ происходили именно тогда, когда разработчики применяли новый метод тестирования. Есть ли какая-то взаимосвязь между этими событиями? Попробуем разобраться.

Рассмотрим три показательных эпизода из истории компьютерных шахмат. Мы сфокусируемся на том, как разработчики шахматных программ искали в них ошибки.

#### 3.8.1.1 Ручной несистематический поиск

В 1960-х годах методология разработки и тестирования ПО только зарождалась. Автор программы сам тестировал её вручную. Обычно он пробовал разные входные данные и проверял, что вывод программы соответствует ожидаемому.

Разработчики первых шахматных программ следовали общепринятой практике. Они применяли простую стратегию тестирования, которая состояла из трёх стадий.

На **первой стадии** автор играет со своей программой несколько партий. Он проверяет, что в ней нет очевидных критических проблем. Вот несколько примеров:

* Программа во время партии аварийно завершается (**сбой** или crash).

* Программа нарушает правила игры.

* Программа зависает.

* Программа жертвует фигуры просто так или делает бессмысленные ходы.

Если одна из подобных проблем происходит, разработчик пытается понять и устранить её причину. После этого он повторяет первую стадию тестирования.

Когда программа начинает работать стабильно без критических ошибок, наступает **вторая стадия** тестирования. Разработчик обращается к одному или нескольким сильным шахматистам. Они проводят серию игр против программы и указывают на её слабости. Типичная их причина — неверные представления разработчика о шахматной игре. Его плохое владение предметной областью выливается в логические ошибки программы.

I> [**Логической ошибкой**](https://ru.wikipedia.org/wiki/Логическая_ошибка_(программирование)) называется неправильное действие программы на этапе принятия решений.

Получив обратную связь от экспертов в предметной области, разработчик шахматной программы исправляет её поведение.

На **третьей стадии** тестирования шахматная программа играет на турнирах. Это партии с классическим контролем времени против шахматистов и других программ. На этой стадии разработчик наблюдает, как программа работает в максимально сложных для неё условиях. Если происходит сбой или слабый ход, автор собирает всю доступную информацию об этом событии. Таким образом, он ищет причину ошибки и исправляет код, который её вызвал.

Мы рассмотрели стратегию поиска ошибок в шахматных программах, состоящую из трёх стадий. Назовём её **ручным несистематическим поиском**. Слово **ручной** означает, что все шаги выполняет человек без какой-либо автоматизации. Так или иначе он играет полные партии против программы.

Поиск называется **несистематическим**, потому что в нём нет строго плана. На каждой стадии тестирования человек играет против программы. Тем самым он проверяет её основные функции. В одной из партий может проявиться какая-то ошибка. Но это будет чистой случайностью. Ходы и позиции могут сложиться так, что проблемы не проявятся ни в одной партии. В этом случае разработчик программы о них не узнает и не устранит.

Эффективность ручного несистематического поиска ошибок зависит только от интенсивности тестирования. Чем больше партий сыграет шахматная программа, тем выше шанс воспроизвести какую-то из её ошибок. Только тогда у разработчика появится шанс исправить проблему. Ошибки, которые ни разу не воспроизвелись, останутся скрытыми. Их невозможно исправить из-за отсутствия информации.

I> **Скрытой ошибкой** (latent defect) программы называется проблема, которая не была обнаружена на этапе тестирования. Она проявляется только после того, как ПО было выпущено и использовалось в определённых условиях.

#### 3.8.1.2 Ручной систематический поиск

Стратегия ручного несистематического поиска ошибок имеет предел. Если интенсивно тестировать шахматную программу таким способом, в какой-то момент уровень её игры перестанет расти. Это происходит по нескольким причинам.

Во-первых, в программе остаётся мало скрытых ошибок. Чтобы их воспроизвести нужны очень специфичные позиции и условия. Они могут никогда не сложиться в тестовых партиях со стандартными дебютами и эндшпилями.

Во-вторых, ручной несистематический поиск малоэффективен. Воспроизведение какой-то конкретной проблемы занимает много времени, потому что тестировщик играет каждую партию сначала. Например, в сложном миттельшпиле программа делает бессмысленный ход. Чтобы воспроизвести такое поведение, надо отыграть дебют и при выходе из него создать подходящую позицию. Для этого может понадобиться несколько попыток.

В-третьих, некоторые промахи программы могут быть очень тонкими. Только профессиональный шахматист высочайшего уровня способен их понять и объяснить разработчику программы. Но у чемпиона мира и претендентов на его место нет времени интенсивно тестировать шахматный движок. Играя против программы матч, профессионал найдёт слабость и воспользуется ею. Заранее же разработчик не узнает о проблеме.

Именно с этими трудностями столкнулась команда Deep Blue в первом матче против Гарри Каспарова в 1996 году. Вероятно, уровень игры компьютера на тот момент был близок к максимуму, который даёт ручной несистематический поиск ошибок. До уровня Гарри Каспарова он не дотягивал.

Главной проблемой разработчиков был слишком долгий цикл обработки ошибок. Он состоит из следующих шагов:

1. Обнаружение 
2. Исследование причин
3. Исправление
4. Тестирование.

Если тестирование показало, что ошибка по-прежнему воспроизводится, цикл начинается сначала.

Чтобы ускорить цикл, команда Deep Blue создала специальные инструменты для тестирования и отладки. Одним из них был программный прототип функции оценки Deep Blue с графическим интерфейсом. Его возможности напоминали современный шахматный движок.

Рассмотрим, как работал инструмент тестирования Deep Blue. Через графический интерфейс пользователь задавал произвольную позицию фигур на доске или загружал её из файла. После этого функция оценки проверяла заданную позицию. Для каждого возможного хода она давала некоторый балл. Графический интерфейс выводил эти баллы в наглядной форме. Также пользователь видел диагностическую информацию о том, какие факторы позиции повлияли на оценку.

Инструмент тестирования стал отправной точкой для новой стратегии поиска ошибок. Раньше штатный гроссмейстер проекта тестировал Deep Blue в полноценных партиях. Теперь достаточно было ввести нужную позицию. Инструмент сразу показывал ход, который выберет функция оценки компьютера. Если ход оказывался слабым, гроссмейстер сообщал о проблеме разработчикам. Такой подход значительно ускорил цикл обработки ошибок.

Вторым компонентом новой стратегии поиска ошибок стало дополнительное правило в играх с компьютером. Чтобы тестовые партии стали эффективнее, разработчики разрешили штатному шахматисту брать ход назад в любой позиции. Это позволило игроку возвращаться назад и исправлять свои слабые ходы. Таким образом он мог играть на равных с Deep Blue, который превосходил его минимум на 200 пунктов Эло. При равной игре ошибки компьютера стали чаще воспроизводиться. Он перестал выигрывать из-за банальных зевков оппонента.

Назовём стратегию поиска ошибок команды Deep Blue **ручным систематическим поиском**. Поиск **ручной**, потому что его по-прежнему выполняет человек без автоматизации. Но на этот раз тестировщик пользуется специальными инструментами и расширенными правилами игры.

Поиск называется **систематическим**, потому что у него есть строгий план действий. Этот план выглядит следующим образом:

1. Получить предварительную информацию о предполагаемой ошибке. Например, тестировщик знает, что в программе изменилась оценка пешечной структуры. Тогда он должен сконцентрироваться на позициях с различной конфигурацией пешек и проверить, что программа правильно в них ориентируется.

2. Создать полностью повторяемую среду для воспроизведения ошибки. Это означает, что ни аппаратное обеспечение, ни программна не должны меняться между тестами. Тестировщик всегда берёт один и тот же компьютер и запускает на нём одну и ту же версию программы или инструмента тестирования.

3. Следовать повторяемым путём для воспроизведения ошибки. Это означает, что в каждом тесте выполняются одни и те же действия, которые приводят к одним и тем же результатам.

4. Если ошибка воспроизвелась, зафиксировать состояние программы и среды её выполнения (например, состояние аппаратуры). Именно один из параметров этого состояния провоцирует проблему. Задача разработчика — понять, какой именно параметр.

Рассмотрим, как команда Deep Blue следовала этому плану тестирования. Первый пункт — узнать о предполагаемой ошибке компьютера. Было несколько способов это сделать:

1. Разработчик сообщал штатному шахматисту проекта об изменении в управляющей программе или прошивке шахматного чипа. Оно могло привести к новой проблеме.

2. Во время тестовой игры с правилом брать ход назад, Deep Blue делает слабый ход. Это сигнал о том, что в программе Deep Blue есть ошибка.

3. Во время очередной турнирной партии Deep Blue делает слабый ход. Лог файл игры позволял точно восстановить ход этой партии.

Второй пункт плана — создать полностью повторяемую среду для воспроизведения ошибки. Разработчики Deep Blue могли его выполнить. Они контролировали версии управляющей программы, шахматных чипов и их прошивки. Это позволяло воссоздать комбинацию аппаратного обеспечения и программ, в которой произошла проблема.

Третий пункт — следовать повторяемым путём для воспроизведения ошибки. Это условие невозможно выполнить, если играть обычные партии против шахматной программы. Дело в том, что на алгоритм её работы влияет много случайностей. Эту проблему решил специальный инструмент тестирования команды Deep Blue. Благодаря ему, можно было сразу задать нужную позицию фигур.

Четвёртый пункт плана — зафиксировать состояние программы и оборудования. У команды Deep Blue были инструменты для анализа управляющей программы и прошивки шахматных процессоров. С их помощью разработчики собирали полную информацию о среде выполнения в состоянии ошибки. Это помогало выяснить её причину и подготовить исправление.

На исход второго матча Гарри Каспарова против Deep Blue 1997 года повлияло много факторов. Одним из них стала новая стратегия поиска ошибок команды Deep Blue. Благодаря ей, разработчики оперативно вносили изменения в управляющую программу компьютера. Если Гарри Каспаров находил какой-то изъян в игре оппонента, команда Deep Blue исправляла его до следующей партии. Теперь не только человек, но и машина адаптировалась к игре оппонента по ходу матча.

#### 3.8.1.3 Автоматический систематический поиск

Возможности тестирования специализированного шахматного компьютера ограничены. Проблема в том, что это уникальное оборудование в единственном экземпляре. Невозможно регулярно проводить партии между разными версиями шахматного компьютера. Версия — это конкретная комбинация аппаратного и программного обеспечения.

В конце 1990-х годов платформой для шахматных программ стал обычный персональный компьютер. Он позволяет запустить два шахматных движка и устроить между ними партию. Это сделало возможным новый метод тестирования. Разработчики начали регулярно сравнивать игру разных версий своих программ. Скоро возникла идея автоматизировать этот процесс. Появились специальные системы автоматического тестирования. Они запускают указанные версии движка и проводят между ними серию партий. Система собирает статистику и выдаёт отчёт с результатами.

Автоматизация стала базой для новой стратегии поиска ошибок. В ней большую часть работы выполняет не человек, а специальная система. Назовём такую стратегию **автоматическим систематическим поиском**.

Поиск называется **систематическим**, потому что выполняется по строгому плану. Он заключается в последовательном запуске ряда автоматических тестов. Каждый из них фокусируется на ошибках определённого типа.

Разработчики обычно выполняют следующие автоматические тесты:

1. **Автоматическое регрессионное тестирование** проверяет новую версию движка на заранее подготовленном наборе типовых позиций. Тест показывает, что ранее исправленные ошибки не вернулись.

2. **Интеграционное тестирование** запускается каждый раз, когда в кодовую базу программы вносится какое-то изменение. Тест проверяет, что не появилось новых ошибок.

3. **Тест производительности** проверяет, что движок не стал работать медленнее из-за последних изменений. Новая версия программы обрабатывает набор специально подготовленных сложных позиций. Для каждой позиции система тестирования оценивает:

   * Глубину поиска, достигнутую в единицу времени.
   * Количество узлов дерева игры, проверяемых в секунду.

4. **Автоматические турниры** между разными версиями движка. Турнир даёт статистику для сравнения относительного уровня Эло этих версий.

5. **Тестирование дебютов и эндшпилей** проверяет, что движок по-прежнему корректно работает на этих стадиях партии.

Тестирование по такому плану обнаруживает проблемы на ранней стадии. Часто интеграционный тест может точно указать на изменение, которое что-то сломало. Это значительно сокращает цикл обработки ошибок и повышает эффективность разработки. Программисты могут смелее экспериментировать с небольшими изменениями и последовательно улучшать разные части шахматного движка.

Автоматическое тестирование легко масштабировать. Для этого достаточно подключить больше компьютеров к системе. Тогда тесты всех пяти типов станут интенсивнее. Команда проекта Stockfish вывела масштаб автоматизированных тестов на беспрецедентный уровень. Система Fishtest объединяет сотни компьютеров добровольцев в единую сеть. Именно благодаря ей, движок Stockfish сохраняет лидерство во всех турнирных таблицах.

### 3.8.2 Игра против шахматного движка

Мы познакомились с тремя стратегиями поиска ошибок, которые применяют разработчики шахматных программ. Какое отношение это имеет к противостоянию человека и машины?

Клод Шеннон в статье "Программирование компьютера для игры в шахматы" указал четыре преимущества машины над человеком:

1. Высокая скорость вычислений.

2. Свобода от ошибок. Ошибки машины происходят из-за изъянов в управляющей программе. В то же время игроки любого уровня регулярно совершают грубые промахи.

3. Свобода от лени. Игрокам слишком легко делать интуитивные ходы без надлежащего анализа позиции.

4. Свобода от "никогда". Игроки склонны к ошибкам из-за чрезмерной самоуверенности в выигрышных позициях. С другой стороны, в проигрышных позициях игроки преждевременно сдаются и не проверяют все возможности.

Таким образом Клод Шеннон утверждает, что изъяны в программе — это единственный источник слабой игры машины.

С момента публикации статьи шахматные программы совершенствовались десятилетиями. Сегодня их вычислительная мощность и точность достигли высочайшего уровня. Программы используют самые полные книги дебютов и таблиц эндшпилей. Они никогда не устают и не испытывают никаких эмоций. Всё это делает шахматный движок практически идеальным игроком.

Теперь давайте поговорим о том, как профессионалы играют в шахматы. Представим партию между двумя гроссмейстерами с примерно равным уровнем Эло. Если обе стороны безошибочно исполняют свой план на игру, вероятнее всего, партия закончится ничьей. Но если одна из сторон допускает промах, оппонент получает преимущество. Речь идёт даже не о зевке пешки. Промахом может быть небольшое смещение фигур, которое лишь немного ухудшает позицию. Такое незначительное преимущество игрок высокого уровня способен превратить в победу.

Партия против современного шахматного движка — это противостояние идеальному игроку. Поэтому цена любого промаха в ней так же высока, как и в партии высокого уровня между двумя гроссмейстерами. Из этого следует два вывода:

1. Играя против программы, нельзя ошибаться. Любой промах приводит к поражению.

2. Единственная возможность выиграть — получить преимущество и развить его в победу, когда программа допускает ошибку.

По мнению Клода Шеннона недочёт в почти идеальной игре шахматного движка создают логические ошибки в коде. Именно их ищут и устраняют разработчики. В этом заключается связь стратегий поиска ошибок и игры человека против машины.

Мы подробно рассмотрели три стратегии поиска ошибок. Возникает вопрос: может ли шахматист применить их, чтобы найти слабые стороны программы? Очевидно, что может. Но перед тем как углубиться в эту тему, поговорим о типах ошибок в шахматных движках. Это объяснит, что именно следует искать.

#### 3.8.2.1 Классификация ошибок шахматного движка

Классифицировать ошибки можно по-разному. Самый очевидный критерий — это компонент шахматной программы, в котором есть изъян.

Мы познакомились с пятью частями типичного шахматного движка:

1. Генератор ходов
2. Функция оценки позиции или её альтернатива
3. Алгоритм поиска
4. Дебютная книга
5. Таблицы эндшпилей.

Опираясь на этот список, можно предложить следующую классификацию ошибок:

1. **Ошибки генерации ходов**. Например, генератор упускает какие-то из возможных ходов или выдаёт ходы, запрещённые правилами игры.

2. **Ошибки функции оценки** или альтернативного механизма (сеть NNUE) могут быть следующими:

   * Ошибка в оценке материала. Например, неверная оценка разности между слонами и конями в определённых позициях.

   * Ошибки в оценке позиции — это неверные суждения программы о нематериальных аспектах. Например, мобильность фигур, безопасность короля, контроль ключевых полей и т.д.

   * Переобучение (overfitting) — результат функции оценки или сети NNUE сильно подогнан под специфичные позиции фигур. В этом случае возможна неверная оценка позиций, которые не попали в тестовый набор.

   * Недообучение (underfitting) — функция оценки или сеть NNUE слишком проста и не учитывает все аспекты позиции.

3. **Ошибки алгоритма поиска** — это изъяны реализации самого алгоритма и вспомогательных эвристик выборочного поиска. Они могут быть следующими:

   * Эффект горизонта — просчёт дерева игры не дальше некоторой глубины. Это может привести к решениям, которые дают краткосрочную выгоду, но плохи в долгосрочной перспективе.

   * Ошибки поиска покоя — продление до позиции, которая ошибочно считается спокойной. На самом деле в ней остаются варианты, которые кардинально меняют её оценку.

   * Ошибки отсечений — отсекаются части дерева игры, которые содержат важные ходы и позиции.

   * Ошибка управления временем — программа неправильно учитывает время, отведённое на ход. Например, она агрессивно отсекает ветви дерева игры, когда в запасе остаётся ещё много времени. В этом случае программа принимает поспешное решение и не использует эффективно глубина поиска.

4. **Ошибки в дебютной книге**. Например, в ней отсутствуют новинки, которые известны некоторым игрокам высшего уровня.

5. **Ошибки в таблице эндшпилей** могут быть следующими:

   * Ошибки чтения и интерпретации импортированных таблиц для решённых эндшпилей.

   * Неполные знания по теории эндшпилей.

6. **Общие программные ошибки** — это проблемы, которые характерны для любой программы и не зависят от её предметной области. Они бывают следующими:

   * Ошибки параллельного исполнения кода — связаны с запуском программы в нескольких потоках выполнения. Они приводят к потере данных и зависанию.

   * Утечки памяти — это ситуация, когда программа запросила память у операционной системы, но не освободила её после использования. Если программа работает долгое время и утечки происходят постоянно, в системе возникает дефицит памяти. Он значительно снижает производительность шахматного движка.

I> [**Поток выполнения**](https://ru.wikipedia.org/wiki/Поток_выполнения) (thread) — это последовательность шагов программы, которая выполняется независимо от остальных. Разделение программы на потоки ускоряет её работу на многоядерных процессорах. В этом случае каждое ядро исполняет один поток.

Любая ошибка может спровоцировать слабую игру шахматного движка. Поэтому имеет смысл искать изъяны всех типов и рассматривать условия, в которых они могут проявляться.

#### 3.8.2.2 Сценарии игры против шахматного движка

Мы познакомились с типами ошибок и стратегиями их поиска. Теперь рассмотрим, как применить эти знания на практике, чтобы найти слабые стороны шахматного движка.

У каждого шахматиста высокого уровня есть команда, которая помогает ему в подготовке к матчам и турнирам. В эту команду обычно входят менеджер, тренер, другие шахматисты и психолог.

Для игры против шахматного движка нужны знания из разных прикладных областей. Маловероятно, что один человек овладеет этими знаниями на высоком уровне. Поэтому мы рассмотрим игру команды экспертов против шахматного движка. Такой подход кажется справедливым. Ведь программа — это не один оппонент. За ней, как и за профессиональным шахматистом, стоит большая команда: разработчики, тестировщики, менеджеры и шахматисты-консультанты проекта.

Состав команды экспертов, которая играет против движка, может быть разным. Этот состав и доступная ей информация определяют сценарий подготовки команды к матчу. Рассмотрим возможные сценарии и начнём с самого простого случая.

#### 3.8.2.3 Первый сценарий РНП

В первом сценарии команда экспертов работает в следующих условиях:

1. Команда состоит только из шахматистов.

2. Версия шахматного движка, с которой предстоит играть, недоступна или неизвестна. Также нет никакой информации о его слабых сторонах.

3. Нет специальных инструментов для подготовки к матчу. Речь идёт о программах, которые не входят в обычный набор шахматиста.

Именно в таких условиях проходит типичный матч шахматиста высокого уровня против программы. Его исход зависит от многих факторов и случайностей, как и матч двух гроссмейстеров. Сейчас мы сконцентрируемся только на одной стороне противостояния — поиске ошибок.

Разработчики шахматной программы следуют одной из трёх стратегий поиска ошибок:

1. Ручной несистематический поиск (РНП).

2. Ручной систематический поиск (РСП).

3. Автоматический систематический поиск (АСП).

Команда экспертов может применить только ручной несистематический поиск ошибок. Другими словами, команда экспертов готовится точно так же, как к обычному матчу против игрока высокого уровня. Затем сильнейший шахматист команды играет серию партий против шахматного движка. Только во время этих игр он может экспериментировать и искать слабости программы. Разберёмся, почему экспертам недоступны более сильные стратегии поиска ошибок.

Ручной систематический поиск ошибок предполагает строгий план из четырёх пунктов. Команда экспертов может выполнить только один из них — создать полностью повторяемую среду для воспроизведения ошибки. Для этого надо договориться с разработчиками движка о том, что ни аппаратное обеспечение, ни программа не будут меняться между партиями. Остальные три пункта плана выполнить невозможно:

1. Получить предварительную информацию о предполагаемой ошибке.

2. Следовать повторяемым путём для воспроизведения ошибки.

3. Если ошибка воспроизвелась, зафиксировать состояние программы и среды её выполнения.

Для автоматического систематического поиска ошибок нужна специальная система тестирования и знания для её использования. Мы рассматриваем сценарий, когда в команде нет эксперта по тестированию и специальных инструментов. Поэтому эта стратегия тоже неприменима.

Возможны три комбинации стратегий, которым следуют разработчики шахматного движка и команда экспертов. Для краткости сократим названия стратегий по первым буквам:

1. Разработчики — РНП, команда экспертов — РНП.

2. Разработчики — РСП, команда экспертов — РНП.

3. Разработчики — АСП, команда экспертов — РНП.

В первом случае (РНП-РНП) стороны следуют одинаковой стратегии поиска ошибок. Для команды экспертов это выглядит следующим образом. Самый сильный шахматист играет партии против программы, опираясь на свои экспертные знания. В ходе игры он создаёт различные позиции, которые считает сложными для просчёта программой. Если в одной из них программа играет слабо, у шахматиста появляется план на матч. Он заключается в эксплуатации найденной ошибки.

I> **Эксплуатация ошибок** — это преднамеренное выявление и использование ошибок или уязвимостей в программе. Цель эксплуатации — достижение результатов, непредусмотренных разработчиками.

История развития шахматных программ показывает, что в первой комбинации стратегий (РНП-РНП) шансы на победу команды экспертов высоки. Допустим, что им удалось найти ошибку, а у разработчиков нет возможности её исправить. Тогда эта ошибка будет воспроизводиться каждый раз, если создать подходящие условия. Вопрос только в том, насколько это сложно сделать. Примеры игр по такому сценарию: матч Гарри Каспарова против Deep Thought 1989 года и его первый матч против Deep Blue 1996 года.

Вторая возможная комбинация стратегий — РСП-РНП. В этом случае стратегия разработчиков сильнее. До матча они уже обнаружили и исправили большинство ошибок, которые можно найти более слабой стратегией РНП. Кроме того, стратегия РСП позволяет разработчикам оперативно исправлять обнаруженные в ходе матча ошибки. Пример игры по такому сценарию: Гарри Каспаров против Deep Blue в 1997 году.

В матче 1997 года у Гарри Каспарова был чёткий план: придерживаться закрытых позиций и не давать оппоненту возможности для сильной тактической игры. Такой подход хорошо работал против шахматных компьютеров и программ того времени. Он заставляет машину вести стратегическую игру, качество которой сильно зависит от точной оценки позиции. Малейшие изъяны функции оценки приводят к слабым ходам и потере темпа.

План Гарри Каспарова оказался успешным: он действительно находил слабости компьютера. Проблема была в том, что у шахматиста не было возможности их эксплуатировать. Когда ошибка проявлялась, команда Deep Blue успевала исправить её до следующей партии. Поэтому в каждой игре Гарри Каспаров начинал искать слабости оппонента с нуля. В таких условиях компьютер с огромной вычислительной мощностью одержал победу.

Третья возможная комбинация стратегий — АСП-РНП. Стратегия разработчиков шахматной программы намного сильнее. С очень большой вероятностью автоматические тесты уже обнаружили все ошибки, которые во время матча можно найти вручную. Поэтому разработчики устранили эти проблемы заранее.

Допустим, что разработчики движка используют стратегию АСП. Это означает, что у них есть специальные инструменты для отладки. Другими словами, у них есть все средства, чтобы также выполнить стратегию РСП. Поэтому во время матча разработчики могут оперативно исправлять обнаруженные экспертами ошибки. Такие широкие возможности оставляют мало шансов команде экспертов. Хороший пример игры по подобному сценарию: матч Владимира Крамника против движка Deep Fritz в 2006 году.

#### 3.8.2.4 Второй сценарий РСП

Второй сценарий игры команды экспертов против шахматного движка выглядит следующим образом:

1. Команда экспертов состоит из шахматистов, разработчика шахматных программ и специалиста по компьютерной безопасности.

2. Доступна точная версия шахматного движка, с которой предстоит играть. Также есть история его изменений и исходный код.

3. Нет специальных инструментов для подготовки к матчу.

В таких условиях команда экспертов может применить стратегию ручного систематического поиска ошибок (РСП). Все её шаги специалисты могут выполнить, имея на руках шахматный движок и его исходный код.

Рассмотрим пример. Допустим, что проводится матч между командой экспертов и Stockfish. Для определённости пусть это будет версия 14, выпущенная в 2021 году. Она достаточно старая и это важно.

Исход матча во многом зависит от подготовки команды экспертов. Она заключается в том, чтобы заранее найти ряд слабостей программы и научиться создавать условия для их воспроизведения. Затем во время матча шахматист команды должен эксплуатировать эти слабости и таким образом получить преимущество.

План подготовки команды экспертов может быть следующим:

1. Разработчик шахматных программ просматривает [историю изменений](https://github.com/official-stockfish/Stockfish/commits/master/) Stockfish. Он составляет список исправлений, которые были сделаны после выпуска версии 14. Они устраняют какие-то ошибки или недочёты этой версии. Чем старее версия движка, тем длиннее получится список.

2. Разработчик шахматных программ оценивает каждое изменение в составленном списке. Он ищет исправления ошибок следующих типов:

   * Ошибки генерации ходов
   * Ошибки функции оценки
   * Ошибки алгоритма поиска
   * Ошибки в дебютной книге
   * Ошибки в таблице эндшпилей.

3. Специалист по компьютерной безопасности тоже оценивает каждое изменение в списке. Он ищет исправления общих программных ошибок.

4. Если не найдено ни одной ошибки, которую можно эксплуатировать, все эксперты выполняют ручной несистематический поиск:

   * Разработчик шахматных движков выполняет ревью программного кода. Он ищет ошибки того же типа, которые искал в списке исправлений.

   * Специалист по компьютерной безопасности выполняет аудит кода. Он ищет общие программные ошибки.

   * Шахматисты прогоняют движок через набор позиций, которые считаются сложными для компьютерных программ.

5. Эксперты обсуждают свои результаты. Разработчик шахматных движков и специалист по компьютерной безопасности объясняют шахматистам найденные ошибки и их предполагаемое влияние на игру программы.

6. Команда экспертов проверяет найденные слабости движка в тестовых партиях.

После такой подготовки самый сильный шахматист команды играет матч. У него есть список потенциальных слабостей программы. План на матч строится вокруг создания условий, в которых эти слабости воспроизводятся. Например, это может быть выбор подходящих дебютов, создание нужных комбинаций и связок фигур в миттельшпиле или выход в определённые эндшпили.

Что даст команде экспертов успешное использование стратегии РСП? Представим следующую гипотетическую ситуацию. Команда Deep Blue проводит третий матч с Гарри Каспаровым. Перед матчем разработчики подробно консультируют шахматиста. Они рассказывают об обнаруженных, но ещё неисправленных ошибках компьютера. Очевидно, что такая информация намного повысит шансы Гарри Каспарова на победу. Примерно такое же преимущество даёт экспертам стратегия РСП.

Рассмотрим комбинации стратегий разработчиков шахматного движка и команды экспертов:

1. Разработчики — РНП, команда экспертов — РСП.

2. Разработчики — РСП, команда экспертов — РСП.

3. Разработчики — АСП, команда экспертов — РСП.

В первом случае (РНП-РСП), вероятнее всего, победит команда экспертов. Разработчики шахматных программ применяют сегодня продвинутые методы тестирования и отладки. Стратегии РНП могут следовать только любители или начинающие программисты. Тогда они создают шахматный движок в качестве учебного или хобби-проекта. У него нет шансов против профессиональных шахматистов.

Вторая комбинация стратегий — РСП-РСП. Разработчики шахматного движка и команда экспертов используют одинаковый подход для поиска ошибок. Но эксперты тратят на это больше усилий. Дело в том, что разработчики лучше знают свою программу и имеют специальные инструменты для её отладки. Они могут быстро связать какую-то слабость в игре программы с конкретным местом в её исходном коде. Команде экспертов сделать это намного сложнее.

Команда экспертов может одержать победу в сценарии РСП-РСП, если выполняются следующие условия:

1. Команде экспертов удалось обнаружить ошибки программы, которые создают слабые ходы.

2. Найденные ошибки стабильно воспроизводятся и команда экспертов научилась создавать подходящие для этого условия.

3. Если разработчики шахматного движка исправляют эксплуатируемые ошибки в ходе матча, у команды экспертов всегда есть как минимум ещё одна неизвестная разработчикам ошибка.

Последний пункт требует пояснения. Рассмотрим пример. Допустим, что матч состоит из шести партий. Во время подготовки команда экспертов нашла три ошибки в программе, которые приводят к слабым ходам.

Исход матча отчасти зависит от успешного воспроизведения ошибок шахматистом и от скорости их исправления разработчиками. Если в какой-то партии игроку удалось воспроизвести ошибку, это ещё не гарантирует победу. Он просто получает преимущество, которое программа может вернуть через несколько ходов. С другой стороны, сразу после этого разработчики узнают о проблеме. Они могут исправить изъян программы до следующей партии. Команда экспертов об этом не узнает. Поэтому повторная эксплуатация одной и той же ошибки может не сработать.

Учитывая эти варианты, план экспертов на матч может быть следующим:

1. Эксплуатировать по одной новой ошибке в каждой из трёх партий за белых. В этих партиях играть на победу.

2. В каждой партии за чёрных эксплуатировать только ошибки, которые уже знакомы разработчикам по прошлым играм. Если проблему в программе уже исправили, играть партию на ничью.

Следуя этому плану, у команды экспертов есть шансы выиграть матч.

Третья комбинация стратегий — АСП-РСП. В этом случае стратегия разработчиков шахматного движка сильнее. Высока вероятность, что их система автоматического тестирования уже нашла все ошибки, которые можно было бы воспроизвести и эксплуатировать в условиях матча. Информация об ошибках даёт разработчикам преимущество. Они либо устраняют проблемы заранее перед матчем, либо имеют план по их оперативному исправлению. В этом случае победа команды экспертов маловероятна.

#### 3.8.2.5 Третий сценарий АСП

В третьем сценарии команда экспертов работает в следующих условиях:

1. Команда экспертов состоит из шахматистов, разработчика шахматных программ, специалиста по компьютерной безопасности, специалиста по тестированию, специалиста по статистике и обработке данных.

2. Доступна точная версия шахматного движка, с которой предстоит играть. Также есть история его изменений и исходный код.

3. Есть инструменты для поиска ошибок в шахматной программе.

Инструменты для поиска ошибок команды экспертов повторяют функции системы тестирования, которую используют разработчики шахматного движка. Благодаря им, эксперты применяют стратегию автоматического систематического поиска ошибок (АСП).

Снова обратимся к примеру, в котором команда экспертов играет против Stockfish версии 14. На этапе подготовки команда ищет слабости в игре программы, чтобы эксплуатировать их в ходе матча. Для этого она применяет специальные инструменты.

Есть несколько способов, как можно автоматизировать поиск ошибок в шахматной программе:

1. Провести турнир между Stockfish 14 и более сильным шахматным движком. Такой турнир даст набор партий, в которых Stockfish проиграл. Шахматисты из команды экспертов должны проанализировать ходы в этих партиях. Они могут указать на слабые стороны Stockfish.

2. Разработчик шахматных программ из команды экспертов составляет список изменений в коде Stockfish, сделанных после выпуска версии 14. Имея на руках исходный код, он может собирать модифицированные версии шахматного движка: включая и исключая эти изменения. После этого влияние каждого из них на силу игры программы оценит система тестирования. Инструмент даст статистику побед, конкретные партии и позиции, в которых Stockfish 14 без исправления сыграл слабо.

3. Инструмент может проанализировать все официальные партии Stockfish версии 14. Он ищет позиции, в которых Stockfish делает слабый ход по мнению более сильного движка. Шахматисты команды экспертов должны проанализировать эти позиции. Они могут указать на слабые стороны Stockfish 14.

Это только несколько идей, как можно использовать специальные инструменты для поиска ошибок. Возможны и другие варианты.

Специальные инструменты не находят ошибки шахматного движка автоматически. Скорее они увеличивают охват поиска. С их помощью эксперты проверяют больше аспектов игры программы по сравнению со стратегией РСП. Инструменты указывают перспективное направление, следуя которому можно найти слабость в игре программы. Всю работу по анализу конкретных игр и позиций по-прежнему выполняет эксперт шахматист.

Рассмотрим комбинации стратегий разработчиков шахматного движка и команды экспертов:

1. Разработчики — РНП, команда экспертов — АСП.

2. Разработчики — РСП, команда экспертов — АСП.

3. Разработчики — АСП, команда экспертов — АСП.

В первой комбинации (РНП-АСП) победа команды экспертов очень вероятна. Если разработчики используют стратегию РНП сегодня, это говорит о низком качестве шахматной программы. Она не может играть на уровне профессиональных шахматистов.

Вторая комбинация стратегий — РСП-АСП. Стратегия команды экспертов сильнее. Потенциально они найдут больше ошибок для эксплуатации, чем дала бы им стратегия РСП. Это означает, что на каждую партию матча у экспертов может быть заготовлено по несколько ошибок программы. Такая подготовка значительно повышает их шансы как в партиях за белых, так и в партиях за чёрных. Теперь шахматист может играть на победу независимо от цвета своих фигур.

После того как шахматист эксплуатирует какую-то ошибку программы, разработчики могут её исправить до следующей партии. Но это практически не повлияет на исход матча, если команда экспертов нашла достаточно ошибок. В таком сценарии эксперты, скорее всего, выиграют матч.

Третья комбинация стратегий — АСП-АСП. Стороны используют одинаковый подход для поиска ошибок. Исход матча зависит от вложенных ресурсов. Разработчики шахматного движка вкладываются в поиск и исправление ошибок, когда выпускают его очередную версию. Эксперты тратят ресурсы на подготовку к матчу. В обоих случаях это одни и те же ресурсы:

1. Вычислительные мощности для запуска системы тестирования или специальных инструментов.

2. Время работы системы тестирования или специальных инструментов.

3. Время шахматистов и других экспертов для анализа найденных ошибок и слабостей программы.

Вероятно, победу в матче одержит сторона, которая вложит в поиск ошибок больше ресурсов. Рассмотрим пример. Разработчики Stockfish версии 14 используют систему интенсивного тестирования Fishtest. Команде экспертов нужны вычислительные ресурсы, соизмеримые с этой системой. В противном случае их поиск ошибок с большой вероятностью закончится неудачей.

#### 3.8.2.6 Реалистичность сценариев

Мы рассмотрели три сценария игры команды экспертов против шахматного движка. Все крупные матчи именитых шахматистов против программ в 2000-х годах проходили в условиях, близких к первому сценарию. Возникает вопрос: насколько реалистичны второй и третий сценарии?

После поражения Владимира Крамника в матче с Deep Fritz в 2006 году шахматное сообщество и публика потеряли интерес к подобным противостояниям. Стало сложно найти спонсоров и участников. Шахматисты высшего уровня не хотят тратить своё время на подготовку к малоперспективному матчу.

Второй и третий сценарии требуют серьезных вложений. Команда экспертов должна состоять из шахматистов уровня претендента. В неё также должны входить эксперты разных направлений ИТ высокого уровня. Чем выше уровень экспертов, тем выше их шансы успешно подготовиться к матчу. Если шахматный движок коммерческий, то необходимо сотрудничество со стороны его разработчиков. Они должны предоставить исходный код и историю изменений программы.

Чтобы выполнить условия второго и третьего сценариев, есть много требований. В теории, они все выполнимы. На практике же возникает вопрос: ради чего такие усилия? В лучшем случае команда экспертов выиграет матч против старой версии не самого сильного шахматного движка. В таком достижении нет ничего привлекательного ни для зрителей, ни для команды экспертов высшего класса, ни для спонсоров мероприятия. Поэтому матч на таких условиях вряд ли когда-нибудь состоится.

Можно ли поднять ставки в таком противостоянии? Есть ли у команды экспертов шансы против последней версии Stockfish? Ряд особенностей этого движка помешает команде экспертов найти в нём ошибки. Даже если они будут следовать стратегии АСП. Эти особенности следующие:

1. **Сеть NNUE вместо функции оценки**. Специалист по шахматным движкам может выполнить ревью кода функции оценки и понять его логику. Возможно, он найдёт в нём изъяны. Но анализ параметров обученной сети NNUE ничего не скажет о её слабостях. Изменения параметров невозможно интерпретировать в шахматных понятиях.

2. **Система тестирования Fishtest**. Интенсивное автоматизированное тестирование выявляет основную массу ошибок в движке Stockfish. Если в нём остались скрытые ошибки, они либо незначительные, либо их очень сложно воспроизвести.

3. **Информация об исправлениях в последней версии Stockfish ограничена**. У команды экспертов есть только небольшая история изменений после последнего релиза. Маловероятно найти среди них подходящую для эксплуатации ошибку.

Из истории противостояния человека и шахматных программ можно сделать следующий вывод. Игра против системы, которая достигла сверхчеловеческого уровня в какой-то дисциплине, не имеет ничего общего с игрой против человека. Это противостояние больше напоминает поиск и эксплуатацию уязвимостей в программной системе. Только такой подход даёт хоть какие-то шансы на победу над машиной.

#### 3.8.3 Стратегия игры против машины

Мы рассмотрели разные стратегии поиска ошибок в программах. Их могут применять обе стороны: как разработчики шахматных движков, так и шахматисты, играющие против программ. Попробуем обобщить эти рассуждения и поговорим о стратегии человека против машины в любой игре.

Начнём с предусловий для такого противостояния. Во-первых, человек должен быть экспертом в игре. Например, если это шахматы, он должен быть гроссмейстером. Чем выше уровень игрока, тем разнообразнее ошибки машины, которые он сможет эксплуатировать. Это могут быть не только понятные новичку тривиальные зевки, но и тонкие стратегические просчёты.

Во-вторых, человеку нужен надёжный источник информации о машине. Это может быть история её прошлых игр, исходный код управляющей программы, технические подробности реализации. Если этого нет, человек должен иметь возможность самостоятельно наиграть достаточно партий против машины.

В-третьих, версия машины и её управляющей программы должна быть зафиксирована. Любое изменение в аппаратном или программном обеспечении означает, что игрок теперь соревнуется с совершенно другой машиной.

Общий алгоритм подготовки и игры против машины выглядит следующим образом:

1. Собрать предварительную информацию о машине.

2. Создать повторяемую среду для работы машины.

3. Найти подходящие для эксплуатации ошибки или закономерности в поведении машины.

4. Научиться воспроизводить найденные ошибки и закономерности поведения машины.

5. Эксплуатировать ошибки в матче против машины.

Начнём с первого пункта: сбор информации. Следующие сведения помогут игроку эффективнее подготовится к матчу:

1. В какой проблемной среде работает машина?

2. К какому типу интеллектуального агента относится машина?

3. Какую стратегию поиска ошибок применяли разработчики?

Ответы на эти вопросы могут сразу указать на потенциальные слабости машины. Например, пусть игра представляет собой частично наблюдаемую среду. Машина представляет собой основанного на полезности агента, который работает на каком-то алгоритме состязательного поиска. В этом случае у неё есть принципиальная проблема с обработкой информации. Машина не способна делать долгосрочные выводы из сведений, полученных несколько шагов назад. Также она не учитывает информацию, которая доступна оппоненту. Этот изъян можно использовать, чтобы получить преимущество.

Второй шаг алгоритма — создать повторяемую среду. Одно из предусловий заключается в том, что версия машины и управляющей программы не меняются. Кроме этого машина должна постоянно играть в одних и тех же условиях.

Допустим, что игра — это [компьютерная стратегия в реальном времени](https://ru.wikipedia.org/wiki/Стратегия_в_реальном_времени) (real-time strategy или RTS). Тогда в каждой партии следующие условия не должны меняться:

* карта
* фракция, за которую играет машина
* фракция игрока
* версия игры (патч)
* аппаратное обеспечение машины.

Такое постоянство среды фиксирует поведение машины. Если в нём удастся обнаружить ошибку или закономерность, они будут воспроизводимы. То есть каждый раз попав в определённые условия, машина всегда будет принимать одни и то же решения.

Третий шаг — найти подходящие для эксплуатации ошибки или закономерности. Выполнять этот шаг можно только тогда, когда среда работы машины зафиксирована. В противном случае любое изменение среды или самой машины потенциально делает обнаруженную ошибку невоспроизводимой.

Перед началом поиска ошибок полезно классифицировать их по каким-то признаком. Это могут быть компоненты машины, которые работают с ошибкой. Также признаками могут быть разные аспекты игры, в которых машина ошибается. Классификация ошибок помогает упорядочить процесс поиска.

Независимо от характера игры есть ряд типичных ошибок:

1. **Машина не справляется со сложностью правил игры**. Например, в игре может быть так много объектов, их параметров и способов взаимодействия, что машина не способна учесть все возможные комбинации. В этом случае достаточно найти такие состояния среды, которые машина не понимает. Её действия в этих состояниях будут неадекватными.

2. **Машина не справляется с вычислительной сложностью игры**. Пример такой проблемы — эффект горизонта в ранних шахматных программах. Они просчитывали до четырёх ходов вперёд. Это означает, что программа не видит планы и комбинации оппонента на пять ходов вперёд и более.

3. **Логические ошибки при выборе действия**. Если машина или её часть реализована как рефлексный агент, типична ошибка интерпретации текущего состояния среды. Например, два состояния похожи по некоторым признакам и машина не может их различить. Тогда она может  выбрать действие, которое корректно для одного состояния, но неверно для другого.

4. **Ошибки обучения модели**. Если машина представляет собой обучающегося агента, надо проверить типичные ошибки алгоритма обучения: низкая производительность модели, переобучение, недообучение, плохая обобщающая способность и т.д.

5. **Ошибки долгосрочного планирования**. Такие проблемы встречаются у всех типов интеллектуальных агентов. В сложных играх решения участников могут иметь долгосрочные последствия. Чтобы их учесть, нужны серьёзные вычислительные ресурсы. Если машина не может связать причины и следствия игровых событий, её действия будут неадекватными.

При поиске слабостей машины важно учитывать стратегию поиска ошибок, которой следовали её разработчики. Стратегия поиска ошибок со стороны игрока должна быть не слабее. В противном случае маловероятно, что он найдёт ещё неисправленные проблемы, подходящие для эксплуатации.

Слабости в игре машины могут создавать не только ошибки в её управляющей программе или оборудовании. В некоторых играх предсказуемость оппонента даёт значительное преимущество. В этом случае стоит искать также закономерности и шаблоны в поведении машины. Если она каждый раз реагирует одинаково на определённую игровую ситуацию, это можно эксплуатировать в своих целях.

Четвёртый шаг алгоритма — научиться воспроизводить найденные слабости машины и закономерности её поведения. Некоторые ошибки и действия могут быть спорадическими. Их можно учитывать в партиях итогового матча, но вокруг них нельзя строить стратегию игры против машины.

I> **Спорадические ошибки** программы воспроизводятся случайно с некоторой долей вероятности. Например, в один запуск из десяти.

Повторяемая среда работы машины так же важна при воспроизведении найденных слабостей, как и при их поиске.

Пятый шаг — эксплуатация найденных слабостей в игре машины. На этой стадии самое важное — вмешательство разработчиков в работу машины. Если они вносят исправления, у игрока должен быть достаточный набор ошибок для эксплуатации. Его должно хватить на все партии итогового матча.

В процессе итогового матча игрок может обнаружить новые слабости машины. Но полагаться на это не стоит, тем более если разработчики сразу получат информацию о проблеме и смогут её исправить. Именно подготовка к матчу во многом определит его исход. 

Если машина играет на сверхчеловеческом уровне, успешная подготовка не гарантирует игроку победы. Любая его случайная ошибка может привести к поражению. Подготовка только повышает шансы на успех.

{pagebreak}
