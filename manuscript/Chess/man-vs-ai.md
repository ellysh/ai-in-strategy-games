## 3.8 Человек против шахматной программы

Последний крупный матч человека против шахматной программы состоялся в ноябре 2006 года. Действующий на тот момент чемпион мира Владимир Крамник играл против движка Deep Fritz. Матч закончился победой Deep Fritz со счётом 4-2: четыре ничьи и две победы программы. Шахматист не смог выиграть ни одной партии.

Во время матча Deep Fritz работал на мощном по меркам того времени персональном компьютере. Но его вычислительные ресурсы значительно уступали шахматному суперкомпьютеру Deep Blue. Для сравнения: движок Deep Fritz просчитывал около 8 миллионов позиций в секунду, а Deep Blue — от 100 до 300 миллионов в зависимости от конфигурации. Несмотря на скромную производительность, Deep Fritz одержал уверенную победу над чемпионом мира. Этот матч показал, насколько выросло качество шахматных программ спустя 10 лет после противостояния Гарри Каспарова и Deep Blue.

В условия матча современные шахматные движки не оставляют шансов лучшим игрокам. Ведущие шахматисты единогласно признают, что человек уже давно не может конкурировать с машиной. Этот вопрос считается решённым однозначно и окончательно.

Можно ли сказать что-то новое о противостоянии человека и шахматной программы? Это возможно, если посмотреть на него под другим углом.

### 3.8.1 Ошибки в программах

Матчи гроссмейстеров с шахматными программами комментируют профессионалы. Они являются экспертами в предметной области и знают все тонкости шахматной игры. Опираясь на свой опыт, комментатор рассказывает о позициях, ходах, вариантах, комбинациях и ошибках. Точка зрения именно этих экспертов звучит в репортажах со всех шахматных событий. Но эта точка зрения не единственная.

Шахматные движки — это в первую очередь компьютерные программы. Их разрабатывают профессиональные программисты. Это другой вид экспертов, который имеет отношение к компьютерным шахматам. К сожалению, эксперты этого рода редко высказываются о поединке человека и машины. Одну из самых известных попыток предпринял Фэн Сюн Сю. Он опубликовал книгу "Behind Deep Blue" о поединке суперкомпьютера IBM и Гарри Каспарова.

Что может рассказать разработчик шахматной программы? В своей книге Фэн Сюн Сю знакомит читателя с техническими задачами и проблемами, которые решала его команда. Комментируя партии, он часто говорит о программных и аппаратных ошибках. Именно из-за них Deep Blue делал слабые ходы, терял позиционное преимущество и проигрывал. Означает ли это, что ключ к победе над шахматной программой кроется в ошибках её реализации? Если да, то изменилось ли что-то со времён Deep Blue?

Управляющая программа для Deep Blue была разработана почти 30 лет назад. Методология программирования продвинулась далеко вперёд за это время. Но проблема ошибок никуда не делась. Современные программы аварийно завершаются, теряют данные пользователей и зависают точно так же, как и 30 лет назад. Главная причина этого в том, что разработка программного обеспечения — это компромисс между функциональностью, стоимостью, временем и качеством. Чем-то всегда приходится жертвовать. Разработка шахматной программы в этом плане ничем не отличается.

Чтобы найти и исправить ошибки в программах, разработчики используют различные методы тестирования. Например, это может быть ручная проверка самых важный функций программы. Тестирование можно автоматизировать. Специальные системы могут запускать программу и выполнять в ней стандартные действия. Тем самым они проверяют, что она по-прежнему работает.

Если внимательно посмотреть на историю шахматных программ, можно заметить некоторую закономерность. Метод поиска ошибок в них постоянно развивался. Одновременно с этим рос и уровень игры программ. Значительные скачки в силе движков происходили именно тогда, когда разработчики начинали использовать новый метод тестирования. Есть ли какая-то взаимосвязь между этими событиями? Возможно, что есть.

Предлагаю снова обратиться к истории компьютерных шахмат. Но на этот раз мы сфокусируемся не на игре, а на поиске ошибок в программах.

#### 3.8.1.1 Ручной несистематический поиск

В 1960-х годах методология разработки и тестирования ПО находилась на начальном этапе развития. Автор программы сам тестировал её вручную. Обычно он пробовал разные входные данные и проверял, что выход программы соответствует ожидаемому результату.

Разработчики первых шахматных программ следовали общепринятой практике. Они применяли самую очевидную стратегию тестирования, которая состояла из трёх стадий.

На первой стадии автор играет со своей программой несколько партий после каждого значительного изменения в её коде. Такая проверка показывает, что программа не завершается с ошибкой после очередного хода и не нарушает правил игры. Если программа делает очень слабые или бессмысленные ходы, разработчик пытается понять и устранить их причину.

Такой тест в терминах современной разработки ПО называется [**альфа-тестированием**](https://ru.wikipedia.org/wiki/Тестирование_программного_обеспечения#Уровни_тестирования). Его выполняет сам разработчик. При этом программа выполняется в некоторой контролируемой среде, например, под управлением отладчика. Этот инструмент позволяет остановить выполнение программы в любой момент и получить состояние её памяти. Таким образом, разработчик сразу получает полную информацию о возникшей ошибке, может найти её в исходном коде и быстро исправить.

Когда программа начинает работать стабильно без критических ошибок, наступает вторая стадия тестирования. Разработчик обращается к одному или нескольким сильным шахматистам. Они проводят серию игр против программы и указывают на её слабости. Типичная причина этих слабостей — неверные представления разработчика о шахматной игре. Его недостаточное владение предметной областью выливается в логические ошибки программы.

I> [**Логической ошибкой**](https://ru.wikipedia.org/wiki/Логическая_ошибка_(программирование)) называется неправильное действие программы на этапе принятия решений.

Сегодня такой вид теста называется [**бета-тестированием**](https://ru.wikipedia.org/wiki/Бета-тестирование). Его выполняет ограниченный круг потенциальных пользователей программы. Во время тестирования пользователи используют свои экспертные знания в предметной области. Они дают разработчику обратную связь об обнаруженных проблемах в программе.

На последней стадии тестирования шахматная программа играла на турнирах. Это были партии с классическим контролем времени против шахматистов и других программ. На этой стадии разработчик наблюдал, как программа работает в максимально сложных для неё условиях. Когда происходил сбой или бессмысленный ход, автор собирал максимум информации об этом событии. Таким образом разработчик искал причину ошибки и код, который её вызвал.

Предлагаю назвать такую стратегию поиска ошибок в шахматных программах **ручным несистематическим поиском**. Слово **ручной** означает, что его выполняет человек без какой-либо автоматизации. Он играет серию партий против программы от начала до конца.

Поиск называется **несистематическим**, потому что в нём нет строго плана. Мы рассмотрели три стадии тестирования. На каждой из них тестировщик просто играет против программы. Тем самым он проверяет её основные функции. В одной из партий может проявиться какая-то из существующих ошибок. Но такое воспроизведение проблемы будет чистой случайностью. Ходы и позиции могут сложиться так, что ошибки не проявятся ни в одной из партий. В этом случае разработчик программы о них не узнает и не устранит.

Эффективность ручного несистематического поиска ошибок зависит только от интенсивности тестирования. Чем больше партий сыграет шахматная программа, тем выше шанс воспроизвести какую-то из её ошибок. Только тогда у разработчика появится шанс исправить проблему. Ошибки, которые ни разу не воспроизводились, остаются скрытыми. Их невозможно исправить из-за отсутствия информации.

I> **Скрытой ошибкой** (latent defect) программы называется проблема, которая не была обнаружена на этапе тестирования. Она проявляется только после того, как ПО было выпущено и использовалось в определённых условиях.

Интенсивность тестирования зависит от ресурсов, которые разработчики инвестируют в проект. Особенно важны ресурсы на его старте. Обратите внимание, что самые сильные шахматные программы разрабатывались профессионалами, за которыми стояли крупные корпорации. Вот несколько примеров:

* Шахматная программа Бернштейна — команда из IBM.

* Компьютер Belle — команда из Bell Labs.

* Программа Cray Blitz — команда из корпорации Cray Research по производству суперкомпьютеров.

* Компьютер Deep Blue — команда из IBM.

В каждый из этих проектов были вложены огромные ресурсы. Конкретнее, вложения были следующими:

1. Деньги на разработку специализированного оборудования (шахматные компьютеры и чипы).

2. Время разработчиков программ, которое в те годы было крайне дорогим. Они писали код, тестировали его и исправляли обнаруженные ошибки.

3. Компьютерное время для тестирования и отладки программы.

4. Время профессиональных шахматистов для тестирования программы.

Вложения на начале проекта позволяли команде разработчиков проводить качественное тестирование. Благодаря ему, обнаруживалась и устранялась большая часть логических ошибок в программе. Это выводило её игру на высокий уровень. Тогда проект привлекал внимание СМИ, шахматного сообщества и специалистов в области ИТ. Программу постоянно приглашали на турниры. Сильнейшие шахматисты охотно проводили с ней матчи. Это только увеличивало интенсивность её тестирования. Как следствие, уровень игры программы продолжал расти.

#### 3.8.1.2 Ручной систематический поиск

Стратегия ручного несистематического поиска ошибок имеет предел. Если таким способом интенсивно тестировать шахматную программу, рано или поздно уровень её игры перестанет расти. Это происходит по нескольким причинам.

Во-первых, в программе остаётся мало скрытых ошибок. Чтобы их воспроизвести нужны очень специфичные позиции и условия. Эти позиции могут никогда не сложиться в тестовых партиях со стандартными дебютами и эндшпилями. 

Во-вторых, некоторые ошибки программы могут быть очень тонкими. Только профессиональный шахматист высочайшего уровня способен понять такую ошибку и объяснить её суть разработчику программы. Но у чемпиона мира и претендентов на его место нет времени интенсивно тестировать шахматный движок. Играя против программы матч, профессионал найдёт эту ошибку и воспользуется ей. Заранее же разработчик никогда про неё не узнает.

Именно с этими трудностями столкнулась команда Deep Blue, когда их компьютер играл первый матч против Гарри Каспарова в 1996 году. На тот момент уровень игры компьютера был близок к максимуму, который мог дать ручной несистематический поиск ошибок. До уровня Гарри Каспарова он не дотягивал.

Чтобы усилить игру Deep Blue, команда разработчиков создала специальные инструменты для тестирования. Главным из них стал программный прототип функции оценки Deep Blue с графическим интерфейсом. Его функции напоминали современный шахматный движок и интерфейс к нему.

Рассмотрим, как работал инструмент тестирования Deep Blue. Через графический интерфейс пользователь задавал произвольную позицию фигур на доске. Позицию также можно было загрузить из файла с ходами сыгранной ранее партией. После этого интерфейс отображал баллы, которые функция оценки ставила каждому возможному ходу. Также пользователь видел диагностическую информацию о том, какие факторы позиции повлияли на оценку.

Новый инструмент тестирования стал отправной точкой для новой стратегии поиска ошибок. Раньше штатный гроссмейстер проекта проверял игру Deep Blue в полноценных партиях. Теперь достаточно было ввести нужную позицию и получить лучший ход по мнению компьютера. Такой подход намного повысил эффективность тестирования.

Вторым компонентом новой стратегии поиска ошибок стало дополнительное правило в играх с компьютером. Чтобы тестовые партии стали эффективнее, разработчики разрешили штатному шахматисту брать ход назад в любой позиции. Это позволило игроку возвращаться назад и исправлять свои ошибки. Таким образом он мог играть на равных с Deep Blue, который превосходил его минимум на 200 пунктов Эло. При равной игре ошибки компьютера стали воспроизводиться чаще и очевиднее. Он перестал выигрывать из-за банальных зевков оппонента.

Предлагаю назвать стратегию поиска ошибок команды Deep Blue **ручным систематическим поиском**. Поиск **ручной**, потому что его по-прежнему выполняет человек без автоматизации. Но на этот раз тестировщик пользуется специальными инструментами и расширенными правилами игры.

Поиск называется **систематическим**, потому что у него есть строгий план действий. Этот план выглядит следующим образом:

1. Получить предварительную информацию о предполагаемой ошибке. Например, тестировщик знает, что в программе изменилась оценка пешечной структуры. Тогда он должен сконцентрироваться на позициях с различной конфигурацией пешек и проверить, что программа правильно в них ориентируется.

2. Создать полностью повторяемую среду для воспроизведения ошибки. Это означает, что ни аппаратное обеспечение, ни программна не должны меняться между тестами. Тестировщик всегда берёт один и тот же компьютер и запускает на нём одну и ту же версию программы или инструмента тестирования.

3. Следовать повторяемым путём для воспроизведения ошибки. Это означает, что тестировщик на каждой итерации выполняет одни и те же действия, которые приводят к одним и тем же результатам. 

4. Если ошибка воспроизвелась, зафиксировать состояние программы и среды её выполнения (например, состояние аппаратуры). Именно один из параметров этого состояния провоцирует возникшую ошибку. Задача разработчика — понять, какой именно параметр.

Рассмотрим, как команда Deep Blue следовала этому плану тестирования. Первый пункт — узнать о предполагаемой ошибке компьютера. Было несколько способов это сделать:

1. Получить информацию от разработчика, который изменили что-то в управляющей программе или прошивке шахматного чипа. Это изменение потенциально могло привести к ошибкам в позициях, когда оно влияет на выбор хода.

2. Во время тестовой игры с правилом брать ход назад, Deep Blue делает слабый ход. Тестировщик должен запомнить все ходы партии и особенности позиции, которые привели к ошибке.

3. Во время очередной турнирной партии Deep Blue делает слабый ход. Лог файл игры позволял точно восстановить ход этой партии.

Второй пункт плана — создать полностью повторяемую среду для воспроизведения ошибки. Разработчики Deep Blue могли его выполнить. Они контролировали версии управляющей программы, шахматных чипов и их прошивки. Это позволяло воссоздать комбинацию аппаратного обеспечения и программ, в которой произошла ошибка.

Третий пункт — следовать повторяемым путём для воспроизведения ошибки. Это условие практически невозможно выполнить, если играть обычные партии против шахматной программы. Дело в том, что на алгоритм её работы влияет много случайностей. Эту проблему решил специальный инструмент тестирования команды Deep Blue. Благодаря ему, можно было не играть партию целиком, а сразу выставить нужную позицию фигур.

Четвёртый пункт плана — зафиксировать состояние программы и оборудования. У команды Deep Blue были инструменты для анализа управляющей программы и прошивки шахматных процессоров. Так они собирали полную информацию о среде выполнения в состоянии ошибки. Это помогало выяснить причину ошибки и исправить её.

На исход второго матча Гарри Каспарова против Deep Blue 1997 года повлияло много факторов. Одним из них стала новая стратегия поиска ошибок команды Deep Blue. Благодаря ей, разработчики могли оперативно вносить изменения в управляющую программу компьютера. Если Гарри Каспаров находил какой-то изъян в игре оппонента, команда Deep Blue успевала исправить его до следующей партии. Это уравнивало шансы сторон: человек и машина адаптировались к игре друг друга по ходу матча.

#### 3.8.1.3 Автоматический систематический поиск

Если программа запускается на специализированном шахматном компьютере, это ограничивает возможности её тестирования. Проблема в том, что шахматный компьютер — это уникальное оборудование в единственном экземпляре. Поэтому невозможно устроить партию между разными версиями этого компьютера или его управляющей программы.

В конце 1990-х годов платформой для шахматных программ стали обычные ПК. Они работают под управлением многозадачной операционной системы (ОС). Такая ОС позволяет выполнять несколько программ одновременно. На одном ПК можно запустить два разных шахматных движка и устроить между ними партию.

Новая аппаратная платформа открыла возможность для новой стратегии поиска ошибок. Разработчики шахматных движков начали регулярно тестировать разные версии своих программ. Скоро они пришли к идее автоматизации этого процесса. Стали появляться системы, которые управляли тестированием. Такая система запускает указанные версии движка и устраивать между ними партии. Она же ведёт статистику побед и записывает ходы в каждой партии. В конце работы система выдаёт полный отчёт с результатами.

Предлагаю назвать такую стратегию поиска ошибок **автоматическим систематическим поиском**. Поиск **автоматический**, потому что выполняется системой тестирования без участия человека. Разработчик шахматного движка только получает отчёт о результатах.

Поиск называется **систематическим**, потому что выполняется по строгому плану. План заключается в последовательном запуске ряда автоматических тестов. Каждый из них фокусируется на ошибках разного типа.

Современный шахматный движок проверяют автоматические тесты следующих типов:

1. **Автоматическое регрессионное тестирование** — проверка новой версии движка на заранее подготовленном наборе типовых позиций. Такой тест показывает, что в программе не появилось новых ошибок и она по-прежнему корректно действует в определённых сценариях.

2. **Интеграционное тестирование** — автоматические тесты запускаются каждый раз, когда в кодовую базу движка вносится какое-то изменение. Такой тест проверяет, что оно как минимум не ухудшает уровень игры движка.

3. **Проверка производительности** — новая версия движка обрабатывает набор специально подготовленных сложных позиций. Для каждой позиции оценивается производительность движка: глубина поиска, достигнутая в единицу времени, и количество узлов дерева игры, проверяемых в секунду. Такой тест показывает, что количественные показатели производительности движка не ухудшились.

4. **Автоматические турниры** проводятся между разными версиями движка. Турнир даёт статистику, которой достаточно для сравнения относительного уровня Эло этих версий.

5. **Тестирование дебютов и эндшпилей** — новая версия движка отыгрывает набор стандартных дебютов и эндшпилей. Тест проверяет, что изменения движка корректно работают на всех стадиях партии.

Такой план тестирования обнаруживает ошибки на ранней стадии. Часто интеграционный тест может точно указать на изменение, которое вызвало ошибку. Это значительно повышает эффективность разработки. Программисты могут смелее экспериментировать с небольшими изменениями и последовательно улучшать разные части движка.

Автоматическое тестирование легко масштабировать. Для этого достаточно подключить больше компьютеров к системе. Тогда все пять типов тестов станут интенсивнее. Команда проекта Stockfish вывела масштаб автоматизированных тестов на беспрецедентный уровень. Система Fishtest объединяет сотни компьютеров добровольцев в единую сеть. Эта сеть выполняет интенсивные автоматические тесты на разнообразном оборудование.

Оценим примерный выигрыш производительности, который дала система Fishtest. Допустим, что две версии движка тестируются в партиях с укороченным контролем времени — 1 минута на игру. Пусть один экземпляр движка работает на одном ядре процессора. Современный процессор Intel имеет минимум 8 ядер. Тогда на одном современном ПК можно запустить примерно `60 * 24 * 8 / 2 = 5760` игр в день.

Компания по разработке коммерческого шахматного движка может выделить для запуска тестов от нескольких десятков до сотни компьютеров. Это позволит проигрывать максимум `100 * 5760 = 576000` партий в день.

К сети системы Fishtest ежедневно подключаются от сотни до тысячи компьютеров. Возьмём среднее число — 550 компьютеров. Тогда в день система сможет сыграть примерно `550 * 5760 = 3,168,000` партий. Это почти в четыре раза больше, чем позволяют ресурсы разработчиков коммерческого движка.

Качество автоматического тестирования напрямую зависит от его интенсивности. Система Fishtest предоставляет колоссальные вычислительные ресурсы. Именно благодаря им движок Stockfish сохраняет лидерство во всех турнирных таблицах.

### 3.8.2 Игра против шахматного движка

Мы познакомились с тремя стратегиями поиска ошибок, которые применяют разработчики шахматных программ. Какое отношение это имеет к игре человека против движка?

Давайте поговорим о том, как профессионалы играют в шахматы. Представим партию между двумя гроссмейстерами с примерно равным уровнем Эло. Если обе стороны идеально исполняют свой план на игру, вероятнее всего, она закончится ничьей. Но если одна из сторон допускает промах, оппонент получает преимущество. Речь идёт не о зевке пешки. Промахом может быть даже небольшое смещение фигур, которое лишь немного ухудшает позицию. Даже такое незначительное преимущество игрок высокого уровня способен превратить в победу.

Партия против современного шахматного движка — это игра на самом высоком уровне. Поэтому цена любого промаха в ней так же высока, как и в партии между двумя гроссмейстерами. Следовательно, чтобы выиграть у программы, надо получить преимущество и развить его в победу. Преимущество над сильным оппонентом можно получить тогда, когда знаешь его слабые стороны. Слабые стороны шахматного движка создают те самые ошибки, которые ищут и устраняют его разработчики. Мы рассмотрели три стратегии поиска этих ошибок.

Возникает вопрос: может ли шахматист применить какую-то из трёх стратегий поиска ошибок, чтобы найти слабые стороны движка? Да, может. Но перед тем как углубиться в эту тему, поговорим о типах ошибок в шахматных движках. Это объяснит, что именно следует искать.

#### 3.8.2.1 Классификация ошибок шахматного движка

Можно придумать разные критерии для классификации ошибок шахматного движка. Самый очевидный критерий — это компонент программы, который работает с ошибкой.

Мы уже знакомы с пятью основными частями типичного шахматного движка: 

1. Генератор ходов
2. Функция оценки позиции
3. Алгоритм поиска
4. Дебютная книга
5. Таблицы эндшпилей.

Опираясь на этот список, можно предложить следующую классификацию ошибок:

1. **Ошибки генерации ходов**. Например, генератор упускает какие-то из возможных ходов или выдаёт ходы, запрещённые правилами игры.

2. **Ошибки функции оценки** или альтернативного механизма (сеть NNUE).

* Ошибка в оценке материала. Например, движок неверно оценивает разность между слонами и конями в определённых позициях.

* Ошибки в оценке позиции — это неверные суждения движка о нематериальных аспектах. Например, мобильность фигур, безопасность короля, контроль ключевых полей.

* Переобучение (overfitting) — результат функции оценки слишком сильно подогнан под специфичные позиции фигур. В этом случае возможна неверная оценка позиций, которые не попали в тестовый набор.

* Недообучение (underfitting) — функция оценки слишком простая и не учитывает все аспекты позиции.

3. **Ошибки алгоритма поиска** — это ошибки в реализации самого алгоритма и вспомогательных эвристик выборочного поиска.

* Эффект горизонта — движок не просматривает дерево игры дальше некоторой глубины. Это может привести к решениям, которые дают краткосрочную выгоду, но плохи в долгосрочной перспективе.

* Ошибки поиска покоя — движок выполнил продление до позиции, которую ошибочно посчитал спокойной. На самом деле в позиции остаются варианты, которые кардинально меняют её оценку. 

* Ошибки отсечений — движок отсекает части дерева, которые содержат важные ходы и позиции.

* Ошибка управления временем — движок неправильно учитывает время, отведённое на ход. Например, он агрессивно отсекает ветви дерева игры, когда у него в запасе остаётся ещё много времени. В этом случае движок принимает поспешное решение и не использует свою глубину поиска эффективно.

4. **Ошибки в дебютной книге**. Например, в ней отсутствуют новинки, которые известны некоторым игрокам высшего уровня.

5. **Ошибки в таблице эндшпилей**.

* Ошибки чтения и интерпретации импортированных таблиц для решённых эндшпилей.

* Неполные знания по теории эндшпилей.

6. **Общие программные ошибки** — это проблемы, которые характерны для любой программы и не зависят от её предметной области.

* Ошибки параллельного исполнения кода — связаны с запуском движка в нескольких потоках выполнения. Такие ошибки приводят к потере данных и блокировке исполнения программы. 

* Утечки памяти — это ситуация, когда программа запросила память у операционной системы, но не освободила её после использования. Если программа работает долгое время и утечки происходят постоянно, в системе возникает дефицит памяти. Он значительно снижает производительность движка.

I> [**Поток выполнения**](https://ru.wikipedia.org/wiki/Поток_выполнения) (thread) — это последовательность шагов программы, которая может выполняться независимо от остальных. Разделение программы на потоки позволяет быстрее выполнять её на многоядерных процессорах. В этом случае каждое ядро получает один поток и исполняет его независимо.

Ошибка любого типа может привести к слабости шахматного движка. Поэтому имеет смысл искать ошибки всех типов и рассматривать условия, в которых они могут проявляться.

#### 3.8.2.2 Сценарии игры против шахматного движка

Мы познакомились с типами ошибок и стратегиями их поиска. Теперь рассмотрим, как применить эти знания на практике, чтобы найти слабые стороны шахматного движка.

У каждого шахматиста высокого уровня есть команда, которая помогает ему в подготовке к матчам и турнирам. В эту команду обычно входят менеджер, тренер, другие шахматисты, диетолог, менеджер и психолог. Поэтому будем говорить об игре не одного шахматиста против шахматного движка, а целой команды.

В зависимости от состава и подготовки команды, которая играет против шахматного движка, возможно несколько сценариев. Начнём с самого простого случая.

#### 3.8.2.3 Первый сценарий РНП

В первом сценарии команда экспертов работает в следующих условиях:

1. Команда состоит только из шахматистов.

2. У команды нет точной информации о конкретной версии движка и его слабостях.

3. У команды нет специальных инструментов для подготовки к игре против движка. Речь идёт о программах, которые не входят в обычный набор шахматиста для подготовки к турнирам.

Именно в таких условиях проходит типичный матч шахматиста высокого уровня против движка. Исход игры зависит от многих факторов и случайностей. Сейчас мы сконцентрируемся только на одной стороне противостояния — поиске ошибок.

Разработчики шахматного движка, с которым проходит игра, следуют одной из трёх стратегий поиска ошибок:

1. Ручной несистематический поиск (РНП).

2. Ручной систематический поиск (РСП).

3. Автоматический систематический поиск (АСП).

Команда экспертов может применить только ручной несистематический поиск ошибок. Другими словами, шахматист играет с движком и ищет его слабости во время партии. Разберёмся, почему команде недоступны более сильные стратегии.

Ручной систематический поиск ошибок предполагает строгий план из четырёх пунктов. Команда экспертов может выполнить только один из них — создать полностью повторяемую среду для воспроизведения ошибки. Для этого надо договориться с разработчиками движка о том, что ни аппаратное обеспечение, ни программа не меняются между партиями. Остальные три пункта плана выполнить невозможно:

1. Получить предварительную информацию о предполагаемой ошибке.

2. Следовать повторяемым путём для воспроизведения ошибки.

3. Если ошибка воспроизвелась, зафиксировать состояние программы и среды её выполнения

Для автоматического систематического поиска ошибок нужна специальная система тестирования. В нашем сценарии у команды нет эксперта по разработке программ, а следовательно нет и специальных инструментов. Поэтому эта стратегия поиска также невыполнима.

Возможны три комбинации стратегий, которым следуют разработчики шахматного движка и команда экспертов. Для краткости сократим названия стратегий поиска по первым буквам:

1. Разработчики движка — РНП, команда экспертов — РНП.

2. Разработчики движка — РСП, команда экспертов — РНП.

3. Разработчики движка — АСП, команда экспертов — РНП.

В первом случае (РНП-РНП) стороны следуют одинаковой стратегии поиска ошибок. Со стороны команды экспертов это выглядит следующим образом. Самый сильный шахматист играет партии против движка, опираясь на свои экспертные знания. В ходе игры он создаёт различные позиции, которые считает сложными для просчёта программой. Если в одной из них движок ошибается, у шахматиста появляется план на матч. Он заключается в эксплуатации найденной ошибки.

I> **Эксплуатация ошибок** — это преднамеренное выявление и использование ошибок или уязвимостей в программе. Цель такого использования — достижение результатов, непредусмотренных разработчиками.

История развития шахматных программ показывает, что в первой комбинации стратегий (РНП-РНП) у команды экспертов очень высокие шансы на победу. Победа практически гарантирована, если им удалось найти ошибку, а у разработчиков движка нет возможности её исправить. Эта ошибка будет воспроизводиться каждый раз при создании подходящих условий. Вопрос только в том, насколько их сложно создать.

Вторая возможная комбинация стратегий: РСП-РНП. В этом случае стратегия разработчиков движка сильнее. До матча они уже обнаружили и исправили большинство ошибок, которые можно найти стратегией РНП. Кроме этого, в ходе самого матча стратегия РСП позволяет оперативно исправлять обнаруженные ошибки. Самый яркий пример игры в таких условиях — матч 1997 года Гарри Каспарова против Deep Blue.

В этом матче у команды шахматиста была чёткая стратегия на матч: придерживаться закрытых позиций и не давать компьютеру возможности для сильной тактической игры. Это был достаточно стандартный подход в игре против шахматных программ того времени. Он провоцировал стратегические просчёты программ.

Особенность этого матча состояла в том, что Гарри Каспаров не мог эксплуатировать найденные ошибки. Когда ошибка проявлялась в какой-то партии, команда Deep Blue исправляла её до следующей. В каждой игре Гарри Каспаров начинал искать слабости компьютера с нуля. В таких условиях очень сложно играть против компьютера с огромной вычислительной мощностью.

Третья возможная комбинация стратегий: АСП-РНП. Стратегия разработчиков движка намного сильнее. С очень большой вероятностью автоматические тесты обнаружили и исправили все ошибки, которые во время матча можно найти вручную. Кроме этого разработчики движка могут использовать стратегию РСП для оперативного исправления ошибок между партиями. То что они используют стратегию АСП, означает что у них уже есть инструменты для более простой стратегии РСП. Это делает победу команды экспертов маловероятной. Хороший пример игры в таких условиях — матч Владимира Крамника против движка Deep Fritz в 2006 году.

#### 3.8.2.4 Второй сценарий РСП

Второй сценарий игры команды экспертов против шахматного движка выглядит следующим образом:

1. Команда экспертов состоит из шахматистов, разработчика шахматных движков и специалиста по компьютерной безопасности.

2. В распоряжении команды есть точная версия шахматного движка, с которой предстоит играть. Также доступна история его изменений и исходный код.

3. У команды нет специальных инструментов для подготовки к матчу.

В таких условиях команда экспертов может применить стратегию ручного систематического поиска ошибок (РСП). Специалисты могут выполнить все шаги этой стратегии, имея на руках движок и его исходный код.

Рассмотрим пример. Допустим, что проводится матч между командой экспертов и движком Stockfish. Для определённости пусть это будет версия 15. Она не последняя и это важно. Исход такой игры во многом зависит от подготовки команды экспертов. Она заключается в том, чтобы заранее найти ряд слабостей программы, которые можно будет эксплуатировать в ходе матча.

План подготовки команды экспертов может быть следующим:

1. Разработчик шахматных движков просматривает [историю изменений](https://github.com/official-stockfish/Stockfish/commits/master/) Stockfish. Он составляет список изменений, которые были сделаны после выпуска версии 15. Они исправляют какие-то ошибки и недочёты этой версии. Чем старее версия движка, тем больше этот список.

2. Разработчик шахматных движков оценивает каждое изменение в составленном списке. Он ищет исправления ошибок следующего типа: 

* Ошибки генерации ходов
* Ошибки функции оценки
* Ошибки алгоритма поиска
* Ошибки в дебютной книге
* Ошибки в таблице эндшпилей.

3. Специалист по компьютерной безопасности тоже оценивает каждое изменение в списке. Он ищет исправления общих программных ошибок.

4. Если не найдено ни одной ошибки, которую можно эксплуатировать, все эксперты выполняют ручной несистематический поиск:

* Разработчик шахматных движков выполняет ревью программного кода. Он ищет ошибки того же типа, которые искал в списке исправлений.

* Специалист по компьютерной безопасности выполняет аудит программного кода. Он ищет общие программные ошибки.

* Шахматисты прогоняют движок через набор позиций, которые считаются сложными для компьютерных программ.

5. Эксперты обсуждают свои результаты. Разработчик шахматных движков и специалист по компьютерной безопасности объясняют шахматистам найденные ошибки и их предполагаемое влияние на игру движку.

6. Команда экспертов проверяет найденные слабости движка в пробных партиях.

После такой подготовки самый сильный из шахматистов команды играет матч с движком. У него есть список потенциальных слабостей программы. План на матч строится вокруг создания условий, в которых воспроизводятся ошибки движка. Например, это может быть выбор подходящих дебютов, создание нужных комбинаций и связок фигур в миттельшпиле или выход в определённые эндшпили.

Как могла бы работать подобная стратегия команды экспертов на практике? Представим следующую гипотетическую ситуацию. Команда Deep Blue проводит третий матч с Гарри Каспаровым. Перед матчем разработчики подробно консультируют шахматиста обо всех обнаруженных, но неисправленных ошибках в той версии компьютера, с которой ему предстоит играть. Очевидно, что такая информация намного повысит шансы Гарри Каспарова на победу. Именно такое преимущество даёт команде экспертов стратегия ручного систематического поиска ошибок.

Стратегия РСП со стороны команды экспертов может не сработать, если разработчики движка применяют стратегию АСП. В этом случае стратегия разработчиков окажется сильнее. Они могут найти и исправить все ошибки, которые команда экспертов способна обнаружить вручную.

#### 3.8.2.5 Третий сценарий АСП

Условия третьего сценария игры команды экспертов против шахматного движка выглядят так:

1. Команда экспертов состоит из шахматистов, разработчика шахматных движков, специалиста по компьютерной безопасности, специалиста по тестированию, специалиста по статистике и обработке данных.

2. В распоряжении команды есть точная версия шахматного движка, история его изменений и исходный код.

3. У команды есть инструменты для автоматизации поиска ошибок в шахматном движке.

Инструменты для поиска ошибок повторяют функции системы тестирования, которую используют разработчики движка. Это позволяет команде экспертов применить стратегию автоматического систематического поиска ошибок (АСП).

Снова обратимся к примеру, в котором команда экспертов играет против движка Stockfish версии 15. На этапе подготовки команда ищет слабости в игре программы, чтобы эксплуатировать их в ходе матча. Для этого она применяет специальные инструменты.

У команды экспертов есть несколько способов, чтобы автоматизировать поиск ошибок в движке:

1. Провести автоматический турнир между Stockfish 15 и более сильным шахматным движком. Такой турнир даст набор партий, в которых Stockfish 15 проиграл. Шахматисты из команды экспертов должны проанализировать ходы в этих партиях. Они могут указать на слабые стороны Stockfish 15.

2. Разработчик шахматных движков из команды экспертов составляет список изменений, сделанных после выпуска версии Stockfish 15. Имея на руках исходный код, он может собирать модифицированные версии движка. Тогда с помощью системы тестирования можно оценить влияние каждого изменения на силу игры. Инструмент даст как статистику побед, так и конкретные партии и позиции, в которых Stockfish 15 без исправления ошибки сыграл слабо.

3. Инструмент для автоматизации анализирует все официальные партии Stockfish версии 15. Он ищет позиции, в которых Stockfish 15 делает слабый ход по мнению более сильного движка. Шахматисты команды экспертов должны проанализировать эти позиции. Они могут указать на слабые стороны Stockfish 15.

Инструмент автоматизации позволяет команде экспертов вести более широкий поиск ошибок. Это вовсе не означает, что инструмент берёт всю работу на себя. Самостоятельно он вряд ли найдёт подходящую ошибку, которую можно эксплуатировать в матче. Скорее, задача инструмента — дать экспертам перспективное направление для ручного систематического поиска.

Эффективность стратегии АСП со стороны команды экспертов зависит от доступных ей вычислительных ресурсов и времени. Если разработчики шахматного движка используют систему для интенсивного тестирования наподобие Fishtest, это значительно понижает шансы команды экспертов найти подходящую ошибку.

#### 3.8.2.6 Реалистичность сценариев

Мы рассмотрели три сценария игры команды экспертов против шахматного движка. Все крупные матчи именитых шахматистов против программ в 2000-х годах проходили в условиях, близких к первому сценарию. Возникает вопрос: насколько реалистичны второй и третий сценарии?

После поражения Владимира Крамника в матче с Deep Fritz в 2006 году шахматное сообщество и публика потеряли интерес к подобным противостояниям. Стало сложно найти как спонсоров, так и шахматистов высшего уровня, которые готовы тратить своё время на подготовку к матчу с движком.

Второй и третий сценарии требует огромных вложений. Команда экспертов должна состоять из шахматистов уровня претендента. В неё также должны входить эксперты трёх направлений ИТ высокого уровня. Чем выше уровень экспертов, тем выше шансы успешно подготовиться к матчу с движком. Если движок коммерческий, то необходимо сотрудничество со стороны его разработчиков. Они должны предоставить исходный код и историю изменений программы.

Чтобы выполнить условия второго и третьего сценариев, есть много требований. Тем не менее в теории они все выполнимы. На практике же возникает вопрос: ради чего такие усилия? В лучшем случае команда экспертов сможет одержать победу в матче против старой версии не самого сильного шахматного движка. В таком достижении нет ничего привлекательного ни для разработчиков шахматного движка, ни для команды экспертов высшего класса, ни для спонсоров мероприятия. Поэтому матч на таких условиях вряд ли когда-нибудь состоится.

Что если поднять ставки? Есть ли у команды экспертов шансы против последней версии Stockfish? Ряд особенностей этого движка помешает найти в нём ошибки, даже при использовании стратегии АСП. Эти особенности следующие:

1. **Сеть NNUE вместо функции оценки**. Специалист по шахматным движкам может выполнить ревью кода функции оценки и понять его логику. Возможно, он даже сможет найти в нём изъяны. Но анализ параметров обученной модели NNUE ничего не скажет о её слабостях. Изменения в модели невозможно интерпретировать в шахматных понятиях. Известно только то, что новая версия модели статистически лучше старой.

2. **Система тестирования Fishtest**. Интенсивное автоматизированное тестирование выявляет основную массу ошибок в движке Stockfish. Если в нём остались скрытые ошибки, они либо незначительные, либо их очень сложно воспроизвести.

3. **Информация об исправлениях в последней версии Stockfish ограничена**. У команды экспертов есть только небольшая история изменений после последнего релиза. Найти среди них потенциальную ошибку очень сложно.

В заключение хочу добавить следующее. Игра против системы, которая достигла сверхчеловеческого уровня в какой-то дисциплине, не имеет ничего общего с игрой против человека. Это противостояние больше напоминает поиск и эксплуатацию уязвимостей в программной системе. Только такой подход даёт хоть какие-то шансы на победу.

{pagebreak}
