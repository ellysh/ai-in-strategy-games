## 3.8 Человек против шахматной программы

Последний крупный матч человека против шахматной программы состоялся в ноябре 2006 года. Действующий на тот момент чемпион мира Владимир Крамник играл против движка Deep Fritz. Матч закончился победой Deep Fritz со счётом 4-2: четыре ничьи и две победы программы. Шахматист не смог выиграть ни одной партии.

Во время матча Deep Fritz работал на мощном по меркам того времени персональном компьютере. Но его вычислительные ресурсы значительно уступали шахматному суперкомпьютеру Deep Blue. Для сравнения: движок Deep Fritz просчитывал около 8 миллионов позиций в секунду, а Deep Blue — от 100 до 300 миллионов в зависимости от конфигурации. Несмотря на скромную производительность, Deep Fritz одержал уверенную победу над чемпионом мира. Этот матч показал, насколько выросло качество шахматных программ спустя 10 лет после противостояния Гарри Каспарова и Deep Blue.

В условия матча современные шахматные движки не оставляют шансов лучшим игрокам. Ведущие шахматисты единогласно признают, что человек уже давно не может конкурировать с машиной. Этот вопрос считается решённым однозначно и окончательно.

Можно ли сказать что-то новое о противостоянии человека и шахматной программы? Это возможно, если посмотреть на него под другим углом.

### 3.8.1 Ошибки в программах

Матчи гроссмейстеров с шахматными программами комментируют профессионалы. Они являются экспертами в предметной области и знают все тонкости шахматной игры. Опираясь на свой опыт, комментатор рассказывает о позициях, ходах, вариантах, комбинациях и ошибках. Точка зрения именно этих экспертов звучит в репортажах со всех шахматных событий. Но эта точка зрения не единственная.

Шахматные движки — это в первую очередь компьютерные программы. Их разрабатывают профессиональные программисты. Это другой вид экспертов, который имеет отношение к компьютерным шахматам. К сожалению, эксперты этого рода редко высказываются о поединке человека и машины. Одну из самых известных попыток предпринял Фэн Сюн Сю. Он опубликовал книгу "Behind Deep Blue" о поединке суперкомпьютера IBM и Гарри Каспарова.

Что может рассказать разработчик шахматной программы? В своей книге Фэн Сюн Сю знакомит читателя с техническими задачами и проблемами, которые решала его команда. Комментируя партии, он часто говорит о программных и аппаратных ошибках. Именно из-за них Deep Blue делал слабые ходы, терял позиционное преимущество и проигрывал. Означает ли это, что ключ к победе над шахматной программой кроется в ошибках её реализации? Если да, то изменилось ли что-то со времён Deep Blue?

Управляющая программа для Deep Blue была разработана почти 30 лет назад. Методология программирования продвинулась далеко вперёд за это время. Но проблема ошибок никуда не делась. Современные программы аварийно завершаются, теряют данные пользователей и зависают точно так же, как и 30 лет назад. Главная причина этого в том, что разработка программного обеспечения — это компромисс между функциональностью, стоимостью, временем и качеством. Чем-то всегда приходится жертвовать. Разработка шахматной программы в этом плане ничем не отличается.

Чтобы найти и исправить ошибки в программах, разработчики используют различные методы тестирования. Например, это может быть ручная проверка самых важный функций программы. Тестирование можно автоматизировать. Специальные системы могут запускать программу и выполнять в ней стандартные действия. Тем самым они проверяют, что она по-прежнему работает.

Если внимательно посмотреть на историю шахматных программ, можно заметить некоторую закономерность. Метод поиска ошибок в них постоянно развивался. Одновременно с этим рос и уровень игры программ. Значительные скачки в силе движков происходили именно тогда, когда разработчики начинали использовать новый метод тестирования. Есть ли какая-то взаимосвязь между этими событиями? Возможно, что есть.

Предлагаю снова обратиться к истории компьютерных шахмат. Но на этот раз мы сфокусируемся не на игре, а на поиске ошибок в программах.

#### 3.8.1.1 Ручной несистематический поиск

В 1960-х годах методология разработки и тестирования ПО находилась на начальном этапе развития. Автор программы сам тестировал её вручную. Обычно он пробовал разные входные данные и проверял, что выход программы соответствует ожидаемому результату.

Разработчики первых шахматных программ следовали общепринятой практике. Они применяли самую очевидную стратегию тестирования, которая состояла из трёх стадий.

На первой стадии автор играет со своей программой несколько партий после каждого значительного изменения в её коде. Такая проверка показывает, что программа не завершается с ошибкой после очередного хода и не нарушает правил игры. Если программа делает очень слабые или бессмысленные ходы, разработчик пытается понять и устранить их причину.

Такой тест в терминах современной разработки ПО называется [**альфа-тестированием**](https://ru.wikipedia.org/wiki/Тестирование_программного_обеспечения#Уровни_тестирования). Его выполняет сам разработчик. При этом программа выполняется в некоторой контролируемой среде, например, под управлением отладчика. Этот инструмент позволяет остановить выполнение программы в любой момент и получить состояние её памяти. Таким образом, разработчик сразу получает полную информацию о возникшей ошибке, может найти её в исходном коде и быстро исправить.

Когда программа начинает работать стабильно без критических ошибок, наступает вторая стадия тестирования. Разработчик обращается к одному или нескольким сильным шахматистам. Они проводят серию игр против программы и указывают на её слабости. Типичная причина этих слабостей — неверные представления разработчика о шахматной игре. Его недостаточное владение предметной областью выливается в логические ошибки программы.

I> [**Логической ошибкой**](https://ru.wikipedia.org/wiki/Логическая_ошибка_(программирование)) называется неправильное действие программы на этапе принятия решений.

Сегодня такой вид теста называется [**бета-тестированием**](https://ru.wikipedia.org/wiki/Бета-тестирование). Его выполняет ограниченный круг потенциальных пользователей программы. Во время тестирования пользователи используют свои экспертные знания в предметной области. Они дают разработчику обратную связь об обнаруженных проблемах в программе.

На последней стадии тестирования шахматная программа играла на турнирах. Это были партии с классическим контролем времени против шахматистов и других программ. На этой стадии разработчик наблюдал, как программа работает в максимально сложных для неё условиях. Когда происходил сбой или бессмысленный ход, автор собирал максимум информации об этом событии. Таким образом разработчик искал причину ошибки и код, который её вызвал.

Предлагаю назвать такую стратегию поиска ошибок в шахматных программах **ручным несистематическим поиском**. Слово **ручной** означает, что его выполняет человек без какой-либо автоматизации. Он играет серию партий против программы от начала до конца.

Поиск называется **несистематическим**, потому что в нём нет строго плана. Мы рассмотрели три стадии тестирования. На каждой из них тестировщик просто играет против программы. Тем самым он проверяет её основные функции. В одной из партий может проявиться какая-то из существующих ошибок. Но такое воспроизведение проблемы будет чистой случайностью. Ходы и позиции могут сложиться так, что ошибки не проявятся ни в одной из партий. В этом случае разработчик программы о них не узнает и не устранит.

Эффективность ручного несистематического поиска ошибок зависит только от интенсивности тестирования. Чем больше партий сыграет шахматная программа, тем выше шанс воспроизвести какую-то из её ошибок. Только тогда у разработчика появится шанс исправить проблему. Ошибки, которые ни разу не воспроизводились, остаются скрытыми. Их невозможно исправить из-за отсутствия информации.

I> **Скрытой ошибкой** (latent defect) программы называется проблема, которая не была обнаружена на этапе тестирования. Она проявляется только после того, как ПО было выпущено и использовалось в определённых условиях.

Интенсивность тестирования зависит от ресурсов, которые разработчики инвестируют в проект. Особенно важны ресурсы на его старте. Обратите внимание, что самые сильные шахматные программы разрабатывались профессионалами, за которыми стояли крупные корпорации. Вот несколько примеров:

* Шахматная программа Бернштейна — команда из IBM.

* Компьютер Belle — команда из Bell Labs.

* Программа Cray Blitz — команда из корпорации Cray Research по производству суперкомпьютеров.

* Компьютер Deep Blue — команда из IBM.

В каждый из этих проектов были вложены огромные ресурсы. Конкретнее, вложения были следующими:

1. Деньги на разработку специализированного оборудования (шахматные компьютеры и чипы).

2. Время разработчиков программ, которое в те годы было крайне дорогим. Они писали код, тестировали его и исправляли обнаруженные ошибки.

3. Компьютерное время для тестирования и отладки программы.

4. Время профессиональных шахматистов для тестирования программы.

Вложения на начале проекта позволяли команде разработчиков проводить качественное тестирование. Благодаря ему, обнаруживалась и устранялась большая часть логических ошибок в программе. Это выводило её игру на высокий уровень. Тогда проект привлекал внимание СМИ, шахматного сообщества и специалистов в области ИТ. Программу постоянно приглашали на турниры. Сильнейшие шахматисты охотно проводили с ней матчи. Это только увеличивало интенсивность её тестирования. Как следствие, уровень игры программы продолжал расти.

#### 3.8.1.2 Ручной систематический поиск

>>> REVIEW

Стратегия ручного несистематического поиска ошибок имеет предел. Если таким способом интенсивно тестировать шахматную программу, рано или поздно уровень её игры перестанет расти. Это происходит по нескольким причинам.

Во-первых, в программе остаётся мало скрытых ошибок. Чтобы их воспроизвести нужны очень специфичные позиции и условия. Эти позиции могут никогда не сложиться в тестовых партиях со стандартными дебютами и эндшпилями. 

Во-вторых, некоторые ошибки программы могут быть очень тонкими. Только профессиональный шахматист высочайшего уровня способен понять такую ошибку и объяснить разработчику программы её суть. Но у чемпиона мира и претендентов на его место нет времени интенсивно тестировать шахматный движок. Играя против программы матч, профессионал найдёт эту ошибку и воспользуется ей. Заранее же разработчик никогда про неё не узнает.

Именно с этими трудностями столкнулась команда Deep Blue, когда их компьютер играл первый матч против Гарри Каспарова в 1996 году. На тот момент уровень игры компьютера достиг максимума, который мог дать ручной несистематический поиск ошибок. До уровня Гарри Каспарова он не дотягивал.

Чтобы вывести Deep Blue на новый уровень игры, команде разработчиков пришлось создать специальные инструменты для разработки и тестирования. Если говорить о тестировании, то главным инструментом стал программный прототип функции оценки Deep Blue с графическим интерфейсом. Отдалённо он напоминает современный шахматный движок и интерфейс к нему.

Рассмотрим, как работал инструмент тестирования Deep Blue. Через графический интерфейс пользователь задавал произвольную позицию фигур на доске. Эту позицию также можно было загрузить из файла с ходами сыгранной ранее партией. После этого интерфейс отображал баллы, которые функция оценки ставила каждому возможному ходу. Также пользователь видел диагностическую информацию о том, какие факторы позиции повлияли на оценку.

Новый инструмент тестирования стал отправной точкой для новой стратегии поиска ошибок. Раньше штатный гроссмейстер проекта проверял новые возможности Deep Blue в полноценных партиях. Теперь можно было проверять поведение компьютера в конкретных позициях и сразу же корректировать его. Такой подход намного повысил эффективность тестирования.

Вторым компонентом новой стратегии поиска ошибок стало дополнительное правило в играх с компьютером. Чтобы тестовые партии стали эффективнее, разработчики разрешили штатному шахматисту брать ход назад в любой позиции. Это позволило игроку возвращаться назад и исправлять допущенные ошибки. Таким образом он мог играть на равных с Deep Blue, который превосходил его минимум на 200 пунктов Эло. При равной игре ошибки компьютера стали воспроизводиться чаще и очевиднее. Он перестал выигрывать из-за банальных зевков оппонента.

Предлагаю назвать стратегию поиска ошибок команды Deep Blue **ручным систематический поиском**. Поиск **ручной**, потому что его по-прежнему выполняет человек без автоматизации. Но на этот раз тестировщик пользуется специальными инструментами и расширенными правилами игры.

Поиск называется **систематическим**, потому что у него есть строгий план действий. Этот план выглядит следующим образом:

1. Получить предварительную информацию о предполагаемой ошибке. Например, тестировщик знает, что в программе изменилась оценка пешечной структуры. Тогда он должен сконцентрироваться на позициях с различной конфигурацией пешек и проверить, что программа правильно в них ориентируется.

2. Создать полностью повторяемую среду для воспроизведения ошибки. Это означает, что ни аппаратное обеспечение, ни программна не должны меняться между тестами. Тестировщик всегда берёт один и тот же компьютер и запускает на нём одну и ту же версию программы или инструмента тестирования.

3. Следовать повторяемым путём для воспроизведения ошибки. Это означает, что тестировщик на каждой итерации выполняет одни и те же действия, которые приводят к одним и тем же результатам. 

4. Если ошибка воспроизвелась, зафиксировать 
состояние программы и среды её выполнения (например, состояние аппаратуры). Именно один из параметров этого состояния провоцирует возникшую ошибку. Задача разработчика — понять, какой именно параметр.

Рассмотрим, как команда Deep Blue следовала этому плану тестирования. Первый пункт — узнать о предполагаемой ошибке компьютера. Было несколько способов это сделать:

1. Получить информацию от разработчика, который изменили что-то в управляющей программе или прошивке шахматного чипа. Это изменение потенциально может привести к ошибкам в позициях, когда оно влияет на выбор хода.

2. Во время тестовой игры с правилом брать ход, Deep Blue делает слабый ход. Тестировщик должен запомнить все ходы партии и особенности позиции, которые привели к ошибке.

3. Во время очередной турнирной партии Deep Blue делает слабый ход. Лог файл игры поможет точно восстановить ход этой партии.

Второй пункт плана — создать полностью повторяемую среду для воспроизведения ошибки. Разработчики Deep Blue могли его выполнить. Они контролировали версии управляющей программы, шахматных чипов и их прошивки. Это позволяло воссоздать комбинацию аппаратного обеспечения и программ, в которой произошла ошибка.

Третий пункт — следовать повторяемым путём для воспроизведения ошибки. Это условие практически невозможно выполнить, если играть обычные партии против шахматной программы. Дело в том, что в на алгоритм её работы влияет много случайностей. Но эту проблему решил специальный инструмент тестирования команды Deep Blue. Благодаря ему, можно было не играть партию целиком, а сразу выставить нужную позицию фигур.

Четвёртый пункт плана — зафиксировать состояние программы и оборудования. У команды Deep Blue были инструменты для анализа управляющей программы и прошивки шахматных процессоров. Так они собирали полную информацию о среде выполнения в состоянии ошибки. Это помогало выяснить причину ошибки и исправить её.

На исход второго матча Гарри Каспарова против Deep Blue 1997 года повлияло много факторов. Одним из них стала новая стратегия поиска ошибок. Благодаря ей, команда разработчиков могла оперативно вносить изменения в управляющую программу компьютера. Если Гарри Каспаров находил какой-то изъян в игре оппонента, команда Deep Blue успевала исправить его до следующей партии. Это уравнивало шансы сторон: человек и машина адаптировались к игре друг друга по ходу матча.

#### 3.8.1.3 Автоматический систематический поиск

>>> REVIEW

Если программа запускается на специализированном шахматном компьютере, это ограничивает возможности её тестирования. Проблема в том, что шахматный компьютер — это уникальное оборудование в единственном экземпляре. Поэтому невозможно устроить партию между разными версиями этого компьютера или его управляющей программы.

В конце 1990-х годов платформой для шахматных программ стали обычные ПК. Они работают под управлением некоторой многозадачной операционной системы (ОС). Такая ОС позволяет выполнять несколько программ одновременно. На одном ПК очень просто запустить два разных шахматных движка и устроить между ними партию.

Новая аппаратная платформа открыла возможность для новой стратегию поиска ошибок. Разработчики шахматных движков начали регулярно тестировать разные версии своих программ. Скоро они пришли к идее автоматизации этого процесса. Стали появляться системы для управления тестированием. Такая система запускает указанные версии движка и устраивать между ними партии. Она же ведёт статистику побед и лог каждой партии. В конце работы система выдаёт полный отчёт с результатами.

Предлагаю назвать такую стратегию поиска ошибок **автоматическим систематическим поиском**. Поиск **автоматический**, потому что выполняется системой тестирования без участия человека. Разработчик программы только получает отчёт о результатах.

Поиск называется **систематическим**, потому что выполняется по строгому плану. План заключается в последовательном выполнении разных автоматических тестов. Каждый из них фокусируется на ошибках разного типа.

Современный шахматный движок проверяется следующими типами тестов:

1. **Автоматическое регрессионное тестирование** — проверка новой версии движка на заранее подготовленном наборе типовых позиций. Такой тест показывает, что в программе не появилось новых ошибок и она по-прежнему корректно действует в определённых сценариях.

2. **Интеграционное тестирование** — автоматические тесты запускаются каждый раз, когда в базу кода движка вносится какое-то изменение. Такой тест проверяет, что любое изменение как минимум не ухудшает уровень игры движка.

3. **Проверка производительности** — новая версия движка обрабатывает набор специально подготовленных сложных позиций. Для каждой позиции оценивается производительность движка: глубина поиска, достигнутая в единицу времени, и количество узлов дерева игры, проверяемых в секунду. Такой тест показывает, что количественные показатели производительности движка не ухудшились.

4. **Автоматические турниры** проводятся между разными версиями одного движка. Они дают достаточную статистику, чтобы сравнить относительный уровень Эло этих версий.

5. **Тестирование дебютов и эндшпилей** — новая версия движка отыгрывает набор стандартных дебютов и эндшпилей. Это гарантирует, что изменения движка корректно работают на всех стадиях партии.

Такой план тестирования обнаруживает ошибки на ранней стадии. Часто интеграционный тест может точно указать на изменение, которое вызвало ошибку. Это значительно повышает эффективность разработки. Программисты могут смелее экспериментировать с небольшими изменениями и последовательно улучшать разные части движка.

Одно из преимуществ автоматического тестирования — простота его масштабирования. Чтобы повысить интенсивность ручного тестирования движка, нужно пригласить больше профессиональных шахматистов и чаще участвовать в турнирах. Это требует значительных вложений. В случае автоматического поиска ошибок достаточно подключить больше компьютеров к системе тестирования. Тогда все пять типов тестов станут интенсивнее.

Команда проекта Stockfish вывело масштаб автоматизированных тестов на беспрецедентный уровень. Система Fishtest объединяет сотни компьютеров добровольцев в единую сеть. Эта сеть выполняет интенсивные автоматические тесты на разнообразном оборудование.

Оценим примерный выигрыш производительности, который дала система Fishtest. Допустим, что мы тестируем две версии движка в партиях с укороченным контролем времени — 1 минута на игру. Пусть один экземпляр движка работает на одном ядре процессора. Современный процессор Intel имеет минимум 8 ядер. Тогда на одном современном ПК можно запустить примерно `60 * 24 * 8 / 2 = 5760` игр в день.

Компания по разработке коммерческого шахматного движка может выделить для запуска тестов от нескольких десятков до сотни компьютеров. Это даст максимум около `100 * 5760 = 576000` партий в день. 

Сеть системы Fishtest состоит от сотни до тысячи компьютеров каждый день. Возьмём среднее число 550 компьютеров. Тогда в день система сможет сыграть примерно `550 * 5760 = 3,168,000` партий. Почти в четыре раза больше чем могут позволить ресурсы разработчиков коммерческого движка.

Качество автоматического тестирования напрямую зависит от его интенсивности. Система Fishtest предоставляет колоссальные вычислительные ресурсы. Именно благодаря им движок Stockfish сохраняет лидерство во всех турнирных таблицах.

### 3.8.2 Игра против шахматного движка

>>> REVIEW

Мы познакомились с тремя стратегиями поиска ошибок, которые применяют разработчики шахматных программ. Какое отношение это имеет к игре человека против движка?

Давайте поговорим о том, как профессионалы играют в шахматы. Представим партию между двумя гроссмейстерами с примерно равным уровнем Эло. Если обе стороны идеально исполняют свой план на игру, вероятнее всего она закончится ничьей. Но если одна из сторон допускает промах, оппонент получает преимущество. Речь идёт не о зевке пешки. Промахом может быть даже небольшое смещение фигур, которое лишь немного ухудшает позицию. Даже такое незначительное преимущество игрок высокого уровня способен превратить в победу.

Партия против современного шахматного движка — это игра на самом высоком уровне. Поэтому в ней действуют те же самые правила, что и в партии между двумя гроссмейстерами. Следовательно, чтобы выиграть у программы, надо получить преимущество и развить его в победу. Преимущество над сильным оппонентом можно получить только тогда, когда знаешь его слабые стороны. Слабые стороны шахматного движка создают те самые ошибки, которые ищут и устраняют его разработчики. Мы рассмотрели три стратегии поиска этих ошибок.

Возникает вопрос: может ли шахматист применить какую-то из трёх стратегий поиска ошибок, чтобы найти слабые стороны движка? Да, может. Но перед тем как углубиться в эту тему, поговорим о типах ошибок в шахматных движках. Это объяснит, что именно следует искать.

#### 3.8.2.1 Классификация ошибок шахматного движка

>>>> REVIEW

Можно придумать различные критерии для классификации ошибок шахматного движка. Самый очевидный критерий — это компонент программы, в работе которого есть ошибка.

Мы уже знакомы с пятью основными частями типичного шахматного движка. Они следующие: 

1. Генератор ходов
2. Функция оценки позиции
3. Алгоритм поиска
4. Дебютная книга
5. Таблицы эндшпилей.

Исходя из этого списка можно предложить следующую классификацию ошибок:

1. **Ошибки генерации ходов**. Например, генератор упускает какие-то из возможных ходов или выдаёт ходы, запрещённые правилами игры.

2. **Ошибки функции оценки** или альтернативного механизма (NNUE).

* Ошибка в оценке материала. Например, движок неверно оценивает разность между слонами и конями в определённых позициях.

* Ошибки в оценке позиции — это неверные суждения движка о нематериальных аспектах. Например, мобильность фигур, безопасность короля, контроль ключевых полей.

* Переобучение (overfitting) — результат функции оценки слишком сильно подогнан под специфичные позиции фигур. В этом случае возможна неверная оценка позиций, которые не попали в тестовый набор.

* Недообучение (underfitting) — функция оценки слишком простая и не учитывает все аспекты позиции.

3. **Ошибки алгоритма поиска** — это класс ошибок в реализации самого алгоритма и вспомогательных эвристик выборочного поиска.

* Эффект горизонта — движок не просматривает дерево игры дальше некоторой глубины. Это может привести к решениям, которые дают краткосрочную выгоду, но плохи в долгосрочной перспективе.

* Ошибки поиска покоя — движок выполнил продление до позиции, которую ошибочно посчитал спокойной. На самом деле в позиции остаются варианты, которые кардинально меняют её оценку. 

* Ошибки отсечений — движок отсекает части дерева, которые содержат важные ходы и позиции.

* Ошибка управления временем — движок неправильно учитывает время, отведённое на хода. Например, он агрессивно отсекает ветви дерева игры, когда у него в запасе остаётся ещё много времени. В этом случае движок принимает поспешное решение и не использует эффективно свою глубину поиска.

4. **Ошибки в дебютной книге**. Например, в ней отсутствуют новинки, которые известны некоторым игрокам высшего уровня.

5. **Ошибки в таблице эндшпилей**.

* Ошибки чтения и интерпретации импортированных таблиц для решенных эндшпилей.

* Неполные знания по теории эндшпилей.

6. **Общие программные ошибки** — это класс проблем, которые характерны для любой программы, независимо от её предметной области.

* Ошибки параллельного исполнения кода — связаны с запуском движка в нескольких потоках выполнения. Такие ошибки приводят к потере данных и блокировке исполнения программы. 

* Утечки памяти — это ситуация, когда программа запросила память у операционной системы, но не освободила её после использования. Если программа работает долгое время и утечки происходят постоянно, в системе возникает дефицит памяти. Он значительно снижает производительность движка.

I> [Поток выполнения](https://ru.wikipedia.org/wiki/Поток_выполнения) — это последовательность шагов программы, которая может выполняться независимо от остальных. Разделение программы на потоки позволяет быстрее выполнять её на многоядерных процессорах. В этом случае каждое ядро получает один поток и исполняет его независимо.

Ошибка любого рассмотренного типа может привести к слабому ходу шахматного движка. Поэтому есть смысл учитывать все типы ошибок и рассматривать сценарии, в которых они могут проявляться.

#### 3.8.2.2 Сценарии игры против шахматного движка

>>>> REVIEW

Мы познакомились с типами ошибок и стратегиями их поиска. Теперь рассмотрим, как применить эти знания их на практике, чтобы найти слабые стороны шахматного движка.

У каждого шахматиста высокого уровня есть команда, которая помогает ему в подготовке к матчам и турнирам. В эту команду обычно входят менеджер, тренер, другие шахматисты, диетолог, агент и психолог. Поэтому будем говорить об игре не одного шахматиста против шахматного движка, а целой команды.

В зависимости от состава и подготовки команды, которая играет против шахматного движка, возможно несколько сценариев. Начнём с самого простого случая.

#### 3.8.2.3 Первый сценарий РНП

>>> REVIEW

Первый сценарий выглядит следующим образом:

1. Команда экспертов состоит только из шахматистов.

2. У команды нет точной информации о конкретной версии движка и его слабостях.

3. У команды нет специальных инструментов для подготовки к игре против движка. Речь идёт о программах, которые не входят в обычный набор шахматиста для подготовки к турнирам.

Именно по такому сценарию проходит типичная игра шахматиста высокого уровня против шахматного движка. Исход игры в таких условиях зависит от многих факторов и случайности. Мы сконцентрируемся только на одной стороне противостояния — поиске ошибок.

Разработчики шахматного движка, с которым проходит игра, следовали одной из трёх стратегий поиска ошибок:

1. Ручной несистематический поиск (РНП).

2. Ручной систематический поиск (РСП).

3. Автоматический систематический поиск (АСП).

Команда экспертов может применить только ручной несистематический поиск ошибок. Разберёмся почему.

Ручной систематический поиск ошибок предлагает строгий план из четырёх пунктов. Команда экспертов может выполнить только один из них. Для этого надо договориться с разработчиками движка о полностью повторяемой среде: ни аппаратное обеспечение, ни программа не должны меняться между партиями. Остальные три пункта плана выполнить невозможно.

Для автоматического систематического поиска ошибок нужна специальная система тестирования. В нашем сценарии у команды нет эксперта по разработке программ, а следовательно нет и специальных инструментов. Поэтому эта стратегия поиска так же невыполнима.

Возможны три комбинации стратегий, которым следуют разработчики шахматного движка и команда экспертов. Для краткости сократим названия стратегий поиска по первым буквам:

1. Разработчики движка — РНП, команда экспертов — РНП.

2. Разработчики движка — РСП, команда экспертов — РНП.

3. Разработчики движка — АСП, команда экспертов — РНП.

В первом случае (РНП-РНП) стороны следуют одинаковой стратегии поиска ошибок. Со стороны экспертов это выглядит следующим образом. Шахматист играет партии против движка, опираясь на свои экспертные знания. В ходе игры он создаёт различные позиции, которые считает сложными для просчёта программой. Если в одной из них движок ошибается, у шахматиста появляется план на матч. Он заключается в эксплуатации найденной ошибки.

I> **Эксплуатация ошибок** — это преднамеренное выявление и использование ошибок или уязвимостей в программе. Цель такого использования — достижение непреднамеренных или злонамеренных результатов.

История развития шахматных программ показывает, что в первой комбинации стратегий (РНП-РНП) у команды экспертов очень высокие шансы на победу. Победа практически гарантирована, если команде экспертов удалось найти ошибку, а у разработчиков нет возможности оперативно её исправить. Эта ошибка будет воспроизводится каждый раз при создании подходящих для неё условий. Вопрос только в том, насколько это сложно сделать.

Вторая возможная комбинация стратегий: РСП-РНП. В этом случае стратегия разработчиков движка сильнее. До матча они уже обнаружили и исправили большинство ошибок, которые можно найти стратегией РНП. Кроме этого в ходе самого матча стратегия РСП позволяет оперативно исправлять обнаруженные ошибки. Самый яркий пример игры в таких условиях — матч команды Гарри Каспарова против Deep Blue.

В этом матче у команды экспертов была чёткая стратегия на матч: придерживаться закрытых позиций и не давать компьютеру возможности для сильной тактической игры. Это был достаточно стандартный подход к игре против шахматных программ того времени. При такой игре часто проявлялись их стратегические просчёты.

Главная сложность этого матча состояла в том, что Гарри Каспаров не мог эксплуатировать найденные ошибки. Команда Deep Blue исправляла между партиями каждую обнаруженную шахматистом ошибку. В каждой партии Гарри Каспаров начинал искать слабости компьютера с нуля. В таких условиях очень сложно обнаружить новую ошибку и суметь ею воспользоваться.

Третья возможная комбинация стратегий: АСП-РНП. Стратегия разработчиков движка намного сильнее. С очень большой вероятностью автоматические тесты обнаружили и исправили все ошибки, которые можно найти вручную. Кроме этого разработчики движка могут использовать стратегию РСП для оперативного исправления ошибок в ходе матча. Всё это делает победу команды экспертов маловероятной. Хороший пример игры в таких условиях — матч команды Владимира Крамника против движка Deep Fritz в 2006 году.

#### 3.8.2.4 Второй сценарий РСП

>>> REVIEW

Второй сценарий игры команды экспертов против шахматного движка выглядит следующим образом:

1. Команда экспертов состоит из шахматистов, разработчика шахматных движков, специалиста по компьютерной безопасности.

2. В распоряжении команды есть точная версия шахматного движка, история его изменений и исходный код.

3. У команды нет специальных инструментов для подготовки к игре против движка.

В таких условиях команда экспертов может применить стратегию ручного систематического поиска ошибок. Имея на руках движок и его исходный код, специалисты могут повторить все шаги разработчиков для поиска ошибок.

Рассмотрим пример. Допустим, что проводится матч между командой экспертов и движком Stockfish. Для определённости пусть это будет версия программы 15. Это не последняя версия. Исход такой игры зависит от подготовки команды экспертов к матчу. Подготовка заключается в том, чтобы заранее найти ряд слабостей программы, которые можно будет эксплуатировать в ходе матча.

План подготовки команды может быть следующим:

1. Разработчик шахматных движков просматривает [историю изменений](https://github.com/official-stockfish/Stockfish/commits/master/) Stockfish. Эксперт составляет список изменений, которые были сделаны после выпуска версии 15. Они исправляют какие-то ошибки и недочёты этой версии.

2. Разработчик шахматных движков оценивает каждое изменение в движке из составленного списка. Он ищет исправления ошибок следующего типа: 

* Ошибки генерации ходов
* Ошибки функции оценки
* Ошибки алгоритма поиска
* Ошибки в дебютной книге
* Ошибки в таблице эндшпилей.

3. Специалист по компьютерной безопасности оценивает каждое изменение из списка. Он ищет исправления общих программных ошибок.

4. Если не найдено ни одной ошибки, которую можно эксплуатировать, все эксперты выполняют ручной несистематический поиск:

* Разработчик шахматных движков выполняет ревью программного кода. Он ищет ошибки того же типа, которые искал в списке исправлений.

* Специалист по компьютерной безопасности выполняет аудит программного кода. Он ищет общие программные ошибки.

* Шахматисты прогоняют движок через набор позиций, которые считаются сложными для компьютерных программ.

5. Все эксперты обсуждают свои результаты. Разработчик шахматных движков и специалист по компьютерной безопасности объясняют шахматистам найденные ошибки и их предполагаемое влияние на игру движку.

После такой подготовки самый сильный из шахматистов команды играет матч с движком. У него есть список потенциальных слабостей программы. План на матч строится вокруг создания условий, в которых воспроизводятся ошибки движка. Это может быть выбор подходящих дебютов, создание нужных комбинаций и связок фигур в миттельшпиле, выход в определённые эндшпили.

Как могла бы работать подобная стратегия команды экспертов на практике? Представим следующую гипотетическую ситуацию. Команда Deep Blue проводит третий матч с Гарри Каспаровым. Перед матчем разработчики подробно консультируют шахматиста обо всех обнаруженных, но неисправленных ошибках в той версии компьютера, с которой ему предстоит играть. Очевидно, что такая информация намного повысила бы шансы Гарри Каспарова на победу. Именно такое преимущество даёт стратегий ручного систематического поиска ошибок.

Стратегия РСП со стороны команды экспертов может не сработать, если разработчики движка применяют стратегию АСП. В этом случае стратегия разработчиков сильнее. Они могут уже найти и исправить все ошибки, которые потенциально способны вручную найти эксперты.

#### 3.8.2.5 Третий сценарий АСП

>>>> REWRITE

Условия третьего сценария игры команды экспертов против шахматного движка выглядят так:

1. Команда экспертов состоит из шахматистов, разработчика шахматных движков, специалиста по компьютерной безопасности, специалиста по тестированию, специалист по статистике и обработке данных.

2. В распоряжении команды есть точная версия шахматного движка, история его изменений и исходный код.

3. У есть инструменты для автоматизации поиска ошибок в шахматном движке.

Инструменты для поиска ошибок частично повторяют систему тестирования, которую используют разработчики движка. Это позволяет команде экспертов применить стратегию автоматического систематического поиска ошибок.

Снова обратимся к примеру, в котором команда экспертов играет против движка Stockfish версии 15. На этапе подготовки команда ищет слабости в игре программы, чтобы эксплуатировать их в ходе матча.

Применять инструменты поиска ошибок можно несколькими способами:

1. Провести автоматический турнир между Stockfish 15 и более сильным шахматным движком. Такой турнир даст набор партий, в которых Stockfish 15 проиграл. Шахматисты из команды экспертов должны проанализировать эти партии. Они могут указать на слабые стороны программы.

2. Разработчик шахматных движков составляет список изменений, сделанных после выпуска версии Stockfish 15. Имея на руках исходный код, он может собирать модифицированные версии движка. Тогда с помощью системы тестирования можно оценить влияние каждого изменения на силу игры. Инструмент даст как статистику побед, так и конкретные партии и позиции, в которых Stockfish 15 без исправления ошибки сыграл слабо.

3. Инструмент может проанализировать все официальные партии Stockfish версии 15. В этих партиях интересны позиции, в которых Stockfish 15 делает слабый ход по мнению более сильного движка. Эти позиции должны проанализировать шахматисты команды экспертов.

Инструмент автоматизации позволяет команде экспертов вести более широкий поиск ошибок. Это вовсе не означает, что инструмент берёт всю работу на себя. Самостоятельно он вряд ли найдёт подходящую ошибку, которую можно эксплуатировать в матче. Скорее задача инструмента — дать экспертам перспективное направление для ручного систематического поиска.

Эффективность стратегии АСП со стороны команды экспертов зависит от доступных ей вычислительных ресурсов и времени. Если разработчики шахматного движка используют систему для интенсивного тестирования наподобие Fishtest, это значительно понижает шансы команды экспертов найти подходящую ошибку.

#### 3.8.2.6 Реалистичность сценариев

>>> REWRITE

Мы рассмотрели три сценария игры команды экспертов против шахматного движка. Все крупные матчи именитых шахматистов против программ в 2000-х годах проходили в условиях, близких к первому сценарию. Возникает вопрос: насколько реалистичны второй и третий сценарий?

После поражения Владимира Крамника в матче с Deep Fritz в 2006 году шахматное сообщество и публика потеряли интерес к подобным противостояниям. Стало сложно найти как спонсоров, так и шахматистов высшего уровня, которые готовы тратить своё время на подготовку матчу с движком.

Второй и третий сценарии требует огромных вложений. Команда экспертов должна состоять из шахматистов уровня претендента. В неё также должны входить эксперты высокого уровня из различных ИТ направлений. Чем выше уровень экспертов, тем выше шансы на успех в подготовке к матчу с движком. Если движок коммерческий, то необходимо сотрудничество со стороны его разработчиков. Они должны предоставить исходный код и историю его изменений.

Условий для выполнения второго и третьего сценариев много. Тем не менее они выполнимы в теории. На практике же возникает вопрос: ради чего такие усилия? В лучшем случае команда экспертов сможет одержать победу в матче против не самой последней версии не самого сильного шахматного движка. В таком достижении нет ничего привлекательно ни для разработчиков шахматного движка, ни для команды экспертов высшего класса, ни для спонсоров такого мероприятия.

Есть ли шансы у команды экспертов против последней версии Stockfish? Ряд особенностей этого движка помешает команде экспертов найти в нём ошибки, даже при использовании стратегии АСП. Эти особенности следующие:

1. **Сеть NNUE вместо функции оценки**. Эксперт может выполнить ревью кода функции оценки и понять его логику. Возможно, специалист даже сможет найти в нём изъяны. Но анализ параметров обученной модели NNUE ничего не скажет эксперту о её слабостях. Изменения в модели невозможно интерпретировать в шахматных понятиях. Известно только, что новая версия статистически лучше старой.

2. **Система тестирования Fishtest**. Интенсивное автоматизированное тестирование выявляет основную массу ошибок в шахматном движке. Если в нём и остались скрытые ошибки, они либо незначительные, либо их очень сложно воспроизвести.

3. **Информация об исправлениях в последней версии Stockfish ограничена**. У команды экспертов есть только небольшая история изменений после последнего релиза. Найти среди них потенциальную ошибку очень сложно.

В заключении могу добавить следующее. Игра против системы, которая достигла сверхчеловеческого уровня в какой-то дисциплине, не имеет ничего общего с игрой против человека. Это противостояние больше напоминает поиск и эксплуатацию уязвимостей в программной системе. Только такой подход может дать хоть какие-то шансы на победу.

{pagebreak}
