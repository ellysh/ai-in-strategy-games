## 3.8 Человек против шахматной программы

Последний крупный матч человека против шахматной программы состоялся в ноябре 2006 года. Действующий на тот момент чемпион мира Владимир Крамник играл против движка Deep Fritz. Матч закончился победой Deep Fritz со счётом 4-2: четыре ничьи и две победы программы. Шахматист не смог выиграть ни одной партии.

Во время матча Deep Fritz работал на мощном по меркам того времени персональном компьютере. Но его вычислительные ресурсы значительно уступали шахматному суперкомпьютеру Deep Blue. Для сравнения: движок Deep Fritz просчитывал около 8 миллионов позиций в секунду, а Deep Blue — от 100 до 300 миллионов в зависимости от конфигурации. Несмотря на скромную производительность, Deep Fritz одержал уверенную победу над чемпионом мира. Этот матч показал, насколько выросло качество шахматных программ спустя 10 лет после противостояния Гарри Каспарова и Deep Blue.

В условия матча современные шахматные движки не оставляют шансов лучшим игрокам. Ведущие шахматисты единогласно признают, что человек уже давно не может конкурировать с машиной. Этот вопрос считается решённым однозначно и окончательно.

Можно ли сказать что-то новое о противостоянии человека и шахматной программы? Это возможно, если посмотреть на него под другим углом.

### 3.8.1 Ошибки в программах

Матчи гроссмейстеров с шахматными программами комментируют профессионалы. Они являются экспертами в предметной области и знают все тонкости шахматной игры. Опираясь на свой опыт, комментатор рассказывает о позициях, ходах, вариантах, комбинациях и ошибках. Точка зрения именно этих экспертов звучит в репортажах со всех шахматных событий. Но эта точка зрения не единственная.

Шахматные движки — это в первую очередь компьютерные программы. Их разрабатывают профессиональные программисты. Это другой вид экспертов, который имеет отношение к компьютерным шахматам. К сожалению, эксперты этого рода редко высказываются о поединке человека и машины. Одну из самых известных попыток предпринял Фэн Сюн Сю. Он опубликовал книгу "Behind Deep Blue" о поединке суперкомпьютера IBM и Гарри Каспарова.

Что может рассказать разработчик шахматной программы? В своей книге Фэн Сюн Сю знакомит читателя с техническими задачами и проблемами, которые решала его команда. Комментируя партии, он часто говорит о программных и аппаратных ошибках. Именно из-за них Deep Blue делал слабые ходы, терял позиционное преимущество и проигрывал. Означает ли это, что ключ к победе над шахматной программой кроется в ошибках её реализации? Если да, то изменилось ли что-то со времён Deep Blue?

Управляющая программа для Deep Blue была разработана почти 30 лет назад. Методология программирования продвинулась далеко вперёд за это время. Но проблема ошибок никуда не делась. Современные программы аварийно завершаются, теряют данные пользователей и зависают точно так же, как и 30 лет назад. Главная причина этого в том, что разработка программного обеспечения — это компромисс между функциональностью, стоимостью, временем и качеством. Чем-то всегда приходится жертвовать. Разработка шахматной программы в этом плане ничем не отличается.

Чтобы найти и исправить ошибки в программах, разработчики используют различные методы тестирования. Например, это может быть ручная проверка самых важный функций программы. Тестирование можно автоматизировать. Специальные системы могут запускать программу и выполнять в ней стандартные действия. Тем самым они проверяют, что она по-прежнему работает.

Если внимательно посмотреть на историю шахматных программ, можно заметить некоторую закономерность. Метод поиска ошибок в них постоянно развивался. Одновременно с этим рос и уровень игры программ. Значительные скачки в силе движков происходили именно тогда, когда разработчики начинали использовать новый метод тестирования. Есть ли какая-то взаимосвязь между этими событиями? Возможно, что есть.

Предлагаю снова обратиться к истории компьютерных шахмат. Но на этот раз мы сфокусируемся не на игре, а на поиске ошибок в программах.

### 3.8.1.1 Ручной несистематический поиск

В 1960-х годах методология разработки и тестирования ПО находилась на начальном этапе развития. Автор программы сам тестировал её вручную. Обычно он пробовал разные входные данные и проверял, что выход программы соответствует ожидаемому результату.

Разработчики первых шахматных программ следовали общепринятой практике. Они применяли самую очевидную стратегию тестирования, которая состояла из трёх стадий.

На первой стадии автор играет со своей программой несколько партий после каждого значительного изменения в её коде. Такая проверка показывает, что программа не завершается с ошибкой после очередного хода и не нарушает правил игры. Если программа делает очень слабые или бессмысленные ходы, разработчик пытается понять и устранить их причину.

Такой тест в терминах современной разработки ПО называется [**альфа-тестированием**](https://ru.wikipedia.org/wiki/Тестирование_программного_обеспечения#Уровни_тестирования). Его выполняет сам разработчик. При этом программа выполняется в некоторой контролируемой среде, например, под управлением отладчика. Этот инструмент позволяет остановить выполнение программы в любой момент и получить состояние её памяти. Таким образом, разработчик сразу получает полную информацию о возникшей ошибке, может найти её в исходном коде и быстро исправить.

Когда программа начинает работать стабильно без критических ошибок, наступает вторая стадия тестирования. Разработчик обращается к одному или нескольким сильным шахматистам. Они проводят серию игр против программы и указывают на её слабости. Типичная причина этих слабостей — неверные представления разработчика о шахматной игре. Его недостаточное владение предметной областью выливается в логические ошибки программы.

I> [**Логической ошибкой**](https://ru.wikipedia.org/wiki/Логическая_ошибка_(программирование)) называется неправильное действие программы на этапе принятия решений.

Сегодня такой вид теста называется [**бета-тестированием**](https://ru.wikipedia.org/wiki/Бета-тестирование). Его выполняет ограниченный круг потенциальных пользователей программы. Во время тестирования пользователи используют свои экспертные знания в предметной области. Они дают разработчику обратную связь об обнаруженных проблемах в программе.

На последней стадии тестирования шахматная программа играла на турнирах. Это были партии с классическим контролем времени против шахматистов и других программ. На этой стадии разработчик наблюдал, как программа работает в максимально сложных для неё условиях. Когда происходил сбой или бессмысленный ход, автор собирал максимум информации об этом событии. Таким образом разработчик искал причину ошибки и код, который её вызвал.

Предлагаю назвать такую стратегию поиска ошибок в шахматных программах **ручным несистематическим поиском**. Слово **ручной** означает, что его выполняет человек без какой-либо автоматизации. Он играет серию партий против программы от начала до конца.

Поиск называется **несистематическим**, потому что в нём нет строго плана. Мы рассмотрели три стадии тестирования. На каждой из них тестировщик просто играет против программы. Тем самым он проверяет её основные функции. В одной из партий может проявиться какая-то из существующих ошибок. Но такое воспроизведение проблемы будет чистой случайностью. Ходы и позиции могут сложиться так, что ошибки не проявятся ни в одной из партий. В этом случае разработчик программы о них не узнает и не устранит.

Эффективность ручного несистематического поиска ошибок зависит только от интенсивности тестирования. Чем больше партий сыграет шахматная программа, тем выше шанс воспроизвести какую-то из её ошибок. Только тогда у разработчика появится шанс исправить проблему. Ошибки, которые ни разу не воспроизводились, остаются скрытыми. Их невозможно исправить из-за отсутствия информации.

I> **Скрытой ошибкой** (latent defect) программы называется проблема, которая не была обнаружена на этапе тестирования. Она проявляется только после того, как ПО было выпущено и использовалось в определённых условиях.

Интенсивность тестирования зависит от ресурсов, которые разработчики инвестируют в проект. Особенно важны ресурсы на его старте. Обратите внимание, что самые сильные шахматные программы разрабатывались профессионалами, за которыми стояли крупные корпорации. Вот несколько примеров:

* Шахматная программа Бернштейна — команда из IBM.

* Компьютер Belle — команда из Bell Labs.

* Программа Cray Blitz — команда из корпорации Cray Research по производству суперкомпьютеров.

* Компьютер Deep Blue — команда из IBM.

В каждый из этих проектов были вложены огромные ресурсы. Конкретнее, вложения были следующими:

1. Деньги на разработку специализированного оборудования (шахматные компьютеры и чипы).

2. Время разработчиков программ, которое в те годы было крайне дорогим. Они писали код, тестировали его и исправляли обнаруженные ошибки.

3. Компьютерное время для тестирования и отладки программы.

4. Время профессиональных шахматистов для тестирования программы.

Вложения на начале проекта позволяли команде разработчиков проводить качественное тестирование. Благодаря ему, обнаруживалась и устранялась большая часть логических ошибок в программе. Это выводило её игру на высокий уровень. Тогда проект привлекал внимание СМИ, шахматного сообщества и специалистов в области ИТ. Программу постоянно приглашали на турниры. Сильнейшие шахматисты охотно проводили с ней матчи. Это только увеличивало интенсивность её тестирования. Как следствие, уровень игры программы продолжал расти.

### 3.8.1.2 Ручной систематический поиск

>>> REVIEW

Стратегия ручного несистематического поиска ошибок имеет предел. Если таким способом интенсивно тестировать шахматную программу, рано или поздно уровень её игры перестанет расти. Это происходит по нескольким причинам.

Во-первых, в программе остаётся мало скрытых ошибок. Чтобы их воспроизвести нужны очень специфичные позиции и условия. Эти позиции могут никогда не сложиться в тестовых партиях со стандартными дебютами и эндшпилями. 

Во-вторых, некоторые ошибки программы могут быть очень тонкими. Только профессиональный шахматист высочайшего уровня способен понять такую ошибку и объяснить разработчику программы её суть. Но у чемпиона мира и претендентов на его место нет времени интенсивно тестировать шахматный движок. Играя против программы матч, профессионал найдёт эту ошибку и воспользуется ей. Заранее же разработчик никогда про неё не узнает.

Именно с этими трудностями столкнулась команда Deep Blue, когда их компьютер играл первый матч против Гарри Каспарова в 1996 году. На тот момент уровень игры компьютера достиг максимума, который мог дать ручной несистематический поиск ошибок. До уровня Гарри Каспарова он не дотягивал.

Чтобы вывести Deep Blue на новый уровень игры, команде разработчиков пришлось создать специальные инструменты для разработки и тестирования. Если говорить о тестировании, то главным инструментом стал программный прототип функции оценки Deep Blue с графическим интерфейсом. Отдалённо он напоминает современный шахматный движок и интерфейс к нему.

Рассмотрим, как работал инструмент тестирования Deep Blue. Через графический интерфейс пользователь задавал произвольную позицию фигур на доске. Эту позицию также можно было загрузить из файла с ходами сыгранной ранее партией. После этого интерфейс отображал баллы, которые функция оценки ставила каждому возможному ходу. Также пользователь видел диагностическую информацию о том, какие факторы позиции повлияли на оценку.

Новый инструмент тестирования стал отправной точкой для новой стратегии поиска ошибок. Раньше штатный гроссмейстер проекта проверял новые возможности Deep Blue в полноценных партиях. Теперь можно было проверять поведение компьютера в конкретных позициях и сразу же корректировать его. Такой подход намного повысил эффективность тестирования.

Вторым компонентом новой стратегии поиска ошибок стало дополнительное правило в играх с компьютером. Чтобы тестовые партии стали эффективнее, разработчики разрешили штатному шахматисту брать ход назад в любой позиции. Это позволило игроку возвращаться назад и исправлять допущенные ошибки. Таким образом он мог играть на равных с Deep Blue, который превосходил его минимум на 200 пунктов Эло. При равной игре ошибки компьютера стали воспроизводиться чаще и очевиднее. Он перестал выигрывать из-за банальных зевков оппонента.

Предлагаю назвать стратегию поиска ошибок команды Deep Blue **ручным систематический поиском**. Он **ручной**, потому что его по-прежнему выполняет человек без автоматизации. Но на этот раз тестировщик пользуется специальными инструментами и расширенными правилами игры.

Поиск называется **систематическим**, потому что у него есть строгий план действий. Этот план выглядит следующим образом:

1. Получить предварительную информацию о предполагаемой ошибке. Например, тестировщик знает, что в программе изменилась оценка пешечной структуры. Тогда он должен сконцентрироваться на позициях с различной конфигурацией пешек и проверить, что программа правильно в них ориентируется.

2. Создать полностью повторяемую среду для воспроизведения ошибки. Это означает, что ни аппаратное обеспечение, ни программна не должны меняться между тестами. Тестировщик всегда берёт один и тот же компьютер и запускает на нём одну и ту же версию программы или инструмента тестирования.

3. Следовать повторяемым путём для воспроизведения ошибки. Это означает, что тестировщик на каждой итерации выполняет одни и те же действия, которые приводят к одним и тем же результатам. 

4. Если ошибка воспроизвелась, зафиксировать 
состояние программы и среды её выполнения (например, состояние аппаратуры). Именно один из параметров этого состояния провоцирует возникшую ошибку. Задача разработчика — понять, какой именно параметр.

Рассмотрим, как команда Deep Blue следовала этому плану тестирования. Первый пункт — узнать о предполагаемой ошибке компьютера. Было несколько способов это сделать:

1. Получить информацию от разработчика, который изменили что-то в управляющей программе или прошивке шахматного чипа. Это изменение потенциально может привести к ошибкам в позициях, когда оно влияет на выбор хода.

2. Во время тестовой игры с правилом брать ход, Deep Blue делает слабый ход. Тестировщик должен запомнить все ходы партии и особенности позиции, которые привели к ошибке.

3. Во время очередной турнирной партии Deep Blue делает слабый ход. Лог файл игры поможет точно восстановить ход этой партии.

Второй пункт плана — создать полностью повторяемую среду для воспроизведения ошибки. Разработчики Deep Blue могли его выполнить. Они контролировали версии управляющей программы, шахматных чипов и их прошивки. Это позволяло воссоздать комбинацию аппаратного обеспечения и программ, в которой произошла ошибка.

Третий пункт — следовать повторяемым путём для воспроизведения ошибки. Это условие практически невозможно выполнить, если играть обычные партии против шахматной программы. Дело в том, что в на алгоритм её работы влияет много случайностей. Но эту проблему решил специальный инструмент тестирования команды Deep Blue. Благодаря ему, можно было не играть партию целиком, а сразу выставить нужную позицию фигур.

Четвёртый пункт плана — зафиксировать состояние программы и оборудования. У команды Deep Blue были инструменты для анализа управляющей программы и прошивки шахматных процессоров. Так они собирали полную информацию о среде выполнения в состоянии ошибки. Это помогало выяснить причину ошибки и исправить её.

На исход второго матча Гарри Каспарова против Deep Blue 1997 года повлияло много факторов. Одним из них стала новая стратегия поиска ошибок. Благодаря ей, команда разработчиков могла оперативно вносить изменения в управляющую программу компьютера. Если Гарри Каспаров находил какой-то изъян в игре оппонента, команда Deep Blue успевала исправить его до следующей партии. Это уравнивало шансы сторон: человек и машина адаптировались к игре друг друга по ходу матча.

### 3.8.1.3 Автоматический несистематический поиск

Следующий шаг в развитии методологии тестирования шахматных программ сделало сообщество разработчиков Stockfish.

Stockfish, как и подавляющее большинство проектов с открытым исходным кодом, развивается энтузиастами. Люди безвозмездно инвестируют своё время и ресурсы в интересный и нужный им проект.

Ключевые фигуры любого проекта с открытым исходным кодом — это безусловно программисты. Так было и с движком Stockfish до тех пор, пока Гэри Линскотт в 2013 году не разработал систему Fishtest. После этого сообщество тестировщиков стало играть очень важную роль в проекте.

Система Fishtest позволила перейти от ручного тестирования шахматного движка к автоматическому. Её главная инновация заключается в том, что она работает по принципу краудсорсинга. Любой желающий может принять участие в тестировании движка. Для этого не нужны специализированные знания. Достаточно установить программу-клиент под названием [**worker**](https://github.com/official-stockfish/fishtest/wiki/Running-the-worker). Эта программа подключается к серверу и предоставляет ему вычислительные ресурсы компьютера, на котором она запущена. Сервер использует эти ресурсы для проигрывания партий между разными версиями Stockfish.

Идея запускать шахматную программу для игры против самой себя не нова. Её использовала команда Deep Blue, чтобы сравнить новую и старую версию своего компьютера. Проблема только в том, что шахматный движок — очень это ресурсоёмкая программа. Используя только один ПК, можно провести несколько тысяч игр в день. Распределённая система Fishtest в среднем играет 1,5 миллиона игр в день. Такая интенсивность тестирования даёт намного более качественный результат.

Система Fishtest тестирует изменения в новых версиях Stockfish. Какое отношение она имеет к поиску ошибок? На самом деле имеет, но косвенное. Некоторые из тестируемых изменений именно исправляют ошибки, а не добавляют в движок новые возможности.

Назовём подход разработчиков Stockfish **автоматическим несистематическим поиском** ошибок. Его применяют отделы тестирования фирм по разработке ПО. В профессиональных терминах он называется [**автоматическим smoke-тестированием**](https://ru.wikipedia.org/wiki/Smoke_test). Эта процедура нужна для обнаружения случайных ошибок, которые появились в результате добавления новой функциональности.

Поиск автоматический, потому что его выполняет не человек, а программа. Программа запускает две версии движка, которые играют друг с другом полную партию. Результат каждой партии фиксируется в отчёте. Когда число сыгранных партий достаточно велико, можно говорить о статистических закономерностях и делать выводы о превосходстве одной версии над другой.

Поиск несистематический, потому что он не направлен на поиск конкретных ошибок. Скорее он позволяет добавлять новые функции в движок Stockfish и проверять, что при этом не возникло каких-то новых ошибок. Новые ошибки неизбежно приведут к понижению уровня игры. Они гарантированно проявятся на миллионах сыгранных партий в системе Fishtest.

Эффективность автоматического несистематического поиска, так же как и ручного несистематического, напрямую зависит от вложенных ресурсов. Разработчики Stockfish нашли колоссальный источник вычислительных мощностей в краудсорсинге.

Благодаря высокому качеству движка, к 2013 году он уже был широко известен среди профессиональных шахматистов и любителей. Поэтому нашлось много добровольцев, готовых выделить процессорное время для его тестирования. Ни одна из команд разработчиков коммерческих движков не обладает такими вычислительными мощностями. Это преимущество вылилось в качественное превосходство Stockfish над конкурентами.

### 3.8.1.4 Автоматический систематический поиск

Последнее улучшение поиска ошибок в шахматных программах сделала команда DeepMind. Их подход привел к настоящей революции в разработке движков и вывел их на совершенно новый уровень игры.

Во-первых, команда DeepMind разработала достаточно сложную deep learning модель. Модель AlphaZero оказалась способна усвоить тонкости шахматной тактики и стратегии. Во-вторых разработчики применили алгоритм обучения с подкреплением.

Что делает алгоритм обучения с подкреплением? Он корректирует ошибки модели. Мы подробно рассмотрели обучение с подкреплением в разделе 2.6.2.3. Повторим только некоторые его ключевые идеи, которые относятся к нашей теме.

Алгоритм обучения с подкреплением выполняет поиск методом проб и ошибок. Модель случайно пробует разные действия. На некоторые из них среда даёт положительный сигнал вознаграждения (победа в партии). Эти действия запоминаются как успешные. Другие действия приводят к отрицательному сигналу со стороны среды (поражение в партии). Модель запоминает их тоже как неуспешные. Запоминание происходит путём коррекции весов в свёрточных и линейных слоях сети (см. иллюстрацию 3-45 со схемой сети). В результате говорят, что модель учится играть в шахматы.

Давайте посмотрим на процесс обучения с точки зрения поиска ошибок. Первые циклы работы алгоритма обучения модель в принципе не умеет играть в шахматы. Она выбирает ходы совершенно случайно. Это происходит потому, что в самом начале обучения веса нейронных слоёв её сети проинициализированы случайными значениями.

После нескольких сотен циклов алгоритма обучения модель начинает играть в шахматы на слабом любительском уровне. С этого момента можно утверждать, что модель в принципе умеет играть. Её проблема в многочисленных ошибках. Эти ошибки происходят из-за того, что веса модели имеют неоптимальные значения. Если подобрать лучшие значения весов, то нейронная сеть станет выбирать более качественные ходы и допускать меньше ошибок. Именно это и происходит на каждом последующем цикле работы алгоритма обучения.

Предлагаю назвать подход разработчиков AlphaZero **автоматическим систематическим поиском** ошибок. На нём строится всё современное машинное обучение. Первой реализацией этого подхода стал метод обратного распространения ошибки.

Поиск систематический, потому что он следует некоторому плану. Сравним его с системой Fishtest. Она проверяет изменения в движке Stockfish на возможную регрессию и реальное улучшение игры. Любое изменение может привести к каким-то неизвестным новым ошибкам. Система тестирования не знает, в чём заключаются эти потенциальные ошибки. Она просто проигрывает очень много партий. В результате велика вероятность их обнаружить. Но по случайному стечению обстоятельств, Fishtest может и не заметить новую ошибку.

Алгоритм обучения с подкреплением действует более систематически. Начиная с определённого цикла его работы, можно утверждать, что модель умеет играть в шахматы на каком-то уровне. Тем не менее алгоритм обучения продолжается. Теперь допустим, что модель играет против самой себя и допускает грубую ошибку. Она приводит к поражению в партии. Алгоритм обучения фиксирует это с помощью отрицательного сигнала. Получив его, модель корректирует соответствующие веса в слоях нейронной сети. В результате модель станет избегать именно этой грубой ошибки.

Конечно это сильно упрощённое описание алгоритма обучения с подкреплением. В результате одной игры может быть совершенно непонятно, какой именно ход был грубой ошибкой. Его последствия отсрочены во времени и проявляются только через несколько ходов. Чтобы отследить эту причинно-следственную связь, нужно много циклов работы алгоритма обучения.

Например, в 100000 партий модель совершает одну и ту же грубую ошибку. В ответ на отрицательный сигнал она корректирует веса в своей нейронной сети. Таким образом модель в каком-то смысле ищет, где именно была допущена ошибка. После многократных попыток исправляются именно те веса, которые приводят к неправильному ходу. Теперь представьте, что модель одновременно пытается скорректировать множество разных ошибок. Это даст вам примерное представление о сложности алгоритма обучения и его ресурсоёмкости.

Автоматический систематический поиск ошибок значительно усилил современные шахматные движки. Прежде всего сама AlphaZero в результате обучения с подкреплением нашла новые сильные дебюты, которые считались малоперспективными среди профессиональных шахматистов. Кроме этого система научилась шахматной тактике и стратегии. Её знания — это нечто намного более сложное, чем минимаксный поиск с применением закодированной вручную функцией оценки. Некоторые принципы игры AlphaZero кардинально отличаются от принятых в шахматном сообществе. Они хороши в исполнении машиной с её огромной вычислительной мощью, но совершенно не подходят для исполнения человеком.

Победа AlphaZero над Stockfish показала превосходство нового подхода DeepMind. Да, сама победа остаётся предметом споров. Есть утверждения о том, что команда DeepMind умышленно ослабила движок Stockfish. Но факт в следующем: AlphaZero намного лучше оценивает шахматную позицию, чем Stockfish. Это подтверждает переход разработчиков Stockfish с вручную запрограммированной оценки на нейронную сеть NNUE.

Что такое в принципе сеть NNUE? Это копия поведения deep learning сети Leela Chess Zero. Сеть же Leela Chess Zero — это эволюция модели AlphaZero нацеленная только на игру в шахматы.

Сеть NNUE обучается с учителем на 16 миллиардах позиций. Каждую из них предварительно оценивает Leela Chess Zero. В результате поведение shallow сети NNUE подгоняется под поведение deep learning сети. Такое "копирование" не бесплатно. Оно приводит к потере данных. Его нельзя сравнить, например с архивацией файла. После упаковки и распаковки, вы получаете тот же исходный файл. В результате переноса данных из одной сети в другую происходит [**аппроксимация**](https://ru.wikipedia.org/wiki/Аппроксимация). Более сложная модель заменяется на простую с похожим поведением.

Почему NNUE модель теряет данные? Это shallow сеть с намного меньшим числом слоёв, чем deep learning сеть Leela Chess Zero. Deep learning сеть хранит представление о признаках шахматной позиции в своих скрытых слоях. Такого пространства для хранения информации у NNUE просто нет. Кроме этого NNUE получает информацию от deep learning сети косвенно. Вместо прямой передачи знаний, NNUE видит как deep learning сеть применяет эти знания для оценки ограниченного набора позиций. Да, этот набор очень большой. Но он не покрывает все знания deep learning сети. В результате, если NNUE встречает новую позицию не из обучающего набора, она только "предполагает" как бы её оценила deep learning сеть. NNUE не может точно реконструировать её работу.

Насколько велика потеря данных в сети NNUE? Об этом говорит эксперимент разработчиков Stockfish. Они настроили движок так, чтобы он выбирал наилучший ход по мнению оценки сети NNUE. Другими словами, движок делал тот ход, который сеть оценивала как наилучший. При этом он не просчитывал дальнейшие ходы вглубь. Такая версия Stockfish играла на уровне 500-600 пунктов Эло. Это ниже уровня среднего любителя. Для сравнения движок Leela Chess Zero с отключенным MCTS поиском играет на уровне 2000 Эло. Это уровень кандидата в мастера спорта.

Эксперимент показал, что потеря данных в NNUE сети значительна. Но несмотря на это, переход Stockfish с вручную запрограммированной функции оценки на сеть NNUE усилил движок на 80 пунктов Эло. Это примерная оценка, выполненная сразу после интеграции NNUE в Stockfish версии 12. Но сеть продолжает совершенствоваться. Сейчас она даёт Stockfish намного больше чем 80 пунктов Эло. В этом и есть разница между автоматическим несистематическим поиском ошибок и автоматическим систематическим.

Благодаря NNUE сети, Stockfish начал использовать автоматический систематический поиск ошибок. Этот подход повторили все ведущие коммерческие и бесплатные шахматные движки. Но в дополнение к NNUE Stockfish по-прежнему использует систему Fishtest. Так он комбинирует оба вида автоматического поиска ошибок. Такая комбинация даёт Stockfish преимущество. Он всё ещё остаётся сильнейшим движком.

### 3.8.2 Сложность игры

Мы рассмотрели разные стратегии поиска ошибок в порядке возрастания их эффективности. Из этого обзора можно сделать вывод: автоматический систематический поиск ошибок гарантирует сильную игру машины. Конечно, это утверждение неверно.

Вторая часть этой книги будет посвящена моделям для игры в киберспортивные дисциплины. Эти модели обучаются алгоритмом с подкреплением. Несмотря на это, они все ещё уступают профессиональным спортсменам. Почему?

Разные стратегические игры имеют разную сложность. Причем есть несколько видов этой сложности.

Вот три настольные игры: крестики-нолики, шахматы, го. Все они имеют одинаковые характеристики с точки зрения теории игр:

* Последовательная
* С нулевой суммой
* С полной информацией
* С совершенной информацией
* Детерминированная
* Многократная и многоходовая
* С фиксированными правилами
* Некооперативная
* Пристрастная
* Дискретная

Несмотря на это, компьютерные программы для игры в них на уровне человека появлялись со значительными временными интервалами. Эти игры различаются размером дерева игры. Самое маленькое дерево игры у крестиков-ноликов, а самое большое у го. Поэтому первая программа OXO для игры в крестики-нолики с совершенной стратегией появилась в 1952 году. Первая программа AlphaGo, способная играть в го на уровне профессионалов, появилась только в 2015 году. Можно сказать, что у этих игр разная **вычислительная сложность**.

Кроме вычислительной сложности, игра может иметь **сложные правила**. Для человека и для машины разные правила создают сложности. Например, игры со следующими характеристиками считаются трудными для машин:

* Несовершенная информация
* Недетерминированная игра
* Непрерывная игра
* Нефиксированные правила

В таких играх программе трудно учитывать все аспекты. Этих аспектов оказывается слишком много. Единственное решение этой проблемы — сделать достаточно сложной саму программу. Тогда она сможет охватить и возможные состояния игры, и возможные действия участников. Но тогда для запуска такой программы потребуются значительные вычислительные ресурсы.

В шахматах проблемы со сложностью правил нет. Уже первые шахматные программы конца 1950-х годов учитывали все правила игры. При этом они запускались на очень слабых по современным меркам компьютерах.

Что происходит, когда сложность игры превосходит сложность программы? Рассмотрим наглядный пример с шахматами. Допустим, что шахматная программа работает на каком-то специальном микроконтроллере. У него очень ограниченные ресурсы: мало памяти и низкая тактовая частота. Из-за этого программа не может учитывать ходы коней. Они слишком сложные и не поместились в код программы.

Теперь применим автоматический систематический поиск ошибок. Например, его реализует какой-то эволюционный алгоритм. Программа будет играть сама с собой и исправлять ошибки. Но во время такого обучения конями ходить она не будет из-за принципиального ограничения. В результате программа научится очень хорошо обращаться с теми фигурами, которыми она играла. Но будет ли такая программа хорошо играть в шахматы? Скорее всего, нет. Любой знающий правила игрок, сразу обнаружит ограничение программы.

### 3.8.3 Виды ошибок

До сих пор мы говорили об ошибках в шахматной программе, но без уточнения их видов. Понятие сложности игры позволяет нам разделить ошибки на три вида:

1. Ошибки из-за непонимания правил игры.

2. Ошибки из-за вычислительной сложности игры.

3. Ошибки проектирования, программирования или алгоритма обучения.

Ошибки перечисленны в порядке увеличения сложности их поиска. Проще всего обнаружить ошибку программы, связанную с правилами игры. Для этого достаточно создать ситуацию, в которой машина должна учесть какое-то правило. Если она его не учитывает, это очевидная слабость.

Сложнее обнаружить ошибки связанные с недостатком вычислительной мощности. Чтобы их найти нужно создать ситуацию, которая требует максимального количества вычислений. Например, в шахматах это может быть ловушка через несколько ходов. Если программа её не видит, значит у неё недостаточная глубина поиска.

Самые сложные для обнаружения ошибки связаны с проектированием, программированием и алгоритмом обучения. Без анализа архитектуры и кода программы невозможно предсказать, в чём именно они могут заключаться и где их следует искать.

Для всех трёх видов ошибок применимы четыре стратегии поиска, которые мы рассмотрели ранее.

### 3.8.4 Экспертные знания

До сих пор мы говорили только о программах и ошибках в них. У читателя могла возникнуть мысль, что для победы над шахматным движком совершенно не обязательно быть профессиональным шахматистом. Достаточно просто найти ошибку в программе. Конечно, это неверно.

На что влияет уровень Эло человека при игре против программы? Во-первых, он определяет качество поиска ошибок. Неважно, какую стратегию поиска применяет игрок. Чем выше его уровень, тем шире диапазон потенциальных ошибок программы он может заметить и понять. Например, начинающий шахматист не поймёт тонкую стратегическую ошибку программы в сложной позиции, а профессионал поймёт. Это означает, что игроки низкого уровня просто не видят целый класс ошибок.

Во-вторых, уровень Эло шахматиста определяет критичность ошибок программы, которые он способен эксплуатировать. Профессиональный шахматист найдёт способ извлечь выгоду даже из незначительной ошибки оппонента. Начинающий игрок может воспользоваться только грубыми ошибками.

Критичность ошибок программы — важный параметр. Грубые ошибки, как правило, очевидны. Их легко найти даже следуя стратегии ручного несистематического поиска. Поэтому разработчики программы исправляют их в первую очередь.

Из нашего рассуждения следует, что чем выше уровень Эло шахматиста, тем выше его шансы в игре против шахматного движка. Это очевидное утверждение. Тем не менее его предпосылка связана с ошибками.

### 3.8.5 Игра против современного шахматного движка

Теперь у нас есть некоторая терминология, чтобы рассмотреть игру человека с шахматным движком с точки зрения поиска ошибок. Для определённости будем говорить только о Stockfish.

Рассуждения об ошибках привели нас к трём критериям для оценки шахматных программ:

1. Справляется ли программа со сложностью правил игры?

2. Справляется ли программа с вычислительной сложностью игры?

3. Какую стратегию поиска ошибок в программе применяли её разработчики?

Оценим по этим критериям движок Stockfish:

1. Да, безусловно. Он знает и учитывает все правила шахмат.

2. Критерий вычислительной сложности игры относителен. Строго говоря, Stockfish не может решить шахматы и просчитать партию до конца. Это означает, что стратегия Stockfish неидеальна. С другой стороны, по сравнению с человеком Stockfish намного лучше справляется с вычислительной сложностью. Он просматривает дерево игры намного глубже.

3. Разработчики Stockfish используют комбинацию автоматического несистематического и систематического поиска ошибок.

Теперь перевернём ситуацию и посмотрим на неё с точки зрения машины. Оценим по этим же самым критериям профессионального шахматиста:

1. Да, конечно. Он знает и учитывает все правила шахмат.

2. Критерий относителен. С точки зрения шахматного движка человек не справляется с вычислительной сложностью игры. Для программы не проблема найти цепочку из десяти единственных лучших ходов, спасающих от мата. Для человека такой трюк невозможен.

3. Шахматист совершенствует своё мастерство, применяя ручной систематический поиск ошибок.

Последний пункт требует разъяснений. В разделе 3.3.2 мы говорили о правиле 10000 часов. Исследования Эрикссона показали, что профессионалы совершенствуются благодаря преднамеренной практике. Это означает, что шахматисты не просто играют в шахматы и становятся лучше. Они целенаправленно совершенствуют разные аспекты своей игры. Они учат новые дебюты. Они анализируют свои прошлые партии, делают из них выводы и пытаются не повторять своих ошибок. Они работают с тренером, который направляет их практику и даёт советы.

Преднамеренная практика, которой следуют профессиональные шахматисты, очень похожа на стратегию ручного систематического поиска ошибок в программе. Нет сомнений, что человек никак не может автоматизировать поиск своих ошибок. Чтобы найти и проработать ошибку, надо обязательно понять в чём она. В то же время профессионал имеет чёткий план, когда работает над улучшением своей игры.

Из нашего сравнения следует, что машина превосходит человека по двум пунктам:

1. Более эффективно справляется с вычислительной сложностью игры.

2. При её разработке использовалась более сильная стратегию поиска ошибок.

Такое превосходство не оставляет никаких шансов человеку. Если шахматист захочет просто сыграть одну партию с шахматным движком, он точно проиграет. Даже на дистанции шахматного матча из нескольких партий, движок будет безусловным лидером.

Кто сегодня играет в шахматы сильнее: человек или машина? Ответ очевиден — машина. Давайте немного сместим наш фокус и переформулируем вопрос. Есть ли хоть какая-то возможность у человека выиграть партию в шахматы против машины?

Мы не будем рассматривать вариант дать фору человеку в одну или несколько фигур. Понятно, что можно подобрать такую фору, которая сравняет силы игроков. Это вполне простой и рабочий вариант. Но есть ли другие опции?

Дальнейшие рассуждения не имеют отношения к честной игре в шахматы. Мы рассмотрим все возможные действия, которые человек может предпринять в принципе.

Первая проблема в игре против машины заключается в её вычислительной мощности. Её можно решить тем же самым путём, которым следовала команда DeepMind для тестирования своей самой первой версии AlphaZero. Оба типа современных шахматных движков (на deep learning сетях и на минимакс поиске с отсечением) чрезвычайно чувствительны к вычислительной мощности компьютера.

Уменьшая число ядер CPU (или GPU) и их частоту, можно на порядок сокращать число просматриваемых позиций в секунду. Таким образом, можно подобрать конфигурацию оборудования, которая заставит движок играть примерно на уровне гроссмейстера. Профессиональный шахматист имеет хорошие шансы справится с движком в такой конфигурации.

Следующая проблема — это количество ошибок во время игры. Шахматный движок ошибается гораздо реже человека. Причин здесь несколько. Во-первых, стратегия поиска ошибок у разработчиков Stockfish намного сильнее, чем у профессионального шахматиста. Автоматический поиск ошибок приводит к тому, что движок наигрывает на несколько порядков больше партий, чем человек. К этим партиям относятся:

1. Тестовые игры в системе Fishtest.

2. Игры в ходе обучения с подкреплением системы Leela Chess Zero. Потом их результаты попадают в сеть NNUE.

Так игра движка проходит гораздо больше проверок в партиях. В итоге она оттачивается намного лучше, чем игра шахматиста.

Вторая причина ошибок связана с тем, как именно человек принимает решения. В профессиональном жаргоне шахматистов даже есть специальный термин [**зевок**](https://ru.wikipedia.org/wiki/Зевок_(шахматы)). Так называется грубая ошибка, которая чаще всего делается по невнимательности.

Как человек может компенсировать свои более частые ошибки? Для этого можно применить подход Джоэла Бенджамина для тестирования Deep Blue. Когда человек в партии против машины допускает ошибку, ему разрешается взять ход назад. Остаётся открытым вопрос: как много ходов назад может взять человек? Результат некоторых ошибок проявляется не сразу, а через несколько ходов.

Допустим, что человек может исправлять только свои самые грубые ошибки и брать один ход назад. Пусть с такими правилами он будет играть против Stockfish. Движок работает на достаточно мощном компьютере. То есть мы целенаправленно не ослабляем его вычислительные возможности. На какой результат может надеяться человек? Я полагаю, что лучший возможный результат — это ничья. Разберёмся почему.

Мы выяснили соотношение ошибок в игре человека и в игре движка. Программа ошибается гораздо реже. Теперь перейдём непосредственно к игре шахматиста и движка. 

Первый сценарий: шахматист никак не готовился к партии. Он не имеет никакой информации об оппоненте. В этом случае он скорее всего будет играть обычную партию, также как против другого человека. Тогда он столкнётся с вычислительной мощностью программы. Движок будет отвечать лучшими ходами и гарантированно сведёт партию к ничьей. Благодаря возврату на один ход назад, человек сможет исправлять свои грубые ошибки. Но таких исправлений недостаточно для победы. Они только предотвращают поражение.

Рассмотренный нами сценарий соответствует ручному несистематическому поиску ошибок. Шахматист многократно играет против программы в надежде случайно поймать её на какой-то слабости, получить из неё преимущество и довести его до победы. Такое развитие событий крайне маловероятно.

Второй сценарий: шахматист знает, что играет против программы и готовится. Во-первых, он фиксирует её версию и компьютер на котором она работает. Так он добивается повторяемой среды. Во-вторых, он ищет информацию в открытых источниках о слабых сторонах программы. Например, если это ранняя версия Stockfish, она может ошибаться в стратегии. В этом случае во время многократных игр человек целенаправленно проверяет программу в сложных позиция, требующих понимания шахматной стратегии. Рано или поздно он надеется подловить движок на ошибке.

Этот сценарий соответствует ручному систематическому поиску ошибок. В нём у шахматиста есть информация, в каком направлении надо искать слабости программы. К сожалению, если речь идёт о современных версиях Stockfish, такой подход вряд ли приведёт к победе. Причина в том, что стратегия поиска ошибок у разработчиков Stockfish сильнее. Они уже нашли и исправили все простые ошибки, которые можно было бы найти ручным поиском.

Третий сценарий: шахматист знает целевую версию движка, против которого играет. Он пытается автоматизировать сбор информации о ней. Для этого, например, можно найти все партии сыгранные целевой версией движка против разных оппонентов. Если партий нет, их можно наиграть в автоматическом режиме против других программ. Дальше отобрать те партии, которые закончились поражением целевого движка.

На следующем шаге отобранные партии можно проанализировать с помощью более сильного движка или более новой версией Stockfish. Этот анализ возможно автоматизировать. Его цель — найти все слабые ходы программы, которые привели к поражению. Когда готов список ходов и позиций, его надо проанализировать вручную. Так шахматист поймёт в чём конкретно заключается слабость целевого движка.

Дальше шахматист многократно играет против движка с возможностью взять ход назад. Он пытается свести партию к одной из известных ему позиций, в которых программа ошибается.

Мы рассмотрели сценарий автоматического несистематического поиска ошибок. Он намного перспективнее двух предыдущих подходов. В случае игры против ранней версии Stockfish без NNUE сети, человек вполне может одержать победу. Но как только появляется NNUE сеть, стратегия поиска ошибок разработчиков снова становится сильнее. Это значит, что автоматический анализ партий шахматиста может не выявить явных ошибок у движка. Он найдёт позиции, в которых программа делала слабый ход. Но извлечь из них достаточное для победы преимущество окажется невозможно. Такой сценарий мне видится наиболее вероятным.

Четвёртый сценарий уже не имеет ничего общего с игрой человека против машины. Он заключается в том, чтобы создать специальную модель. Например, её архитектура может повторять AlphaZero. Модель должна обучаться с подкреплением, играя против целевой версии шахматного движка. Если алгоритм обучения будет сходиться, модель рано или поздно начнёт обыгрывать движок.

Проблема этого сценария в том, что невозможно надёжно извлечь знания из обученной модели. После обучения модель знает ошибки целевого шахматного движка. Играя против него, она использует найденные слабости программы и выигрывает.

Извлечь знания из обученной модели можно только косвенным способ. Например так, как это делает команда разработчиков Stockfish при обучении сети NNUE. Модель проходит по миллиардам шахматных позиций и оценивает каждую из них. Эта оценка указывает на знания нейронной сети. К сожалению, человек не способен проанализировать такой объём информации, найти в ней закономерности и сделать выводы об ошибках целевого движка.

Мы рассмотрели сценарий автоматического систематического поиска ошибок. Он самый перспективный и скорее всего приведёт к победе над целевой версией шахматного движка. В этом случае стратегия поиска ошибок в нём не слабее стратегии, применяемой разработчиками. Но как я заметил ранее, это уже не противостояние человека и машины. Скорее это путь создания специализированной машины для единственной цели — победы над целевой машиной.

### 3.8.6 Стратегия игры против машины

Мы рассмотрели четыре возможных сценария. Следуя им, шахматист может собрать информацию и найти ошибки в шахматном движке. Попробуем обобщить эти рассуждения и поговорим о стратегии человека против машины в любой игре.

Важная оговорка: чтобы играть с машиной, человек должен иметь соответствующие экспертные знания. Чем они выше, тем выше шансы человека на победу. Мы не рассматриваем случаи тривиальных ошибок машины, которые сможет эксплуатировать игрок начального уровня.

Сценарии игры шахматиста против движка приводят нас к некоторой общей стратегии. Она состоит из следующих шагов:

1. Собрать информацию о машине.

2. Создать повторяемую среду для поиска ошибок.

3. Искать ошибки.

4. Эксплуатировать найденные ошибки.

На первом шаге оценим возможности машины по трём критериям:

1. Справляется ли она со сложностью правил игры?

2. Справляется ли она с вычислительной сложностью игры?

3. Какую стратегию поиска ошибок применяли её разработчики?

Допустим, что ответ на первый вопрос отрицательный. Тогда мы получаем самый простой вид ошибок машины для эксплуатации. Вспомним пример с шахматной программой, которая не понимает ходы коней. Согласитесь, что играть против неё достаточно просто. Она не будет защищаться от атак конями и будет жертвовать свои фигуры.

В более сложных играх, эксплуатировать такой вид ошибок может быть нетривиально. Но человек-эксперт сможет справиться с этой задачей.

Отрицательный ответ на второй вопрос даёт нам вид ошибок, который эксплуатировать несколько сложнее. Продолжим аналогию с шахматной программой. Допустим, что она работает на слабом компьютере. Его мощности хватает только для проверки дерева игры на четыре хода вперёд. Мы получили эффект горизонта, которым можно воспользоваться. Для этого надо создать ловушку для программы на пятом ходу, которую она просто не увидит.

Если ответы на первые два вопроса положительные, придётся искать самый сложный вид ошибок машины. Ответ на третий вопрос даёт нам подсказку о том, как следует вести этот поиск.

Переходим ко второму шагу нашей стратегии. Создать повторяемую среду для поиска ошибки принципиально важно. Если программа машины или её аппаратная часть меняется, все полученные ранее результаты становятся недействительными. Фактически вы получаете совершенно новую машину с новыми характеристиками. Это значит, что сбор информации о ней надо начинать с самого начала.

Третий шаг стратегии — поиск ошибки не связанной с ограничениями машины из-за правил или вычислительной сложности игры. На этом шаге самое важное применять стратегию поиска ошибок не слабее, чем та которую применяли разработчики машины.

Возможны три варианта соотношения стратегий поиска ошибок:

1. Человек применяет стратегию слабее, чем разработчики машины. В этом случае высока вероятность, что все ошибки, которые можно найти таким способом, уже были найдены и исправлены.

2. Человек применяет равную стратегию той, которой следовали разработчики машины. В этом случае есть шанс найти ещё неисправленную ошибку. Почему? Потому что профессиональные шахматисты всё ещё играют друг с другом. Они используют равные стратегии поиска и при этом продолжают находить ошибки в игре друг с другом. Причём на турнирах высокого уровня большинство ошибок не "зевки".

3. Человек применяет более сильную стратегию, чем разработчики машины. Такая стратегия гарантированно найдёт хотя бы одну ещё неисправленную ошибку.

Последний шаг нашей стратегии — эксплуатация найденной ошибки. Успех напрямую зависит от экспертных знаний и навыков человека. Например, только что научившийся играть в шахматы ребёнок не сможет эффективно воспользоваться даже грубой ошибкой шахматной программы.

Вполне возможна ситуация, когда человек обнаружил ошибку в игре машины. Но ему не хватает экспертных знаний, чтобы ей воспользоваться. Пример из шахмат. Из-за ошибки в определённых позициях сила шахматного движка падает с уровня Эло 2900 до уровня 2500. Теперь вопрос к человеку — играет ли он выше уровня 2500, чтобы суметь воспользоваться ошибкой программы?

Допустим, человеку не хватает экспертных знаний. Поэтому он не способен эксплуатировать найденную ошибку машины. В этом случае у него есть два варианта:

1. Взять таймаут и приобрести недостающие знания.

2. Искать следующую ошибку машины, которая окажется грубее.

Второй путь мне видится менее предсказуемым. Человек может потратить уйму времени и сил, но так и не найти ещё одну ошибку машины. С другой стороны, может быть совсем неочевидно, каких именно знаний не хватает человеку для эксплуатации найденной ошибки. В этом выборе нет однозначного простого решения.

### 3.8.7 Польза от машины

Мы поняли, что машина может оказаться серьёзным оппонентом для профессионального игрока. Но такая её роль не единственная. Кроме этого машина — это эффективный инструмент человека для развития экспертных знаний и навыков.

Снова обратимся к примеру шахмат. Шахматные программы вывели профессиональную игру на совершенно уровень. Речь идёт не только об их вкладе в шахматную теорию и популяризацию этого вида спорта. Исследования говорят, что средний уровень сильнейших шахматистов за последние 20 лет вырос примерно на 70 пунктов Эло. После 2000 года значительно понизился средний возраст получения гроссмейстерского титула. А число самих гроссмейстеров стало намного больше, чем в прошлые десятилетия. Всё это произошло благодаря шахматным программам.

Почему шахматные программы повышают уровень игроков? Во-первых, они легкодоступны. Интересующиеся шахматами дети со всего мира получают возможность для практики.

Во-вторых, шахматные программы гибко настраиваются на любой уровень игры. Для этого совершенно не обязательно конфигурировать производительность запускающего их компьютера. В интерфейс многих программ заложена настройка желаемого уровня Эло, на котором они должны играть. Благодаря такой настройке, шахматисты разного уровня получают идеального оппонента для тренировок. Это особенно актуально для игроков высокого уровня, которых не так много в мире.

В-третьих, шахматные программы и графический интерфейс к ним представляют собой мощный инструмент для анализа позиций. С его помощью можно изучать сыгранные турнирные партии. Программа даёт оценку каждому ходу и предлагает собственные альтернативы. Таким образом игроку легче находить и анализировать свои ошибки.

Наконец, сильная программа — это идеальный инструмент для поиска шахматистом собственных ошибок. Достаточно просто играть против неё партии так же, как против человека. Современный шахматный движок замечает не то что любую ошибку, но даже малейшую погрешность в ходе оппонента. После этого он находит способ ей воспользоваться и получить преимущество. Конечно, нет не никакого спортивного интереса играть против такого оппонента — он всё равно победит. Но последующий анализ игр поможет обнаружить собственные ошибки и слабости. Это полезная информация для преднамеренной практики.

{pagebreak}
