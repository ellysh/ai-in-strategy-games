## 3.8 Человек против шахматной программы

Последний крупный матч человека против шахматной программы состоялся в ноябре 2006 года. Действующий на тот момент чемпион мира Владимир Крамник играл против движка Deep Fritz. Матч закончился победой Deep Fritz со счётом 4-2: четыре ничьи и две победы программы. Шахматист не смог выиграть ни одной партии.

Во время матча Deep Fritz работал на мощном по меркам того времени персональном компьютере. Но его вычислительные ресурсы значительно уступали шахматному суперкомпьютеру Deep Blue. Для сравнения: движок Deep Fritz просчитывал около 8 миллионов позиций в секунду, а Deep Blue — от 100 до 300 миллионов в зависимости от конфигурации. Несмотря на скромную производительность, Deep Fritz одержал уверенную победу над чемпионом мира. Этот матч показал, насколько выросло качество шахматных программ спустя 10 лет после противостояния Гарри Каспарова и Deep Blue.

В условия матча современные шахматные движки не оставляют шансов лучшим игрокам. Ведущие шахматисты единогласно признают, что человек уже давно не может конкурировать с машиной. Этот вопрос считается решённым однозначно и окончательно.

Можно ли сказать что-то новое о противостоянии человека и шахматной программы? Это возможно, если посмотреть на него под другим углом.

### 3.8.1 Ошибки в программах

Матчи гроссмейстеров с шахматными программами комментируют профессионалы. Они являются экспертами в предметной области и знают все тонкости шахматной игры. Опираясь на свой опыт, комментатор рассказывает о позициях, ходах, вариантах, комбинациях и ошибках. Точка зрения именно этих экспертов звучит в репортажах со всех шахматных событий. Но эта точка зрения не единственная.

Шахматные движки — это в первую очередь компьютерные программы. Их разрабатывают профессиональные программисты. Это другой вид экспертов, который имеет отношение к компьютерным шахматам. К сожалению, эксперты этого рода редко высказываются о поединке человека и машины. Одну из самых известных попыток предпринял Фэн Сюн Сю. Он опубликовал книгу "Behind Deep Blue" о поединке суперкомпьютера IBM и Гарри Каспарова.

Что может рассказать разработчик шахматной программы? В своей книге Фэн Сюн Сю знакомит читателя с техническими задачами и проблемами, которые решала его команда. Комментируя партии, он часто говорит о программных и аппаратных ошибках. Именно из-за них Deep Blue делал слабые ходы, терял позиционное преимущество и проигрывал. Означает ли это, что ключ к победе над шахматной программой кроется в ошибках её реализации? Если да, то изменилось ли что-то со времён Deep Blue?

Управляющая программа для Deep Blue была разработана почти 30 лет назад. Методология программирования продвинулась далеко вперёд за это время. Но проблема ошибок никуда не делась. Современные программы аварийно завершаются, теряют данные пользователей и зависают точно так же, как и 30 лет назад. Главная причина этого в том, что разработка программного обеспечения — это компромисс между функциональностью, стоимостью, временем и качеством. Чем-то всегда приходится жертвовать. Разработка шахматной программы в этом плане ничем не отличается.

Чтобы найти и исправить ошибки в программах, разработчики используют различные методы тестирования. Например, это может быть ручная проверка самых важный функций программы. Тестирование можно автоматизировать. Специальные системы могут запускать программу и выполнять в ней стандартные действия. Тем самым они проверяют, что она по-прежнему работает.

Если внимательно посмотреть на историю шахматных программ, можно заметить некоторую закономерность. Метод поиска ошибок в них постоянно развивался. Одновременно с этим рос и уровень игры программ. Значительные скачки в силе движков происходили именно тогда, когда разработчики начинали использовать новый метод тестирования. Есть ли какая-то взаимосвязь между этими событиями? Возможно, что есть.

Предлагаю снова обратиться к истории компьютерных шахмат. Но на этот раз мы сфокусируемся не на игре, а на поиске ошибок в программах.

### 3.8.1.1 Ручной несистематический поиск

В 1960-х годах методология разработки и тестирования ПО находилась на начальном этапе развития. Автор программы сам тестировал её вручную. Обычно он пробовал разные входные данные и проверял, что выход программы соответствует ожидаемому результату.

Разработчики первых шахматных программ следовали общепринятой практике. Они применяли самую очевидную стратегию тестирования, которая состояла из трёх стадий.

На первой стадии автор играет со своей программой несколько партий после каждого значительного изменения в её коде. Такая проверка показывает, что программа не завершается с ошибкой после очередного хода и не нарушает правил игры. Если программа делает очень слабые или бессмысленные ходы, разработчик пытается понять и устранить их причину.

Такой тест в терминах современной разработки ПО называется [**альфа-тестированием**](https://ru.wikipedia.org/wiki/Тестирование_программного_обеспечения#Уровни_тестирования). Его выполняет сам разработчик. При этом программа выполняется в некоторой контролируемой среде, например, под управлением отладчика. Этот инструмент позволяет остановить выполнение программы в любой момент и получить состояние её памяти. Таким образом, разработчик сразу получает полную информацию о возникшей ошибке, может найти её в исходном коде и быстро исправить.

Когда программа начинает работать стабильно без критических ошибок, наступает вторая стадия тестирования. Разработчик обращается к одному или нескольким сильным шахматистам. Они проводят серию игр против программы и указывают на её слабости. Типичная причина этих слабостей — неверные представления разработчика о шахматной игре. Его недостаточное владение предметной областью выливается в логические ошибки программы.

I> [**Логической ошибкой**](https://ru.wikipedia.org/wiki/Логическая_ошибка_(программирование)) называется неправильное действие программы на этапе принятия решений.

Сегодня такой вид теста называется [**бета-тестированием**](https://ru.wikipedia.org/wiki/Бета-тестирование). Его выполняет ограниченный круг потенциальных пользователей программы. Во время тестирования пользователи используют свои экспертные знания в предметной области. Они дают разработчику обратную связь об обнаруженных проблемах в программе.

На последней стадии тестирования шахматная программа играла на турнирах. Это были партии с классическим контролем времени против шахматистов и других программ. На этой стадии разработчик наблюдал, как программа работает в максимально сложных для неё условиях. Когда происходил сбой или бессмысленный ход, автор собирал максимум информации об этом событии. Таким образом разработчик искал причину ошибки и код, который её вызвал.

Предлагаю назвать такую стратегию поиска ошибок в шахматных программах **ручным несистематическим поиском**. Слово **ручной** означает, что его выполняет человек без какой-либо автоматизации. Он играет серию партий против программы от начала до конца.

Поиск называется **несистематическим**, потому что в нём нет строго плана. Мы рассмотрели три стадии тестирования. На каждой из них тестировщик просто играет против программы. Тем самым он проверяет её основные функции. В одной из партий может проявиться какая-то из существующих ошибок. Но такое воспроизведение проблемы будет чистой случайностью. Ходы и позиции могут сложиться так, что ошибки не проявятся ни в одной из партий. В этом случае разработчик программы о них не узнает и не устранит.

Эффективность ручного несистематического поиска ошибок зависит только от интенсивности тестирования. Чем больше партий сыграет шахматная программа, тем выше шанс воспроизвести какую-то из её ошибок. Только тогда у разработчика появится шанс исправить проблему. Ошибки, которые ни разу не воспроизводились, остаются скрытыми. Их невозможно исправить из-за отсутствия информации.

I> **Скрытой ошибкой** (latent defect) программы называется проблема, которая не была обнаружена на этапе тестирования. Она проявляется только после того, как ПО было выпущено и использовалось в определённых условиях.

Интенсивность тестирования зависит от ресурсов, которые разработчики инвестируют в проект. Особенно важны ресурсы на его старте. Обратите внимание, что самые сильные шахматные программы разрабатывались профессионалами, за которыми стояли крупные корпорации. Вот несколько примеров:

* Шахматная программа Бернштейна — команда из IBM.

* Компьютер Belle — команда из Bell Labs.

* Программа Cray Blitz — команда из корпорации Cray Research по производству суперкомпьютеров.

* Компьютер Deep Blue — команда из IBM.

В каждый из этих проектов были вложены огромные ресурсы. Конкретнее, вложения были следующими:

1. Деньги на разработку специализированного оборудования (шахматные компьютеры и чипы).

2. Время разработчиков программ, которое в те годы было крайне дорогим. Они писали код, тестировали его и исправляли обнаруженные ошибки.

3. Компьютерное время для тестирования и отладки программы.

4. Время профессиональных шахматистов для тестирования программы.

Вложения на начале проекта позволяли команде разработчиков проводить качественное тестирование. Благодаря ему, обнаруживалась и устранялась большая часть логических ошибок в программе. Это выводило её игру на высокий уровень. Тогда проект привлекал внимание СМИ, шахматного сообщества и специалистов в области ИТ. Программу постоянно приглашали на турниры. Сильнейшие шахматисты охотно проводили с ней матчи. Это только увеличивало интенсивность её тестирования. Как следствие, уровень игры программы продолжал расти.

### 3.8.1.2 Ручной систематический поиск

>>> REVIEW

Стратегия ручного несистематического поиска ошибок имеет предел. Если таким способом интенсивно тестировать шахматную программу, рано или поздно уровень её игры перестанет расти. Это происходит по нескольким причинам.

Во-первых, в программе остаётся мало скрытых ошибок. Чтобы их воспроизвести нужны очень специфичные позиции и условия. Эти позиции могут никогда не сложиться в тестовых партиях со стандартными дебютами и эндшпилями. 

Во-вторых, некоторые ошибки программы могут быть очень тонкими. Только профессиональный шахматист высочайшего уровня способен понять такую ошибку и объяснить разработчику программы её суть. Но у чемпиона мира и претендентов на его место нет времени интенсивно тестировать шахматный движок. Играя против программы матч, профессионал найдёт эту ошибку и воспользуется ей. Заранее же разработчик никогда про неё не узнает.

Именно с этими трудностями столкнулась команда Deep Blue, когда их компьютер играл первый матч против Гарри Каспарова в 1996 году. На тот момент уровень игры компьютера достиг максимума, который мог дать ручной несистематический поиск ошибок. До уровня Гарри Каспарова он не дотягивал.

Чтобы вывести Deep Blue на новый уровень игры, команде разработчиков пришлось создать специальные инструменты для разработки и тестирования. Если говорить о тестировании, то главным инструментом стал программный прототип функции оценки Deep Blue с графическим интерфейсом. Отдалённо он напоминает современный шахматный движок и интерфейс к нему.

Рассмотрим, как работал инструмент тестирования Deep Blue. Через графический интерфейс пользователь задавал произвольную позицию фигур на доске. Эту позицию также можно было загрузить из файла с ходами сыгранной ранее партией. После этого интерфейс отображал баллы, которые функция оценки ставила каждому возможному ходу. Также пользователь видел диагностическую информацию о том, какие факторы позиции повлияли на оценку.

Новый инструмент тестирования стал отправной точкой для новой стратегии поиска ошибок. Раньше штатный гроссмейстер проекта проверял новые возможности Deep Blue в полноценных партиях. Теперь можно было проверять поведение компьютера в конкретных позициях и сразу же корректировать его. Такой подход намного повысил эффективность тестирования.

Вторым компонентом новой стратегии поиска ошибок стало дополнительное правило в играх с компьютером. Чтобы тестовые партии стали эффективнее, разработчики разрешили штатному шахматисту брать ход назад в любой позиции. Это позволило игроку возвращаться назад и исправлять допущенные ошибки. Таким образом он мог играть на равных с Deep Blue, который превосходил его минимум на 200 пунктов Эло. При равной игре ошибки компьютера стали воспроизводиться чаще и очевиднее. Он перестал выигрывать из-за банальных зевков оппонента.

Предлагаю назвать стратегию поиска ошибок команды Deep Blue **ручным систематический поиском**. Поиск **ручной**, потому что его по-прежнему выполняет человек без автоматизации. Но на этот раз тестировщик пользуется специальными инструментами и расширенными правилами игры.

Поиск называется **систематическим**, потому что у него есть строгий план действий. Этот план выглядит следующим образом:

1. Получить предварительную информацию о предполагаемой ошибке. Например, тестировщик знает, что в программе изменилась оценка пешечной структуры. Тогда он должен сконцентрироваться на позициях с различной конфигурацией пешек и проверить, что программа правильно в них ориентируется.

2. Создать полностью повторяемую среду для воспроизведения ошибки. Это означает, что ни аппаратное обеспечение, ни программна не должны меняться между тестами. Тестировщик всегда берёт один и тот же компьютер и запускает на нём одну и ту же версию программы или инструмента тестирования.

3. Следовать повторяемым путём для воспроизведения ошибки. Это означает, что тестировщик на каждой итерации выполняет одни и те же действия, которые приводят к одним и тем же результатам. 

4. Если ошибка воспроизвелась, зафиксировать 
состояние программы и среды её выполнения (например, состояние аппаратуры). Именно один из параметров этого состояния провоцирует возникшую ошибку. Задача разработчика — понять, какой именно параметр.

Рассмотрим, как команда Deep Blue следовала этому плану тестирования. Первый пункт — узнать о предполагаемой ошибке компьютера. Было несколько способов это сделать:

1. Получить информацию от разработчика, который изменили что-то в управляющей программе или прошивке шахматного чипа. Это изменение потенциально может привести к ошибкам в позициях, когда оно влияет на выбор хода.

2. Во время тестовой игры с правилом брать ход, Deep Blue делает слабый ход. Тестировщик должен запомнить все ходы партии и особенности позиции, которые привели к ошибке.

3. Во время очередной турнирной партии Deep Blue делает слабый ход. Лог файл игры поможет точно восстановить ход этой партии.

Второй пункт плана — создать полностью повторяемую среду для воспроизведения ошибки. Разработчики Deep Blue могли его выполнить. Они контролировали версии управляющей программы, шахматных чипов и их прошивки. Это позволяло воссоздать комбинацию аппаратного обеспечения и программ, в которой произошла ошибка.

Третий пункт — следовать повторяемым путём для воспроизведения ошибки. Это условие практически невозможно выполнить, если играть обычные партии против шахматной программы. Дело в том, что в на алгоритм её работы влияет много случайностей. Но эту проблему решил специальный инструмент тестирования команды Deep Blue. Благодаря ему, можно было не играть партию целиком, а сразу выставить нужную позицию фигур.

Четвёртый пункт плана — зафиксировать состояние программы и оборудования. У команды Deep Blue были инструменты для анализа управляющей программы и прошивки шахматных процессоров. Так они собирали полную информацию о среде выполнения в состоянии ошибки. Это помогало выяснить причину ошибки и исправить её.

На исход второго матча Гарри Каспарова против Deep Blue 1997 года повлияло много факторов. Одним из них стала новая стратегия поиска ошибок. Благодаря ей, команда разработчиков могла оперативно вносить изменения в управляющую программу компьютера. Если Гарри Каспаров находил какой-то изъян в игре оппонента, команда Deep Blue успевала исправить его до следующей партии. Это уравнивало шансы сторон: человек и машина адаптировались к игре друг друга по ходу матча.

### 3.8.1.3 Автоматический систематический поиск

>>> REVIEW

Если программа запускается на специализированном шахматном компьютере, это ограничивает возможности её тестирования. Проблема в том, что шахматный компьютер — это уникальное оборудование в единственном экземпляре. Поэтому невозможно устроить партию между разными версиями этого компьютера или его управляющей программы.

В конце 1990-х годов платформой для шахматных программ стали обычные ПК. Они работают под управлением некоторой многозадачной операционной системы (ОС). Такая ОС позволяет выполнять несколько программ одновременно. На одном ПК очень просто запустить два разных шахматных движка и устроить между ними партию.

Новая аппаратная платформа открыла возможность для новой стратегию поиска ошибок. Разработчики шахматных движков начали регулярно тестировать разные версии своих программ. Скоро они пришли к идее автоматизации этого процесса. Стали появляться системы для управления тестированием. Такая система запускает указанные версии движка и устраивать между ними партии. Она же ведёт статистику побед и лог каждой партии. В конце работы система выдаёт полный отчёт с результатами.

Предлагаю назвать такую стратегию поиска ошибок **автоматическим систематическим поиском**. Поиск **автоматический**, потому что выполняется системой тестирования без участия человека. Разработчик программы только получает отчёт о результатах.

Поиск называется **систематическим**, потому что выполняется по строгому плану. План заключается в последовательном выполнении разных автоматических тестов. Каждый из них фокусируется на ошибках разного типа.

Современный шахматный движок проверяется следующими типами тестов:

1. **Автоматическое регрессионное тестирование** — проверка новой версии движка на заранее подготовленном наборе типовых позиций. Такой тест показывает, что в программе не появилось новых ошибок и она по-прежнему корректно действует в определённых сценариях.

2. **Интеграционное тестирование** — автоматические тесты запускаются каждый раз, когда в базу кода движка вносится какое-то изменение. Такой тест проверяет, что любое изменение как минимум не ухудшает уровень игры движка.

3. **Проверка производительности** — новая версия движка обрабатывает набор специально подготовленных сложных позиций. Для каждой позиции оценивается производительность движка: глубина поиска, достигнутая в единицу времени, и количество узлов дерева игры, проверяемых в секунду. Такой тест показывает, что количественные показатели производительности движка не ухудшились.

4. **Автоматические турниры** проводятся между разными версиями одного движка. Они дают достаточную статистику, чтобы сравнить относительный уровень Эло этих версий.

5. **Тестирование дебютов и эндшпилей** — новая версия движка отыгрывает набор стандартных дебютов и эндшпилей. Это гарантирует, что изменения движка корректно работают на всех стадиях партии.

Такой план тестирования обнаруживает ошибки на ранней стадии. Часто интеграционный тест может точно указать на изменение, которое вызвало ошибку. Это значительно повышает эффективность разработки. Программисты могут смелее экспериментировать с небольшими изменениями и последовательно улучшать разные части движка.

Одно из преимуществ автоматического тестирования — простота его масштабирования. Чтобы повысить интенсивность ручного тестирования движка, нужно пригласить больше профессиональных шахматистов и чаще участвовать в турнирах. Это требует значительных вложений. В случае автоматического поиска ошибок достаточно подключить больше компьютеров к системе тестирования. Тогда все пять типов тестов станут интенсивнее.

Команда проекта Stockfish вывело масштаб автоматизированных тестов на беспрецедентный уровень. Система Fishtest объединяет сотни компьютеров добровольцев в единую сеть. Эта сеть выполняет интенсивные автоматические тесты на разнообразном оборудование.

Оценим примерный выигрыш производительности, который дала система Fishtest. Допустим, что мы тестируем две версии движка в партиях с укороченным контролем времени — 1 минута на игру. Пусть один экземпляр движка работает на одном ядре процессора. Современный процессор Intel имеет минимум 8 ядер. Тогда на одном современном ПК можно запустить примерно `60 * 24 * 8 / 2 = 5760` игр в день.

Компания по разработке коммерческого шахматного движка может выделить для запуска тестов от нескольких десятков до сотни компьютеров. Это даст максимум около `100 * 5760 = 576000` партий в день. 

Сеть системы Fishtest состоит от сотни до тысячи компьютеров каждый день. Возьмём среднее число 550 компьютеров. Тогда в день система сможет сыграть примерно `550 * 5760 = 3,168,000` партий. Почти в четыре раза больше чем могут позволить ресурсы разработчиков коммерческого движка.

Качество автоматического тестирования напрямую зависит от его интенсивности. Система Fishtest предоставляет колоссальные вычислительные ресурсы. Именно благодаря им движок Stockfish сохраняет лидерство во всех турнирных таблицах.

### 3.8.2 Игра против шахматного движка

>>> REVIEW

Мы познакомились с тремя стратегиями поиска ошибок, которые применяют разработчики шахматных программ. Какое отношение это имеет к игре человека против движка?

Давайте поговорим о том, как профессионалы играют в шахматы. Представим партию между двумя гроссмейстерами с примерно равным уровнем Эло. Если обе стороны идеально исполняют свой план на игру, вероятнее всего она закончится ничьей. Но если одна из сторон допускает промах, оппонент получает преимущество. Речь идёт не о зевке пешки. Промахом может быть даже небольшое смещение фигур, которое лишь немного ухудшает позицию. Даже такое незначительное преимущество игрок высокого уровня способен превратить в победу.

Партия против современного шахматного движка — это игра на самом высоком уровне. Поэтому в ней действуют те же самые правила, что и в партии между двумя гроссмейстерами. Следовательно, чтобы выиграть у программы, надо получить преимущество и развить его в победу. Преимущество над сильным оппонентом можно получить только тогда, когда знаешь его слабые стороны. Слабые стороны шахматного движка создают те самые ошибки, которые ищут и устраняют его разработчики. Мы рассмотрели три стратегии поиска этих ошибок.

Возникает вопрос: может ли шахматист применить какую-то из трёх стратегий поиска ошибок, чтобы найти слабые стороны движка? Да, может. Но перед тем как углубиться в эту тему, поговорим о типах ошибок в шахматных движках. Это объяснит, что именно следует искать.

### 3.8.2.1 Классификация ошибок шахматного движка

>>> REWRITE

// TODO: Ввести классификацию ошибок

// TODO: Рассмотреть подробные сценарии применения стратегий. Пример - игра Каспарова против Deep Blue

>>>

### 3.8.2 Сложность игры

Мы рассмотрели разные стратегии поиска ошибок в порядке возрастания их эффективности. Из этого обзора можно сделать вывод: автоматический систематический поиск ошибок гарантирует сильную игру машины. Конечно, это утверждение неверно.

Вторая часть этой книги будет посвящена моделям для игры в киберспортивные дисциплины. Эти модели обучаются алгоритмом с подкреплением. Несмотря на это, они все ещё уступают профессиональным спортсменам. Почему?

Разные стратегические игры имеют разную сложность. Причем есть несколько видов этой сложности.

Вот три настольные игры: крестики-нолики, шахматы, го. Все они имеют одинаковые характеристики с точки зрения теории игр:

* Последовательная
* С нулевой суммой
* С полной информацией
* С совершенной информацией
* Детерминированная
* Многократная и многоходовая
* С фиксированными правилами
* Некооперативная
* Пристрастная
* Дискретная

Несмотря на это, компьютерные программы для игры в них на уровне человека появлялись со значительными временными интервалами. Эти игры различаются размером дерева игры. Самое маленькое дерево игры у крестиков-ноликов, а самое большое у го. Поэтому первая программа OXO для игры в крестики-нолики с совершенной стратегией появилась в 1952 году. Первая программа AlphaGo, способная играть в го на уровне профессионалов, появилась только в 2015 году. Можно сказать, что у этих игр разная **вычислительная сложность**.

Кроме вычислительной сложности, игра может иметь **сложные правила**. Для человека и для машины разные правила создают сложности. Например, игры со следующими характеристиками считаются трудными для машин:

* Несовершенная информация
* Недетерминированная игра
* Непрерывная игра
* Нефиксированные правила

В таких играх программе трудно учитывать все аспекты. Этих аспектов оказывается слишком много. Единственное решение этой проблемы — сделать достаточно сложной саму программу. Тогда она сможет охватить и возможные состояния игры, и возможные действия участников. Но тогда для запуска такой программы потребуются значительные вычислительные ресурсы.

В шахматах проблемы со сложностью правил нет. Уже первые шахматные программы конца 1950-х годов учитывали все правила игры. При этом они запускались на очень слабых по современным меркам компьютерах.

Что происходит, когда сложность игры превосходит сложность программы? Рассмотрим наглядный пример с шахматами. Допустим, что шахматная программа работает на каком-то специальном микроконтроллере. У него очень ограниченные ресурсы: мало памяти и низкая тактовая частота. Из-за этого программа не может учитывать ходы коней. Они слишком сложные и не поместились в код программы.

Теперь применим автоматический систематический поиск ошибок. Например, его реализует какой-то эволюционный алгоритм. Программа будет играть сама с собой и исправлять ошибки. Но во время такого обучения конями ходить она не будет из-за принципиального ограничения. В результате программа научится очень хорошо обращаться с теми фигурами, которыми она играла. Но будет ли такая программа хорошо играть в шахматы? Скорее всего, нет. Любой знающий правила игрок, сразу обнаружит ограничение программы.

### 3.8.3 Виды ошибок

До сих пор мы говорили об ошибках в шахматной программе, но без уточнения их видов. Понятие сложности игры позволяет нам разделить ошибки на три вида:

1. Ошибки из-за непонимания правил игры.

2. Ошибки из-за вычислительной сложности игры.

3. Ошибки проектирования, программирования или алгоритма обучения.

Ошибки перечисленны в порядке увеличения сложности их поиска. Проще всего обнаружить ошибку программы, связанную с правилами игры. Для этого достаточно создать ситуацию, в которой машина должна учесть какое-то правило. Если она его не учитывает, это очевидная слабость.

Сложнее обнаружить ошибки связанные с недостатком вычислительной мощности. Чтобы их найти нужно создать ситуацию, которая требует максимального количества вычислений. Например, в шахматах это может быть ловушка через несколько ходов. Если программа её не видит, значит у неё недостаточная глубина поиска.

Самые сложные для обнаружения ошибки связаны с проектированием, программированием и алгоритмом обучения. Без анализа архитектуры и кода программы невозможно предсказать, в чём именно они могут заключаться и где их следует искать.

Для всех трёх видов ошибок применимы четыре стратегии поиска, которые мы рассмотрели ранее.

### 3.8.4 Экспертные знания

До сих пор мы говорили только о программах и ошибках в них. У читателя могла возникнуть мысль, что для победы над шахматным движком совершенно не обязательно быть профессиональным шахматистом. Достаточно просто найти ошибку в программе. Конечно, это неверно.

На что влияет уровень Эло человека при игре против программы? Во-первых, он определяет качество поиска ошибок. Неважно, какую стратегию поиска применяет игрок. Чем выше его уровень, тем шире диапазон потенциальных ошибок программы он может заметить и понять. Например, начинающий шахматист не поймёт тонкую стратегическую ошибку программы в сложной позиции, а профессионал поймёт. Это означает, что игроки низкого уровня просто не видят целый класс ошибок.

Во-вторых, уровень Эло шахматиста определяет критичность ошибок программы, которые он способен эксплуатировать. Профессиональный шахматист найдёт способ извлечь выгоду даже из незначительной ошибки оппонента. Начинающий игрок может воспользоваться только грубыми ошибками.

Критичность ошибок программы — важный параметр. Грубые ошибки, как правило, очевидны. Их легко найти даже следуя стратегии ручного несистематического поиска. Поэтому разработчики программы исправляют их в первую очередь.

Из нашего рассуждения следует, что чем выше уровень Эло шахматиста, тем выше его шансы в игре против шахматного движка. Это очевидное утверждение. Тем не менее его предпосылка связана с ошибками.

### 3.8.5 Игра против современного шахматного движка

Теперь у нас есть некоторая терминология, чтобы рассмотреть игру человека с шахматным движком с точки зрения поиска ошибок. Для определённости будем говорить только о Stockfish.

Рассуждения об ошибках привели нас к трём критериям для оценки шахматных программ:

1. Справляется ли программа со сложностью правил игры?

2. Справляется ли программа с вычислительной сложностью игры?

3. Какую стратегию поиска ошибок в программе применяли её разработчики?

Оценим по этим критериям движок Stockfish:

1. Да, безусловно. Он знает и учитывает все правила шахмат.

2. Критерий вычислительной сложности игры относителен. Строго говоря, Stockfish не может решить шахматы и просчитать партию до конца. Это означает, что стратегия Stockfish неидеальна. С другой стороны, по сравнению с человеком Stockfish намного лучше справляется с вычислительной сложностью. Он просматривает дерево игры намного глубже.

3. Разработчики Stockfish используют комбинацию автоматического несистематического и систематического поиска ошибок.

Теперь перевернём ситуацию и посмотрим на неё с точки зрения машины. Оценим по этим же самым критериям профессионального шахматиста:

1. Да, конечно. Он знает и учитывает все правила шахмат.

2. Критерий относителен. С точки зрения шахматного движка человек не справляется с вычислительной сложностью игры. Для программы не проблема найти цепочку из десяти единственных лучших ходов, спасающих от мата. Для человека такой трюк невозможен.

3. Шахматист совершенствует своё мастерство, применяя ручной систематический поиск ошибок.

Последний пункт требует разъяснений. В разделе 3.3.2 мы говорили о правиле 10000 часов. Исследования Эрикссона показали, что профессионалы совершенствуются благодаря преднамеренной практике. Это означает, что шахматисты не просто играют в шахматы и становятся лучше. Они целенаправленно совершенствуют разные аспекты своей игры. Они учат новые дебюты. Они анализируют свои прошлые партии, делают из них выводы и пытаются не повторять своих ошибок. Они работают с тренером, который направляет их практику и даёт советы.

Преднамеренная практика, которой следуют профессиональные шахматисты, очень похожа на стратегию ручного систематического поиска ошибок в программе. Нет сомнений, что человек никак не может автоматизировать поиск своих ошибок. Чтобы найти и проработать ошибку, надо обязательно понять в чём она. В то же время профессионал имеет чёткий план, когда работает над улучшением своей игры.

Из нашего сравнения следует, что машина превосходит человека по двум пунктам:

1. Более эффективно справляется с вычислительной сложностью игры.

2. При её разработке использовалась более сильная стратегию поиска ошибок.

Такое превосходство не оставляет никаких шансов человеку. Если шахматист захочет просто сыграть одну партию с шахматным движком, он точно проиграет. Даже на дистанции шахматного матча из нескольких партий, движок будет безусловным лидером.

Кто сегодня играет в шахматы сильнее: человек или машина? Ответ очевиден — машина. Давайте немного сместим наш фокус и переформулируем вопрос. Есть ли хоть какая-то возможность у человека выиграть партию в шахматы против машины?

Мы не будем рассматривать вариант дать фору человеку в одну или несколько фигур. Понятно, что можно подобрать такую фору, которая сравняет силы игроков. Это вполне простой и рабочий вариант. Но есть ли другие опции?

Дальнейшие рассуждения не имеют отношения к честной игре в шахматы. Мы рассмотрим все возможные действия, которые человек может предпринять в принципе.

Первая проблема в игре против машины заключается в её вычислительной мощности. Её можно решить тем же самым путём, которым следовала команда DeepMind для тестирования своей самой первой версии AlphaZero. Оба типа современных шахматных движков (на deep learning сетях и на минимакс поиске с отсечением) чрезвычайно чувствительны к вычислительной мощности компьютера.

Уменьшая число ядер CPU (или GPU) и их частоту, можно на порядок сокращать число просматриваемых позиций в секунду. Таким образом, можно подобрать конфигурацию оборудования, которая заставит движок играть примерно на уровне гроссмейстера. Профессиональный шахматист имеет хорошие шансы справится с движком в такой конфигурации.

Следующая проблема — это количество ошибок во время игры. Шахматный движок ошибается гораздо реже человека. Причин здесь несколько. Во-первых, стратегия поиска ошибок у разработчиков Stockfish намного сильнее, чем у профессионального шахматиста. Автоматический поиск ошибок приводит к тому, что движок наигрывает на несколько порядков больше партий, чем человек. К этим партиям относятся:

1. Тестовые игры в системе Fishtest.

2. Игры в ходе обучения с подкреплением системы Leela Chess Zero. Потом их результаты попадают в сеть NNUE.

Так игра движка проходит гораздо больше проверок в партиях. В итоге она оттачивается намного лучше, чем игра шахматиста.

Вторая причина ошибок связана с тем, как именно человек принимает решения. В профессиональном жаргоне шахматистов даже есть специальный термин [**зевок**](https://ru.wikipedia.org/wiki/Зевок_(шахматы)). Так называется грубая ошибка, которая чаще всего делается по невнимательности.

Как человек может компенсировать свои более частые ошибки? Для этого можно применить подход Джоэла Бенджамина для тестирования Deep Blue. Когда человек в партии против машины допускает ошибку, ему разрешается взять ход назад. Остаётся открытым вопрос: как много ходов назад может взять человек? Результат некоторых ошибок проявляется не сразу, а через несколько ходов.

Допустим, что человек может исправлять только свои самые грубые ошибки и брать один ход назад. Пусть с такими правилами он будет играть против Stockfish. Движок работает на достаточно мощном компьютере. То есть мы целенаправленно не ослабляем его вычислительные возможности. На какой результат может надеяться человек? Я полагаю, что лучший возможный результат — это ничья. Разберёмся почему.

Мы выяснили соотношение ошибок в игре человека и в игре движка. Программа ошибается гораздо реже. Теперь перейдём непосредственно к игре шахматиста и движка. 

Первый сценарий: шахматист никак не готовился к партии. Он не имеет никакой информации об оппоненте. В этом случае он скорее всего будет играть обычную партию, также как против другого человека. Тогда он столкнётся с вычислительной мощностью программы. Движок будет отвечать лучшими ходами и гарантированно сведёт партию к ничьей. Благодаря возврату на один ход назад, человек сможет исправлять свои грубые ошибки. Но таких исправлений недостаточно для победы. Они только предотвращают поражение.

Рассмотренный нами сценарий соответствует ручному несистематическому поиску ошибок. Шахматист многократно играет против программы в надежде случайно поймать её на какой-то слабости, получить из неё преимущество и довести его до победы. Такое развитие событий крайне маловероятно.

Второй сценарий: шахматист знает, что играет против программы и готовится. Во-первых, он фиксирует её версию и компьютер на котором она работает. Так он добивается повторяемой среды. Во-вторых, он ищет информацию в открытых источниках о слабых сторонах программы. Например, если это ранняя версия Stockfish, она может ошибаться в стратегии. В этом случае во время многократных игр человек целенаправленно проверяет программу в сложных позиция, требующих понимания шахматной стратегии. Рано или поздно он надеется подловить движок на ошибке.

Этот сценарий соответствует ручному систематическому поиску ошибок. В нём у шахматиста есть информация, в каком направлении надо искать слабости программы. К сожалению, если речь идёт о современных версиях Stockfish, такой подход вряд ли приведёт к победе. Причина в том, что стратегия поиска ошибок у разработчиков Stockfish сильнее. Они уже нашли и исправили все простые ошибки, которые можно было бы найти ручным поиском.

Третий сценарий: шахматист знает целевую версию движка, против которого играет. Он пытается автоматизировать сбор информации о ней. Для этого, например, можно найти все партии сыгранные целевой версией движка против разных оппонентов. Если партий нет, их можно наиграть в автоматическом режиме против других программ. Дальше отобрать те партии, которые закончились поражением целевого движка.

На следующем шаге отобранные партии можно проанализировать с помощью более сильного движка или более новой версией Stockfish. Этот анализ возможно автоматизировать. Его цель — найти все слабые ходы программы, которые привели к поражению. Когда готов список ходов и позиций, его надо проанализировать вручную. Так шахматист поймёт в чём конкретно заключается слабость целевого движка.

Дальше шахматист многократно играет против движка с возможностью взять ход назад. Он пытается свести партию к одной из известных ему позиций, в которых программа ошибается.

Мы рассмотрели сценарий автоматического несистематического поиска ошибок. Он намного перспективнее двух предыдущих подходов. В случае игры против ранней версии Stockfish без NNUE сети, человек вполне может одержать победу. Но как только появляется NNUE сеть, стратегия поиска ошибок разработчиков снова становится сильнее. Это значит, что автоматический анализ партий шахматиста может не выявить явных ошибок у движка. Он найдёт позиции, в которых программа делала слабый ход. Но извлечь из них достаточное для победы преимущество окажется невозможно. Такой сценарий мне видится наиболее вероятным.

Четвёртый сценарий уже не имеет ничего общего с игрой человека против машины. Он заключается в том, чтобы создать специальную модель. Например, её архитектура может повторять AlphaZero. Модель должна обучаться с подкреплением, играя против целевой версии шахматного движка. Если алгоритм обучения будет сходиться, модель рано или поздно начнёт обыгрывать движок.

Проблема этого сценария в том, что невозможно надёжно извлечь знания из обученной модели. После обучения модель знает ошибки целевого шахматного движка. Играя против него, она использует найденные слабости программы и выигрывает.

Извлечь знания из обученной модели можно только косвенным способ. Например так, как это делает команда разработчиков Stockfish при обучении сети NNUE. Модель проходит по миллиардам шахматных позиций и оценивает каждую из них. Эта оценка указывает на знания нейронной сети. К сожалению, человек не способен проанализировать такой объём информации, найти в ней закономерности и сделать выводы об ошибках целевого движка.

Мы рассмотрели сценарий автоматического систематического поиска ошибок. Он самый перспективный и скорее всего приведёт к победе над целевой версией шахматного движка. В этом случае стратегия поиска ошибок в нём не слабее стратегии, применяемой разработчиками. Но как я заметил ранее, это уже не противостояние человека и машины. Скорее это путь создания специализированной машины для единственной цели — победы над целевой машиной.

### 3.8.6 Стратегия игры против машины

Мы рассмотрели четыре возможных сценария. Следуя им, шахматист может собрать информацию и найти ошибки в шахматном движке. Попробуем обобщить эти рассуждения и поговорим о стратегии человека против машины в любой игре.

Важная оговорка: чтобы играть с машиной, человек должен иметь соответствующие экспертные знания. Чем они выше, тем выше шансы человека на победу. Мы не рассматриваем случаи тривиальных ошибок машины, которые сможет эксплуатировать игрок начального уровня.

Сценарии игры шахматиста против движка приводят нас к некоторой общей стратегии. Она состоит из следующих шагов:

1. Собрать информацию о машине.

2. Создать повторяемую среду для поиска ошибок.

3. Искать ошибки.

4. Эксплуатировать найденные ошибки.

На первом шаге оценим возможности машины по трём критериям:

1. Справляется ли она со сложностью правил игры?

2. Справляется ли она с вычислительной сложностью игры?

3. Какую стратегию поиска ошибок применяли её разработчики?

Допустим, что ответ на первый вопрос отрицательный. Тогда мы получаем самый простой вид ошибок машины для эксплуатации. Вспомним пример с шахматной программой, которая не понимает ходы коней. Согласитесь, что играть против неё достаточно просто. Она не будет защищаться от атак конями и будет жертвовать свои фигуры.

В более сложных играх, эксплуатировать такой вид ошибок может быть нетривиально. Но человек-эксперт сможет справиться с этой задачей.

Отрицательный ответ на второй вопрос даёт нам вид ошибок, который эксплуатировать несколько сложнее. Продолжим аналогию с шахматной программой. Допустим, что она работает на слабом компьютере. Его мощности хватает только для проверки дерева игры на четыре хода вперёд. Мы получили эффект горизонта, которым можно воспользоваться. Для этого надо создать ловушку для программы на пятом ходу, которую она просто не увидит.

Если ответы на первые два вопроса положительные, придётся искать самый сложный вид ошибок машины. Ответ на третий вопрос даёт нам подсказку о том, как следует вести этот поиск.

Переходим ко второму шагу нашей стратегии. Создать повторяемую среду для поиска ошибки принципиально важно. Если программа машины или её аппаратная часть меняется, все полученные ранее результаты становятся недействительными. Фактически вы получаете совершенно новую машину с новыми характеристиками. Это значит, что сбор информации о ней надо начинать с самого начала.

Третий шаг стратегии — поиск ошибки не связанной с ограничениями машины из-за правил или вычислительной сложности игры. На этом шаге самое важное применять стратегию поиска ошибок не слабее, чем та которую применяли разработчики машины.

Возможны три варианта соотношения стратегий поиска ошибок:

1. Человек применяет стратегию слабее, чем разработчики машины. В этом случае высока вероятность, что все ошибки, которые можно найти таким способом, уже были найдены и исправлены.

2. Человек применяет равную стратегию той, которой следовали разработчики машины. В этом случае есть шанс найти ещё неисправленную ошибку. Почему? Потому что профессиональные шахматисты всё ещё играют друг с другом. Они используют равные стратегии поиска и при этом продолжают находить ошибки в игре друг с другом. Причём на турнирах высокого уровня большинство ошибок не "зевки".

3. Человек применяет более сильную стратегию, чем разработчики машины. Такая стратегия гарантированно найдёт хотя бы одну ещё неисправленную ошибку.

Последний шаг нашей стратегии — эксплуатация найденной ошибки. Успех напрямую зависит от экспертных знаний и навыков человека. Например, только что научившийся играть в шахматы ребёнок не сможет эффективно воспользоваться даже грубой ошибкой шахматной программы.

Вполне возможна ситуация, когда человек обнаружил ошибку в игре машины. Но ему не хватает экспертных знаний, чтобы ей воспользоваться. Пример из шахмат. Из-за ошибки в определённых позициях сила шахматного движка падает с уровня Эло 2900 до уровня 2500. Теперь вопрос к человеку — играет ли он выше уровня 2500, чтобы суметь воспользоваться ошибкой программы?

Допустим, человеку не хватает экспертных знаний. Поэтому он не способен эксплуатировать найденную ошибку машины. В этом случае у него есть два варианта:

1. Взять таймаут и приобрести недостающие знания.

2. Искать следующую ошибку машины, которая окажется грубее.

Второй путь мне видится менее предсказуемым. Человек может потратить уйму времени и сил, но так и не найти ещё одну ошибку машины. С другой стороны, может быть совсем неочевидно, каких именно знаний не хватает человеку для эксплуатации найденной ошибки. В этом выборе нет однозначного простого решения.

### 3.8.7 Польза от машины

Мы поняли, что машина может оказаться серьёзным оппонентом для профессионального игрока. Но такая её роль не единственная. Кроме этого машина — это эффективный инструмент человека для развития экспертных знаний и навыков.

Снова обратимся к примеру шахмат. Шахматные программы вывели профессиональную игру на совершенно уровень. Речь идёт не только об их вкладе в шахматную теорию и популяризацию этого вида спорта. Исследования говорят, что средний уровень сильнейших шахматистов за последние 20 лет вырос примерно на 70 пунктов Эло. После 2000 года значительно понизился средний возраст получения гроссмейстерского титула. А число самих гроссмейстеров стало намного больше, чем в прошлые десятилетия. Всё это произошло благодаря шахматным программам.

Почему шахматные программы повышают уровень игроков? Во-первых, они легкодоступны. Интересующиеся шахматами дети со всего мира получают возможность для практики.

Во-вторых, шахматные программы гибко настраиваются на любой уровень игры. Для этого совершенно не обязательно конфигурировать производительность запускающего их компьютера. В интерфейс многих программ заложена настройка желаемого уровня Эло, на котором они должны играть. Благодаря такой настройке, шахматисты разного уровня получают идеального оппонента для тренировок. Это особенно актуально для игроков высокого уровня, которых не так много в мире.

В-третьих, шахматные программы и графический интерфейс к ним представляют собой мощный инструмент для анализа позиций. С его помощью можно изучать сыгранные турнирные партии. Программа даёт оценку каждому ходу и предлагает собственные альтернативы. Таким образом игроку легче находить и анализировать свои ошибки.

Наконец, сильная программа — это идеальный инструмент для поиска шахматистом собственных ошибок. Достаточно просто играть против неё партии так же, как против человека. Современный шахматный движок замечает не то что любую ошибку, но даже малейшую погрешность в ходе оппонента. После этого он находит способ ей воспользоваться и получить преимущество. Конечно, нет не никакого спортивного интереса играть против такого оппонента — он всё равно победит. Но последующий анализ игр поможет обнаружить собственные ошибки и слабости. Это полезная информация для преднамеренной практики.

{pagebreak}
