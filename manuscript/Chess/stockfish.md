## 3.5 Stockfish

Все шахматные движки состоят из следующих основных частей:

1. Генератор ходов
2. Функция оценки позиции
3. Алгоритм поиска
4. Дебютная книга
5. Таблицы эндшпилей.

Игровую силу программы во многом определяют генератор ходов, функция оценки и алгоритм поиска. Мы рассмотрим, как устроены эти механизмы в самых сильных современных шахматных движках.

### 3.5.1 История Stockfish

На сегодня Stockfish считается сильнейшим шахматным движком. Он занимает первые строчки в рейтингах [Chess Engines Grand Tournament](http://www.cegt.net/40_40 Rating List/40_40 BestVersion/rangliste.html) (CEGT) и [Computer Chess Rating Lists](https://ccrl.chessdom.com/ccrl/4040/) (CCRL).

Stockfish вырос из проекта шахматного движка Glaurung, который разработал норвежский программист Торд Ромстад. Первая версия Glaurung вышла в 2004 году. Это была программа для ПК с интерфейсом командной строки и открытым исходным кодом. Позднее к Торду Ромстаду присоединились другие энтузиасты. Они портировали более поздние версии Glaurung на мобильные телефоны и планшеты.

В 2008 году итальянский программист Марко Костальба разрабатывал новый шахматный движок. Чтобы не начинать с нуля, он взял код Glaurung как основу для своего проекта. Для этого итальянец сделал форк Glaurung. [**Форком**](https://ru.wikipedia.org/wiki/Форк) (от английского fork — вилка) называется использование кодовой базы одного проекта в качестве старта для другого. Марко Костальба назвал свой проект Stockfish. Первая версия этого движка вышла в ноябре 2008 года.

В течение 2008 года Glaurung и Stockfish развивались параллельно. Оба проекта распространялись с открытым исходным кодом. Их команды свободно обменивались идеями по улучшению алгоритма поиска и оценочной функции.

В декабре 2008 года Торд Ромстад выпустил последнюю версию Glaurung 2.2. После этого он прекратил поддержку своего проекта и присоединился к команде Stockfish. На тот момент Stockfish превзошёл Glaurung по уровню игры. Возможно, именно поэтому Торд Ромстад оставил свой проект.

В 2011 году Торд Ромстад вышел из проекта Stockfish. Он занялся разработкой шахматной программы для iOS. В 2014 году проект покинул Марко Костальба. Современная версия Stockfish развивается группой энтузиастов. Сейчас в команде активных разработчиков около 20 человек.

### 3.5.2 Система тестирования Fishtest

Stockfish достиг высокого уровня игры благодаря системе автоматизированных распределённых тестов под названием Fishtest. Её разработал канадец Гэри Линскотт в 2013 году. Система оценивает каждое изменение, которое делают разработчики Stockfish. Это гарантирует, что любой патч улучшает производительность движка, а не ухудшает её.

Тестирование изменения в Fishtest происходит в несколько этапов:

1. Разработчик готовит изменение и предлагает его для тестирования. Это может быть корректировка функции оценки, алгоритма поиска или других механизмов движка, которые улучшают его игровую силу.

2. Сервер Fishtest получает изменение и добавляет его в очередь на тестирование. Состояние текущей очереди и результаты тестирования каждого изменения доступны через веб-интерфейс.

3. Любой доброволец запускает на своём компьютере программу-клиент Fishtest Worker.

4. Fishtest Worker автоматически загружает задачи тестирования с сервера Fishtest. Задачи представляют собой шахматные партии между версией Stockfish с изменением и последней стабильной версией.

5. Fishtest Worker играет тысячи партий с быстрым контролем времени между сравниваемыми версиями Stockfish.

6. Fishtest Worker отправляет результаты сыгранных партий на сервер.

7. Сервер Stockfish определяет, улучшает ли тестируемое изменение производительность движка. Для этого применяется статистический метод [SPRT](https://en.wikipedia.org/wiki/Sequential_probability_ratio_test) (Sequential Probability Ratio Test).

8. Если результаты превышают статистическое пороговое значение, изменение интегрируется в кодовую базу Stockfish. Пороговое значение гарантирует, что модифицированная версия движка выигрывает больше игр, чем стабильная версия. Если результаты ниже порога, изменение отклоняется.

Система Fishtest позволяет быстро и надёжно проверять качество всех предлагаемых изменений. Эффективность её работы можно оценить по первым 12 месяцам использования. За это время уровень игры Stockfish вырос на 120 пунктов Эло. Такое усиление подняло Stockfish до лидирующих позиций в рейтинге шахматных движков.

Благодаря системе Fishtest, к декабрю 2022 года разные версии Stockfish сыграли друг с другом около 5 миллиардов партий. На это ушло более 8650 лет процессорного времени. Никакая система тестирования, запускаемая на компьютерах разработчиков, не может дать сопоставимый результат.

### 3.5.3 Генератор ходов

Генератор ходов создаёт список всех допустимых ходов для указанного игрока в заданной позиции на доске. При составлении этого списка генератор учитывает правила шахматной игры и особые условия. К таким условиям относятся: шах, мат, пат, рокировка, взятие на проходе и проведение пешки.

Генератор ходов в современных шахматных движках работает по следующему алгоритму:

1. Определить расположение на доске всех фигур игрока, который делает ход.

2. Для каждого типа фигур применить свои правила перемещения.

3. Проверить специальные условия (шах, мат, рокировка и т.д.).

4. Составить список допустимых ходов.

Эффективность генератора ходов напрямую влияет на общую производительность шахматного движка. Поэтому разработчики уделяют особое внимание оптимизации этого механизма.

#### 3.5.3.1 Битборды

Скорость генерации ходов зависит от формата, в котором движок хранит состояние шахматной доски. Наиболее эффективным форматом для современных ПК считаются [**битборды**](https://hmn.wiki/ru/Bitboard) (bitboard).

Идея битбордов совсем не нова. В 1952 году британский учёный Кристофер Стрейч разработал первую программу для игры в шашки. В ней учёный впервые применил битборды на практике. В шахматах первыми использовали битборды разработчики советской шахматной программы [Каисса](https://ru.wikipedia.org/wiki/Каисса_(программа)) в конце 1960-х годов.

Битборд представляет собой одно 64-разрядное число. Всего на шахматной доске 64 поля. Обратите внимание, что число полей равно разрядности битборда. Идея заключается в том, чтобы представить состояние каждого поля одним битом 64-разрядного числа. Если бит равен единице, поле занято фигурой. Если бит равен нулю, то поле свободно.

Как с помощью битборда сохранить состояние всех фигур на шахматной доске? Всего есть шесть типов фигур: пешки, ладьи, кони, слоны, короли и ферзи. Для каждого типа нужен отдельный битборд. У каждой фигуры есть цвет: белый или чёрный. Чтобы его учесть, можно ввести ещё два битборда. Первый указывает положение всех белых фигур независимо от их типа, а второй — положение всех чёрных. Итого в сумме получается восемь битбордов. На практике обычно используют набор из 12 битбордов: по одному для каждого типа фигур, каждого цвета. То есть, белые пешки имеют свой битборд, чёрные пешки — свой и т.д. Такой подход эффективнее для генерации допустимых ходов.

Рассмотрим пару примеров. Представим битборд для начальной позиции белых пешек в наглядном виде:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
```

Такое представление удобно для человека. Но компьютер хранит этот битборд в памяти как 64-разрядное число в двоичной системе счисления. Оно выглядит следующим образом:
{line-numbers: false, format: text}
```
0000000000000000000000000000000000000000000000001111111100000000
```

Битборд для двух чёрных коней в начальной позиции выглядит так:
{line-numbers: false, format: text}
```
  0 1 0 0 0 0 1 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Компьютер хранит его в памяти в виде следующего числа:
{line-numbers: false, format: text}
```
0100001000000000000000000000000000000000000000000000000000000000
```

На первый взгляд, битборд кажется неудобными для работы. Человеку трудно его прочитать в том виде, в котором его хранит компьютер. Тем не менее у битбордов есть огромные преимущества перед другими форматами. Во-первых, все современные процессоры для ПК оперируют 64-разрядными регистрами. Это означает, что один битборд целиком помещается в один регистр. Побитовые операции над регистрами обычно выполняются за один [**такт**](https://hardwareguide.ru/процессор/частота-процессора/) процессора. Тактовая частота достигает 4 гигагерц и выше. Это означает, что в секунду выполняется более 4*10^6^ операций. Таким образом битборды обрабатываются намного быстрее любых аналогичных форматов представления доски.

Во-вторых, битборды позволяют обрабатывать несколько фигур и полей за одну единственную побитовую операцию. Например, одна операция может оценить пути атаки всех фигур одного типа по всем направлениям.

В-третьих, битборд — это очень компактное представление доски. Компактность снижает использование памяти. Поэтому все битборды с состоянием доски обычно помещаются в кэш быстрого доступа процессора. Это сводит к минимуму задержки доступа к оперативной памяти.

Битборды хранят текущее расположение фигур на доске. Это исходные данные для генерации допустимых ходов. Сами ходы нужно рассчитывать с помощью битовых операций. Для пешек, коней и королей это делается с помощью битовых сдвигов.

Рассчитаем все ходы для белых пешек в начальной позиции. Во-первых, они могут пойти на одно поле вперёд. В этом случае битовая маска допустимых ходов выглядит так:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Во-вторых, каждая пешка из начальной позиции может пойти на два поля вперёд. Это даст следующую битовую маску:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Применим побитовое OR к двум маскам допустимых ходов. Получим следующий битборд:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Для простоты мы не рассматриваем взятия. Обозначим битборд с начальной позицией как A, а битборд с допустимыми ходами — как B. Тогда B получается из A с помощью двух операций битового сдвига влево и побитового OR между ними. Формула для расчёта выглядит так:
{line-numbers: false, format: text}
```
B = (A << 8) | (A << 16)
```

Допустим, что некоторые белые пешки уже двигались. В результате получился следующий битборд с их позициями:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 1 1 0 0 0
  0 0 0 0 0 0 1 0
  1 1 1 0 0 1 0 1
  0 0 0 0 0 0 0 0
```

Обозначим этот битборд как C. Битборд с допустимыми ходами пешек в такой позиции выглядит следующим образом:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 1 1 0 0 0
  1 1 1 0 0 1 1 1
  1 1 1 0 0 1 0 1
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Обозначим этот битборд как D. Для его расчёта формула с двумя битовыми сдвигами влево и OR не подходит. Проблема в том, что теперь не все пешки могут сходить на два поля вперёд. Нам надо как-то их отличать. Применим побитовое AND к маске начальной позиции белых пешек и битборду C. Маска представляет собой битборд A начальных позиций пешек. Так мы получим универсальную формулу расчёта возможных ходов для белых пешек на любой стадии партии:
{line-numbers: false, format: text}
```
D = (C << 8) | ((C & A) << 16)
```

Аналогично выводятся формулы для расчёта допустимых ходов чёрных пешек, коней и королей обоих цветов.

Вычислить ходы скользящих фигур сложнее. [**Скользящими фигурами**](https://www.chessprogramming.org/Sliding_Pieces) (sliding pieces) называют слона, ладью и ферзя. Они ходят по диагоналям, вертикалям и горизонталям через всю доску, если их не блокируют другие фигуры. Это означает, что для расчёта ходов битовых сдвигов теперь недостаточно. Нужны более сложные вычисления.

Чтобы найти допустимые ходы скользящей фигуры, нужно знать следующее:

1. Тип фигуры.
2. Поле, где она находится.
3. Битборд с расположением фигур, которые её блокируют.

Для примера найдём допустимые ходы ладьи. Предположим, что ладья занимает поле e4. Алгоритм расчёта выглядит так:

1. Рассчитать луч в каждом из восьми направлений для поля, которое занимает фигура. **Луч** представляет собой все поля по горизонтали, вертикали или диагонали от заданной клетки. Например, луч на запад из клетки e4 выглядит так:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Остальные семь направлений это: северо-запад, север, северо-восток, восток, юго-восток, юг, юго-запад.

2. Из восьми лучей выбрать только те, которые подходят для данного типа фигуры. Например, для ладьи нужны лучи на север, восток, юг и запад.

3. Применить побитовое AND к каждому лучу и битборду блокирующих фигур. Так мы получим все фигуры, которые стоят на пути данной фигуры на каждом направлении. Допустим, что битборд блокирующих фигур выглядит так:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

4. Найти первую блокирующую фигуру на каждом направлении. Для направлений на запад и юг нужно найти **наибольший индекс ненулевого бита** (most significant set bit). Эта операция называется **битовое сканирование вперед** ([bit scan forward](https://www.chessprogramming.org/BitScan#Bitscan_forward)). Для направлений на восток и север надо найти **наименьший индекс не нулевого бита** (least significant set bit). Эта операция называется **битовое сканирование назад** ([bit scan reverse](https://www.chessprogramming.org/BitScan#Bitscan_reverse)). Для нашего примера первая блокирующая фигура будет такой:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 1 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

5. Рассчитать лучи от найденной первой блокирующей фигуры. Например, если мы рассчитываем все ходы ладьи e4 на запад, нам нужен луч блокирующей фигуры на запад. Он выглядит так:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

6. Инвертируем луч блокирующей фигуры. Для нашего примера это даст следующую маску:
{line-numbers: false, format: text}
```
  1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
  0 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
```

7. Применим побитовое AND к маске инвертированного луча блокирующей фигуры и лучу с ходами ладьи e4 на запад. Получим битборд всех полей, которые атакует эта ладья на западе:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 1 1 1 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Этот же алгоритм находит битборды с полями, которые атакует ладья в остальные три стороны. Аналогично можно найти поля, которые атакует слон. Ферзь ходит как слон и ладья одновременно. Поэтому для него достаточно скомбинировать результаты алгоритма для ладьи и слона.

Мы рассмотрели один из алгоритмов для расчёта ходов скользящих фигур. Он основан на операциях битового сканирования (bit scan). Есть и альтернативные алгоритмы, например [**вращаемые битборды**](https://habr.com/ru/post/155045/) и магические битборды.

#### 3.5.3.2 Магические битборды

Метод [**магических битбордов**](https://habr.com/ru/post/272815/) даёт лучшую производительность на современных процессорах. Его используют самые мощные шахматные движки, в том числе и Stockfish. Идея магических битбордов заключается в кэшировании. **Кэширование** (caching) — это однократное вычисление некоторого результата и сохранение его в памяти для повторного использования.

Шахматный движок работает с магическими битбордами по следующему алгоритму:

1. Пользователь запускает шахматный движок.

2. Сразу после старта движок рассчитывает все допустимые ходы скользящих фигур на всех полях с учётом всех возможных позиций блокирующих фигур. Для этого он использует операции битового сканирования или любой другой метод.

3. Движок сохраняет результаты расчёта в оперативную память (RAM) компьютера.

4. Когда движку нужно сгенерировать ходы в какой-то позиции на доске, он обращается к RAM и читает нужные ему допустимые ходы.

Результат расчёта ходов хранится в RAM как набор **двумерных массивов**. Каждый массив соответствует фигурам одного типа. Первый индекс массива — это поле, которое занимает фигура. Второй индекс — битборд с блокирующими фигурами. При этом цвет фигур не важен. Элемент массива — это битборд со всеми допустимыми ходами скользящей фигуры.

Формат двумерных массивов создаёт проблему. Дело в том, что число всех возможных битбордов с блокирующими фигурами огромно. Оно равно 2^64^. Чтобы сохранить массив возможных ходов для фигур одного типа (например, ладей), нужен следующий объём памяти. Один битборд занимает 64 бита. Число возможных битбордов блокирующих фигур равно 2^64^. Число полей, которые может занимать атакующая фигура равно 64. Получаем массив размером 64×2^64^×64=2^76^ бит. Это примерно равно 10^10^ терабайт. Даже на современных суперкомпьютерах нет такого объёма оперативной памяти.

Метод магических битбордов решает задачу экономии памяти. Он предлагает формат упаковки 64-х битного битборда в число с меньшей разрядностью. Эту упаковку выполняет **хэш-функция**. Она должна удовлетворять следующим требованиям:

1. Работает быстрее, чем расчёт ходов скользящих фигур любым доступным методом.

2. Даёт на выходе уникальное число для любого возможного битборда блокирующих фигур.

Если нарушается первое требование, то пропадает смысл кэширования. Движку будет быстрее считать допустимые ходы по мере их необходимости. Если нарушается второе требование, возникнут коллизии. Из-за них движок не сможет различать разные наборы блокирующих фигур.

I> [**Коллизия**](https://ru.wikipedia.org/wiki/Коллизия_хеш-функции) — это ситуация, когда на разные входные данные хэш-функция возвращает одно и то же значение.

Рассмотрим пример упаковки битборда с помощью хэш-функции. Предположим, что для ладьи на e4 есть следующий битборд блокирующих фигур:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 1 0
  0 0 1 0 1 0 0 0
  0 0 0 0 0 0 1 0
  0 0 0 0 0 0 0 0
  1 1 0 0 r 0 1 0
  0 0 0 0 0 0 0 0
  0 0 1 0 1 0 0 0
  0 0 0 0 0 0 1 0
```

Сама ладья обозначается буквой r для удобства. В этом битборде нас интересуют только поля по горизонтали 4 и вертикали e. Те из них, которые находятся по краям доски, можно игнорировать. Они никак не влияют на допустимые ходы ладьи.

Поля по горизонтали 4 и вертикали e, кроме самых крайних, называются **маской ладьи**. Она выглядит следующим образом:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 1 0 0 0
  0 1 1 1 0 1 1 0
  0 0 0 0 1 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 0 0 1 0
```

Применим операцию побитового AND к маске ладьи и битборду блокирующих фигур. Мы получим битборд только с теми полями, которые важны для расчёта ходов ладьи на e4:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 0 0 r 0 1 0
  0 0 0 0 0 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 0 0 0 0
```

Хэш-функция должна сдвигать биты важных полей в начало битборда. Тогда она вернёт число с разрядностью меньше 64-х. Если сдвигать биты важных полей для всех возможных ходов ладей и слонов из всех полей доски, получим 2^10^ возможных чисел. Обратите внимание, что 2^10^ гораздо меньше чем 2^64^. Теперь двумерные массивы с кэшированными допустимыми ходами помещаются в RAM. Они займут всего 64×2^10^×64=4194304 бит или 512 Кбайт.

Как устроена хэш-функция? Она умножает биты важных полей для расчёта ходов фигуры на некоторое "магическое" число. В результате умножения биты группируются вместе. Следующая операция функции — побитовый сдвиг группы битов вправо. В результате все биты важных полей оказываются в начале 64-битного числа.

Следующий вопрос: как находить "магические" числа, которые группируют важные биты битборда? Эти числа находятся [**полным перебором**](https://ru.wikipedia.org/wiki/Полный_перебор) для ладьи и слона на каждой клетке доски. Когда перебор находит эти числа, они сохраняются в коде движка. Поэтому движку не надо искать их заново на каждом старте.

Алгоритм расчёта второго индекса двумерного массива с кэшем допустимых ходов фигуры выглядит так:

1. Применить побитовое AND к битборду блокирующих фигур в текущей позиции и маске фигуры (например, к маске ладьи на e4).

2. Передать результат операции AND на вход хэш-функции.

3. Использовать результат хэш-функции как второй индекс двумерного массива.

Идею магических битбордов хорошо демонстрирует следующее [видео](https://www.youtube.com/watch?v=K0rp1vXV3Ek).

### 3.5.4 Алгоритм поиска

Механизм поиска Stockfish типичен для современных шахматных движков. Он основан на минимаксном алгоритме. Чтобы его ускорить, движок применяет ряд эвристик. Прежде всего это альфа-бета отсечение. Кроме него есть и более сложные эвристики.

Мы подробно рассмотрели работу алгоритма минимакс в разделе 2.5.2. Альфа-бета отсечение подробно разбирается в разделе 2.5.3. Алгоритм применения минимакс в шахматах описывает стратегия А Клода Шеннона. Мы говорили о ней в разделе 3.1.3.

Здесь мы рассмотрим, как именно взаимодействуют три основные части шахматного движка:

1. Генератор ходов
2. Функция оценки позиции
3. Алгоритм поиска.

Связующим звеном является алгоритм поиска. Именно он в ходе своей работы вызывает генератор ходов и функцию оценки. Моменты их вызова зависят от характера проверяемой позиции фигур на доске.

Основные шаги алгоритма поиска следующие:

1. Движок запускает алгоритм поиска для текущей позиции фигур на доске.

2. Алгоритм поиска вызывает генератор ходов и передаёт ему текущую позицию.

3. Генератор ходов возвращает список всех допустимых ходов в текущей позиции.

4. Алгоритм поиска проходит по каждому сгенерированному ходу и получает набор новых позиций фигур на доске.

5. Алгоритм поиска проверяет характер каждой полученной позиции. Основные проверки следующие:

* Достигнута ли максимальная глубина анализа? Максимальная глубина анализа — это тонко подобранный параметр, который хранится в коде движка.

* Является ли позиция терминальным узлом дерева игры? К таким позициям относится мат, пат, ничья.

* Является ли позиция спокойной? Это означает, что в ней нет хода, который резко меняет соотношение сил.

6. Если любая из проверок позиции дала положительный результат (например, белые поставили мат), алгоритм поиска вызывает функцию оценки для этой позиции. Затем алгоритм возвращается назад по дереву игры к ещё не проверенным позициям.

7. Если все проверки дали отрицательный результат, алгоритм поиска возвращается к шагу 2. Он снова вызывает генератор ходов для текущей позиции и обрабатывает дерево игры дальше вглубь.

8. На основе оценок позиций алгоритм поиска выполняет альфа-бета отсечение.

9. Когда все позиции на максимальной глубине анализа проверены, алгоритм поиска выбирает лучший ход по методу минимакс.

Этому алгоритму поиска следует большинство современных шахматных движков. Отличительная особенность Stockfish не в этом алгоритме, а в дополнительных эвристиках для его ускорения. Именно они обеспечивают высокую производительность и непревзойдённую силу игры Stockfish. Рассмотрим самые важные из этих эвристик.

#### 3.5.4.1 Сортировка ходов

Сама по себе эвристика альфа-бета отсечения не гарантирует высокую производительность. При её использовании возможны неблагоприятные случаи. Это происходит, когда алгоритм поиска в первую очередь проверяет посредственные ходы. Тогда он обрежет слишком мало ветвей дерева игры. В результате альфа-бета отсечение даст незначительное ускорение по сравнению с чистым алгоритмом минимакс.

Эффективность альфа-бета отсечения можно повысить, если сортировать проверяемые ходы. Поместим самые перспективные в начало очереди на проверку. Тогда посредственные ходы окажутся в середине и конце очереди. В этом случае алгоритм поиска отсечёт большую часть ветвей дерева игры с посредственными ходами. Такая оптимизация альфа-бета отсечения называется сортировкой ходов. **Сортировка ходов** ([move ordering](https://www.chessprogramming.org/Move_Ordering) (сортировка ходов)) — это упорядочение ходов по убыванию их перспективности с учётом всей доступной на данный момент информации.

Для сортировки ходов Stockfish применяет по порядку следующие техники:

1. **Основной вариант** (principal variation move или PV move). На каждой итерации поиска Stockfish находит и кэширует последовательность лучших ходов для текущей глубины анализа. Эта последовательность называется **основным вариантом** (principal variation). Следующую итерацию поиска движок начинает с анализа ходов сохранённого основного варианта.

2. **Сортировка взятий** (capture moves sorting). После основного варианта Stockfish проверяет ходы, которые приводят к взятиям фигур. Чтобы составить их список, движок применяет эвристику самая ценная жертва, наименее ценный агрессор (MVV-LVA). В начало списка попадают самые выгодные взятия (например, пешка берёт ферзя).

3. **Убийственные ходы** (killer moves). Stockfish запоминает хорошие ходы в аналогичной позиции на той же глубине дерева игры. Эти ходы ранее приводили к отсечению других ветвей дерева. Это означает, что они были лучшей из возможных альтернатив.

4. **Эвристика истории** (history heuristic). Для каждого типа фигуры и поля, на которое она ходит, Stockfish ведёт счётчик. Он увеличивается каждый раз, когда ход фигуры в это поле приводит к отсечению других ветвей дерева игры. Ходы упорядочиваются по убыванию значения счётчика. Так самые перспективные из них оказываются в начале списка.

5. **Таблица транспозиций** (transposition table). Если текущая позиция оценивалась ранее и сохранена в таблице транспозиций, Stockfish в первую очередь проверяет лучший ход для неё. Этот ход был найден на предыдущей итерации поиска и сохранён в кэше. Высока вероятность, что он снова окажется лучшим.

6. **Внутреннее итеративное углубление** (internal iterative deepening или IID). Применяется, когда ни одна из эвристик сортировки ходов не сработала. Stockfish выполняет поиск на небольшую глубину дерева игры, чтобы определить вероятный лучший ход. Затем движок просчитывает именно этот ход на максимальную глубину анализа в первую очередь.

Если Stockfish играет несколько партий, он накапливает информацию между играми. Например, одна из эвристик истории — это **история ответных ходов** (continuation history). Stockfish запоминает свои ответы на ходы противника. Например, противник ходит конём на f6 и шахматный движок отвечает слоном на c4. Если ответ оказался успешным, он получает положительную оценку. В противном случае его оценка — отрицательная. Когда противник ходит конём на f6 в другой позиции или партии, Stockfish сортирует свой ответ слоном на c4 в зависимости от его сохранённой оценки.

Сортировка ходов значительно повышает эффективность отсечения ветвей дерева игры. Stockfish не тратит время на исследование малоперспективных ходов. Вместо этого он глубже просчитывает основной вариант и самые перспективные ходы. Это усиливает игру движка и позволяет точнее оценивать позиции.

#### 3.5.4.2 Выборочный поиск

Альфа-бета отсечение является базовой эвристикой для ускорения поиска минимакс. Кроме неё Stockfish использует ряд дополнительных эвристик. Они определяют, какие ветви дерева игры проверяет алгоритм поиска и на какую глубину. Эти эвристики называются **выборочным поиском** ([selective search](https://www.chessprogramming.org/Selectivity)). По принципу работы они делятся на три основные группы:

1. **Продление** ([extension](https://www.chessprogramming.org/Extensions)) — движок помечает определённые ходы и позиции, как критические. Он исследует их на большую глубину, чем обычно.

2. **Сокращение** ([reduction](https://www.chessprogramming.org/Reductions)) — метод противоположный продлению. Движок уменьшает глубину просчёта ходов и позиций, которые выглядят менее важными.

3. **Отсечение** ([pruning](https://www.chessprogramming.org/Pruning)) — движок отсекает определённые ветви дерева игры, которые не влияют на результат поиска. Такие ветви приводят к позициям с плохой оценкой. Они значительно хуже, чем результат лучшего хода, найденного на данный момент.

Рассмотрим эвристики каждой из этих групп подробнее.

#### 3.5.4.3 Продления

Продления нужны, чтобы бороться с эффектом горизонта. **Эффект горизонта** (horizon effect) — это ограничение всех шахматных движков, которые используют алгоритм поиска с фиксированной глубиной прохода по дереву игры. Суть эффекта в том, что программа учитывает только игровые события, которые попадают в её максимальную глубину анализа. Если какое-то событие находится за этим пределом, то движок не способен его учесть.

Из-за эффекта горизонта шахматный движок может допускать грубые ошибки. Эти ошибки можно разделить на три группы:

1. **Отложенные последствия**. Программа выбирает ход, который кажется выгодным в пределах её горизонта поиска. Но за пределами этого горизонта ход приводит к негативным последствиям.

2. **Тактические ошибки**. Программа хорошо справляется с краткосрочными тактическими угрозами и целями. Но она упускает из виду более сложные комбинации, которые требуют глубокого просчёта многих ветвей дерева игры.

3. **Стратегические ошибки**. Программа упускает из виду стратегические планы, которые разворачиваются на протяжении многих ходов. Это происходит, если её горизонт поиска не охватывает весь план целиком.

Эффект горизонта хорошо демонстрирует следующий тактический просчёт. Допустим, что на максимальной глубине анализа движок находит взятие вражеского ферзя. Это приводит к позиции с очень хорошей оценкой. Последующие ходы программа не видит, потому что они выходят за горизонт поиска. Движок выбирает ветвь дерева игры, которая ведёт к взятию ферзя. Теперь это его основной вариант.

Программа делает первый ход по выбранному основному варианту. Это немного ухудшает её позицию. Горизонт поиска увеличивается на один ход вперёд. Программа просчитывает основной вариант с прошлой итерации поиска для новой глубины. Она обнаруживает, что теряет своего ферзя сразу после взятия ферзя оппонента. Получается, что основной вариант приводит не к выигрышу материала, а только к размену.

В этом примере эффект горизонта привёл к двум проблемам:

1. Движок уже сделал ход, который ухудшил его позицию.

2. Движок вынужден полностью менять свой план. Он потратит значительное время на поиск нового основного варианта.

Подобные просчёты могут стоить победы в партии с сильным оппонентом. Именно для их решения разработчики Stockfish используют продления.

Движок выполняет продление, когда в позиции на максимальной глубине анализа выполняется одно из следующих условий:

1. Происходит взятие.
2. Происходит шах.
3. Ход единственный.
4. Ход гораздо лучше альтернатив.
5. При наличии проходной пешки.

Если движок выполняет продление, он просчитывает ходы вплоть до спокойной позиции. В такой позиции нет взятий, шахов и единственных ходов. Эта техника называется **поиск спокойствия** ([quiescence search](https://www.chessprogramming.org/Quiescence_Search)). Только в спокойной позиции функция оценки даёт достоверный результат.

#### 3.5.4.4 Сокращения 

Эвристики из группы сокращений корректируют направление алгоритма поиска. Они уменьшают глубину анализа определённых ходов при выполнении некоторых условий. Эта техника фокусирует вычислительные ресурсы компьютера на анализ самых перспективных вариантов. Так движок получает дополнительное время, которое тратит на более глубокий просчёт лучших ходов.

Stockfish использует следующие эвристики сокращений:

1. [**Late Move Reductions**](https://www.chessprogramming.org/Late_Move_Reductions) (LMR) — уменьшает глубину просчёта ходов, которые алгоритм сортировки поместил в конец списка. В его начале находятся самые лучшие ходы. Движок рассматривает их в первую очередь. После этого нет смысла глубоко просчитывать ходы, которые заведомо хуже. Ожидается, что они менее перспективны и меньше влияют на результат оценки позиции.

2. [**Null Move Reductions**](https://www.chessprogramming.org/Null_Move_Reductions) (NMR). Допустим, что движок проверяет некоторую позицию. Чтобы оценить насколько она хороша, программа пропускает свой ход. Такая передача хода называется [**null move**](https://www.chessprogramming.org/Null_Move). Она запрещена правилами шахмат, но полезна как эвристика. С помощью null move движок проверяет: сможет ли противник добиться решающего преимущества за два хода подряд? Если не сможет, проверяемая позиция очень сильная. Поэтому нет смысла глубоко просчитывать ходы в ней. Вместо этого движок концентрируется на позициях, оценку которых существенно меняют ответы противника.

3. [**Fail-High Reductions**](https://www.chessprogramming.org/Fail-High_Reductions) (FHR) — эта эвристика непосредственно связана с алгоритмом альфа-бета отсечения. Допустим, что оценка текущей позиции оказывается выше бета. Это означает, что к ней приводит ход, который значительно лучше альтернатив. Дальнейшая проверка этого хода либо подтвердит его силу, либо опровергнет её. Поэтому движок сначала делает неглубокий анализ найденного лучшего хода. Чтобы опровергнуть его высокую оценку, этого может оказаться достаточно. Если поверхностный анализ подтвердил силу хода, движок проверяет его на максимальную глубину поиска.

Эвристики сокращения помогают шахматному движку оптимально распределять ресурсы компьютера и доступное время. Каждая из них повышает уровень игры Stockfish на несколько пунктов Эло.

#### 3.5.4.5 Отсечения

Эвристики отсечения уменьшают коэффициент ветвления дерева игры. Это даёт те же преимущества, что и использование эвристик сокращения:

* Ускорение алгоритма поиска
* Оптимальное распределение вычислительных ресурсов
* Усиление игры шахматного движка.

Недостаток отсечений в том, что движок случайно вместе со слабыми ходами отбрасывает и сильные. Эти ходы могут привести к сильным комбинациям или форсированному мату, но оказываются вне поле зрения программы.

Разработчики Stockfish [приводят следующие цифры](https://www.youtube.com/watch?v=2vBxlnrqenI). На протяжении шахматной партии у игрока есть в среднем 30 возможных ходов в каждой позиции. Поэтому без отсечений коэффициент ветвления дерева игры равен 30. Stockfish исключает из рассмотрения около 28 потенциальных ходов в каждой позиции. Таким образом, он сокращает коэффициент ветвления примерно до 2. Если учесть просчёт ходов вглубь, то окажется что Stockfish отсекает 90% всего дерева игры. Это даёт движку огромный выигрыш в производительности.

Stockfish использует следующие эвристики отсечения:

1. [**Mate Distance Pruning**](https://www.chessprogramming.org/Mate_Distance_Pruning) корректирует границы поиска, когда найден форсированный мат в несколько ходов. Допустим, что мат неизбежен через 5 ходов. Тогда движок отсекает ветви, которые ведут к мату за более чем 5 ходов. Также он отсекает варианты защиты за пределом 5 ходов, если они не могут задержать найденный мат. Проверять эти варианты нет смысла.

2. [**Futility pruning**](https://www.chessprogramming.org/Futility_Pruning) связана с алгоритмом альфа-бета отсечения. Эвристика выполняется за один ход до достижения максимальной глубины поиска. Она отсекает узлы, оценка которых не может превысить текущий параметр альфа. Чтобы подсчитать приблизительную оценку ещё не посещённых узлов, к оценке их корневого узла прибавляется константа под названием **запас бесполезности** (futility margin). Если сумма не превышает текущую альфа, то все подузлы отсекаются.

3. [**Static Exchange Evaluation based pruning**](https://www.chessprogramming.org/Static_Exchange_Evaluation) (SSE based pruning). Эвристика оценивает результат размена фигур на конкретном поле доски без глубокого просчёта дерева игры. Она определяет вероятное изменение материала у шахматного движка после размена. Отрицательное значение соответствует проигрышу материала, а положительное — выигрышу. В случае проигрыша движок отсекает ветвь дерева, которая ведёт к размену.

4. [**History Leaf Pruning**](https://www.chessprogramming.org/History_Leaf_Pruning) сохраняет статистику по спокойным ходам на максимальной глубине анализа. **Спокойный ход** не приводит к взятию или шаху. Статистика представляет собой таблицу с форматом записей: ход, оценка. Оценка отражает то, как часто ход приводил к хорошей позиции или способствовал альфа-бета отсечению. Если оценка хода низкая, движок отсекает соответствующую ветвь дерева.

5. [**Multi-cut pruning**](https://www.chessprogramming.org/Multi-Cut) связана с алгоритмом альфа-бета отсечения. Эвристика просчитывает ветвь дерева игры на небольшую глубину. Допустим, что поиск не нашёл в ней перспективных ходов, которые повышают текущее значение альфа. Тогда движок не проверяет ветвь на максимальную глубину анализа на текущей итерации поиска. Вместо этого на следующей итерации он повторно проверяет ветвь на небольшую глубину. Если три такие попытки не нашли хороших ходов, движок отсекает ветвь и больше её не рассматривает.

Эвристики сокращения дают Stockfish преимущество перед конкурирующими движками. С другой стороны чрезмерное отсечение слишком упрощает дерево игры. Это приводит к неверным оценкам перспективных вариантов и ухудшает стратегическое планирование. Поэтому каждая эвристика сокращения требует тонкой настройки параметров. Такая настройка позволяет найти баланс между количеством отсечённых ветвей и качеством ходов в оставшейся части дерева игры.

### 3.5.5 Оценка позиций

В Stockfish заложены два механизма для оценки позиций:

1. Запрограммированная функция оценки

2. Нейронная сеть [**NNUE**](https://www.chessprogramming.org/Stockfish_NNUE).

Рассмотрим, как они работают, и когда движок использует каждую из них.

#### 3.5.5.1 Запрограммированная функция оценки

До 2020 года Stockfish использовал вручную запрограммированную функцию оценки позиции. Разработчики многократно её расширяли и настраивали соответствующие параметры. Результат каждого изменения они проверяли в системе Fishtest. Так они достигли высокой точности при определении качества шахматной позиции. Рассмотрим, как работает эта функция оценки.

На вход функция принимает текущее положение всех фигур на доске. Функция возвращает знаковое рациональное число, например -1.5. Знак числа показывает, какая сторона имеет преимущество:

* Плюс — преимущество белых
* Минус — преимущество чёрных.

Чем больше число, тем больше преимущество. Например, +0.45 означает незначительное преимущество белых, а -4 — гарантированную победу чёрных. Оценка 0 соответствует равной позиции сторон.

В ранних шахматных программах функция оценки давала результат в пешках. То есть результат +1 означает, что у белых преимущество ровно в одну пешку. Stockfish нужны более точные единицы оценки позиции чем одна пешка. Поэтому он использует **сантипешки** (centipawns). Одна сантипешка равна 1/100 пешки. Например, оценка +0,35 означает преимущество белых в 35 сантипешек. Графический интерфейс для Stockfish выводит результат оценки в целых пешках. Такой формат удобнее для пользователя.

В Stockfish заложена следующая ценность материала:

* Пешка — 1
* Конь — 3
* Слон — 3
* Ладья — 5
* Ферзь — 9

Эти оценки меняются по ходу партии и в зависимости от пешечной структуры. Например, в дебюте и миттельшпиле слоны немного ценнее коней в открытых позициях. В закрытых позициях, когда центр заблокирован пешками, кони более ценны.

Функция оценки Stockfish проверяет по порядку следующие факторы позиции:

1. **Материал**. Движок подсчитывает стоимость каждой фигуры, которая находится на доске.

2. **Пешечная структура**. Движок последовательно перебирает все пешки на доске. Так он находит сильные и слабые структуры. Если пешка изолированная, отсталая или сдвоенная, позиция получает отрицательный бал. Если пешка является связанной или проходной, позиция получает положительный бал.

3. **Мобильность** измеряет количество допустимых ходов для фигур каждого игрока. Большая мобильность даёт преимущество. Она означает больше тактических и стратегических возможностей.

4. **Таблицы фигура-поле** (piece-square tables) оценивают фигуру каждого типа, когда она находится на каждой клетке доски. Это отражает стратегическое преимущество от размещения определённых фигур в определённых позициях. Например, кони становятся ценнее, если они расположены не по краям доски, а в центре.

5. **Безопасность короля**. Движок проверяет потенциальные угрозы королю, в том числе открытые вертикали и открытые поля вокруг него. Также движок считает число атак на кольцо короля. **Кольцо короля** — это восемь клеток вокруг фигуры.

6. **Очевидные угрозы**. Например, к ним относится атака на ферзя или возможность напасть на него за один ход. Угроза считается недостатком позиции.

7. **Специальные эвристики** проверяют особые ситуации. Например, контроль открытых вертикалей ладьями, занятие аванпоста конём или ладьёй и т.д. Всё это даёт некоторое преимущество в позиции.

8. **Сужающаяся оценка** или **коническая оценка** (tapered evaluation) корректирует важность факторов позиции в зависимости от стадии партии. Стадию определяет количество фигур на доске. Например, безопасность короля важна в миттельшпиле, но в эндшпиле важнее его активность.

9. **Проверка эндшпиля**. Если партия находится в эндшпиле, движок оценивает возможность победы. Для этого он проверяет набор оставшихся на доске фигур и их расположение. Например, если пешек мало, то провести их сложно и выиграть эндшпиль тяжело. Такая позиция получает отрицательный бал.

10. **Фактор масштабирования** — это коэффициент, на который умножается уже подсчитанная оценка эндшпиля. Коэффициент применяется при выполнении некоторых условий. Например, у сторон остались разноцветные слоны. При разноцветных слонах сложно выиграть эндшпиль. Поэтому фактор масштабирования равен от 1/3 до 1/2. Таким образом понижается общая оценка эндшпиля (положительная или отрицательная).

В 2020 году версия Stockfish 12 впервые стала использовать нейронную сеть для оценки позиций. Это повысило точность оценки и значительно усилило движок. Несмотря на это, Stockfish по-прежнему использует запрограммированную функцию оценки. Она применяется в особых случаях, когда высокая скорость работы функции важнее чем точность нейронной сети. Например, когда у одной из сторон значительный перевес.

#### 3.5.5.2 Нейронная сеть NNUE

#### 3.5.5.2.1 История NNUE

После внедрения системы Fishtest в 2013 году игровая сила Stockfish значительно выросла. Движок стал выделяться на фоне конкурентов. На него обратили внимание разработчики программ для игры [сёги](https://ru.wikipedia.org/wiki/Сёги), которая так же известна как японские шахматы. Во второй половине 2010-х годов несколько независимых групп начали адаптировать Stockfish для правил сёги. 

Сёги считается более сложной игрой чем шахматы. В ней есть правило **сбрасывания**. Согласно ему, игрок может вернуть на поле ранее взятую противником фигуру. Это правило не заложено в алгоритмы Stockfish, поскольку в шахматах его нет. Но оно очень сильно влияет на функцию оценки позиции.

Разработчики программ для сёги начали исправлять функцию оценки Stockfish. Им удалось адаптировать большинство эвристики для правил игры. Проблема возникла с таблицами фигура-поле (piece-square tables). Для шахмат эти таблицы представляют собой набор массивов размерностью 6x8x8. То есть для каждого из 6 типов фигур указывается оценка при занятии одного из 64 полей доски. В сёги у этого набора массивов добавилась ещё одна размерность — типы уже взятых фигур, которые можно сбросить. Из-за увеличения размерности получилось слишком много параметров для точной ручной настройки.

Японский учёный [Ю Насу](https://www.chessprogramming.org/Yu_Nasu) сотрудничал с Токийским технологическим институтом и исследовательской лабораторией Toshiba. Он занимался обработкой естественного языка, распознаванием речи и её синтезом с помощью методов машинного обучения. По совместительству Ю Насу участвовал в проекте [YaneuraOu](https://www.chessprogramming.org/YaneuraOu). Это был один из нескольких проектов по адаптации Stockfish для сёги.

Ю Насу предложил использовать методы машинного обучения для подбора параметров в таблицах фигура-поле. В 2018 году после ряда экспериментов учёный пришёл к новой архитектуре для нейронной сети. Он назвал её **эффективно обновляемая нейронная сеть** (efficiently updatable neural network). Сокращение названия EUNN можно записать в обратном порядке как NNUE. Это слово напоминает имя японского мифического существа [Нуэ](https://ru.wikipedia.org/wiki/Нуэ). Из-за этого сходства Ю Насу стал использовать обратный порядок букв в сокращении. Именно под таким именем сеть получила широкую известность.

Работа над сетью NNUE начиналась как автоматизация расчёта параметров для одной из эвристик. В результате сеть полностью заменила запрограммированную функцию оценки движка YaneuraOu. После этого сила его игры увеличилась на 500 пунктов Эло.

В проекте YaneuraOu участвовал другой японский учёный [Хисаюри Нода](https://www.chessprogramming.org/Hisayori_Noda). В качестве эксперимента он интегрировал сеть NNUE в оригинальный Stockfish версии 10 в 2019 году. Тесты разработчиков показали усиление игры движка примерно на 50 пунктов Эло. В течение года этот проект развивался как форк Stockfish под названием [Stockfish NNUE](https://www.chessprogramming.org/Stockfish_NNUE).

Примерно в это же время компания DeepMind опубликовала статью с результатами своей новой сети AlphaZero. Затем появилась её адаптация для шахмат Leela Chess Zero, которая играла на совершенно новом уровне. Эти события вызвали интерес разработчиков шахматных движков к нейронным сетям.

В августе 2020 года система тестирования Fishtest показала, что Stockfish NNUE сильнее оригинального движка на 80 пунктов Эло. Тогда разработчики Stockfish включили сеть NNUE в следующий официальный релиз. Все наработки форка Stockfish NNUE добавили в код Stockfish. Сам форк был закрыт за ненадобностью.

2 сентября 2020 года вышел первый релиз Stockfish версии 12 с сетью NNUE. Он играл значительно сильнее, чем предыдущая версия. Разработчики продолжают совершенствовать и обучать сеть NNUE. Это усиливает игру движка Stockfish с каждым следующим релизом.

#### 3.5.5.2.2 Принципы работы NNUE

Рассмотрим, как устроена и работает нейронная сеть NNUE. Сначала разберёмся, какие цели ставил Ю Насу перед новой моделью. Это объяснит, почему он выбрал те или иные архитектурные решения. Главная задача модели — заменить вручную запрограммированную функцию оценки позиции, которую использует минимаксный поиск с альфа-бета отсечением.

У функции оценки любого шахматного движка есть следующие параметры:

1. Скорость работы.

2. Точность оценки.

3. **Масштабируемость** — насколько хорошо функция использует все имеющиеся вычислительные ресурсы.

4. **Адаптируемость** — как функция подстраивается к разным типам позиций и этапам партии.

Новая модель должна превосходить функцию оценки по некоторым параметрам, а по остальным быть не хуже. Исходя из этой предпосылки, Ю Насу сформулировал следующие требования:

1. Модель должна работать примерно с той же скоростью, что и функция оценки. Если скорость будет значительно ниже, глубина поиска шахматного движка сильно сократится. Ослабнет и его сила игры.

2. Модель должна выполнять инкрементальные вычисления. Каждый отдельный ход меняет состояние доски незначительно. Поэтому для анализа модель должна использовать свои расчёты, выполненные на прошлой итерации.

3. Модель должна эффективно работать на том же оборудовании, которое использует функция оценки. Другими словами, она должна работать на обычных CPU, а не GPU.

4. Модель должна быть масштабируемой. Это означает, что она справляется с увеличением набора обучающих данных и эффективно использует доступные вычислительные ресурсы.

Точность оценки не была проблемой. Её гарантировал алгоритм машинного обучения, который автоматически подбирал параметры модели. При подходящей архитектуре и правильно выполненном обучении модель должна была оценивать позиции лучше, чем функция. Главной проблемой была скорость работы.

Опираясь на требования, Ю Насу сформулировал следующие принципы организации модели:

1. Модель должна иметь относительно небольшое количество ненулевых входов.

2. Входные данные должны меняться как можно меньше между последующими оценками.

3. Модель должна быть достаточно простой, чтобы выводить результат низкой точности в целочисленном виде.

**Первый принцип** ограничивает число ненулевых входов. Если следовать ему, то при масштабировании модели входные данные станут редкими. **Масштабирование нейронной сети** означает увеличение в ней числа нейронов, слоёв или входных параметров. Данные называются **редкими**, когда значительная их часть — это нули или очень маленькие значения.

Что дают редкие входные данные? Допустим, что у нейронной сети мало ненулевых входов. Тогда она тратит меньше времени для полной оценки входных данных с нуля. Другими словами, уменьшается верхняя граница времени, необходимого для такой оценки. Это открывает возможности для масштабирования. Сеть NNUE может быть большой и иметь много параметров, но при этом работать быстро.

**Второй принцип** позволяет сети быстро обновлять выходное значение в ответ на небольшие изменения входных данных. Модели не нужно выполнять оценку позиции с нуля после каждого хода. Вместо этого она корректирует выполненные ранее расчёты, с учётом сделанного хода. Такой подход значительно ускоряет её работу.

**Третий принцип** накладывает ограничение на архитектуру модели. Типичная нейронная сеть оперирует [**числами с плавающей запятой**](https://ru.wikipedia.org/wiki/Число_с_плавающей_запятой). Это повышает точность её вывода и упрощает алгоритм обучения. В отличие от стандартного подхода, модель Ю Насу оперирует целыми числами. Такой перевод нейронной сети на целочисленные расчёты называется **квантованием** (quantization).

Квантование значительно ускоряет обработку входных данных модели. Кроме этого оно позволяет запускать модель на обычных CPU. Они работают с целыми числами быстрее, чем с числами с плавающей запятой. Главный минус квантования — потеря точности. Оно приводит к ошибке вычислений, которая накапливается тем больше, чем глубже сеть.

I> **Глубина сети** — это количество слоёв в ней.

Чтобы скомпенсировать ошибку вычислений из-за квантования, число скрытых слоёв в нейронной сети должно быть минимальным. Такое решение также помогает удовлетворить третье требование Ю Насу — использовать то же оборудование, что и функция оценки. Когда модель попадает в разряд deep learning, ей для эффективной работы требуется намного больше вычислительных ресурсов. Возможностей обычного CPU становится недостаточно.

NNUE — это собирательное название для целого семейства моделей, которые удовлетворяют трём принципам Ю Насу. Детали каждой конкретной реализации могут отличаться. Тем не менее все модели объединяет общая идея и принцип построения.

Каждый современный шахматный движок высокого уровня, построенный на поиске минимакс, использует свою собственную реализацию сети NNUE. Более того разные версии одного движка (например, Stockfish) могут использовать разные архитектуры NNUE.

#### 3.5.5.2.3 Входные данные HalfKp

Рассмотрим архитектуру NNUE под названием [**HalfKp**](https://www.chessprogramming.org/Stockfish_NNUE#HalfKP) (Half King-Piece). Именно этот вариант сети впервые интегрировал Хисаюри Нода в Stockfish версию 10. Разработчики проекта [nnue-pytorch](https://github.com/official-stockfish/nnue-pytorch/blob/master/docs/nnue.md) подробно описали архитектуру HalfKp на Github.

После первой интеграции в Stockfish архитектуру HalfKp развивал польский учёный [Томаш Собчик](https://www.chessprogramming.org/Tomasz_Sobczyk). Он также активный разработчик шахматного движка. Благодаря ему, появились следующие варианты сети NNUE:

* [**HalfKA**](https://www.chessprogramming.org/Stockfish_NNUE#HalfKA) (Half King-Attacker) — дальнейшее развитие архитектуры HalfKp, которое лучше учитывает атакующие возможности фигур.

* HalfKAv2 — развитие HalfKA, которое используется в Stockfish 14.

* HalfKAv2_hm — используется в последней версии Stockfish 16.

Архитектура HalfKp — это нейронная сеть с прямой связью (FNN) категории shallow learning. Помимо входного и выходного слоёв она имеет три скрытых слоя.

Сначала рассмотрим, как устроен входной слой сети. Согласно первому принципу Ю Насу, входные данные модели должны быть редкими. Поэтому учёный разработал для них специальный формат.

Всего на шахматной доске 64 поля. Есть 6 типов фигур: пешка, конь, слон, ладья, ферзь и король. Фигуры могут быть двух цветов: черные и белые. В качестве входных данных модели Ю Насу закодировал позиции фигур. Каждый нейрон входного слоя сети соответствует одному набору из трёх элементов: `(поле, фигура, цвет)`. Количество таких наборов `64 * 6 * 2 = 768`. Это означает, что входной слой сети имеет 768 нейронов.

Обозначим некоторое поле доски как S. Также есть некоторая фигура P цвета C. Один из нейронов входного слоя соответствует набору `(S,P,C)`. Этот вход равен 1, если фигура P цвета C занимает поле S. Если фигуры на поле нет, вход равен 0.

В начальной позиции на шахматной доске находятся 32 фигуры. По ходу партии их количество только уменьшается. Это означает, что сеть NNUE получает не более 32 ненулевых входов в любой возможной позиции фигур. Один ход может поменять максимум 4 входа сети: это случай рокировки. В среднем один ход меняет менее 3-х входов.

Рассмотрим, как кодируется шахматная позиция на вход модели. Иллюстрация 3-32 демонстрирует позицию с четырьмя фигурами.

{caption: "Иллюстрация 3-32. Шахматная позиция с четырьмя фигурами", height: "40%"}
![Шахматная позиция с четырьмя фигурами](images/Chess/Stockfish-HalfKp-input.png)

Четыре фигуры на доске кодируются следующими четырьмя наборами:

* `(A1, король, белые)`
* `(C3, пешка, белые)`
* `(B8, король, чёрные)`
* `(D4, ладья, чёрные)`.

Как меняются входы сети после хода одной из сторон? Для примера рассмотрим варианты пешки на c3. Во-первых, её ход на c4 изменит вход сети `(C3, пешка, белые)` на 0, а `(C4, пешка, белые)` на 1. Во-вторых, взятие cxd4 изменит вход сети `(C3, пешка, белые)` на 0, `(D4, пешка, белые)` на 1 и `(D4, ладья, чёрные)` на 0. При этом все остальные входы сети остаются неизменными.

Мы получили редкие входные данные. После каждого хода они меняются незначительно. Такой формат позволяет нейронной сети выполнять инкрементальные вычисления. Для этого у неё есть механизм под названием **накапливающий сумматор** (accumulator). Его реализует первый скрытый слой модели. Мы рассмотрим его далее.

Ю Насу не остановился на полученном формате и продолжил его оптимизировать. Он хотел сделать входные данные ещё более редкими. Для этого учёный добавил в каждый набор позицию короля. Получился следующий новый формат: `(поле_короля, поле_фигуры, фигура, цвет)`. Такие наборы имеют все типы фигур кроме короля.

Число наборов входных данных в новом формате следующее: `64*64*5*2=40960`. В архитектуре HalfKp для Stokfish есть 64 неиспользуемых входных набора. Они применялись для сёги, но оказали ненужны для шахмат. Поэтому итоговое количество нейронов входного слоя сети получилось следующим: `40960 + 64 = 41024`.

Новый формат сделал входные данные более редкими. Инкрементальные вычисления стали ещё быстрее. Единственный минус заключался в том, что ход короля стало сложно рассчитывать. Он приводит к изменению всех входов модели. Поэтому после каждого хода короля сеть пересчитывает оценку позиции с нуля. Ю Насу посчитал это приемлемым компромиссом.

Новый формат добавляет позицию короля в каждый набор входных данных. Возникает вопрос: о каком именно короле идёт речь — белом или чёрном? На самом деле речь идёт об обоих королях. Архитектура HalfKp имеет два накапливающих сумматора: для чёрных и для белых фигур. Это означает, что количество входных наборов тоже удваивается. Таким образом нейронная сеть получает на вход следующее:

* Позиции всех фигур относительно белого короля

* Позиции всех фигур относительно чёрного короля.

Решение с двумя накапливающими сумматорами имеет плюсы и минусы. Главный минус в том, что увеличивается объём вычислений в сети. Во-первых, каждый ход приводит к пересчётам в самих сумматорах. Во-вторых, результаты сумматоров надо свести в конечный результат, который передаётся на второй скрытый слой сети. В архитектуре HalfKp это выполняется простым объединением выходных векторов y1 и y2 обоих сумматоров. Плюс решения в том, что два сумматора увеличивают точность модели.

Возникает ещё один вопрос. В чём различие между позициями фигур относительно белого короля и чёрного? Для эффективной работы сети нужно, чтобы входные наборы относительно каждого короля различались между собой. В противном случае объём вычислений увеличится, а точность модели — нет. В архитектуре HalfKp эта проблема решается сменой цвета фигур для точки зрения чёрных.

Рассмотрим на примере, как происходит смена цвета фигур. Ещё раз обратимся к позиции на иллюстрации 3-32. С учётом разворота доски она кодируется следующими двумя наборами:

* С точки зрения белых: `(A1, C3, пешка, белая)`, `(A1, D4, ладья, чёрная)`

* С точки зрения чёрных: `(B1, C6, пешка, чёрная)`, `(B1, D5, ладья, белая)`

Пример показывает, что для точки зрения чёрных поменялся не только цвет фигур, но и номера полей. Это произошло потому, что белые фигуры начинают игру на горизонталях 1 и 2. Следовательно, смена цвета чёрного короля означает, что он находится не на поле b8, а на b1. То же самое справедливо для всех остальных фигур.

#### 3.5.5.2.4 Архитектура HalfKp

Мы познакомились с форматом входных данных нейронной сети HalfKp. Теперь рассмотрим, как именно устроены её слои. Иллюстрация 3-34 демонстрирует схему архитектуры HalfKp. Схема достаточно сложная. Чтобы её понять, сначала разберёмся с принципом работы одного слоя нейронной сети.

Любой слой нейронов имеет две основные характеристики:

1. Тип слоя.
2. Функция активации его нейронов.

Самые распространённые типы слоёв следующие:

1. **Линейный слой** (linear layer)
2. Свёрточный слой (convolution layer)
3. Слой подвыборки (pooling layer)
4. Рекуррентный слой (recurrent layer)

Все слои любой сети NNUE относятся к линейному типу. Поэтому мы сконцентрируемся только на нём.

Тип слоя определяет, как именно его нейроны соединены с нейронами предыдущего слоя. В случае линейного типа — это прямая связь без замыканий. При такой связи информация распространяется только в одном направлении: от входов нейронов слоя к их выходам.

В NNUE сети все линейные слои являются полносвязными. **Полносвязным** (fully connected) называется слой, каждый нейрон которого связан с каждым нейроном предыдущего слоя.

В нейронной сети данные передаются от одного слоя к другому. Способ связи между их нейронами определяет преобразование данных при передаче. Рассмотрим пример. Допустим, что в сети есть два слоя C и D. Выходы нейронов слоя C связаны со входами нейронов слоя D. Данные передаются из слоя C в слой D. Связь между ними определяет формулу для преобразования данных.

Допустим, что слой D линейный и полносвязный. Обозначим выходные значения слоя C как `out_C`, а входные значения D как `in_D`. Тогда `in_D` рассчитывается по следующей формуле:
{width: "30%"}
![](images/Chess/nnue-linear-layer-formula.png)

В ней используются следующие обозначения:

* x — вектор `out_C` выходных значений слоя C
* A — матрица весов размера `(in_D, out_C)`
* b — вектор смещения (bias) размера `in_D`
* y — вектор `in_D` входных значений слоя D.

Обратите внимание, что эта формула не зависит от типа слоя C. Для неё важен только тип слоя D и его связь со слоем C.

Теперь поговорим о функции активации. Строго говоря, это характеристика не самого слоя, а его строительной единицы — нейрона. Обычно все нейроны одного слоя имеют одинаковую функцию активации. Это выгодно с точки зрения скорости и эффективности обучения модели. Только в некоторых специализированных архитектурах нейронных сетей это правило не выполняется.

Функция активации — это операция каждого отдельного нейрона над своими входными значениями. В результате этой операции получаются выходные значения нейрона.

Вернёмся к примеру с двумя слоями C и D. Функция активации каждого нейрона слоя D получает на вход значение из вектора `in_D`. Позиция значения в векторе определяет, какой именно нейрон слоя D его получит.

Выходные значения всех нейронов слоя D объединяются в вектор и передаются в следующий за ним слой (например, E). В зависимости от типа слоя E, над этим вектором снова происходит преобразование с участием матрицы весов. Связи между нейронами слоёв D и E определяют, какой нейрон слоя E получит какое значение из выходного вектора слоя D.

Нейроны всех скрытых слоёв NNUE сети Stockfish используют функцию активации **clipped ReLU**. Ещё раз напомню, что функция активации относится к каждому отдельному нейрону. Формула clipped ReLU в HalfKp архитектуре выглядит так:
{width: "50%"}
![](images/Chess/nnue-clipped-relu-layer-formula-127.png)

В ней используются следующие обозначения:

* x — входное значение нейрона
* y — выходное значение нейрона.

Иллюстрация 3-33 демонстрирует график функции clipped ReLU.

{caption: "Иллюстрация 3-33. Функция активации clipped ReLU", height: "40%"}
![Функция активации Clipped ReLU](images/Chess/nnue-clipped-relu-graph.png)

**ReLU** — это сокращение от rectified linear unit. Название переводится как **усеченное линейное преобразование**. Обычная ReLU функция преобразует входное значение x в результат y от 0 до положительной бесконечности. Если входное значение меньше или равно нулю, то ReLU выдаёт ноль. В противном случае — входное значение.

Функция clipped ReLU (обрезанная ReLU) ведёт себя как ReLU, но с одним отличием: выходные значения в ней ограничены некоторой константой. В случае HalfKp архитектуры эта константа равна 127. Если входное значение clipped ReLU оказалось больше 127, то на выходе она вернёт 127. Для всех остальных входных значений выход будет таким же, как и для обычной ReLU функции.

Зачем сети NNUE нужны слои с функцией активации нейронов clipped ReLU? Они добавляют **нелинейность** (non-linearity) в модель. Если бы в ней были только слои с линейной функцией активации, их можно было бы свернуть в один. Для этого достаточно перемножить их матрицы весов. В результате сеть не смогла бы научиться оценивать сложные шахматные позиции. С другой стороны, сеть с нелинейностью способна аппроксимировать сложные нелинейные функции. Оценка позиции фигур как раз и является такой функцией.

В архитектуре HalfKp используется не обычная ReLU функция, а clipped ReLU из-за квантования. Оно требует уменьшения динамического диапазона входных данных скрытого слоя. **Динамический диапазон** (dynamic range) означает диапазон значений, который слой сети может принимать на вход. Для случая HalfKp этот диапазон ограничен числом 127. Ограничение повышает скорость работы модели.

Теперь познакомимся со схемой архитектуры HalfKp. Её демонстрирует иллюстрация 3-34.

{caption: "Иллюстрация 3-34. Архитектура HalfKp сети NNUE для Stockfish 10", width: "100%"}
![Архитектура HalfKp сети NNUE для Stockfish 10](images/Chess/Stockfish-NNUE-HalfKp.png)

В левой части иллюстрации изображена шахматная доска с некоторой позицией. Ход в ней делают белые.

Справа от доски мы видим два прямоугольника: серый и под ним белый. Серый прямоугольник объединяет нейроны входного слоя сети, которые соответствуют позициям фигур относительно чёрного короля. В белом прямоугольнике — нейроны входного слоя, соответствующие позициям фигур относительно белого короля. Каждый прямоугольник содержит 41024 нейрона, что в сумме составляет 82048. Это число входов нейронной сети HalfKp.

**Входной слой** любой сети с прямой связью не имеет весов и смещения, а его нейроны не имеют функции активации. Этот слой не выполняет никаких вычислений, а просто передаёт входные данные на следующий за ним скрытый слой.

**Первый скрытый слой** модели разделён на две части, также как входной слой. На иллюстрации 3-34 этому слою соответствуют розовый и зелёный прямоугольники. Нейроны в розовом прямоугольнике получают на вход позиции фигур относительно чёрного короля. Нейроны в зелёном прямоугольнике — позиции фигур относительно белого короля.

Розовая и зелёная части первого слоя работают как накапливающие сумматоры для своих входных данных. Каждая имеет по 256 нейронов, что в сумме даёт 512. Поэтому в выходном векторе слоя всего 512 значений.

Первый скрытый слой модели линейный с функцией активации нейронов clipped ReLU. Это означает, что вектор его входных значений сначала умножается на матрицу весов. У каждой части слоя своя матрица. Каждая из них имеет размер 41024x256. Каждый вес в матрице — это целое число со знаком размерностью 16 бит. К результату умножения прибавляются смещения размерностью 16 бит. Смещения хранятся в векторе из 256 элементов.

После умножения на матрицу весов и прибавления смещения получаются входные значения для нейронов первого скрытого слоя. Они представляют собой вектор из 512 элементов размерностью 8 бит. К каждому из них применяется функция активации clipped ReLU. В результате получается вектор выходных значений первого скрытого слоя. Это 512 целых чисел в диапазоне от 0 до 127.

**Накапливающий сумматор** отвечает за инкрементальные вычисления. Как он работает? Модель сохраняет результат умножения входных значений первого скрытого слоя на матрицу весов A. После очередного хода этот результат обновляется в зависимости от изменения входных наборов `(поле_короля, поле_фигуры, фигура, цвет)`. Эти изменения могут быть двух видов:

1. Входное значение для набора i изменилось с 1 на 0. Тогда из сохранённого результата вычитается столбец i матрицы весов A.

2. Входное значение для набора i изменилось с 0 на 1. Тогда к сохранённому результату прибавляется столбец i матрицы весов A.

После этого к пересчитанным входным значениям первого скрытого слоя применяется функция активации его нейронов clipped ReLU.

**Второй скрытый слой** сети HalfKp состоит из 32 нейронов. Он линейный с функцией активации clipped ReLU. Линейный тип слоя означает, что каждый его нейрон связан со всеми нейронами предыдущего слоя. Таким образом, второй скрытый слой объединяет выходные данные обоих сумматоров.

Матрица весов второго слоя имеет размер 512x32. Каждый вес в ней — это целое число со знаком размерностью 8 бит. После умножения матрицы весов на вектор входных значений получается вектор из 32 элементов размерностью 32 бита. К каждому из них добавляется 32 битное смещение. Результат делится на 64. После этого над ним выполняется функция clipped ReLU. В итоге получается вектор из 32 значений в диапазоне от 0 до 127. Это выходные данные второго скрытого слоя модели.

**Третий скрытый слой**, также как и второй, состоит из 32 нейронов. Это линейный слой с функцией активации clipped ReLU. Он работает точно так же, как и второй слой. Единственное отличие в том, что его матрица весов имеет размер 32x32.

**Выходной слой** модели состоит из одного нейрона. Это линейный слой с функцией активации `y = x/16`. Его матрица весов имеет размер 32x1. Каждый вес имеет размерность 8 бит. После умножения вектора входных значений слоя на матрицу весов получается одно 32 битное целое знаковое число. Это число делится на 16 и к нему прибавляется смещение. Так сеть HalfKp получает конечную оценку позиции на доске.

Выходное значение сети NNUE интерпретируется так же, как результат вручную запрограммированной функции оценки. Его единицы измерения — сантипешки. Если оценка сети больше 0, позиция лучше для движка. Если оценка меньше 0, позиция лучше для оппонента.

Веса сети NNUE для Stockfish подбирает алгоритм обучения с учителем. Он принимает на вход около 16 миллиардов позиций и оценку для каждой из них. Позиции берутся из реальных турнирных партий с разными дебютами. Это гарантирует их разнообразие. Предварительную оценку позиций выполняет шахматный движок Leela Chess Zero. Движок построен на модели deep learning. Она даёт более точный результат, но работает гораздо медленнее чем NNUE. Алгоритм обучения настраивает матрицы весов сети NNUE так, чтобы она давала оценку позициям близкую к оценкам Leela Chess Zero.

Система тестирования Fishtest проверяет результат обучения сети NNUE. Тест считается пройденным, если Stockfish с новой версией сети играет сильнее, чем последний стабильный релиз движка. В этом случае следующий релиз Stockfish получает новую версию сети.

Несмотря на все оптимизации в архитектуре сети NNUE, её скорость работы уступает вручную запрограммированной функции оценки. Именно поэтому функция оценки всё ещё остаётся в коде Stockfish. Движок использует её в особых случаях.

### 3.5.6 Результаты Stockfish

Stockfish по праву считается эталонной реализацией шахматного движка. На него равняются все коммерческие и исследовательские проекты в области компьютерных шахмат. Разработчики в первую очередь сравнивают свои программы именно со Stockfish. Команда DeepMind не исключение. Именно так они оценивали свою систему AlphaZero в 2017 году.

Многие коммерческие движки также перенимают идеи Stockfish. Пример — нейронная сеть NNUE, которая впервые была интегрирована в Stockfish 10. Именно эта интеграция доказала перспективность нового подхода. Несмотря на копирование идей, коммерческие проекты остаются в роли догоняющего. Stockfish по-прежнему занимает первые строчки рейтинга среди шахматных движков.

Влияние Stockfish на шахматный мир огромно. Прежде всего он развивает современную шахматную теорию. Во-первых, многие существующие дебюты были пересмотрены. Stockfish обнаружил в них новые сильные ходы. Так он подтвердил некоторые основные линии и опроверг другие, которые ранее считались перспективными. Также Stockfish нашёл новые дебюты, которые раньше не игрались на турнирах высокого уровня. Во-вторых, глубокий анализ Stockfish помог профессиональным игрокам и шахматным теоретикам лучше понять эндшпили. Речь идёт о сложных многофигурных эндшпилях, которые ещё не просчитаны до конца.

Помимо вклада в шахматную теорию Stockfish помогает игрокам любого уровня. Профессионалы и тренеры анализируют с его помощью турнирные партии. Опираясь на рекомендации движка, они разрабатывают новые стратегии. Любители используют Stockfish как инструмент обучения. Они анализируют свои игры и так учатся на своих ошибках.

Благодаря хорошей инфраструктуре и открытому исходному коду, Stockfish продолжает активно развиваться. Его сила игры растёт с каждой новой версией.

{pagebreak}
