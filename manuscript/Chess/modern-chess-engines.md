## 3.5 Современные шахматные движки

В конце 1990-х годов шахматные программы для ПК достигли уровня игры специализированных суперкомпьютеров наподобие Deep Blue. В результате новые разработки представляли собой именно программы. Компании и энтузиасты перестали проектировать специализированное шахматное аппаратное обеспечение, потому что это было слишком дорого.

Как настольные компьютеры достигли уровня игры суперкомпьютеров? Во-первых, значительно увеличилась мощность ПК. Большая часть таких компьютеров имела [IBM-совместимую](https://ru.wikipedia.org/wiki/IBM-PC-совместимый_компьютер) архитектуру и работала на процессорах от Intel. В 1993 году вышел процессор [Intel Pentium](https://ru.wikipedia.org/wiki/X86#Процессоры_Intel). К концу 1990-х его конструкция была усовершенствована. Так доступные ПК получили мощный и недорогой процессор. Его производительности хватало шахматным программам, чтобы просчитывать ходы на глубину, достаточную для качественной игры.

Вторая причина — это совершенствование самих шахматных программ. Основные улучшения касались оценочной функции. Благодаря им, программы качественнее оценивали позиции и выбирали более сильные ходы. Так же появились новые эвристики поиска. Это позволяло программам отбрасывать больше бесперспективных ходов и глубже просчитывать перспективные.

### 3.5.1 Шахматные движки

В 1993 году разработчик шахматных программ [Мартин Хирш](https://www.chessprogramming.org/Marty_Hirsch) ввёл термин [**шахматный движок**](https://ru.wikipedia.org/wiki/Шахматный_движок). Хирш сделал это, чтобы отличать коммерческие шахматные игры от инструментов для профессиональных шахматистов.

Шахматные игры для ПК начали появляться в конце 1980-х годов. Примеры таких игр: [Chessmaster](https://en.wikipedia.org/wiki/Chessmaster) и [Battle Chess](https://en.wikipedia.org/wiki/Battle_Chess). Эти программы имеют красивый графический интерфейс по меркам своего времени. Например, в Battle Chess после каждого хода фигуры оживают и перемещаются на указанное поле доски. Если это поле уже занимает фигура противника, то происходит сражение. Шахматные игры предназначались для широкой аудитории. Они продавались по низкой цене и позиционировались как развлечения. Уровень их игры был достаточно низким: около 1600 пунктов Эло.

В отличие от игр, шахматные движки не имеют графического интерфейса. Они предназначены для анализа и поиска наилучшего хода в заданной на доске позиций. Пользователь работает с такой программой через интерфейс командной строки. Шахматные движки изначально позиционировались как инструменты для профессионалов. С их помощью шахматисты анализировали партии и готовились к турнирам. Соответственно, цена на шахматные движки высока, как и на любой профессиональный инструмент. Их уровень игры намного выше, чем у шахматных игр.

Интерфейс командной строки был неудобен для большинства пользователей. Поэтому в начале 1990-х стали появляться программы для визуализации работы шахматного движка. Большинство современных программ визуализации коммерческие и достаточно дорогие. При этом наиболее сильные шахматные движки сегодня бесплатны и распространяются с [открытым исходным кодом](https://ru.wikipedia.org/wiki/Свободное_и_открытое_программное_обеспечение).

Все шахматные движки состоят из двух основных частей:

1. Механизм поиска.
2. Статическая оценка позиции.

Рассмотрим как реализованы эти части в самых сильных шахматных движках.

### 3.5.2 Stockfish

Stockfish считается сильнейшим современным шахматным движком. Он занимает первые строчки в рейтингах [Chess Engines Grand Tournament](http://www.cegt.net/40_40 Rating List/40_40 BestVersion/rangliste.html) (CEGT) и [Computer Chess Rating Lists](https://ccrl.chessdom.com/ccrl/4040/) (CCRL) за 2022 год.

Stockfish вырос из проекта шахматного движка Glaurung, который разработал Торд Ромстад. Первая версия Glaurung вышла в 2004 году. Это была программа для ПК с открытым исходным кодом. Разработчики портировали её более поздние версии на мобильные телефоны и планшеты.

В ноябре 2008 году Марко Костальба решил сделать [**форк**](https://ru.wikipedia.org/wiki/Форк) (от английского fork — вилка) кода Glaurung. Форком называется использование кодовой базы одного проекта в качестве старта для другого. Костальба назвал свой проект Stockfish. Первая версия этого движка вышла в ноябре 2008 года.

В течение 2008 года Glaurung и Stockfish развивались параллельно. Оба проекта распространялись с открытым исходным кодом. Поэтому их команды свободно обменивались идеями и усовершенствованиями алгоритмов.

В декабре 2008 года Ромстад выпустил последнюю версию Glaurung 2.2. Он прекратил поддержку своего проекта и присоединился к команде Stockfish. Stockfish на тот момент превзошёл Glaurung по уровню игры. Возможно, это стало причиной решения Ромстада.

В 2011 году Торд Ромстад вышел из проекта Stockfish. Он занялся разработкой шахматной программы для iOS. В 2014 году проект покинул Марко Костальба. Современная версия Stockfish развивается группой энтузиастов в которой около 20 человек.

#### 3.5.2.1 Система тестирования Fishtest

Stockfish достиг высокого уровня игры во многом благодаря специальной системе распределённых тестов под названием Fishtest. Её разработал Гэри Линскотт в 2013 году. Система Fishtest позволяет добровольцам выделять процессорное время своих компьютеров на тестирование шахматного движка. Суть тестирования заключается в многократных играх модифицированной версии Stockfish против последней стабильной версии. Только статистически значимые улучшения принимаются сообществом разработчиков и попадают в следующую стабильную версию.

Эффективность Fishtest можно оценить по первым 12 месяцам его использования. За это время уровень игры Stockfish вырос на 120 пунктов Эло. В результате этого прогресса Stockfish поднялся до лидирующих позиций во всех основных рейтингах шахматных движков.

К декабрю 2022 года благодаря системе Fishtest разные версии Stockfish сыграли друг с другом около 5 миллиардов партий. На это ушло более 8650 лет процессорного времени.

#### 3.5.2.2 Механизм поиска в Stockfish

Поиск в Stockfish основан на следующих алгоритмах:

* Магические битборды
* Минимаксный поиск
* Эвристика альфа-бета отсечения
* Оптимизация move ordering

Рассмотрим их подробнее.

##### 3.5.2.2.1 Магические битборды

Чтобы начать поиск, шахматному движку нужно получить список возможных ходов, допустимых правилами. Решение этой задачи зависит от формата, в котором движок хранит состояние шахматной доски. Наиболее эффективным форматом для современных компьютеров считаются [**битборды**](https://hmn.wiki/ru/Bitboard). Разберёмся, как они работают.

Впервые на практике битборды использовал Кристофер Стрейч в своей программе для игры в шашки в 1952 году. Битборды в шахматах впервые применили разработчики советской шахматной программы [Каисса](https://ru.wikipedia.org/wiki/Каисса_(программа)) в конце 1960-х годов.

Идея битбордов в том, чтобы оптимизировать обработку состояния доски. Битборд представляет собой одно 64-разрядное число. Каждый бит этого числа соответствует одному из 64-х полей шахматной доски. Если бит равен единице, поле занято фигурой. Если бит равен нулю, то поле свободно.

Чтобы сохранить состояние всех фигур на шахматной доске, нужно минимум восемь битбордов. По одному на каждый из шести типов фигур: пешки, ладьи, кони, слоны, короли, ферзи. Два битборда нужны для определения цвета фигуры на каждом поле: черный или белый. На практике обычно применяется набор из 12 битбордов: по одному для каждого типа фигур, каждого цвета. Такой подход удобнее для расчётов возможных ходов.

Рассмотрим пример. Битборд для начальной позиции белых пешек наглядно можно представить так:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
```

На самом деле, в памяти компьютера этот битборд хранится как 64-разрядное число в двоичной системе счисления так:
{line-numbers: false, format: text}
```
0000000000000000000000000000000000000000000000001111111100000000
```

Аналогично, битборд для двух чёрных коней в начальной позиции выглядит так:
{line-numbers: false, format: text}
```
  0 1 0 0 0 0 1 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Ему соответствует такое 64-разрядное число в памяти:
{line-numbers: false, format: text}
```
0100001000000000000000000000000000000000000000000000000000000000
```

Какие преимущества дают битборды? Современные процессоры оперируют 64-разрядными регистрами. Это означает, что один битборд целиком помещается в один регистр. Также любую проверку или действие над числом процессор выполняет за одну операцию. Одна операция длится один [**такт**](https://hardwareguide.ru/процессор/частота-процессора/). Тактовая частота современных процессоров достигает 4 гигагерц. Это соответствует 4*10^6^ операций в секунду. Благодаря битбордам, современные шахматные программы достигают очень высокой производительности.

Битборды хранят состояния доски. Но сами по себе они не дают все доступные ходы для каждой фигуры. Эти ходы можно посчитать с помощью битовых операций. Для пешек, коней и королей их легко рассчитать с помощью битовых сдвигов.

Вот расчёт ходов для белых пешек в начальной позиции. Все пешки могут пойти на одно поле вперёд. В этом случае битовая маска допустимых ходов выглядит так:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Кроме этого каждая пешка из начальной позиции может пойти на два поля вперёд. Это даст такую битовую маску:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Если мы наложим две битовые маски с допустимыми ходами друг на друга, то получим такой битборд:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 1 1 1 1
  1 1 1 1 1 1 1 1
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Этот битборд возможных ходов (B) можно получить из битборда начальной позиции (A) с помощью операций битового сдвига влево и побитового OR. Формула для расчёта выглядит так:
{line-numbers: false, format: text}
```
B = (A << 8) | (A << 16)
```

Если некоторые пешки двигались в ходе партии, мы можем получить, например, такой битборд (C) c их позицией:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 1 1 0 0 0
  0 0 0 0 0 0 1 0
  1 1 1 0 0 1 0 1
  0 0 0 0 0 0 0 0
```

В этом случае наша формула для расчёта возможных ходов не подходит. Нам нужно отличать пешки, которые ещё могут сходить на два поля вперед. Для этого наложим маску начальной позиции белых пешек на битборд C с помощью побитого AND. Эта маска представляет собой битборд A начальных позиций пешек. Так мы получим универсальную формулу расчёта возможных ходов для белых пешек на любой стадии партии:
{line-numbers: false, format: text}
```
B = (C << 8) | ((C & A) << 16)
```

Аналогично выводятся формулы расчёта возможных ходов для чёрных пешек, а также коней и королей обоих цветов.

Найти ходы [**скользящих фигур**](https://www.chessprogramming.org/Sliding_Pieces) (sliding pieces) сложнее. Скользящими фигурами называют слона, ладью и ферзя. Они могут ходить по диагоналям, вертикалям и горизонталям через всю доску, если их не блокируют другие фигуры. Это означает, что битовых сдвигов будет недостаточно. Требуются более сложные вычисления.

Для расчёта возможных ходов скользящих фигур нам нужно знать:

1. Тип фигуры.
2. Поле, где она находится.
3. Битборд с расположением фигур, которые её блокируют.

Рассмотрим алгоритм расчёта возможных ходов. Для примера найдём возможные ходы ладьи на поле e4 на запад. Для этого нам надо выполнить следующие шаги:

1. Рассчитать **луч** в каждом из восьми направлений для поля, которое занимает фигура. Луч представляет собой все поля по горизонтали, вертикали или диагонали от заданной клетки. Например, вот луч на запад из клетки e4:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 1 1 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
```

Остальные семь направлений это: северо-запад, север, северо-восток, восток, юго-восток, юг, юго-запад.

2. Выбрать, какие лучи подходят для данного типа фигуры. Например, для ладьи нужны только лучи на север, восток, юг и запад.

3. Использовать лучи как маски для битборда блокирующих фигур. Так мы получаем все фигуры, которые стоят на пути данной фигуры на каждом направлении.

4. Найти первую блокирующую фигуру на каждом направлении. Для направлений на запад и юг нужно найти **наибольший индекс ненулевого бита** (most significant set bit). Эта операция называется [**bit scan forward**](https://www.chessprogramming.org/BitScan#Bitscan_forward). Для направлений на восток и север мы ищем **наименьший индекс не нулевого бита** (least significant set bit). Эта операция называется [**bit scan reverse**](https://www.chessprogramming.org/BitScan#Bitscan_reverse).

5. Рассчитать лучи от найденной первой блокирующей фигуры. Для нашего примера нам нужен только луч на запад. Используем его как маску для луча от ладьи на e4 на запад.

Так мы получили все клетки, которые ладья e4 атакует на западе. Следуя тому же алгоритму, мы находим клетки атаки ладьи для остальных сторон.

Клетки, которые атакует слон, находятся аналогично ладье. В случае ферзя нам просто надо скомбинировать результаты алгоритма поиска клеток для ладьи и слона.

Мы рассмотрели один из алгоритмов для расчёта ходов скользящих фигур. Он основан на bit scan операциях. Существуют и другие алгоритмы, например [**вращаемые битборды**](https://habr.com/ru/post/155045/).

Для расчёта ходов фигур передовые шахматные движки используют подход под названием [**магические битборды**](https://habr.com/ru/post/272815/). На современных процессорах он даёт наилучшую производительность.

Идея магических битбордов в том, чтобы однократно посчитать все доступные ходы для всех фигур с учётом всех возможных позиций блокирующих фигур. Для этого расчёта можно использовать алгоритм на операциях bit scan или любой другой. Результат сохраняется в память. Далее в процессе работы движок обращается к памяти и читает уже рассчитанные доступные ходы, которые соответствуют текущей позиции на доске. Такая техника однократного расчёта и сохранения результата в память для повторного использования называется **кешированием**.

Результат расчёта ходов фигур хранится в наборе **двумерных массивов**. Каждый массив, соответствует определённому типу фигур. Первый индекс массива — это поле, которое занимает фигура. Второй индекс — битборд с блокирующими фигурами.

Проблема с кешированием возможных ходов в том, что число всех возможных битбордов с блокирующими фигурами огромно. Оно равно 2^64^. Подсчитаем, сколько памяти нужно для хранения массива возможных ходов для фигур одного типа (например, ладей). Один битборд занимает 64 бита. Число возможных битбордов блокирующих фигур 2^64^. Число полей, которые может занимать атакующая фигура 64. Получаем массив размером 64*2^64^*64=2^76^ бит. Это примерно равно 10^10^ терабайт. На современных компьютерах столько памяти нет.

Подход магических битбордов решает задачу экономии памяти. Его идея в том, чтобы использовать **хэш-функцию**, которая вместо 64-битного битборда блокирующих фигур даст меньшее число.

Требования к хэш-функции такие:

1. Она должна работать быстрее, чем расчёт ходов скользящих фигур.

2. Для каждого битборда блокирующих фигур она даёт уникальное число на выходе. В противном случае возникнут [**коллизии**](https://ru.wikipedia.org/wiki/Коллизия_хеш-функции).

Рассмотрим пример. Предположим, что у нас есть такой битборд блокирующих фигур для ладьи на e4:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 1 0
  0 0 1 0 1 0 0 0
  0 0 0 0 0 0 1 0
  0 0 0 0 0 0 0 0
  1 1 0 0 r 0 1 0
  0 0 0 0 0 0 0 0
  0 0 1 0 1 0 0 0
  0 0 0 0 0 0 1 0
```

В этом случае нас интересуют только поля по горизонтали 4 и вертикали e. Поля по краям доски можно проигнорировать, поскольку они не влияют на набор полей, которые атакует ладья.

Итак, мы получили 10 клеток, которые называются маской ладьи. Эта маска выглядит так:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 1 0 0 0
  0 1 1 1 0 1 1 0
  0 0 0 0 1 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 0 0 1 0
```

Если наложить маску на битборд блокирующих фигур, мы получим только те биты, которые важны для расчёта ходов ладьи на e4:
{line-numbers: false, format: text}
```
  0 0 0 0 0 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 0 0 0 0
  0 0 0 0 0 0 0 0
  1 1 0 0 r 0 1 0
  0 0 0 0 0 0 0 0
  0 0 0 0 1 0 0 0
  0 0 0 0 0 0 0 0
```

Наша хэш-функция должна опускать эти биты в начало битборда. Тогда мы получим число, меньшее, чем 64-битный битборд. Всего таких чисел 2^10^, что значительно меньше чем 2^64^.

Хэш-функция умножает биты для расчёта ходов ладьи на некоторое "магическое" число. В результате такого умножения биты группируются вместе. Следующая операция — побитовый сдвиг группы битов вправо. В результате все важные нам биты оказываются в начале 64-битного числа.

Вопрос в том, как находить "магические" числа, которые группируют нужные нам биты битборда? Эти числа находятся [**полным перебором**](https://ru.wikipedia.org/wiki/Полный_перебор) для ладьи и слона на каждой клетке. После нахождения этих чисел они сохраняются в коде движка. То есть повторно находить их не нужно.

Полный алгоритм поиска хода с помощью магического битборда выглядит так:

1. Наложить на битборд блокирующих фигур маску фигуры (например маску ладьи на e4).

2. Передать результат наложения маски на битборд в хэш-функцию.

3. Использовать результат хэш-функции как индекс двумерного массива с рассчитанными ранее ходами.

I> Идею магических битбордов наглядно объясняет следующее [видео](https://www.youtube.com/watch?v=K0rp1vXV3Ek).

##### 3.5.2.2.2 Минимакс и альфа-бета отсечение

Механизм поиска Stockfish типичен для современных шахматных программ — это минимаксный поиск с альфа-бета отсечением.

Мы познакомились с общим принципом работы алгоритма минимакс и альфа-бета отсечения в разделах 2.5.2 и 2.5.3. Теперь рассмотрим, как именно они работают в шахматах.

Допустим для примера, что шахматный движок рассматривает два **полухода**. Термин полуход используют разработчики шахматных программ. Он означает ход одной из сторон: белых или чёрных. Два полухода составляют один полный ход.

Поскольку шахматы просчитать до конца нельзя, то минимакс ориентируется не на конечный результат партии, а на промежуточную статическую оценку позиции. Эта оценка рассчитывается для каждого полухода. Функция статической оценки возвращает положительное или отрицательное целое число. Чем оно больше, тем позиция лучше для шахматного движка. Чем число меньше — тем лучше для противника.

Шахматный движок использует поиск минимакс и статическую оценку. Так он находит свой лучший полуход, с учётом лучшего ответного полухода противника. В шахматах рассматривать только два полухода мало. Для качественной игры надо просчитывать более отдалённые последствия своих действий. Поэтому движок не останавливается на проверке одного полного хода, а просчитывает  полуходы обеих сторон дальше вглубь. Результат их статической оценки влияет на оценку полухода, который движок должен сделать прямо сейчас.

Сам по себе механизм минимакс очень ресурсоёмкий. На протяжении партии у каждой стороны в среднем есть по 30 возможных полуходов в каждой позиции. Получается, чтобы просчитать 10 всех возможных полуходов вперёд (или 5 полных ходов), надо проверить 30^10^ позиций. Это потребует слишком много времени.

Чтобы ускорить поиск минимакс, шахматный движок использует метод альфа-бета отсечения. Как она работает? Предположим, что шахматный движок рассматривает свой полуход A. Далее движок перебирает все возможные ответные полуходы противника. Пусть статическая оценка дала число +4 на лучший из ответов противника. Теперь движок переходит к следующему своему возможному полуходу B. Для примера оценка первого рассмотренного ответа противника оказалась -1. Это позволяет исключить из рассмотрения все остальные ответы противника на полуход B движка. Независимо от их статической оценки, полуход B всегда будет хуже, чем A. Причина в том, что в ответ на полуход B противник может создать позицию с оценкой -1 или хуже. Это значит, что для движка предпочтительнее полуход A, на который лучший ответ противника создаст позицию +4. Этот алгоритм даёт такой же результат, что и чистый минимакс поиск, только намного быстрее.

Применение метода альфа-бета не гарантирует высокую эффективность. Если в первую очередь движок проверяет посредственные ходы обеих сторон, то обрезание веток поиска будет происходить слишком поздно. Из-за этого будет обрезано только незначительное число веток и выигрыш в скорости поиска по сравнению с минимаксом будет незначительный.

Чтобы повысить эффективность альфа-бета отсечения, необходимо сортировать рассматриваемые ходы. В первую очередь надо проверять наиболее перспективные из них. Тогда большую часть посредственных ходов удастся отсечь. Эта оптимизация называется [**move ordering**](https://www.chessprogramming.org/Move_Ordering) (сортировка ходов) — сортировка ходов по их перспективности с учётом всей доступной на данный момент информации.

Stockfish реализует move ordering с помощью ряда эвристик под названием **истории ходов**. Всего таких эвристик шесть штук. Одна из них — это **continuation history** (история ответных ходов). Если Stockfish играет серию партий, он запоминает результаты своих ответных ходов на ходы противника. Например противник ходит конём на f6, а шахматный движок отвечает слоном на c4. Если ход оказался успешным, он получает положительную оценку. В противном случае оценка хода будет отрицательная. Далее когда противник ходит конём на f6 в другой позиции, Stockfish сортирует свой ход слоном на c4 в зависимости от его оценки по прошлым партиям.

Кроме истории ответных ходов Stockfish запоминает историю своих успешных последовательностей ходов. Например, в одной из сыгранных партий движок сходил конь f3. Его следующим ходом был конь g5. Статическая оценка дала ему высокий результат. Stockfish запоминает это. В другой партии после хода конь f3 движок рассмотрит последующий ход конь g5 в первую очередь.

##### 3.5.2.2.3 Выборочный поиск

Чтобы ускорить минимаксный поиск с альфа-бета отсечением, Stockfish использует разные эвристики **выборочного поиска** ([selective search](https://www.chessprogramming.org/Selectivity)). Такой поиск включает в себя три техники:

1. **Продление** ([extension](https://www.chessprogramming.org/Extensions)) — продолжение просчёта вглубь для перспективного хода.

2. **Сокращение** ([reduction](https://www.chessprogramming.org/Reductions)) — просчёт малоперспективного хода на меньшую глубину, чем обычно.

3. **Отсечение** ([pruning](https://www.chessprogramming.org/Pruning)) — удаление ветвей дерева поиска без их просчёта.

Продление выполняют в следующих случаях:

1. Произошло взятие.
2. Произошёл шах.
3. Ход единственный.
4. Ход гораздо лучше альтернатив.
5. При наличии проходной пешки.

Продления нужны, чтобы бороться с эффектом горизонта. Этот эффект приводит к неверной оценки позиции, когда движок достигает максимальной глубины поиска. Причина ошибки в том, что последующие не просчитанные ходы оппонента кардинально меняют позицию.

Рассмотрим пример. Допустим, что на максимальной глубине поиска движок видит взятие вражеского ферзя. После взятия оценка позиции очень высокая. Но на следующий ход противник может взять ферзя в ответ: то есть происходит размен. В результате позиция снова становится равная. Если ответное взятие оказалось за пределами глубины поиска — происходит эффект горизонта. Движок будет выбирать ходы, которые ведут его к взятию ферзя, пока ответное взятие не попадёт в максимальную глубину поиска. Тогда программа "увидит" размен и будет вынуждена полностью менять свой план.

Продления выполняются до спокойной позиции. В такой позиции нет взятий, шахов и единственных ходов. Эта техника называется **поиск спокойствия** ([quiescence search](https://www.chessprogramming.org/Quiescence_Search)). Спокойная позиция гарантирует, что у противника нет способа кардинально изменить позицию и её оценку для движка.

Сокращения и отсечения нужны, чтобы понизить коэффициент ветвления. В Stockfish этот коэффициент в среднем равен 1.7 или 1.8. На протяжении партии у каждой стороны есть около 30 возможных ходов в каждой позиции. Это означает, что движок отбрасывает 28 потенциальных ходов и рассматривает из них только 2. Если учесть просчёт ходов вглубь, то окажется что Stockfish отбрасывает 90% всего дерева поиска. Такая оптимизация значительно ускоряет поиск. Её недостаток в том, что программа может отсекать хорошие ходы, которые ведут к сильным комбинациям или мату.

Stockfish использует следующие алгоритмы сокращений:

1. [Late Move Reductions](https://www.chessprogramming.org/Late_Move_Reductions) (LMR) — уменьшение глубины поиска для ходов, которые алгоритм сортировки move ordering поместил в конец списка. В конце списка оказываются малоперспективные ходы, поэтому движок просчитывает их на меньшую глубину.

2. [Fail-High Reductions](https://www.chessprogramming.org/Fail-High_Reductions) (FHR) — уменьшение глубины поиска в спокойных позициях, когда на стороне делающего ход игрока есть существенное преимущество. [**Fail-high node**](https://www.chessprogramming.org/Fail-High) (или Cut-node) означает позицию, которая слишком хорошая для одной из сторон. При этом алгоритм поиска уже нашел ход оппонента, который предотвращает эту позицию. Вероятнее всего этот ход будет сделан, поэтому нет смысла просчитывать позицию глубоко. В этом случае происходит [beta-cutoff](https://www.chessprogramming.org/Beta-Cutoff), то есть отсечение по значению β.

3. [Null Move Reductions](https://www.chessprogramming.org/Null_Move_Reductions) (NMR). Допустим, что у одной из сторон есть существенное преимущество в рассматриваемой позиции. Если просто передать ход оппоненту и оценка позиции всё равно останется высокой, глубину поиска можно сократить. Передача ходу оппоненту называется [**null move**](https://www.chessprogramming.org/Null_Move). Такая передача запрещена правилами шахмат, но полезна для оптимизаций поиска.

Stockfish использует такие методы отсечения: 

1. [Mate Distance Pruning](https://www.chessprogramming.org/Mate_Distance_Pruning) работает, когда движок нашёл форсированный мат в несколько ходов. После этого он отсекает поддеревья, в которых невозможен мат за меньшее число ходов. Другими словами, когда мат найден, программа просчитывает самый короткий путь к нему.

2. [Futility pruning](https://www.chessprogramming.org/Futility_Pruning) выполняется за один ход до достижения максимальной глубины поиска. Эвристика отсекает узлы, оценка которых не может превысить уже найденную α. Чтобы подсчитать приблизительную оценку ещё не посещённых узлов, к оценке их корневого узла прибавляется константа под названием **запас бесполезности** (futility margin). Если сумма не превышает текущую α, то все подузлы отсекаются.

3. [SEE based pruning](https://www.chessprogramming.org/Static_Exchange_Evaluation). Статическая оценка обмена (Static Exchange Evaluation или SSE) проверяет последствия разменов на определённом поле, которые произойдут после выбранного хода. В результате вычисления SSE даёт вероятное изменение материала, которое будет потеряно или получено. Если функция SSE вернула отрицательное значение (т.е. проигрыш материала), Stockfish не рассматривает последствия хода, который ведёт к размену.

4. [History Leaf Pruning](https://www.chessprogramming.org/History_Leaf_Pruning) основана на эвристики истории ([history heuristic](https://www.chessprogramming.org/History_Heuristic)). Идея в том, чтобы считать сколько раз конкретный ход вызвал отсечение независимо от позиции, в которой он был сделан. Когда счётчик превышает пороговое значение, соответствующее этому ходу поддерево поиска отсекается.

5. [Multi-cut pruning](https://www.chessprogramming.org/Multi-Cut) — этот алгоритм выполняет сокращённый поиск в поддереве на небольшую глубину. Если из всех обойдённых узлов заданное число (например, три) оказалось fail-high node, то всё поддерево отсекается.

#### 3.5.2.3 Статическая оценка в Stockfish

Stockfish использует следующие механизмы для статической оценки позиций:

* Запрограммированная оценка.
* Нейронная сеть [**NNUE**](https://www.chessprogramming.org/Stockfish_NNUE).

Рассмотрим, как они работают.

##### 3.5.2.3.1 Запрограммированная оценка

До 2020 год Stockfish использовал вручную запрограммированную статическую оценку позиции. Эта оценка складывается из нескольких факторов.

Сначала Stockfish подсчитывает материал в заданной позиции. Это самая простая и быстрая оценка.

Затем проверяется пешечная структура. Для этого используются разные эвристики. Чтобы применить эти эвристики, алгоритм Stockfish перебирает все пешки на доске одна за другой. Для каждой из них выполняется ряд проверок. Вот несколько примеров:

1. Является ли пешка проходной?
2. Является ли пешка отсталой?
3. Является ли пешка сдвоенной?

В первом случае владеющий пешкой игрок получает бонус, а в двух других — штраф.

После проверки пешек Stockfish делает аналогичный перебор по фигурам. Для каждой из них проверяется мобильность. Для мобильности подсчитывается число клеток, которые:

1. Фигура атакует.
2. Не заблокированы своими фигурами.
3. Не бьются пешками противника.

С помощью таблиц подсчитанные клетки перекладываются на числовую оценку.

Следующая оценка Stockfish проверяет позицию короля. Она включает следующее:

1. Потенциальные шахи.
2. Число атак на **кольцо короля**. Этим кольцом называется восемь клеток вокруг короля.

Далее Stockfish с помощью эвристик проверяет очевидные угрозы. Например, что противник атакует ферзя или может напасть на него за один ход.

Если партия находится в эндшпиле, то для каждой позиции Stockfish оценивает возможность победы. Эта оценка складывается из проверки набора фигур и их расположения на доске. Прежде всего оценивается число пешек. Если пешек мало, то выиграть эндшпиль тяжело. Потому что часто победа достигается проведением пешки в ферзи. Другой пример с оценкой позиции фигур. Если все пешки на одном фланге, то выиграть ладейный эндшпиль сложно. Такая позиция также получит низкую оценку.

Последняя проверка эндшпиля называется **фактор масштабирования**. Этот термин означает коэффициент, на который умножается уже подсчитанная оценка эндшпиля. Умножение происходит при выполнении некоторых условий. Например, если у сторон остались разноцветные слоны, то коэффициент будет от 1/3 до 1/2. Таким образом понижается общая оценка эндшпиля (положительная или отрицательная). Причина в том, что при разноцветных слонах выиграть эндшпиль тяжело.

В 2020 году версия Stockfish 12 перешла на статическую оценку позиции с помощью нейронной сети NNUE.

##### 3.5.2.3.2 Нейронная сеть NNUE

Сеть NNUE (efficiently updatable neural network) разработал японский учёный [Ю Насу](https://www.chessprogramming.org/Yu_Nasu) в 2018 году. Она представляет собой сеть с прямой связью (FNN) категории shallow learning. Ю Насу разрабатывал NNUE специально для оценки текущей позиции фигур на доске. Она не учитывает временные зависимости и последовательности событий.

Первая версия сети NNUE анализировала позиции не в шахматах, а в японской адаптации этой игры под названием [сёги](https://ru.wikipedia.org/wiki/Сёги). Ю Насу помимо научной деятельности участвовал в проектах по адаптации движка Stockfish для сёги. [YaneuraOu](https://www.chessprogramming.org/YaneuraOu) — это один из таких проектов. Его разработчики применили новую сеть NNUE для статической оценки позиции. Это усилило игру движка примерно на 500 Эло.

В проекте YaneuraOu участвовал другой японский учёный [Хисаюри Нода](https://www.chessprogramming.org/Hisayori_Noda). В качестве эксперимента он интегрировал сеть NNUE в оригинальный Stockfish версии 10 в 2019 году. Тесты показали усиление игры движка на 50 Эло. В течение года этот проект развивался как форк Stokfish под названием [Stockfish NNUE](https://www.chessprogramming.org/Stockfish_NNUE). Он заинтересовал многих разработчиков шахматных движков.

В августе 2020 года система тестирования Fishtest показала, что Stockfish NNUE сильнее оригинального движка на 80 пунктов Эло. Тогда разработчики Stockfish решили включить сеть NNUE в следующий официальный релиз. Все наработки форка Stockfish NNUE добавили в код Stockfish.

2 сентября 2020 года вышел первый релиз Stockfish версии 12 с сетью NNUE. Он играл значительно сильнее, чем предыдущая версия. Разработчики продолжают совершенствовать и обучать сеть NNUE. Эта работа усиливает игру движка Stockfish с каждым следующим релизом.

Рассмотрим, как устроена NNUE. Чтобы понять её архитектурные решения, сначала надо разобраться, какие цели ставил Ю Насу перед этой сетью. Учёный разрабатывал модель для замены вручную запрограммированной статической оценки позиции в минимаксном поиске с альфа-бета отсечением. Чтобы модель работала лучше чем запрограммированная оценка, она должна удовлетворять следующим требованиям:

1. Скорость работы модели должна быть сопоставима скорости запрограммированной оценки. Если модель работает слишком медленно, шахматный движок будет оценивать намного меньше позиций в секунду. Это значительно снизит силу его игры.

2. Модель должна выполнять инкрементальные вычисления. Каждый ход лишь незначительно меняет состояние доски. Поэтому для анализа текущего хода сеть должна использовать свои расчёты, выполненные для предыдущего хода.

3. Модель должна эффективно работать на том же оборудовании, которое использует запрограммированная оценка. Другими словами сеть должна работать на обычных CPU, а не GPU.

Ю Насу решил, что именно инкрементальные вычисления — это главная отличительная черта его новой модели. Поэтому он назвал её **эффективно обновляемая нейронная сеть** (efficiently updatable neural network. Сокращенное название сети EUNN можно записать в обратном порядке букв как NNUE. Это слово напоминает имя японского мифического существа [Нуэ](https://ru.wikipedia.org/wiki/Нуэ). Из-за этого сходства Ю Насу и назвал свою сеть NNUE.

Чтобы удовлетворить требованиям к модели, учёный сформулировал три принципа её организации:

1. Сеть должна иметь относительно небольшое количество ненулевых входов.

2. Входные данные должны меняться как можно меньше между последующими оценками.

3. Сеть должна быть достаточно простой, чтобы выводить результат низкой точности в целочисленном виде.

Первый принцип означает, что при **масштабировании сети** входные данные должны стать **редкими**. Масштабировании сети означает увеличение в ней числа нейронов, уровней или входных параметров. Данные называются редкими, когда значительная их часть — это нули или очень маленькие значения.

Когда у сети мало ненулевых входов, понижается верхняя граница времени, необходимого для полной оценки входных данных с нуля. Именно благодаря первому принципу, сети NNUE могут быть большими, но при этом быстро оценивать позиции.

Следование второму принципу позволяет сети переиспользовать результаты оценки позиции с прошлого хода. Это даёт дополнительный выигрыш в скорости работы.

Третий принцип означает, что модель должна оперировать целыми числами, а не [**числами с плавающей запятой**](https://ru.wikipedia.org/wiki/Число_с_плавающей_запятой). Такой перевод нейронной сети на целочисленные расчёты называется **квантованием**. Квантование значительно ускоряет обработку входных данных модели, поскольку обычные CPU выполняют целочисленные операции быстрее. Минус квантования в потере точности. Оно приводит к ошибке вычислений, которая накапливается тем больше, чем глубже сеть.

Из-за накопления ошибки в результате квантования модель должна иметь минимальное число скрытых слоёв. Это также необходимо, чтобы удовлетворить третье требование — использовать то же оборудование, что и запрограммированная оценка. Как только модель попадает в разряд deep learning, ей перестаёт хватать производительности обычных CPU для эффективной работы.

NNUE — это собирательное название для моделей, которые удовлетворяют трём принципам организации Ю Насу. Детали реализации каждой модели могут различаться. Это значит, что современные шахматные движки используют разные вариации NNUE. Более того разные версии Stockfish используют разные архитектуры NNUE.

Рассмотрим архитектуру под названием [**HalfKp**](https://www.chessprogramming.org/Stockfish_NNUE#HalfKP). Она подробно описана разработчиками проекта [nnue-pytorch](https://github.com/official-stockfish/nnue-pytorch/blob/master/docs/nnue.md) на Github. Именно вариант HalfKp был впервые интегрирован в Stockfish версии 10.

Затем архитектуру HalfKp развивал польский учёный [Томаш Собчик](https://www.chessprogramming.org/Tomasz_Sobczyk), который также участвует в проекте Stockfish. Так появились варианты NNUE под названием [**HalfKA**](https://www.chessprogramming.org/Stockfish_NNUE#HalfKA), HalfKAv2 (используется в Stockfish 14) и HalfKAv2_hm (используется в последнем Stockfish 16). Томаш Собчик оптимизировал оригинальную архитектуру HalfKp, чтобы ускорить время обучения модели и сократить объём обучающего набора данных.

Архитектура HalfKp — это shallow learning модель, которая имеет три скрытых слоя. Для начала рассмотрим, как устроен её входной слой. Входные данные NNUE сети должны быть редкими. Поэтому Ю Насу предложил для них специальный формат.

Всего на шахматной доске 64 поля. Есть 6 типов фигур: пешка, конь, слон, ладья, ферзь и король. Фигуры могут быть двух цветов: черные и белые. В качестве входных данных модели закодируем позиции фигур. Тогда каждый нейрон входного слоя будет соответствовать одному набору из трёх элементов: `(поле, фигура, цвет)`. Всего таких наборов будет: `64 * 6 * 2 = 768`. Если на поле S есть фигура P цвета C, то мы устанавливаем в 1 вход сети, соответствующий набору `(S,P,C)`. В противном случае этот вход устанавливаем в 0. Тогда в любой возможной шахматной позиции будет не более 32 ненулевых входов, поскольку на доске может находится не более 32 фигур. При этом любой ход меняет не более 4 входов сети (это случай рокировки). В среднем же один ход меняет менее 3-х входов.

Рассмотрим пример кодирования шахматной позиции на вход модели. Иллюстрация 3-32 демонстрирует позицию с четырьмя фигурами.

{caption: "Иллюстрация 3-32. Шахматная позиция с четырьмя фигурами", height: "40%"}
![Шахматная позиция с четырьмя фигурами](images/Chess/Stockfish-HalfKp-input.png)

Четыре фигуры на доске кодируются такими наборами: `(A1, король, белые)`, `(C3, пешка, белые)`, `(B8, король, черные)`, `(D4, ладья, черные)`. Ход пешки на c4 изменит вход `(C3, пешка, белые)` на 0, а вход `(C4, пешка, белые)` на 1. Ход пешки cxd4 изменит вход `(C3, пешка, белые)` на 0, вход `(D4, пешка, белые)` — на 1 и `(D4, ладья, черные)` — на 0.

Итак мы получили редкие входные данные, которые незначительно меняются после каждого хода. Как именно нейронная сеть использует это преимущество и выполняет инкрементальные вычисления? Для этого у неё есть механизм под названием **накапливающий сумматор** (accumulator). Его реализует первый скрытый слой модели.

Ю Насу не остановился на полученном формате и продолжил его оптимизировать. Он хотел получить ещё более редкие входные данные для модели. Для этого в каждый набор входных данных он добавил позицию короля так: `(поле_короля, поле_фигуры, фигура, цвет)`. Эти наборы есть для всех типов фигур кроме короля. Такой формат позволяет модели лучше понимать расположение фигур относительно короля. Общее количество таки наборов будет равно: `64*64*5*2=40960`. В HalfKp реализации NNUE для Stokfish есть 64 неиспользуемых входных набора, что даёт общую сумму входов модели: `40960 + 64 = 41024`. Эти входы использовались в сёги, но оказали ненужны для шахмат.

Новый формат сделал входные данные более редкими. Его единственный минус — это ход короля, который стал очень дорогостоящим. Он приводит к изменению всех входов модели. Ю Насу посчитал это приемлемым компромиссом.

У внимательного читателя мог возникнуть вопрос: позиция какого короля (белого или чёрного) указывается во всех входных наборах модели? Ответ — обоих королей. Архитектура HalfKp имеет два накапливающих сумматора: для чёрных и для белых. Это означает, что количество входных наборов тоже удваивается: позиции всех фигур относительно белого короля и то же самое относительно чёрного.

Решение с двумя накапливающими сумматорами приводит к дополнительным вычислениям. Во-первых, каждый ход приводит к пересчётам в самих сумматорах. Во-вторых, результаты сумматоров надо свести в конечный результат, который передаётся на второй скрытый слой сети. В HalfKp архитектуре это выполняется простым объединением выходных векторов y1 и y2 обоих сумматоров. Преимущество двух сумматоров в увеличении точности модели.

Возникает ещё один вопрос. Если есть входные наборы с точки зрения белого короля и чёрного, то чем они различаются? Для эффективной работы сети нужно, чтобы эти входные наборы отличались между собой. В противном случае увеличения точности модели не будет. В HalfKp архитектуре эта проблема решается сменой цвета фигур для точки зрения чёрных.

Ещё раз обратимся к позиции на иллюстрации 3-32. С учётом разворота доски она кодируется следующими двумя наборами:

* С точки зрения белых: `(A1, C3, пешка, белая)`, `(A1, D4, ладья, чёрная)`

* С точки зрения чёрных: `(B1, C6, пешка, чёрная)`, `(B1, D5, ладья, белая)`

Пример показывает, что для точки зрения чёрных поменялся не только цвет фигур, но и номера полей. Это произошло потому, что белые фигуры всегда начинают игру на горизонталях 1 и 2. Следовательно, смена цвета чёрного короля означает, что он находится не на поле b8, а на b1. То же самое справедливо для всех остальных фигур.

Теперь рассмотрим архитектуру HalfKp. Иллюстрация3-34 демонстрирует её схему. Она достаточно сложная. Чтобы её понять, сначала надо разобраться в том, как работают отдельные слои нейронных сетей.

Каждый слой любой нейронной сети имеет две важные характеристики:

1. Тип слоя.
2. Функция активации его нейронов.

Самые распространённые типы слоёв следующие:

1. **Линейный слой** (linear layer)
2. Свёрточный слой (convolution layer)
3. Слой подвыборки (pooling layer)
4. Рекуррентный слой (recurrent layer)

Все слои NNUE сети относятся к линейному типу. Поэтому сконцентрируемся только на нём.

Тип слоя определяет, как именно его нейроны соединены с нейронами предыдущего слоя. В случае линейного типа это прямая связь без замыканий. При такой связи информация распространяется в одном направлении: от входов нейронов слоя к их выходам.

В NNUE сети все линейные слои являются **полносвязными** (fully connected). Полносвязным называется слой, каждый нейрон которого связан с каждым нейроном предыдущего слоя.

Предположим, что в некоторой сети есть два слоя C и D. Выходы нейронов слоя C связаны со входами нейронов слоя D. Способ этой связи определяет, как преобразуются данные при их передаче от слоя C к D.

Допустим, что слой D линейный и полносвязный. Назовём выходные значения предыдущего слоя C `out_C`, а входные значения D — `in_D`. Тогда `in_D` рассчитывается по следующей формуле:
{width: "30%"}
![](images/Chess/nnue-linear-layer-formula.png)

В ней используются следующие обозначения:

* x — вектор выходных значений слоя C: `out_C`
* A — матрица весов размера `(in_D, out_C)`
* b — вектор смещения (bias) с размером `in_D`
* y — вектор входных значений слоя D: `in_D`.

Обратите внимание, что для этой формулы тип слоя C не важен.

Теперь поговорим о функции активации. Строго говоря это харакетеристика не самого слоя, а его строительной единицы — нейрона. Обычно все нейроны одного слоя имеют одинаковую функцию активации. Это выгодно с точки зрения скорости и эффективности обучения модели. Только в некоторых специлизированных архитектурах нейронных сетей это правило не выполняется.

Функция активации — это операция каждого отдельного нейрона над своими входными значениями. В результате этой операции получаются выходные значения нейрона.

Вернёмся к примеру с двумя слоями C и D. Функция активации каждого нейрона слоя D получает на вход значение из вектора `in_D`. Позиция значения в векторе определяет, какой именно нейрон слоя D его получит.

Выходные значения всех нейронов слоя D объединяются в вектор и передаются в следующий за ним слой (например E). В зависимости от типа слоя E, над этим вектором снова происходит преобразование с участием матрицы весов. Связи между нейронами слоёв D и E определяют, какое значение из выходного вектора слоя D получит какой нейрон слоя E.

Нейроны всех скрытых слоёв NNUE сети Stockfish используют функцию активации **clipped ReLU**. Ещё раз напомню, что функция активации относится к каждому отдельному нейрону. Формула clipped ReLU в HalfKp архитектуре выглядит так:
{width: "50%"}
![](images/Chess/nnue-clipped-relu-layer-formula-127.png)

В ней используются следующие обозначения:

* x — входное значение нейрона
* y — выходное значение нейрона.

Иллюстрация 3-33 демонстрирует график функции clipped ReLU.

{caption: "Иллюстрация 3-33. Функция активации clipped ReLU", height: "40%"}
![Функция активации Clipped ReLU](images/Chess/nnue-clipped-relu-graph.png)

**ReLU** — это сокращение от rectified linear unit, что переводится как усеченное линейное преобразование. Обычная ReLU функция преобразует входное значение значение x в результат y от 0 до положительной бесконечности. Если входное значение меньше или равно нулю, то ReLU выдаёт ноль. В противном случае — входное значение.

Функция Clipped ReLU ведёт себя как ReLU, но с одним отличием: выходные значения в ней ограничены некоторой константой. В случае HalfKp архитектуры эта константа равна 127. Если входное значение clipped ReLU оказалось больше 127, то на выходе мы получим 127. Для всех остальных входных значений выход будет таким же, как и для обычной ReLU функции.

Зачем в сети NNUE нужны слои с функцией активации нейронов clipped ReLU? Они добавляют нелинейность в модель. Если бы в ней были только слои с линейной функцией активации, их можно было бы свернуть в один. Для этого достаточно перемножить их матрицы весов. В результате сеть не смогла бы научиться оценивать сложные шахматные позиции. С другой стороны, сеть с нелинейностью способна аппроксимировать сложные нелинейные функции. Оценка позиции как раз и является такой функцией.

В архитектуре HalfKp используется не ReLU, а clipped ReLU из-за квантования. Оно требует уменьшения **динамического диапазона** входных данных скрытого слоя. Динамический диапазон означает диапазон значений, который слой сети может принимать на вход. Для случая HalfKp этот диапазон ограничен 127. Это важно для высокой скорости работы модели.

Теперь мы готовы познакомиться с общей схемой архитектуры HalfKp. Её демонстрирует иллюстрация 3-34.

{caption: "Иллюстрация 3-34. Архитектура HalfKp сети NNUE для Stockfish 10", height: "40%"}
![Архитектура HalfKp сети NNUE для Stockfish 10](images/Chess/Stockfish-NNUE-HalfKp.png)

В левой части иллюстрации изображена шахматная доска с некоторой позицией. Ход в ней делают белые.

Справа от доски мы видим два прямоугольника: серый и под ним белый. Серый прямоугольник объединяет нейроны входного слоя сети, которые соответствуют позициям фигур относительно чёрного короля. В белом прямоугольнике — нейроны входного слоя сети, соответствующие позициям фигур относительно белого короля. В каждом прямоугольнике по 41024 нейрона, что в сумме составляет 82048.

Входной слой любой сети с прямой связью не имеет весов и смещения, а его нейроны не имеют функции активации. Этот слой не выполняет никаких вычислений, а просто передаёт входные данные модели на следующий за ним скрытый слой.

Первый скрытый слой модели разделён на две части также как входной слой. Каждая часть выполянет роль накапливающего сумматора для соответствующей ей входных данных. В каждой части слоя по 256 нейронов, что в сумме даёт 512. Это значит, что вектор выходных значений слоя имеет размер 512.

Нейроны первого слоя в розовом прямоугольнике получают на вход позиции фигур относительно чёрного короля. Нейроны в зелёном прямогульнике — позиции фигур относительно белого короля.

Первый скрытый слой модели линейный с функцией активации нейронов clipped ReLU. Это означает, что сначала вектор с входными значениями этого слоя умножается на матрицу весов. У каждой части слоя своя матрица. Каждая из них имеет размер 41024x256. Каждый вес в матрице — это целое число со знаком размерностью 16 бит. К результату умножения прибавляются смещения  размерностью 16 бит. Смещения хранятся в векторе из 256 элементов.

После умножения на матрицу весов и прибавления смещения получаются входные значения для нейронов первого скрытого слоя. Они передаются в виде вектора из 512 элементов размерностью 8 бит. К каждому из них применяется функция активации clipped ReLU. В результате получается вектор выходных значений первого скрытого слоя. Это 512 целых чисел в диапазоне от 0 до 127.

Накапливающий сумматор отвечает за инкрементальные вычисления. Модель сохраняет результат умножения входных данных первого скрытого слоя на матрицу весов. После очередного хода этот результат обновляется в зависимости от изменения входных наборов `(поле_короля, поле_фигуры, фигура, цвет)`. Для обновления слой обрабатывает два простых случая:

* Входной набор i был удалён (1->0), тогда из сохранённого результата вычитается столбец i матрицы весов A.

* Входной набор i был добавлен (0->1), тогда к сохранённому результату прибавляется столбец i матрицы весов A.

Далее к изменившимся входным значения первого скрытого слоя применяется функция активации clipped ReLU.

Второй скрытый слой HalfKp сети состоит из 32 нейронов. Он линейный с функцией активации clipped ReLU. Линейный тип слоя означает, что каждый его нейрон связан со всеми нейронами предыдущего слоя. Таким образом второй скрытый слой объединяет выходные данный обоих сумматоров.

Матрица весов второго слоя имеет размер 512x32. Каждый вес в ней — это целое число со знаком размерностью 8 бит. После умножения матрицы весов на вектор входных получается вектор из 32 элементов размерностью 32 бита. К каждому из элементов добавляется 32 битное смещение. Результат делится на 64. После этого над ним выполняется функция clipped ReLU. В результате получается вектор из 32 чисел в диапазоне от 0 до 127. Это выходные данные второго скрытого слоя модели. 

Третий скрытый слой также как и второй состоит из 32 нейронов. Опять же это линейный слой с функцией активации clipped ReLU. Он работает точно так же как и второй слой. Единственное отличие в том, что его матрица весов имеет размер 32x32.

Выходной слой модели состоит из одного нейрона. Это линейный слой с функцией активации `y = x/16`. Его матрица весов имеет размер 32x1. Каждый вес имеет размерность 8 бит. После умножения вектора входных значений слоя на матрицу весов получается одно 32 битное целое число. Это число делится на 16. Так сеть HalfKp получает конечную оценку позиции на доске.

Для подготовки сети NNUE в Stockfish применяется алгоритм обучения с учителем. Он принимает на вход 16 миллиардов позиций и оценку для каждой из них. Позиции берутся из реальных партий с разными дебютами. Так достигается их разнообразие. Предварительную оценку позиций выполняет шахматный движок с открытым исходным кодом Leela Chess Zero.

Алгоритм обучения подбирает веса в сети NNUE так, чтобы она давала оценку позициям близкую к оценкам Leela Chess Zero. Значение оценки интерпретируется так же, как и для вручную запрограммированных алгоритмов. Чем большее число вернула сеть NNUE, тем позиция лучше для движка. Чем число меньше — тем позиция хуже.

Результат обучения нейросети проверяется с помощью системы тестирования Fishtest. Если движок Stockfish с новой сетью NNUE показывает лучшую игру, чем текущая версия движка — тест считается пройденным. В этом случае новая версия сети NNUE попадает в очередной релиз Stockfish.

Несмотря на все оптимизации в архитектуре сети NNUE её скорость работы всё равно уступает вручную запрограммированной оценки. Поэтому эта оценка до сих пор используется в Stockfish. Она применяется в позициях, когда скорость работы важнее чем точность оценки. Например, когда у одной из сторон значительный материальный перевес: как минимум в ферзя или ладью.

### 3.5.3 AlphaZero

5 декабря 2017 года компания [DeepMind](https://en.wikipedia.org/wiki/Google_DeepMind) из Лондона опубликовала статью о своей новой системе [AlphaZero](https://en.wikipedia.org/wiki/AlphaZero). Система обучалась в течении 24-х часов и после этого смогла победить движок Stockfish версии 8. Принцип работы AlphaZero кардинально отличался от обычных шахматных движков с минимаксным поиском и вручную запрограммированной функцией оценки позиции. Это событие стало сенсацией в шахматном мире.

#### 3.5.3.1 AlphaGo

DeepMind пришли к своей революционной системе AlphaZero не сразу. Она появилась в результате развития более ранних систем AlphaGo и AlphaGo Zero.

Первый проект DeepMind, посвящённый настольным играм, назывался [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo). Его разработка началась в 2014 году. Исследователи DeepMind хотели выяснить, способна ли deep learning модель научиться играть в го на высоком уровне.

К началу 2010-х годов программы для го сильно уступали профессиональным игрокам. Они играли на среднем любительском уровне. Лучшие результаты показали две программы. В 2012 году программа [Zen](https://en.wikipedia.org/wiki/Zen_(software)) дважды выиграла у профессионального игрока Масаки Такемия (9 дан) с форой в пять и четыре камня. В 2013 году программа [Crazy Stone](https://en.wikipedia.org/wiki/Crazy_Stone_(software)) выиграла у Ёсио Исида (9 дан) с форой четыре камня.

Система AlphaGo была чисто исследовательским проектом. Разработчики экспериментировали с разными идеями и их комбинациями. В результате они спроектировали пять нейронных сетей. Некоторых из них обучались с учителем. В этом случае модель в качестве обучающих наборов получала позиции из профессиональных игр и их оценку. Другие сети обучались алгоритмом с подкреплением. В этом случае модель играла сама с собой и запоминала удачные ходы.

Финальная система AlphaGo работала как **ансамбль** из пяти нейронных сетей. Лучший ход выбирался поиском по дереву методом Монте-Карло.

I> **Ансамблем** алгоритмов машинного обучения называется комбинирование нескольких моделей для решения поставленной задачи. Каждая из моделей обучается отдельно. Когда они готовы, результаты их работы объединяются.

AlphaGo значительно превзошла все программы для игры в го, разработанные в 2010-х годах. Лушчая из них CrazyStone имела уровень Эло порядка 2000. Когда AlphaGo начала играть офицальные матчи, её уровень оказался равным примерно 3000 Эло.

В октябре 2015 года AlphaGo обыграла чемпиона Европы [Фань Хуэя](https://ru.wikipedia.org/wiki/Фань_Хуэй) со счётом 5-0. В марте 2016 года AlphaGo победила одного из лучших игроков в мире [Ли Седоля](https://ru.wikipedia.org/wiki/Ли_Седоль) из Южной Кореи со счётом 4-1. Затем в декабре 2016 года AlphaGo одержала 60 побед в онлайн играх с профессионалами и лучшими игроками го. В мае 2017 AlphaGo обыграла лучшего игрока в го [Кэ Цзе](https://ru.wikipedia.org/wiki/Кэ_Цзе) из Китая со счётом 3-0. После этого [Китайская Ассоциация Вэйци](https://ru.wikipedia.org/wiki/Китайская_ассоциация_вэйци) офицально присвоила системе 9-ый самый высокий профессиональный дан.

#### 3.5.3.2 AlphaGo Zero

Проект AlphaGo убедил исследователей DeepMind в том, что deep learning модель может играть в го на высоком уровне. Но несмотря на достигнутые результаты, у системы AlphaGo было несколько серьёзных проблем:

1. Чрезмерно сложная архитектура. Все пять нейронных сетей AlphaGo обучались отдельно. Для этого использовались разные алгоритмы, причём некоторые из них требовали большие обучающие наборы. Это сильно осложняло улучшение системы.

2. Алгоритм обучения некоторых нейронных сетей AlphaGo требовал трудоёмкой ручной [**настройки гиперпараметров**](https://ru.wikipedia.org/wiki/Оптимизация_гиперпараметров) (hyperparameter optimization). **Гиперпараметр** — это некоторое значение, которое используется для управления процессом обучения.

3. Система AlphaGo ввиду своей сложности требовала огромных вычислительных ресурсов для обучения и работы.

Команда DeepMind решила прекратить поддержку и развитие системы AlphaGo. Вместо неё запустили новый проект, получивший название [AlphaGo Zero](https://en.wikipedia.org/wiki/AlphaGo_Zero). DeepMind впервые объявили о своей новой системе 19 октября 2017 года в статье журнала Nature.

Вот основные отличия AlphaGo Zero от своего предшественника:

1. Модель использовала одну нейронную сеть вместо пяти. Эта сеть получала на вход текущую позицию камушков на доске и давала ей оценку.

2. В нейронную сеть были добавлены остаточные соединения (residual connections).

3. Модель обучалась по алгоритму с подкреплением без использования каких-либо обучающих данных, подготовленных человеком.

4. Более эффективное использование вычислительных ресурсов. Это ускорило обучение модели. Кроме этого поддерживать и совершенствовать модель стало значительно проще.

Система AlphaGo Zero училась играть в го исключительно на своих собственных играх. Слово "Zero" (ноль) в названии проекта означает, что при разработке системы не использовались никакие знания людей-экспертов в предметной области. То есть система, в отличие от AlphaGo, не изучала игры профессионалов.

Через три дня самостоятельного обучения AlphaGo Zero достигла уровня игры одной из первых версий AlphaGo. Через 21 день — AlphaGo Zero поднялась до уровня версии AlphaGo, которая обыграла 60 профессионалов онлайн. Через 40 дней — AlphaGo Zero превзошла все предыдущие версии AlphaGo.

Исследователи DeepMind задались вопросом: какой алгоритм обучения даёт лучшие результаты для игры в го? Чтобы ответить на этот вопрос, они разработали модель похожую на AlphaGo Zero. Эта модель обучалась по алгоритму с учителем на примерах позиций из профессиональных игр. Для неё и AlphaGo Zero одновременно запустили процесс обучения. Результаты сравнения двух моделей оказались неожиданными:

1. В самом начале обучения AlphaGo Zero проигрывала новой модели. Но после 20 часов обучения игра AlphaGo Zero стала сильнее. Через 40 часов уровень игры модели на обучении с учителем достиг примерно 3500 Эло и больше не рос. AlphaGo Zero продолжила совершенствовать свою игру и превысила уровень 4000 Эло.

2. Модели сравнили в точности предсказаний результата партии по текущей позиции на доске. Для этого использовались позиции из базы данных профессиональных игр. Сначала модель, обучаемая с учителем, давала лучшие предсказания. Но через 15 часов обучения модель, обучаемая без учителя, стала давать лучшие прогнозы.

3. Готовые модели проверили в предсказании следующего хода, который в данной позиции сделает профессиональный игрок. Снова для этого эксперимента использовали базу данных сыгранных профессионалами партий. Модель, обучаемая с учителем, давала более точные предсказания. Из этого исследователи DeepMind сделали вывод, что сила игры AlphaGo Zero превзошла уровень профессионалов. Во время своего обучения с подкреплением эта модель обнаружила закономерности в го, которые люди не понимают. Поэтому в показанных ей позициях AlphaGo Zero выбирала самый сильный ход с точки зрения её сверхчеловеческого уровня игры. При этом ходы профессионалов в этой позиции оказывались слабее и система их не предлагала.

Комбинирование поиска по дереву методом Монте-Карло с deep learning моделью, которая обучаётся по алгоритму с подкреплением, доказал свою эффективность в настольных играх.

#### 3.5.3.3 Особенности и архитектура AlphaZero

Разработчики AlphaGo Zero решили проверить, насколько универсален разработанный ими подход. Компания DeepMind запустила несколько проектов в [области биохимии](https://ru.wikipedia.org/wiki/AlphaFold), чтобы оценить эффективность аналогичных систем для научных задач. Кроме этого исследователи решили применить систему, аналогичную AlphaGo Zero, для других настольных игр. Для этой цели они начали новый проект под названием AlphaZero.

Команда DeepMind подготовила три экземпляра системы AlphaZero. Это были три модели с одинаковыми параметрами: архитектура нейронной сети, алгоритм обучения и гиперпараметры. Каждый экземпляр системы учился только одной из трёх игр: го, шахматы и сёги.

7 декабря 2017 года команда DeepMind опубликовала [статью](https://arxiv.org/abs/1712.01815) в журнале Science, посвящённую новой модели и её результатам. После 24 часов обучения с подкреплением каждый экземпляр AlphaZero превзошёл уровень профессионалов в той игре, которой он обучался. Соответствующие модели смогли обыграть сильнейшие на 2017 год программы: Stockfish в шахматах, [Elmo](https://en.wikipedia.org/wiki/Elmo_(shogi_engine)) в сёги и AlphaGo Zero в го.

Алгоритмы обучения AlphaZero и AlphaGo Zero отличаются следующим:

1. AlphaGo Zero оценивает вероятность результата партии, предполагая только два возможных исхода в го: победа или поражение. AlphaZero оценивает вероятность результата, учитывая ещё и ничьи в шахматах и сёги.

2. Алгоритм обучения AlphaGo Zero учитывал, что у каждой позиции в го есть 8 симметричных позиций. Они создаются поворотами доски вправо, влево и вокруг плоскостей симметрии. Поэтому в процессе обучения с подкреплением алгоритм случайным образом заменял реальную позицию на симметричную. Это повышало качество обучения. В шахматах и сёги симметрии позиций нет. Поэтому механизм замены не использовался для AlphaZero.

3. При обучении AlphaGo Zero применялись разные экземпляры модели. Самый сильный из них играл сам с собой. В результате обучения с подкреплением он настраивал свои параметры. Получившуюся новую модель сравнивали с прошлым самым сильным экземпляром. Если новая модель одерживала в среднем 55% побед, она становилась самым сильным экземпляром и играла сама с собой на следующей итерации. При обучении AlphaZero всегда применялся только один экземпляр модели. В результате обучения с подкреплением он последовательно настраивал свои параметры.

4. В процессе обучении AlphaGo Zero оптимизировались гиперпараметры обучения. В случае AlphaZero гиперпараметры не менялись на протяжении всего процесса обучения.

В качестве механизма поиска AlphaZero использует [**поиск по дереву методом Монте-Карло**](https://habr.com/ru/articles/282522/) (Monte Carlo tree search или MCTS). Статическую оценку позиции выполняет одна deep learning нейронная сеть.

#### 3.5.3.4 Поиск по дереву методом Монте-Карло

[**Методом Монте-Карло**](https://en.wikipedia.org/wiki/Monte_Carlo_method) называется широкий класс вычислительных алгоритмов, которые полагаются на повторную случайную выборку и статистический анализ для получения численных результатов.

В 1930-х годах физики начали экспериментировать с ранними вариантами метода Монте-Карло. Он давал хорошие результаты в физике элементарных частиц. Современную версию метода Монте-Карло разработал польский математик [Станислав Улам](https://ru.wikipedia.org/wiki/Улам,_Станислав) в конце 1940-х годов. Он учавствовал в  Манхэттенском проекте по разработке ядерного оружия. Новый метод позволил создать более точную модель [**диффузии нейтронов**](https://ru.wikipedia.org/wiki/Диффузия_нейтронов), чем применявшиеся ранее комбинаторные методы.

Хорошее интуитивное представление о методе Монте-Карло даёт рассказа Станислава Улама о том, как он пришёл к этой идее. В 1946 году учёный выздоравливал после болезни и раскладывал пасьянс, чтобы скоротать время. Он задался вопросом: какова вероятность того, что пасьянс из 52 карт сложится успешно? Для решения этой задачи Станислав попытался применить комбинаторные методы, но это оказалось слишком трудоёмко. Тогда учёный решил, что практичнее будет разложить пасьянс, например, сто раз и подсчитать долю успешных игр. Именно в этом сусть метода Монте-Карло: многократно повторять эксперимент и оценивать статистику полученных результатов.

Метод Монте-Карло нашел применение в поиске по дереву. В 1987 году Брюс Абрамсон из Колумбийского университета Нью-Йорка защищал докторскую диссертацию. В ней он предложил заменить статическую функцию оценки в минимаксном поиске на специальную модель. Она давала ожидаемый результат игры для заданного состояния игрового поля. Чтобы получить результат, модель начинала с некоторого хода, допустимого в заданной позиции, и проигрывала партию до конца. Во время такой игры наперёд каждая сторона делала случайные ходы, разрешённые правилами. Брюс применил свой подход для шамат и крестики-нолики. Он утверждал, что его **модель ожидаемого результата** (expected-outcome model) даёт точные и легко вычислимые результаты, которые не зависят от преметной области. Предложенный Брюс алгоритм стал прототипом поиска по дереву методом Монте-Карло.

Скорее всего, вы зададитесь вопросом: как статистический поиск по дереву может в принципе превзойти строго детерминированный минимаксный поиск с альфа-бета отсечением? Вы просто недооцениваете статистические данные.

Когда профессиональные шахматисты готовят свои дебюты, они в равной степени полагаются на собственный анализ и статистику. В интернете доступны сайты с перечнем часто отыгрываемых дебютов на турнирах. Например, сайт [365chess](https://www.365chess.com/opening.php) приводит следующую информацию:

1. Первый ход белых e4 был сыгран в офицальных партиях 1833019 раз. Он привел к следующим результатам:

* 38% партий закончились победой белых
* 30,3% партий — ничья
* 31,6% партий — победа черных.

2. Первый ход белых f3 был сыгран в официальных партиях 90 раз. Он привел к следующим результатам:

* 31,1% партий — победа белых
* 25,6% партий — ничья
* 43,3% партий — победа черных.

Теперь представьте, что вы играете турнирную партию и должны сделать первый ход за белых. Какой из ходов e4 или f3 вы предпочтёте? Профессиональные игроки предпочитают вариант e4. Кроме того, он даёт белым больше шансов на победу: 38% против 31,1%. Логичнее из двух предложенных ходов выбрать именно его.

Вернёмся у поиску методом Монте-Карло. Он перебирает возможные ходы в текущей позиции на доске. Проблема в том, что не существует готовой базы данных с результатами партии для каждого рассматриваемого хода. Однако, вычислительная мощность современных компьютеров позволяет быстро составить нечто похожее на такую базу данных.

Представьте себе ситуацию. Вы играете в шахматы, и ваш оппонент допускает ошибку. На своём текущем ходе вы можете взять ладью. Упростим пример и допустим, что вы выбираете между двумя возможными вариантами: брать или не брать ладью. Чтобы сделать выбор, вам нужна статистика. Тогда вы берёте другую доску и расставляете на ней позицю после вашего взятия ладьи. Далее из этой позиции вы играете партию до конца 1000 раз. Причём в каждой из этих партий вы просто делаете случайные ходы, допустимые шахматными правилами. В результате у вас есть процент побед, ничей и поражений для варианта взять ладью. Точно так же вы собираете статистику для варианта без взятия ладьи. Теперь достаточно сравнить, какой из двух ходов приведёт к потенциально большему числу побед. Скорее всего, ход со взятием ладьи даст больший процент побед и окажется лучшим. Вы возвращаетесь к доске, за которой вас ждёт оппонент, и играете лучший из двух ходов. Именно в этом заключается идея поиска по дереву методом Монте-Карло.

##### 3.5.3.4.1 Алгоритм MCTS

Рассмотрим подробнее алгоритм поиска методом Монте-Карло. Он заключается в циклическом повторении следующих четырёх шагов:

1. **Selection** (выбор)

2. **Expansion** (расширение)

3. **Simulation** (симуляция)

4. **Backpropagation** (обратное распространение)

Рассмотрим иллюстрацию 3-35. Она демонстрирует первый шаг selection (выбор) алгоритма поиска. Перед вами дерево игры в шахматы, который построил алгоритм поиска после нескольких итераций. Зеленые узлы соответствуют возможным ходам программы, которая применяет поиск методом Монте-Карло. Красные узлы — это ходы её оппонента.

Только что оппонент сделал ход A, который привёл к текущей позиции на доске. Теперь программа рассматривает свои возможные ответные ходы: B, C и D.

На первом шаге алгоритм выбирает, какой из узлов дерева ему исследовать. У этого узла должен быть минимум один потенциальный дочерний узел, для которого ещё не выполнялся шаг simulation (симуляция).

Для выбора узла нужна стратегия, которая определяет наиболее перспективные ходы. Допустим, что у программы есть такая стратегия и она выбрала узел B. На иллюстрации 3-35 этот выбор отмечен стрелкой.

{caption: "Иллюстрация 3-35. Первый шаг selection в поиске по дереву методом Монте-Карло", height: "30%"}
![Шаг selection в MCTS](images/Chess/monte-carlo-search-selection.png)

Второй шаг алгоритма expansion (расширение) демонстрирует иллюстрация 3-36. На этом шаге для выбранного узла B создаётся дочерний узел F. Он отмечен стрелкой. F соответствует потенциальному ходу оппонента, который разрешён правилами игры. Алгоритм может выбрать этот ход случайным образом или с помощью какой-то стратегии.

{caption: "Иллюстрация 3-36. Второй шаг expansion в поиске по дереву методом Монте-Карло", height: "30%"}
![Шаг expansion в MCTS](images/Chess/monte-carlo-search-expansion.png)

Третий шаг алгоритма simulation (симуляция) демонстрирует иллюстрация 3-37. На этом шаге программа запускает вычисления, чтобы получить статистическую информацию о новом узле. Самый простой способ — сыграть определённое количество партий, начиная с позиции в этом узле. Ходы в них выбираются случайным образом, пока партия не завершится победой, ничьей или поражением. Одна такая сыгранная партия называется **playout** (воспроизведение).

На иллюстрации 3-37 мы видим, что программа выполнила один playout. Он обозначен пунктирной стрелкой. В результате симуляции программа выиграла. 

{caption: "Иллюстрация 3-37. Третий шаг simulation в поиске по дереву методом Монте-Карло", height: "50%"}
![Шаг simulation в MCTS](images/Chess/monte-carlo-search-simulation.png)

Четвёртый шаг алгоритма backpropagation (обратное распространение) демонстрирует иллюстрация 3-38. На этом шаге программа передаёт статистическую информацию, полученную в результате simulation, для узла F в корень дерева игры A. Направление передачи информации обозначено стрелками.

{caption: "Иллюстрация 3-38. Четвёртый шаг backpropagation в поиске по дереву методом Монте-Карло", height: "30%"}
![Шаг backpropagation в MCTS](images/Chess/monte-carlo-search-backpropagation.png)

Каждый узел дерева игры хранит следующую информацию:

1. Число побед игрока, делающего ход в этом узле. Это сумма его побед во всех playout, выполненных для всех дочерних узлов.

2. Число выполненных playout для всех дочерних узлов.

В результате шага expansion алгоритм добавил узел F. В нём ход делает оппонент. Программа выполнила один playout для этого узла и он привёл к поражению оппонента.

Вернёмся к иллюстрации 3-37. Она показывает состояние узла B до симуляции партии в узле F. В узле B ход делает программа. Его состояние 1/3 означает, что для его дочерних узлов было выполнено три playout и в них один раз выиграла программа. На самом деле все три playout выполнялись для узла E с состоянием 2/3. Обратите внимание, что две победы оппонента в трёх playout в узле E, означают одну победу программы в трёх playout в узле B.

Иллюстрация 3-38 показывает обновлённое состояние 0/1 узла F. Учитывая это, программа обновляет состояние узла B до 2/4. Это означает, что в двух дочерних узлах E и F в сумме было выполнено четыре playout. В двух из них победил оппонент. Следовательно, два других playout привели к победе программы.

После обновления состояния узла B, программа переходит к узлу A. Это текущая позиция после хода оппонента. На иллюстрации 3-37 состояние A равно 9/12. Программа обновляет это значение до 9/13. Потому что для одного из дочерних узлов A (узла F) выполнился один playout, который привел к поражению оппонента.

Предположим, что у программы закончилось время на поиск по дереву. Теперь она должна выбрать свой ход. Из трёх вариантов B, C и D наилучшим будет ход B. Согласно статистике, которую программа успела собрать, этот ход в 50% случаев приводит к победе и в 50% к поражению. При этом ход C приводит к 100% поражению, а ход D — к поражению с вероятностью 60%.

Для простоты нашего примера мы проигнорировали случаи, когда шаг simulation приводит к ничьей. Если это учесть, то возможные результаты каждого playout будут такими:

* 1 — победа
* 0.5 — ничья
* 0 — поражение.

В этом случае состояния узлов на шаге backpropogation рассчитываются точно так же как для целочисленных результатов.

Иллюстрация 3-39 демонстрирует шаг backpropogation, когда playout в узле F закончился ничьей (результат 0.5/1).

{caption: "Иллюстрация 3-39. Результат backpropagation в для дробного результата simulation", height: "30%"}
![Backpropagation для дробного результата simulation](images/Chess/monte-carlo-search-backpropagation-fraction.png)

Рассмотрим порядок backpropogation на иллюстрации 3-39 по шагам:

1. После симуляции одного playout для узла F, необходимо обновить состояние его родительского узла B.

2. Для обновления узла B сначала надо посчитать сумму playout у всех его дочерних узлов (E и F). Она равна: `3 + 1 = 4`. Запишем 4, как число playout, выполненных для узла B.

3. Затем посчитаем сколько playout закончились победами игрока, делающего ход в узлах E и F. Сумма побед равна: `2 + 0.5 = 2.5`.

4. Посчитаем сколько побед у игрока, делающего ход в узле B. Для этого вычтем из общего числа playout в узле B число побед игрока, делающего ход в дочерних узлах E и F. Получим `4 - 2.5 = 1.5`. Запишем это число в состояние узла B.

Следуя этому же алгоритму, мы обновляем состояние корневого узла A. Сначала находим сумму playout в его дочерних узлах B, C и D: `4 + 3 + 6 = 13`. Затем число побед игрока, делающего ход в этих узлах: `1.5 + 0 + 2 = 3.5`. Наконец, вычитаем из суммы playout число побед в узлах B, C и D: `13 - 3.5 = 9.5`. Мы получили новое состояние узла A 9.5/13.

##### 3.5.3.4.2 Формула UCT

Когда мы знакомились с алгоритмом поиска методом Монте-Карло и его первым шагом selection, мы говорили про стратегию выбора узла. Она должна отличать перспективные ходы для их дальнейшей проверки. Давайте рассмотрим, как именно это работает.

Существует две стратегии для выбора узла в дереве игры:

1. **Exploration** (исследование) — посещать узлы с наименьшим числом симуляций для дочерних узлов.

2. **Exploitation** (эксплуатирование) — глубже проверять узел с максимальным числом побед.

Очевидно, что следование только одной из этих стратегий неоптимально. Только exploration не даст возможности глубоко просчитать перспективные ходы. Таким образом у лучшего найденного хода может оказаться **опровержение**, которое алгоритм поиска не увидел.

I> Опровержение в шахматах — это ход или серия ходов, доказывающих несостоятельность действий противника.

Если следовать только стратегии exploitation, то лучшие ходы остануться вне поля зрения алгоримта поиска. Он будет глубоко просчитывать несколько первых попавшихся ходов и выберет наилучший из них.

Мы уже обсуждали эти стратегии в разделе "2.6.2.3 Обучение с подкреплением". Там речь шла о проблеме многорукого бандита. В случае поиска по дереву методом Монте-Карло задача та же самая — найти оптимальный компромисс между exploration и explotation.

В 2006 году венгерские учёные в области информатики [Левенте Кочиш](https://www.chessprogramming.org/Levente_Kocsis) и [Чаба Сепешвари](https://www.chessprogramming.org/Csaba_Szepesvári) предложили формулу под названием [**Upper Confidence bounds applied to Trees**](https://www.chessprogramming.org/UCT) или UCT (верхние границы уверенности, применяемые к деревьям).

Предположим, что алгоритм поиска находится в некотором узле дерева i. Формула UCT вычисляет оценку для его каждого дочернего узла j:
{width: "50%"}
![](images/Chess/uct-formula.png)

В ней используются следующие обозначения:

* X~j~ — коэффициент выигрыша для дочернего узла j. Рассчитывается как w~j~/n~j~. То есть отношение числа побед w~j~ к количеству посещений узла n~j~.

* n~i~ — количество посещений родительского узла i.

* n~j~ — количество посещений дочернего узла j.

* C — константа, задающее соотношение между шириной и глубиной поиска. Чем она больше, тем глуюже будет поиск.

Первая часть формулы (X~j~) соответствует стратегии exploitation. Это значение больше для дочерних узлов с высоким коэффициентом выигрыша. Вторая часть формулы соответствует стратегии exploration. Это значение выше для дочерних узлов с маленьким числом посещений и соответственно выполненных playout.

На шаге selection алгоритм поиска методом Монте-Карло должен выбирать дочерний узел j с максимальной оценкой UCT~j~.

Формула UCT предлагает альтернативу для стратегии финального выбора хода. Ранее мы рассматривали шаги поиска методом Монте-Карло. После выполнения backpropogation мы получили состояние дерева как на иллюстрации 3-38. Из этого состояния мы сделали вывод, что наилучшим ходом будет B. В этом узле у программы самый высокий коэфициент побед.

С другой стороны, если бы мы применяли формулу UCT для всех шагов selection, то лучшим ходом оказался бы D. Почему? Поиск методом Монте-Карло с формулой UCT чаще посещает самые перспективные дочерние узлы. Это означает, что узел с наибольшим числом посещений и есть наилучший.

Для выбора дочернего узла на шаге selection у формулы UCT есть несолько альтернатив. Одна из них — нейронная сеть. Она должна отличать более перспективные ходы в текущей позиции. В этом случае нейронная сеть сможет направлять шаги selection и expansion. Таким образом алгоритм поиска потратит меньше времени на анализ бесперспективных ходов.

##### 3.5.3.4.3 Преимущества и недостатки MCTS

Поиск по дереву методом Монте-Карло разрабатывался как универсальный алгоритм. Брюс Абрамсон особенно почёркивал его независимость от предметной области. Учёный применял его в различных играх с двумя участниками. А в 1989 году австрийские учёные Вольфганг Эртель, Иоганн Шуман и Кристиан Саттнер применили MCTS в своей системе для автоматического доказательства теорем.

В 1993 году немецкий учёный Бернд Брюгманн из института физики общества Макса Планка впервые применил поиск методом Монте-Карло в программе для игры в го. В своей [статье](http://www.ideanest.com/vegos/MonteCarloGo.pdf) учёный утверждает, что программа играла на начальном любительском уровне 25 кю на уменьшеной доске 9x9 линий. При этом в неё не закладывалось никаких знаний об игре го кроме правил.

Программы для игры в го продолжали развиваться на протяжении 1990-х и 2000-х годов. Самые сильные из них применяли тот или иной вариант поиска меотдом Монте-Карло. В 2012 году программа Zen впервые выиграла матч у любителя 2-ого дана на стандартной доске 19x19 линий. В этой программе не использовались модели машинного обучения, а только MCTS с некоторыми эвристиками.

Поиск методом Монте-Карло оказался особенно успешным в играх и задачах с очень высоким **фактором ветвления**. Фактор ветвления — это среднее количество вариантов действий у игроков на каждом ходе. В шахматах он равен 35, а в го — 250. Именно из-за высокого фактора ветвления минимаксный поиск с альфа-бета отсечением плохо справляется с деревом игры го.

Ещё одно преимущество поиска методом Монте-Карло — это слабая зависимость от функции оценки. Эта функция играет ключевую роль в поиске альфа-бета. Если оценка низкого качества, то поиск вместо лучших ходов выбирает посредственные. В MCTS важнее количество симуляций и статистика их результатов. С другой стороны для игр с низким фактором ветвления альфа-бета поиск работает быстрее и даёт более точный результат чем MCTS.

Поиск методом Монте-Карло хорошо работает вообще без функции оценки. Для него достаточно подготовить модель игровой механики: допустимые ходы в каждой позиции и условия окончания партии. Таким образом MCTS преминим в играх и задачах, для которых ещё не разработана подходящая теория.

У поиска методом Монте-Карло есть несколько недостатков. Один из них — алгоритм всегда предполагает, что работает в стохастической среде. В конкурентной среде, когда оппонент активно противодействует, алгоритму MCTS сложнее находить оптимальные действия.

Ещё один недостаток MCTS — это ошибка при оценки ходов у которых есть опровержение, состоящее из последовательности лучших ходов. MCTS может упускать из виду такие последовательности из-за своей стратегии выбора узлов на шагах selection и expansion.

Поиск методом Монте-Карло чувствителен к следующим параметрам:

1. Константа C в формуле UCT, которая определяет соотношение стратегий exploration и exploitation.

2. Число симуляций для проверяемых дочерних узлов.

Подобрать оптимальные значения этих параметров для конкретной задачи бывает сложно и трудоёмко.

Поиск методом Монте-Карло требует намного больше ресурсов чем альфа-бета поиск. Ему нужны большие вычислительные мощности для выполнения многократных симуляций и больше памяти для хранения их результатов. Только при условии неограниченного времени работы результат поиска методом Монте-Карло с формулой UCT сходится к результату минимаксного поиска.

#### 3.5.3.5 Свёрточная нейронная сеть

В нейронной сети AlphaZero применяются **свёрточные слои** (convolutional layer). Поэтому перед тем как изучить сеть AlphaZero, познакомимся со свёрточными нейронными сетями (CNN).

До начала 1980-х годов задача распознавания изображений решалась моделями с архитектурой [многослойного перцептрона](https://en.wikipedia.org/wiki/Multilayer_perceptron). Это универсальная архитектура, которая также может решать задачи классификации, регрессии и апроксимации функций.

Если применять многослойный перцептрон для распознавания изображений, возникает несколько проблем. Главная из них связана с большим количество связей между нейронами. В сети перцептрона все слои линейные и, следовательно, полносвязные. Каждый нейрон следующего слоя связан с каждым нейроном предыдущего. Это приводит к проблеме известной как [**проклятие размерности**](https://en.wikipedia.org/wiki/Curse_of_dimensionality#Machine_learning).

Суть проклятия размерности в том, что небольшое увеличение разрешения входного изображения приводит к взрывному росту связей между нейронами в сети. Рассмотрим пример. Предположим, что модель многослойного перцептрона обрабатывает [RGB изображение](https://ru.wikipedia.org/wiki/RGB) с тремя цветовыми каналами (красный, зелёный, синий). Его размер 32x32 пикселя. Тогда во входном слое модели должно быть по три нейрона на каждый пиксель. То есть список входов выглядит примерно так:

* пиксель с координатой (1, 1) канал красного цвета
* пиксель с координатой (1, 1) канал зелёного цвета
* пиксель с координатой (1, 1) канал синего цвета
* пиксель с координатой (2, 1) канал красного цвета
* пиксель с координатой (2, 1) канал зелёного цвета
* пиксель с координатой (2, 1) канал синего цвета
* пиксель с координатой (3, 1) канал красного цвета
* пиксель с координатой (3, 1) канал зелёного цвета
* пиксель с координатой (3, 1) канал синего цвета
и т.д.

В случае 8-битной кодировки цветов каждый из этих нейронов принимает на вход число от 0 до 255. 0 соответствует минимальной интенсивности цвета у данного пикселя, а 255 — максимальной. Всего входных нейронов у модели будет `32 * 32 * 3 = 3072`.

Перейдём к первому скрытому слою. Каждый нейрон этого слоя соединяется с каждым нейроном входного слоя. Таких соединений будет 3072. Допустим для примера, что в первом скрытом слое будет 512 нейронов. Тогда мы получим `3072 * 512 = 1572864` соединений между слоями. У каждого соединения есть вес, который надо корректировать в процессе обучения.

Теперь представим, что многослойный перцептрон обрабатывает RGB изображение размером 200x200 пикселей. В этом случае входной слой вырастет до `200 * 200 * 3 = 120000` нейронов. Число соединений между входным и первым скрытым слоем вырастет до `120000 * 512 = 61440000`. Именно столько весов надо подобрать при обучении модели.

Мы увеличили размер изображения в 6,25 раза, в результате число соединений между слоями выросло примерно в 39 раз. Из-за такого взрывного роста соединений многослойный перцептрон не может обрабатывать изображения с высоким разрешением. Это вычислительно неразрешимая задача.

У многослойного перцептрона есть и другие проблемы. Полносвязные слои не учитывают пространственную структуру данных. Что это значит? Некоторые пиксели изображения расположены рядом друг с другом. Другие находятся на разных концах картинки. Перцептрон обрабатывает их одинаково. Такой подход малоэффективен. Причина в том, что изображения состоят из наборов близко расположенных элементов (например, линий), которые складываются в определённые шаблоны (например, контуры деревьев). Эти отношения между соседними элементами очень важны, но перцептрон не способен их учесть.

Свёрточная нейронная сеть (CNN) — это специальная архитектура для распознавания изображений. Она решает проблемы многослойного перцептрона.

В основе архитектуры CNN лежит идея применения фильтров (filter) для извлечения признаков (features) изображённого объекта. Это очень похоже на то, как мозг человека распознаёт объекты. Например, чтобы различать лица, мы ориентируемся на следующие признаки: контур всего лица, линии носа, ушей и глаз, оттенок кожи, цвет волос и глаз. Фильтры выделяют из исходного изображения ключевые признаки и отбрасывают несущественные детали. Таким образом уменьшается объём информации для обработки на следующем этапе.

Рассмотрим, как именно работают фильтры на примере. В качестве исходного изображения возьмём известный фрагмент [фотографии Лены Сёдерберг](https://ru.wikipedia.org/wiki/Лена_(изображение)) (см. иллюстрацию 3-40).

{caption: "Иллюстрация 3-40. Фрагмент фотографии Лены Сёдерберг", height: "30%"}
![Фрагмент фотографии Лены Сёдерберг](images/Chess/lena.png)

Применим к этой фотографии фильтр, который [выделяет границы объектов](https://ru.wikipedia.org/wiki/Выделение_границ). После его применения мы ожидаем, что линии лица и шляпы станут хорошо различимы. Сам фильтр представляет собой следующую матрицу размера 3x3:
{width: "25%"}
![](images/Chess/sobel-vertical-kernel.png)

Это вертикальный фильтр [**оператора Собеля**](https://ru.wikipedia.org/wiki/Оператор_Собеля). Сам оператор заключается в применении двух фильтров (горизонтального и вертикального) размера 3x3 к исходному изображению. Их результат комбинируется в выходное изображение, на котором чётко видны границы объектов. Такое изображение, полученное в результате наложения фильтров, называется **картой признаков** (feature map).

Иллюстрация 3-41 демонстрирует карту признаков после применения вертикального фильтра оператора Собеля.

{caption: "Иллюстрация 3-41. Карта признаков после применения фильтра", height: "30%"}
![Карта признаков после применения фильтра](images/Chess/lena-edge-detection-filter.png)

Наложение фильтра сделало линии границ объёктов более отчётливыми. Они хорошо выделяются на чёрном фоне. Это упрощает следующие шаги по распознаванию лица.

Python скрипт для применения фильтра описан в приложении 4.2.1 и доступен на [Github](https://github.com/ellysh/ai-in-strategy-games/blob/master/manuscript/resources/code/Chess/sobel-vertical-filter.py).

Хороший пример использования оператора Собеля описан в следующей [статье](https://www.adeveloperdiary.com/data-science/computer-vision/how-to-implement-sobel-edge-detection-using-python-from-scratch/). В ней автор применяет и горизонтальный и вертикальный фильтры. Затем он комбинирует их результаты. Исходный код этого примера доступен на [Github](https://github.com/adeveloperdiary/blog/tree/master/Computer_Vision/Sobel_Edge_Detection).

Типичная CNN сеть последовательно выполняет следующие операции над входными данными:

1. **Свёртка**

2. **Пакетная нормализация** (batch normalization)

3. Применение **функции активации** (activation function)

4. **Подвыборка** (pooling)

5. **Сглаживание** (flattening)

Некоторый из этих операций могут повторяться несколько раз.

Иллюстрация 3-42 демонстрирует архитектуру типичной CNN сети для распознавания изображений. Пример задачи для такой сети — определить вид животного на картинке: собака или кошка.

{caption: "Иллюстрация 3-42. Архитектура типичной CNN сети", height: "60%"}
![Архитектура CNN сети](images/Chess/typical-cnn-architecture.png)

Входные данные модели (Input) передаются на первый слой свёртки (Convolution). Этот слой изображает прямоугольник красного цвета. Выходные данные этого слоя передаются на следующий за ним слой подвыборки (Pooling). Затем пара слоёв свёртки и подвыборки повторяется. Обратите внимание, что параметры этих слоёв отличаются от предыдущих.

Все слои свёртки и подвыборки выполняют одну задачу: **извлечение признаков** (feature extraction) из исхдного изображения. На иллюстрации 3-42 эти слои объединяются в один блок розового цвета для наглядности.

После извлечения признаков модель решает задачу **классификации** (classification). За неё отвечают слои, объединённые в зеленый блок. Первый из них слой сглаживания (Flatten) получает данные из последнего слоя подвыборки. Свой результат он передаёт в соединённые последовательно линейный полносвязные слои (Dense), которые и выполняют классификацию. Результат их работы и является результатом (Output), который выдаёт модель.

##### 3.5.3.5.1 Операция свёртки

Мы рассмотрели применение фильтра к изображению. Эта операция называется [**свёрткой**](https://proglib.io/p/convolution) (convolution). Именно из-за этой операции архитектура CNN и получила своё название.

Рассмотрим подробнее, как работает свёртка. Для простоты допустим, что у нас есть чёрно-белое изображение размером 5x5 пикселей. У него есть один канал серого цвета. Таким образом, каждому пикселю соответствует значение от 0 (белый цвет) до 255 (чёрный цвет).

Компьютер представляет наше изображение в виде двумерного массива пикселей размером 5x5. Пусть он выглядит следующим образом:
{width: "40%"}
![](images/Chess/convolution-source-image-5x5.png)

В CNN сетях перед работой с изображением все значения его пикселей **нормализуют**. Нормализация — это приведение числа к некоторому заданному диапазону. В случае изображений, значения его пикселей приводят к диапазону от 0 до 1. Для простоты нашего примера, мы не будем выполнять нормализацию.

Применим к этому изображению тот же фильтр, который мы использовали для обработки иллюстрации 3-40. Представим его в виде двумерного массива размером 3x3:
{width: "25%"}
![](images/Chess/convolution-kernel-3x3.png)

Эта матрица содержит веса признаков и называется **ядром** (convolution kernel). Она проходит по матрице исходного изображения с заданным шагом, начиная с левого верхнего угла. На каждом шаге выполняется поэлементное умножение: число из ячейки исходного изображения умножается на число из перекрывшей её ячейки ядра. Обратите внимание, что это не [**умножение матриц**](https://ru.wikipedia.org/wiki/Умножение_матриц), а [**произведение Адамара**](https://ru.wikipedia.org/wiki/Произведение_Адамара). В литературе обе эти операции могут обозначаться одинаково: `*`, `×` или `⋅`. Результаты перемножения ячеек суммируются в однин элемент выходного массива.

Рассмотрим подробнее поэлементное умножение. На первом шаге ядро перекрывает ячейки исходного изображения, выделенные зелёным цветом:
{width: "40%"}
![](images/Chess/convolution-source-image-5x5-highlight-first.png)

Перемножаем перекрытые ячейки изображения и ядра, складываем результаты и получаем следующее:
{line-numbers: false, format: text}
```
19 *  1 + 10 *  2 + 39  *  1 +
30 *  0 + 68 *  0 + 238 *  0 +
45 * -1 + 6  * -2 + 59  * -1 = -38
```

Мы получили значение -38 первого элемента в первом ряду карты признаков. Обратите внимание, что карта признаков — это не изображение, а его элементы — не цвета пикселей. В примере с фотографией Лены Сёдерберг мы для наглядности визуализировали карту признаков, полученную после свёртки. Для такой визуализации необоходимо сопоставить значения из карты признаков с некоторыми цветами. Есть разные методы такого споставления. Например, функция [`imshow`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) из библиотеки Python Matplotlib предлагает целый ряд [**цветовых карт**](https://matplotlib.org/stable/users/explain/colors/colormaps.html) (colormap).

Допустим, что мы выбрали шаг равный единице. Тогда ядро смещается на один столбец вправо. Оно перекроет следующие ячейки исходного изображения:
{width: "40%"}
![](images/Chess/convolution-source-image-5x5-highlight-second.png)

Снова выполняем произведение Адамара. Затем суммируем получившиеся числа:
{line-numbers: false, format: text}
```
10 *  1 + 39  *  2 + 48  *  1 +
68 *  0 + 238 *  0 + 73  *  0 +
6  * -1 + 59  * -2 + 202 * -1 = -190
```

Второй элемент в первом ряду карты признаков равен -190.

Когда ядро достигает правого края изображения, оно смещается вниз на один ряд. После этого ядро движется снова с левого края изображения направо с шагом в один столбец. На последнем шаге ядро перекроет следующую часть изображения:
{width: "40%"}
![](images/Chess/convolution-source-image-5x5-highlight-last.png)

После того, как ядро пройдёт по всему исходному изображению, на выходе мы получим следующую карту признаков:
{width: "25%"}
![](images/Chess/convolution-result-image-3x3.png)

Python скрипт для расчёта результирующего изображения для нашего примера описан в приложении 4.2.2. Он также доступен на [Github](https://github.com/ellysh/ai-in-strategy-games/blob/master/manuscript/resources/code/Chess/apply-filter-manually.py).

Вы заметили, что размер карты признаков уменьшился до 3x3 по сравнению с размером исходного изображения 5x5? Это связано с потерей информации о пикселях на границах. Если эти пиксели важны, мы можем расширить исходное изображение. Для этого дополним его по краям занулёнными пикселями. Эта операция называется **выравниванием**. 

После выравнивания наше исходное изображение станет таким:
{width: "40%"}
![](images/Chess/convolution-source-image-aligned-7x7.png)

Синим цветом отмечены занулённые пиксели, которые мы добавили. Теперь если мы выполним свёртку для выровненного изображения, на выходе получится карта признаков размером 5x5. Информация о пикселях на границах не будет потеряна.

Конечная и начальная позиции ядра при обработке выровненного изображения выглядят так:
{width: "80%"}
![](images/Chess/convolution-source-image-aligned-7x7-highlight.png)

Как операция свёртки решает проблему проклятия размерности? В нашем примере исходное изображение имеет размер 5x5 пикселей. Это означает, что входной слой модели имеет `5 * 5 = 25` входных признаков. Карта признаков на выходе имеет размер 3x3. Следовательно, число выходных признаков равно `3 * 3 = 9`. Если для обработки изображения применить полносвязный слой нейронов, в нём должно быть `25 * 9 = 225` весовых параметров. Если же применить операцию свёртки, число весовых параметров будет равно размеру ядра 3x3. Это значит, что весовых параметров только `3 * 3 = 9`. Увеличение размера исходного изображение никак не повлияет на размер ядра.

Для простоты примера мы применили вертикальный фильтр оператора Собеля к входному изображению. Его ядро имеет константные весовые параметры. На практике параметры ядра подбираются в процессе обучения модели.

Другая проблема многослойного перцептрона — работа с пространственной структурой данных. Операция свёртки позволяет модели учесть эту структуру. Один и тот же набор весовых параметров ядра применяется к разным областям изображения. Таким образом модель находит одни и те же признаки (например, линии), независимо от их расположения на изображении. На следующем скрытом слое сети обнаруженные признаки обобщаются до шаблонов. Далее шаблоны складываются в объекты. Так свёртка естественным образом восстанавливает иерархию абстракций элементов изображения.

Мы рассмотрели свёртку на примере чёрно-белого изображения. У него есть только один канал серого цвета. Если исходное изображение цветное с тремя каналами (RGB), то говорят об операции **свёртки по объёму** (convolutions over volume). В этом случае для каждого канала нужно отдельное ядро. Все три ядра вместе образуют один фильтр. То есть **фильтр** — это набор ядер, каждое из которых соответствует одному каналу цвета. При этом сами ядра могут между собой различаться.

Допустим, что размер исходного изображения равен `N x N x C`, где `N` — число пикселей, а `C` — число каналов цвета. Тогда для его обработки нужен фильтр размером `F x F x C`, где `F` — число элементов, а `C` — число ядер. После свёртки по объёму  с шагом 1 карта признаков на выходе будет иметь размер `(N - F + 1) x (N - F + 1)`. Обратите внимание, что третье измерение для цветовых каналов пропадает.

Интуитивно мы воспринимаем исходное цветное изображение, как двумерное. Но фактически оно является трёхмерным, если учесть каналы цвета. Именно из-за этого третьего измерения возникает понятие **объёма** (volume). Для его обработки нужны трёхмерные или **3D фильтры**, состоящие из трёх ядер.

В CNN моделях к исходному изображению часто применяют несколько фильтров. Например, мы хотим распознавать не только вертикальные границы объектов, но и горизонтальные. В этом случае нам нужны два отдельных фильтра. Если изображение цветное, то у каждого из них будет по три ядра. Каждый фильтр извлекает разные признаки из исходного изображения и даёт свою карту признаков на выходе. Эти карты мы складываем в **стэк** (stack). Таким образом у нас снова появляется третье измерение. На этот раз оно связано не с числом цветовых каналов, а с числом применяемых фильтров.

Стэк карт признаков передаётся на следующий слой CNN сети. Он обрабатывается следующим трёхмерным фильтром. Этот фильтр распознаёт признаки более высокого уровня абстракции, чем фильтры предыдущего слоя.

I> Если фильтр состоит из нескольких ядер, то выполняется свёртка по объёму. Результат комбинируется в одну карту признаков. Если применяются несколько фильтров, каждый из которых имеет только одно ядро, выполняется обычная свёртка. В результате получается стек карт признаков. Их число равно числу применённых фильтров.

##### 3.5.3.5.2 Применение функции активации

Мы уже познакомились с понятием функции активации нейронов слоя сети, когда рассматривали архитектуру NNUE. Это одна из двух важных характеристик слоя нейронов.

Функцию активации каждый нейрон выполняет над своими входными данными, чтобы получить данные на выходе. Нейроны свёрточного слоя CNN сети — не исключение и делают то же самое.

Разберёмся, зачем функция активации нейронов нужна свёрточному слою. На это есть несколько причин:

1. Добавление нелинейности в модель. Благодаря функция активации, сеть может усваивать сложные закономерности во входных данных.

2. Выбор признаков. Функция активации позволяет модели концентрироваться на наиболее важных и отличительных признаках данных. Для этого сеть выборочно увеличивает или уменьшает определённые элементы карты признаков.

3. Улучшение обобщающей способности модели. Сеть эффективно работает с новыми изображениями, которые не входили в обучающие наборы.

В свёрточных слоях обычно используется функция активации **ReLU**. Её формула выглядит так:
{width: "50%"}
![](images/Chess/cnn-relu-formula.png)

В ней используются следующие обозначения:

* x — входное значение нейрона
* y — выходное значение нейрона.

Иллюстрация 3-43 демонстрирует график функции ReLU.

{caption: "Иллюстрация 3-43. Функция активации ReLU", height: "40%"}
![Функция активации ReLU](images/Chess/cnn-relu-graph.png)

ReL преобразут входное значение x в результат y от 0 до положительной бесконечности. Если входное значение меньше или равно нулю, то ReLU выдаёт ноль. В противном случае — входное значение.

Рассмотрим, что означает применение функции активации ReLU с точки зрения обработки исходного изображения. Для простоты предположим, что оно чёрно-белое.

Функция активации удаляет все чёрные пиксели и оставляет только те, которые имеют положительное значение (серый и белый цвета). В результате этого цвета на изображении меняются более резко. Нет больше их постепенного изменения. Это указывает на то, что мы избавились от линейности.

##### 3.5.3.5.3 Операция подвыборки

Начнём с операции подвыборки. Она считается второй фундаментальной концепцией CNN сетей и выполняется после свёртки. Подвыборка решает следующие задачи:

1. Уменьшает пространственные размеры (dimensionality reduction) карты признаков. Это позволяет контролировать вычислительную сложность сети. Меньше признаков означает меньше параметров модели и необходимых вычислений. Небольшие карты признаков быстрее обрабатываются в следующих слоях сети.

2. Инвариантность представлений (translation invariance) признаков. Благодаря операции подвыборки, модель становится менее чувствительной к пространственному расположению объектов на исходном изображении.

3. Агрегация локальных признаков (local feature aggregation). Операция подвыборки выделяет наиболее важные признаки в каждой области входных данных. Это помогает модели отделить важную входную информацию от шума.

4. Уменьшает вероятность переобучения (overfitting) модели. Благодаря упрощению карты признаков, операция подвыборки снижает риск подгонки модели под шум во входных данных.

Операция подвыборки уменьшает размеры карты признаков, полученной после свёртки. Для этого задаётся некоторое **окно подвыборки** (pooling window). Это примерно то же самое, что и ядро в операции свёртки. Отличие в том, что окно подвыборки имеет размер, но не имеет весов. Его единственная задача — проходить по входному массиву и выделять его элементы. На каждом шаге к выделенным элементам применяется операция подвыборки. Обычно это одна из следующих:

1. **Max pooling** (подвыборка по максимальному значению).

2. **Average pooling** (подвыборка по среднему значению).

Подвыборка по максимальному значению выбирает из всех выделенных элементов наибольший. Именно он записывается в выходной массив, а остальные отбрасываются.

Рассмотрим пример. Допустим, что у нас есть карта признаков размером 5x5. Для её обработки мы выбираем окно подвыборки размером 3x3. Выберем шаг прохода по входному массиву равный двум. Тогда на первом шаге, окно перекроет следующую часть карты признаков:
{width: "40%"}
![](images/Chess/pooling-source-image-5x5-highlight-first.png)

В перекрытой области максимальное значение ранво 251. Это будет значением первого элемента в выходной матрице операции подвыборки. 

На втором шаге окно подвыборки перекроет такую часть карты признаков:
{width: "40%"}
![](images/Chess/pooling-source-image-5x5-highlight-second.png)

В этой области максимальное значение снова равно 238. Это второй элемент в выходной матрице.

Теперь окно подвыборки возвращается в левый край карты признаков и смещается вниз на два ряда, потому что мы выбрали шаг равный двум. Мы повторяем операцию ещё два раза и получаем следующую выходную матрицу:
{width: "25%"}
![](images/Chess/max-pooling-result-image-2x2.png)

Подвыборка по среднему значению рассчитывает среднее значение всех выделенных элементов. Вернёмся к первому шагу нашего примера:
{width: "40%"}
![](images/Chess/pooling-source-image-5x5-highlight-first.png)

Среднее значение элементов в перекрытой области карты признаков рассчитывается так:
{line-numbers: false, format: text}
```
(19 + 10 + 39 + 30 + 251 + 238 + 45 + 6 + 59) / 9 = 77.4444
```

Полученный результат округляем до целого и получаем 77. Это и будет значением первого элемента в выходной матрице операции подвыборки. Повторим операцию для оставшихся трёх шагов и получим такой результат:
{width: "25%"}
![](images/Chess/average-pooling-result-image-2x2.png)

##### 3.5.3.5.4 Операция сглаживания

Операция сглажэивания выполняется после подвыборки. Её главная задача преобразовать пространственную информацию из карты признаков в формат, который может обработать полносвязный слой сети. В терминологии CNN такой слой также называется **плотным** (dense).

Операция сглаживания важна по следующим причинам:

1. Переход к полносвязному слою сети, который выполняет высокоуровневое прогнозирование, классификацию или распознавание объектов. Такой слой требует одномерных входных данных. Операция сглаживания как раз предоставляет такой формат на выходе.

2. Сохранение пространственной информации. Слои свёртки фиксируют пространственную иерархию признаков: края объектов, их текстуры и части. Эта информация отображается на карте признаков. Операция сглаживания сохраняет обнаруженные при свёртке признаки, но отбрасывает пространственную информацию. Другими словами, одномерные выходные данные сглаживания сохраняют семантическую информацию карты признаков.

Рассмотрим операцию сглаживания на примере. Допустим, что мы получили такую карту признаков после подвыборка по максимальному значению:
{width: "25%"}
![](images/Chess/max-pooling-result-image-2x2.png)

Операция сглаживания развернёт эту матрицу размером 2x2 в одномерный массив из четырёх элементов:
{width: "40%"}
![](images/Chess/flattening-result-image-4x1.png)

Если операция подвыборки возвращает стек карт признаков, то сглаживание развернёт все эти карты в один одномерный массив. Только такой формат данных сможет обработать последующий полносвязный слой сети.

##### 3.5.3.5.5 Пакетная нормализация

При обучении deep learning моделей часто встречается проблема [**ковариантного сдвига**](https://habr.com/ru/articles/422185/) (covariance shift). Рассмотрим её на наглядном примере.

В разделе "2.6.2.1.1 Классификация" мы классифицировали ирисы из набора данных Фишера. Допустим, что теперь мы хотим обучить более сложную модель. Она получает на вход фотографию некоторого цветка. По нему модель отвечает на вопрос: "относится ли цветок к роду ирисов?".

Разные виды ирисов имеют разные цвета. Иллюстрация 3-44 демонстрирует их вариативность.

{caption: "Иллюстрация 3-44. Фотография ирисов разных цветов", width: "75%"}
![Ирисы разных цветов](images/Chess/iris-flowers.jpg)

Теперь предположим, что в обучающий набор данных (training set) попали только цветки ирисов фиолетового цвета и другие растения. В тестовом наборе (test set) данных помимо других растений есть ирисы разных цветов (фиолетовый, белый, желтый). В этом случае точность работы модели будет неудовлетворительной. Она не сможет распознавать ирисы не фиолетового цвета.

Причина низкой точности модели в том, что обучающий и тестовый наборы содержат фотографии ирисов разных цветов в разных пропорциях. Наша модель обучена отображать исходное множество X (цветки) в целевое множество Y (ирисы). Если пропорция элементов в X меняется, то необходимо переобучить модель заново. Таким образом мы выравниваем пропорции элементов в обоих множествах X и Y. Именно это изменение пропорций элементов и называется ковариантным сдвигом.

Мы рассмотрели пример ковариантного сдвига во входных данных модели. Эта проблема решается случайным перемешиванием данных из обучающего набора перед созданием **пакетов** (batch). Что такое пакет?

Алгоритм градиентного спуска имеет [три возможные реализации](https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a):

1. **Стохастический градиентный спуск** (stochastic gradient descent) — на каждой итерации алгоритма из обучающего набора данных случайно выбирается только один элемент.

2. **Пакетный градиентный спуск** (batch gradient descent) — на каждой итерации алгоритм просматривает обучающий набор данных целиком и только после этого меняет веса модели.

3. Промежуточное решени — на каждой итерации алгоритм просматривает некоторое подмножество обучающего набора данных фиксированного размера (batch size). Эти подмножества называются **мини-пакетами** (mini-batch).

На практике чаще всего применяется третья реализации алгоримта градиентного спуска. Поэтому для простоты мини-пакеты называют просто пакетами.

Ковариантный сдвиг встречается не только во входных данных модели. Он происходит и в данных, которые передаются между скрытыми слоями сети. В этом случае пропорции элементов входного массива слоя изменяются каждый раз, когда меняются параметры в предыдущем слое. Эта проблема называется **внутренним ковариантным сдвигом** (internal covariate shift). Её невозможно решить перемешиванием входных данных. Именно для неё был разработан метод [**пакетной нормализации**](https://en.wikipedia.org/wiki/Batch_normalization).

Метод пакетной реализации предложили сотрудники Google Сергей Иоффе и Кристиан Сегеди в 2015 году. Они подробно описали новый подход в своей статье "Пакетная нормализация: Ускорение глубокого обучения за счёт уменьшения внутреннего ковариатного сдвига" (["Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"](https://arxiv.org/pdf/1502.03167.pdf)).

Разберёмся, как работает пакетная нормализация. Её алгоритм выглядит следующим образом:

1. Вычислить [**среднее арифметическое**](https://en.wikipedia.org/wiki/Mean) (mean) всех элементов пакета по формуле:
{height: "15%"}
![](images/Chess/mean-formula.png)

В этой формуле следующие обозначения:

* x~i~ — элементы выборки под номером i
* m — размер пакета.

2. Вычислить [**дисперсию**](https://en.wikipedia.org/wiki/Variance) (variance) для элементов пакета по формуле:
{width: "40%"}
![](images/Chess/variance-formula.png)

3. Для простоты допустим, что пакет представляет собой одномерный массив. Тогда нормализованное значение каждого его элемента рассчитывается по формуле:
{width: "50%"}
![](images/Chess/normalized-value-formula.png)

В этой формуле следующие обозначения:

* ϵ — некоторая малая константа.

В результате такой нормализации мы получим распределение значений с центром в 0 и дисперсией равной 1.

I> **Дисперсия случайной величины** — это ожидаемое значение [**квадрата отклонения от среднего значения**](https://en.wikipedia.org/wiki/Squared_deviations_from_the_mean) случайной величины.

Нормализация входа слоя может изменить представление данных в слое. Чтобы этого избежать, вводятся два дополнительных параметра модели: сжатие (γ) и сдвиг (β)нормализованной величины. Они действуют следующим образом:
{width: "50%"}
![](images/Chess/scale-and-shift-formula.png)

Параметры γ и β настраиваются в процессе обучения вместе с остальными параметрами модели.

Предположим, что мы хотим применить пакетную нормализацию к скрытому слою B сети. Этот слой полчает данные от предыдущего слоя A. В этом случае пакетная нормализация выполняется после преобразования данных при их передачи из слоя A в слой B. Только после этого применяется функция активации слоя.

Использование пакетной нормализации в моделе даёт следующие преимущества:

1. Устраняет внутренний ковариантный сдвиг, возникающий во время обучения. Это повышает стабильность процесса обучения и упрощает оптимизацию модели.

2. Улучшает обобщающую способность модели и уменьшает вероятность переобучения.

3. Снижает чувствительность модели к начальным весам, которые задаются на этапе инициализации. Это упрощает обучение модели.

4. Повышает скорость обучения, поскольку позволяет использовать более высокий [**темп обучения**](https://en.wikipedia.org/wiki/Learning_rate) (learning rate). Часто увеличение темпа обучения приводит к взрыву или исчезновению градиента, но пакетная нормализация предотвращает эти проблемы.

I> Темп обучения — настраиваемый параметр алгоритма оптимизации, который определяет размер шага на каждой итерации при движении к минимуму **функции потерь** (loss function). Функция потерь отображает стоимость непраивльного принятия решений на основе наблюдаемых данных.

Метод пакетной нормализации применим к различным архитектурам нейронных сетей, которые ориентированы на разные задачи. Среди этих задач: классификация изображений, обнаружение объектов, обработка естественного языка и многое другое. Благодаря своей универсальности, метод стал широко распространён в различных областях машинного обучения.

#### 3.5.3.6 Нейронная сеть AlphaZero

Мы познакомились со свёрточными нейронными сетями. У читателя может возникнуть вопрос: как сеть, оптимизированная для распознавания изображений, может оценивать шахматные позиции?

Начнём с того, что позицию фигур на доске можно представиь в виде матрицы размером 8x8. Свёрточные слои хорошо подходят для обработки входных данных подобной структуры. Она напоминает структуру типичного изображения.

В разделе "3.3.1.2 Теория блоков" мы познакомились с теорией блоков Герберта Саймона. Согласно ей, профессиональные шахматисты иерархически упаковывают информацию о позиции. Это позволяет им рассматривать не отдельные фигуры, а их сочетания.

Свёрточная нейронная сеть делает примерно то же самое, что и шахматисты. Она работает с визуальной структурой, когда оценивает позицию на шахматной доске. Сеть может извлекать такие признаки как:

* открытые вертикали
* расположение коней
* открытые диагонали слонов
* пешечная структура

Сложно ввыяснить, какие именно признаки оценивает обученная готовая модель. Эти признаки обобщаются в высокоуровневые шаблоны наподобие тех, которые распознают профессиональные игроки. Таким образом поведение модели больше напоминает действия шахматистов, чем алгоритмы традиционнх движков наподобие Stockfish.

Вот общие принципы работы модели AlphaZero:

* Нейронная сеть получает на вход текущюу позицию фигур на доске.

* Нейронная сеть на выходе даёт два значения. Первое — **общая оценка позиции**. Она указывает вероятность победы белых, чёрных или ничьи. Второе значение — вероятность каждого возможного в текущей позиции хода. По-сути это оценка ходов: насколько хорош каждый из них.

* Для поиска лучшего хода в данной позиции модель AlphaZero использует поиск методом Монте-Карло. Процессом поиска управляет нейронная сеть. Она определяет, какой ход в дереве поиска выбрать на первом шаге selection для исследования. Из всех возможных ходов выбираются только ходы с максимальными вероятностями. Далее шаг simulation в AlphaZero отличается от обычного алгоритма MCTS. Обычно MCTS проигрывает партию до конца, выбирая случайные ходы. Вместо этого алгоритм AlphaZero узнаёт вероятный результат партии из общей оценки позиции. Её выдаёт нейронная сеть после анализа хода, выбранного на шаге selection.

* Алгоритм MCTS применяется также во время обучения нейронной сети, когда AlphaZero играет сам с собой. Для каждого хода в партии выполняется поиск MCTS. Им управляет текущая версия нейронной сети. В результате получаются наборы позиций и конечные результаты партий, к которым они приводят. Алгоритм обучения получает эти данные на вход.

##### 3.5.3.6.1 Входные данные сети

Традиционные шахматные дивжки наподобие Stockfish используют битборды для представляения позиций фигур. Такой подход идеально подходит для выполнения битовых операци на 64-разрядных процессорах. В случае нейронной сети, работающей на GPU, такая оптимизации ненужна.

Нейронная сеть AlphaZero получает на вход набор матриц (plane) размера 8x8. Эти матрицы кодируют как позицию фигур на доске, так и состояние партии (например, какой игрок сейчас ходит). Рассмотрим эти матрицы подробнее:

* Шесть матриц кодируют положение белых фигур на доске. На фигуры каждого типа отводится своя матрица: пешки, кони, слоны, ладьи, ферзь, король. Если фигура стоит на каком то поле, то элемент матрицы с этим индексом равен 1. В противном случае этот элемент равен 0. Например, белая пешка стоит на поле b2. Тогда соответствующий ей элемент с индексом (2, 2) равен 1.

* Шесть матриц кодируют положение чёрных фигур на доске. Они работают точно так же, как для белых фигур.

* Две матрицы используются для подсчёта повторяющихся ходов. Все элементы одной из них заполняется единицами, если текущая позиция повторялась ранее единожды. Элементы второй матрицы выставляются в единицы, если текущая позиция повторялась дважды. Это нужно, чтобы отслеживать ничью при троекратном повторении позиции (правило трёх ходов).

* Чтобы отслеживать правило трёх ходов, во входных данных сети запоминаются последние восемь позиций. В начале партии они занулены. Далее по ходу партии они отражают реальные позиции. Чтобы хранить эту историю позиций, нужно `(6 + 6) * 8 = 96` матриц.

* Одна матрица хранит цвет фигур игрока, который делает ход. Все её элементы равны 1, если ходят белые. При ходе чёрных она зануляется.

* Четыре матрицы кодируют правила рокировки: белые короткая (на королевском фланге), белые длинная (на ферзевом фланге), чёрная короткая и чёрная длинная. Если соответствующая матрице рокировка возможна, все её элементы выставляются в 1. В противном случае все матрицы элементы выставляются в 0.

* Одна матрица используется как счётчик ходов с начала партии. Её элементы, начиная с первого (1,1), интерпретируются как разряды целого числа.

* Одна матрица кодирует счётчик для отслеживания правила 50-ти ходов. Согласно ему, если в течении 50-ти ходов не было взятий и ходов пешками, то объявляется ничья.

Мы рассмотрели 117 входных матриц размера 8x8 сети AlphaZero. Комнда DeepMind опубликовала статью [Mastering Chess and Shogi by Self-Play with aGeneral Reinforcement Learning Algorithm](https://arxiv.org/pdf/1712.01815.pdf) с описанием архитектуры AlphaZero. В ней сказано, что сеть имеет 119 входов. При этом назначаение двух оставшихся входов не уточняется.

##### 3.5.3.6.2 Выходные данные сети

Нейронная сеть AlphaZero на выходе даёт два значение. Первое — **общая оценка позиции** (value). Это грубая оценка наиболее вероятного результата партии, учитывая текущую позицию. Она нужна, чтобы заменить проигрывание партии с выполнением случайных ходов на шаге simulation алгоритма MCTS. Общая оценка позиции всё равно оказывается точнее, чем подобное проигрывание партии.

Общая оценка позиции принимает одно из трёх возможных значений:

* -1 — проигрывает игрок, выполняющий текущий ход.
* 0 — ничья.
* 1 — выигрывает игрок, выполняющий текущий ход.

Второй вывод сети — **вероятность каждого возможного хода** в текущий позиции (policy). Его формат достаточно сложный. Проблема заключается в том, что количество допустимых ходов меняется в зависимости от позиции фигур на доске. С другой стороны число выходов нейронной сети должно быть постоянным. Рассмотрим, как команда DeepMind решила это затруднение.

Идея разработчиков AlphaZero заключается в том, чтобы для любой позиции на доске рассматривать некоторый одинаковый шаблон возможных ходов. В этот шаблон входят все поля на доске в качестве точек старта. В них начинает свой ход некоторая фигура. Далее для каждого исходного поля перечисляются все возможные ходы "суперфигуры". Она может ходить как ферзь и конь. Каждому возможному ходу "суперфигуры" из каждого начального поля доски соответствует один выход нейронной сети.

Такой формат выходных данных избыточен. Нейронная сеть будет оценивать вероятность некоторых ходов как ненулевую. Но эти ходы будут запрещены по правилам шахмат. Чтобы решить эту проблему, достаточно занулять вероятности запрещённых ходов. После этого необходимо пересчитать вероятности оставшихся разрешённых ходов так, чтобы их сумма снова стала равна единице.

Представим для наглядности шаблоны возможных ходов в виде набора таблиц. Таблица 3-1 демонстрирует все ходы "суперфигуры" как ферзя из всех начальных полей доски. Первый столбец указывает поле, из которого фигура начинает ход. Второй столбец — это направление, в котором она двигается. Третий столбец — число полей, на которое передвигается фигура. Каждая строка таблицы соответствует одному выходу нейронной сетри AlphaZero.

{caption: "Таблица 3-1. Все возможные ходы ферзём", width: "80%"}
| Начальное поле | Направление | Число полей |
| --- | --- | --- |
| a1 | Вверх | 1 |
| a1 | Вверх | 2 |
| ... | ... | ... |
| a1 | Вверх | 6 |
| a1 | Вверх | 7 |
| a1 | Вверх-вправо | 1 |
| ... | ... | ... |
| a1 | Вверх-вправо | 7 |
| a1 | Вправо | 1 |
| ... | ... | ... |
| a1 | Вправо | 7 |
| a1 | Вниз | 1 |
| ... | ... | ... |
| a1 | Вниз | 7 |
| ... | ... | ... |
| ... | ... | ... |
| h8 | Влево | 7 |

Первая строка таблицы соответствует ходу любой фигуры, стоящей на a1, вверх на одно поле. Таким образом этот выход нейронной сети определяет вероятность хода a1-a2. Следующая строка таблицы и соответствующий выход сети описывают ход фигуры a1-a3. Продолжая аналогично, описываются все возможные ходы ферзём со всех полей доски.

Обратите внимание, что таблица 3-1 учитывает в том числе и ходы за пределы доски. Например, ходы из поля a1 в направлениях: вниз-вправо, вниз, вниз-влево, влево, вверх-влево. Такое решение упрощает формат входных данных. Ходы за пределы доски запрещены правилами шахмат, поэтому их вероятность всегда зануляется.

Ходы ферзём покрывают следующие типы фигур: пешка, слон, ладья, ферзь, король. Остаются ходы конём, которые не учитывает таблица 3-1. Составим для коней аналогичную таблицу 3-2.

{caption: "Таблица 3-2. Все возможные ходы конём", width: "80%"}
| Начальное поле | Направление |
| --- | --- |
| a1 | Два вверх, одно вправо |
| a1 | Два вправо, одно вверх |
| a1 | Два вправо, одно вниз |
| a1 | Два вниз, одно вправо |
| a1 | Два вниз, одно влево |
| a1 | Два влево, одно вниз |
| a1 | Два влево, одно вверх |
| a1 | Два вверх, одно влево |
| a2 | Два вверх, одно вправо |
| ... | ... |
| a2 | Два вверх, одно влево |
| ... | ... |
| ... | ... |
| h8 | Два вверх, одно влево |

Первая строка таблицы описывает ход коня из поля a1 на поле b3. Она соответствует выходу нейронной сети, который определяет вероятность хода a1-b3. Продолжая аналогично, мы получили выходы сети для всех возможных ходов конём. Некоторые из них выходят за пределы доски и запрещены правилами игры точно так же, как ходы ферзём из таблицы 3-1.

Последний тип ходов, которые не учитывают таблицы 3-1 и 3-2 — это превращение пешки. По правилам пешка, достигшая последней горизонтали (8-ой для белых и 1-ой для чёрных), превращается в любую фигуру кроме короля. Пешка может достигнуть последней диагонали в результате одного из следующи ходов:

* Движение вперёд на одно поле.
* Взятие вражеской фигуры на соседнем поле по диагонали слева.
* Взятие фигуры на соседнем поле по диагонали справа.

Чтобы учесть эти ходы, составим отдельную таблицу 4.3.

{caption: "Таблица 3-3. Все ходы с превращением пешки", width: "80%"}
| Начальное поле | Тип хода | Превращение в фигуру |
| --- | --- | --- |
| a1 | Вперёд | Конь |
| a1 | Вперёд | Слон |
| a1 | Вперёд | Ладья |
| a1 | Взятие влево | Конь |
| ... | ... | ... |
| a1 | Взятие влево | Ладья |
| a1 | Взятие вправо | Конь |
| ... | ... | ... |
| a1 | Взятие вправо | Ладья |
| a2 | Вперёд | Конь |
| ... | ... | ... |
| a2 | Взятие вправо | Ладья |
| ... | ... | ... |
| h8 | Взятие вправо | Ладья |

Мы не рассматриваем ходы пешки с превращением в ферзя, потому что они покрываются таблицей 3-1.

Из таблицы 3-3 очевидно, что только малая часть перечисленных в ней ходов допустима правилами шахмат. Например, ходы из поля a1 не достигают последней горизонтали (8-ой или 1-ой). Поэтому их вероятность всегда зануляется. Тем не менее каждая строка таблицы 3-3 соответствует одному выходу нейронной сети.

Рассчитаем сумму всех выходов нейронной сети. Таблица 3-1 содержит следующее число строк:
{line-numbers: false, format: text}
```
8 * 7 * 64 = 3584
```
В этой формуле: 

* 8 — число направлений для хода ферзём.
* 7 — число полей при движении в каждом направлении.
* 64 — число полей на доске, с которых может ходить ферзь.

Таблица 3-2 содержит такое число строк:
{line-numbers: false, format: text}
```
8 * 64 = 512
```
В этой формуле: 

* 8 — число направлений для хода конём.
* 64 — число полей на доске, с которых может ходить конь.

В таблице 3-3 строк столько:
{line-numbers: false, format: text}
```
3 * 3 * 64 = 576
```
В этой формуле: 

* 3 — число направлений для хода пешкой.
* 3 — число фигур для превращения пешки.
* 64 — число полей на доске, с которых может ходить пешка.

Сложим полученные результаты:
{line-numbers: false, format: text}
```
3584 + 512 + 576 = 4672
```

Таким образом у нейронной сети AlphaZero всего 4672 выхода. Эти выходы относятся только ко второму выводу сети, который оценивает вероятности возможных ходов. Они никак не связаны с первым выводом, который по текущей позиции оценивает вероятный результат партии.

Для обучения сети с таким большим количеством выходов нужны значительные вычислительные ресурсы. Почему команда DeepMind выбрала такой подход? На самом деле разработчики экспериментировали с альтернативным кодированием выходов. В этом случае перечислялись все допустимые ходы: a1-a2, a1-a3, a1-a4 и т.д. Таким образом полчаются все возможные комбинации пар: исходное поле, целевое поле. При этом исключаются запрещённые правилами ходы за пределы шахматной доски. К этому списку нужно добавить допустимые правилами ходы на превращение пешки. В итоге получится менее 2000 выходов сети.

На практике оказалось, что нейронная сеть с меньшим числом выходов обучается дольше. Причина в том, что подход с 4672 выходами сфокусирован на исходном поле фигуры. Это позволяет модели разделить решение о выборе хода на две части. Сначала грубо решить, какая именно фигура должна ходить в текущей позиции. Чтобы обучится этому, модели достаточно совсем немного итераций алгоритма обучения. Затем после дополнительных итераций, сеть учится более точно определять, куда именно должна пойти выбранная фигура.

##### 3.5.3.6.3 Архитектура сети

Архитектура нейронной сети AlphaZero очень похожа на сеть AlphaGo Zero. Эта архитектура подробно описана в статье [Mastering Go without Human Knowledge](https://discovery.ucl.ac.uk/10045895/1/agz_unformatted_nature.pdf).

Здесь мы рассмотрим наглядную блок-схему нейронной сети AlphaZero. Её демонстрирует иллюстрация 3-45.

{caption: "Иллюстрация 3-45. Блок схема нейронной сети AlphaZero", width: "100%"}
![Нейронная сеть AlphaZero](images/Chess/alphazero-network-architecture.png)

Как мы уже выяснили, входные данные сети (Input) представляют собой стек bp 119 матриц размером 8x8. Его последовательно обрабатывают несколько блоков. Познакомимся с ними в порядке следования.

Сначала входные данные поступают на первый **блок свёртки** (Convolutional block). Этот блок последовательно выполняет следующие операции:

1. **Свёртка типа А** (Convolution A). Этот свёрточный слой состоит из стека 256 фильтров. Каждый фильтр имеет одно ядро размером 3x3. Операция свёртки выполняется с шагом 1.

2. **Пакетная нормализация** (Batch normalization).

3. **Функция активации ReLU** (Activation function ReLU).

Первый блок вызывает несколько вопросов. Во-первых, если во входном стеке только 119 матриц, то как их обрабатывают 256 фильтров свёрточного слоя? В этом случае нельзя применить свёртку по объёму. При такой операции число слоёв исходного изображения совпадает с числом ядер. В результате все слои исходного изображения сводятся в один слой карты признаков. В случае AlphaZero это решение неприемлемо. Каждый из 119 слоёв несёт важную информацию и их данные не должны смешиваться между собой.

Вместо свёртки по объему происходит обычная свёртка. При этом каждое из 256 ядер применяется к каждой из 119 входных матриц. В результате получается 119 наборов по 256 карт признаков в каждом. Затем каждый набор из 256 карт признаков сворачивается в одну карту признаков. Для этого можно, например, просто просуммировать их элементы. То есть элемент (1,1) результирующей карты признаков равен сумме всех элементов (1,1) из набора 256 карт признаков. Так на выходе из свёрточного слоя мы получим стек из 119 карт признаков.

Второй вопрос — какой размер имеет каждая из 119 карт признаков после операции свёртки? Если применять фильтры без выравнивания, то это приведёт к потере данных. Информация об элементах на границах (левая, верхняя, правая, нижняя) входных матриц 8x8 потеряется. Это допустимо при обработке изображений, но совершенно неприемлемо для матриц с расположением фигур на доске. Поэтому перед обработкой каждой входной матрицы выполняется выравнивание. В результате все 119 выходных карт признаков имеют тот же размер 8x8.

Выходные данные первого блока свёртки (Convolutional block) передаются на первый **остаточный блок** (Residual block). Этот блок последовательно выполняет следующие операции:

1. **Свёртка типа А** (Convolution A).

2. **Пакетная нормализация** (Batch normalization).

3. **Функция активации ReLU** (Activation function ReLU).

4. **Свёртка типа А** (Convolution A).

5. **Пакетная нормализация** (Batch normalization).

6. **Остаточное соединение** (Residual connection).

7. **Функция активации ReLU** (Activation function ReLU).

Остаточнй блок нейронной сети можно представить, как комбинацию двух блоков свёртки. В нём выполняются точно такие же операции только дважды. Принципальное отличие блока — это **остаточное соединение** (Residual connection).

Остаточный блок работает следующим образом:

1. **Первый поток данных**: входные данные блока последовательно проходят через слои свёртки, пакетную нормализацию и функции активации.

2. **Второй поток данных**: остаточное соединение передаёт входные данные блока как есть напрямую к выходу блока, минуя все его слои.

3. **Остаточная операция** (residual operation): первый и второй потоки данных суммируются.

4. **Выходные данные блока** представляют собой результат остаточной операции. Они вычисляются по следующей формуле:
{line-numbers: false, format: text}
```
output = layer(input) + input
```
В этой формуле:

* `output` — выходные данные остаточного блока.
* `layer(input)` — результат прохода входных данных блока через все его слои (первый поток данных).
* `input` — входные данные блока как есть (второй поток данных).

Остаточные блоки позволили команде DeepMind избежать проблемы исчезающего градиента при обучении такой глубокой нейронной сети как у AlphaZero.

Всего в сети 19 остаточных блоков. Они следуют друг за другом. На выходе из них мы получаем 119 карт признаков размера 8x8. Они отличаются от выходных карт признаков блока свёртки тем, что содержат шаблоны более высокого уровня абстрации. Как и в случае сетей CNN для распознавания изображений, выяснить суть этих шаблонов крайне сложно.

Выходные данные последовательности остаточных блоков передаются по двум разным направляениям. В терминологии сети AlphaZero каждое направление идёт в блоки под названем **головы** (head).

Первая **голова вычисляет вероятности возможных ходов** (policy head). Она последовательно выполняет следующие операции:

1. **Свёртка типа B** (Convolution B). Этот свёрточный слой состоит из стека 2-х фильтров. Каждый фильтр имеет одно ядро размером 1x1. Операция свёртки выполняется с шагом 1.

2. **Пакетная нормализация** (Batch normalization).

3. **Функция активации ReLU** (Activation function ReLU).

4. **Операция сглаживания** (Flatten). После свёртки типа B получается 119 карт признаков размером 8x8. Операция сглаживания приводит их в формат одномерного массива, который нужен следующему далее линейному слою.

5. **Линейный полносвязный слой типа A** (Dense A). По входным данным вычисляет значения для каждого из 4672 выходов нейронной сети, которые оценивают вероятности всех возможных ходов в текущей позиции.

Вторая **голова вычисляет общую оценку позиции** (value head). Она последовательно выполняет следующие операции:

1. **Свёртка типа C** (Convolution C). Этот свёрточный слой состоит из одного фильтра, который имеет одно ядро размером 1x1. Операция свёртки выполняется с шагом 1.

2. **Пакетная нормализация** (Batch normalization).

3. **Функция активации ReLU** (Activation function ReLU).

4. **Операция сглаживания** (Flatten). После свёртки типа C получается 119 карт признаков размером 8x8. Операция сглаживания приводит их в формат одномерного массива, который нужен следующему далее линейному слою.

5. **Линейный полносвязный слой типа B** (Dense B). Сводит входные данные в выходной одномерный массив из 256 элементов. Это входной формат следующего далее линейного слоя.

6. **Функция активации ReLU** (Activation function ReLU).

7. **Линейный полносвязный слой типа C** (Dense C). Приводит входные данные к одному из трёх возможных значений: -1, 0, 1. Они определяют наиболее вероятный исход партии с учётом текущей позиции на доске.

##### 3.5.3.6.4 Совместная работа сети и MCTS

>>>

### 3.5.4 Leela Chess Zero

// TODO: Решить - нужен ли раздел про Lc0? Там другая нейронная сеть и улучшения по сравнению с AlphaZero.

#### 3.5.4.1 Нейронная сеть

// TODO: Решить про абзац ниже - нужен ли он?

В отличие от сети NNUE, сеть Leela Chess Zero возвращает оценку позиции и move ordering. То есть на выходе нейронной сети мы получаем порядок ходов для алгоритма поиска. Этот move ordering заменяет эвристики истории ходов Stockfish.