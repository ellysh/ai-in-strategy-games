## 3.3 Теория ИИ и шахматы

Рассмотрим шахматы с точки зрения теории интеллектуальных агентов. Так мы выясним тип ИИ, который сможет справиться с этой игрой.

### 3.3.1 Проблемная среда

С точки зрения интеллектуального агента игра в шахматы — это проблемная среда. Определим, к какому типу она относится. Для этого обратимся к таблице 2-5 с признаками классификации сред.

Агент может прочитать позицию фигур на доске в любой момент времени. Скрытых состояний у игры нет. Следовательно, шахматы — это полностью наблюдаемая среда.

В шахматах нет случайных событий. Каждое состояние среды зависит от трёх факторов:

1. Текущая позиция на доске.
2. Действия агента.
3. Действия оппонента.

Это означает, что среда является детерминированной.

В шахматах агент должен воспринимать среду последовательно. Каждый ход обоих игроков влияет на последующие позиции фигур на доске.

В шахматах игроки делают ходы друг за другом. Позиция на доске меняется только после очередного хода. Такие изменения характерны для статических сред. Однако, по правилам классических шахмат каждому участнику отводится определённое время на все ходы. Когда время заканчивается, игроку засчитывается поражение. Получается, что показатели производительности агента меняются с течением времени. Это характерно для полудинамических сред.

Агент способен однозначно различать состояния шахматной доски. Все фигуры находятся на определённых полях. Поэтому сомнений в позиции быть не может. Количество состояний доски огромно, но конечно. Точно так же различимы и конечны игровое время и ходы игроков. Следовательно, шахматы — это сложная дискретная среда.

В шахматы играет одновременно два участника. Победа одного из них означает поражение другого. Следовательно, показатели производительности игроков обратно пропорциональны. Из этого следует, что шахматы — это мультиагентная конкурентная среда.

В шахматах не так много правил. Они определяют допустимые ходы фигур и условия окончания партии. Эти правила легко представить в удобной для агента форме такой как таблица или программа. Знание правил обязательно для агента. Без них он не сможет делать ходы. Поэтому шахматы — это известная агенту среда.

Подведём итог. С точки зрения теории интеллектуальных агентов шахматы являются средой с такими признаками:

* Полностью наблюдаемая
* Детерминированная
* Последовательная
* Полудинамическая
* Дискретная
* Мультиагентная и конкурентная
* Известна агенту
* Сложная

### 3.3.2 Интеллектуальный агент

Мы определили признаки шахмат как проблемной среды. Теперь выясним, агенты какого типа способны в ней эффективно работать.

Объединим агентов из таблицы 2-7 на три группы по алгоритму работы:

1. Рефлексные агенты.
2. Агенты, использующие поиск.
3. Обучающиеся агенты.

Рассмотрим каждую из этих групп.

#### 3.3.2.1 Рефлексные агенты

Сможет ли играть в шахматы простой рефлексный агент? Агент этого типа игнорирует последовательность актов восприятия. Он ориентируется только на текущее состояние среды. Принимая решения, агент не учитывает будущие возможные состояния среды.

Рефлексный агент может работать в простой среде, с такими же признаками как у шахмат.
Пример такой среды — крестики-нолики с полем 3 на 3 клетки. Крестики-нолики считаются [решённой игрой](https://en.wikipedia.org/wiki/Solved_game). Это значит, что для каждого игрока найдена стратегия, которая приводит к наилучшему результату. Если оба игрока придерживаются лучшей стратегии, партия заканчивается ничьей.

Чтобы рефлексный агент смог играть в крестики-нолики, его таблица правил должна содержать следующее:

* Все возможные состояния поля игры, допустимые правилами.

* Ход агента для каждого возможного состояния поля, который реализует лучшую стратегию.

Используя такую таблицу, простой рефлексный агент будет выбирать лучший ход на любое действие оппонента.

Какой размер таблицы правил нужен рефлексному агенту для игры в крестики-нолики? Всего существует 3^9^ или 19683 способов заполнить поле 3 на 3. Каждая клетка может быть пустой, либо в ней может стоять крестик или нолик. Из всех 19683 комбинаций только 5478 удовлетворяют правилам игры. Таким образом таблица правил рефлексного агента содержит 5478 строк.

Каждая строка таблицы правил — это состояние игрового поля (9 клеток) и соответствующее ему действие агента. Действие агента можно закодировать в 9 битах. Это ход в одну из девяти клеток. Состояние поля можно сохранить в `9 * 3 = 27` битах. Это три состояния для каждой клетки: пустая, крестик или нолик. Итого мы получаем размер таблицы `5478 * (27 + 9) = 197208` бит или 24651 байт.

Мы выяснили, что для простой игры в крестики-нолики рефлексному агенту нужна таблица правил размером около 25 Мбайт. Теперь оценим размер такой таблицы для шахмат.

Согласно расчётам Клода Шеннона, существует около 10^44^ возможных позиций на шахматной доске. Это число несоизмеримо больше 5478 — числа возможных состояний поля в крестиках ноликах. Соотношение чисел 10^44^ и 5478 показывает насколько больше таблица правил для шахмат, чем для крестиков-ноликов. Современные компьютерные технологии просто не позволяют сохранить такой объем информации.

Есть ещё одна проблема при создании рефлексного агента для игры в шахматы. Шахматы до сих пор не решены. Это означает, что лучшие стратегии для белых и чёрных неизвестны. Поэтому даже если бы удалось составить таблицу правил для игры, стратегия рефлексного агента была бы далеко не лучшей.

Есть два способа улучшить рефлексного агента. Первый способ — добавить внутреннее состояние. Это решает проблему с запоминанием прошлых ходов. Такой агент способен следить за развитием партии и соотносить ходы с их последствиями.

Второе улучшение — добавление модели среды в программу агента. Благодаря модели, агент сможет рассчитывать последствия ходов: своих и оппонента.

В теории рефлексный агент с внутренним состоянием и моделью смог бы играть в шахматы. Проблема в том, что на практике реализовать такого агента невозможно. Алгоритм его работы всё равно основан на таблице правил. Но как мы выяснили, современные технологии не позволяют составить и сохранить таблицу размера, достаточного для игры в шахматы.

#### 3.3.2.2 Агенты, использующие поиск

Рассмотрим интеллектуальных агентов, которые используют алгоритмы поиска. Есть два типа таких агентов:

1. Основанные на цели.
2. Основанные на полезности.

Первый тип использует знание о цели. Цель шахматной партии заключается в том, чтобы поставить оппоненту мат. В теории агент мог бы перебрать все возможные ходы обеих сторон и найти позицию с выигрышем партии.

На практике основанный на цели агент сталкивается с рядом проблем. Первая из них — это сложность среды. Агент начинает свой поиск из корневого узла дерева. Этот узел соответствует начальному положению фигур на шахматной доске. Далее дерево игры стремительно растёт. Клод Шеннон оценил его сложность как 10^120^ узлов от начала до конца типичной партии. У современных компьютеров не достаточно памяти, чтобы сохранять посещённые узлы дерева такого размера. Кроме того нет вычислительной мощности, чтобы обойти столько узлов за адекватное время.

Вторая проблема агента в том, что он не оценивает качество проверяемых ходов. Если узел дерева соответствует очевидно плохой позиции, все его дочерние узлы можно не рассматривать. Так агент мог бы отсекать целые поддеревья без проверки их узлов. К сожалению, основанный на цели агент знает признаки конечного состояния, которое нужно найти (то есть мат оппоненту). У него нет информации для проверки промежуточных состояний.

Проблему с оценкой промежуточных состояний решает агент, основанный на полезности. Функция полезности позволяет оптимизировать поиск несколькими путями.

Во-первых, все дерево игры из 10^120^ узлов можно разбить на поддеревья. Их глубина может составлять 10-15 ходов вперёд. Функция полезности даст оценку каждому проверяемому состоянию среды. Так агент найдёт состояние с наибольшей оценкой. Последовательность ходов, которая к нему приведёт, будет лучшей в краткосрочной перспективе.

Второе преимущество функции полезности в том, что она позволяет отсекать поддеревья. Предположим, что агент проверяет очередной узел дерева. Функция полезности даёт низкую оценку соответствующей ему позиции. В этом случае агент может исключить из рассмотрения все дочерние узлы. Таким образом алгоритм поиска проверяет только перспективные ходы. Это позволяет сэкономить время и ресурсы компьютера.

Самое сложность для реализации основанного на полезности агента — выбрать надёжную функции полезности. Шахматная теория предлагает ряд универсальных правил для оценки позиций. Функция полезности должна учитывать все эти правила.

Возможны неоднозначные позиции на доске, в которых разные правила шахматной теории требуют разных действий. В этом случае агент должен решить, какое правило важнее и предпочесть его.

Качество игры основанного на полезности агента зависит от двух факторов:

* Количество ходов, которые агент просчитывает наперёд.

* Качество функции полезности для оценки позиций.

Постепенно улучшая каждый из этих двух факторов, от агента можно добиться высокого уровня игры в шахматы. Однако, с точки зрения когнитивных наук такой агент играет тем же способом, что и начинающий шахматист. Он использует стратегию сравнительной оценки, сопоставляя несколько позиций по ряду критериев. Чтобы применить эту стратегию, человеку требуется очень много времени. Компьютер решает эту проблему благодаря высокой вычислительной мощности.

#### 3.3.2.3 Обучающиеся агенты

Обучающиеся агенты успешно справляются с такими средами как шахматная игра.

Мы рассмотрели три парадигмы алгоритмов обучения:

* Обучение с учителем.
* Обучение без учителя.
* Обучение с подкреплением.

Первые две парадигмы работают только в эпизодических средах. Поэтому они не подходят для создания агента, играющего в шахматы. Только обучение с подкреплением может решить эту задачу.

Шахматы — это сложная среда со множеством состояний. Поэтому алгоритму обучения потребуется значительное время и вычислительные ресурсы, чтобы создать агента.

Разработчик должен задать правила шахмат для алгоритма обучения. Прежде всего это допустимые ходы фигур, а также условия победы и ничьей. Без этих фундаментальных знаний об игре, создать агента не получится.

Рассмотрим типичный алгоритм обучения с подкреплением в общем виде. Он будет проводить шахматные партии между разными модификациями агента. Первое поколение модификаций будет выполнять случайные ходы, допустимые правилами. Несмотря на случайные ходы сторон, партия закончится либо ничьей, либо чьей-то победой.

На следующем шаге алгоритм обучения отсеет менее успешные модификации, которые проигрывают чаще чем выигрывают. Более успешные станут прототипами для модификаций агента второго поколения. Подготовив агентов второго поколения, алгоритм обучения снова проводит партии между ними.

Продолжая совершенствовать модификации агента, алгоритм обучения достигнет требуемого процента побед на каком-то поколении. В этом случае задача алгоритма будет решенной.

С точки зрения когнитивных наук обучающийся агент играет в шахматы так же как эксперт. Алгоритм обучения путём многократных повторений выводит типичные позиции на доске и правильные реакции на них. Эти позиции могут упаковываться иерархически в блоки в терминологии Саймона. Таким образом во время партии агент располагает огромной библиотекой блоков.

Обучающийся агент не тратит время на просчёт ходов вперёд. Вместо этого он распознает типичные позиции и сразу реагирует на них.

Чем больше времени и ресурсов есть у алгоритма обучения, тем больше блоков создаваемый агент научится распознавать. Чем большим количеством шаблонов располагает агент, тем реже он будет ошибаться в своей игре. Таким образом качество агента во многом зависит от объёма ресурсов, которые были потрачены на его создание.

{pagebreak}
