# 4 Приложение

## 4.1 Машинное обучение

### 4.1.1 Классификация набора ирисы Фишера

Скрипт `linear-classifier.py` из листинга 5-1 демонстрирует линейную классификацию точек из набора данных ирисы Фишера. Для этой классификации используется модель логистической регрессии.

{caption: "Листинг 5-1. Скрипт для линейной классификации", line-numbers: true, format: Python}
![`linear-classifier.py`](code/ArtificialIntelligence/linear-classifier.py)

Вот общий алгоритм работы скрипта:

1. Загрузить набор данных ирисы Фишера и объединить классы ирисов 1 и 2.

2. Обучить модель линейного классификатора.

3. Вывести результат классификации в виде графике.

Для работы скрипт импортирует следующие модули:

* `datasets` из библиотеки `sklearn` — содержит эталонный набор данных ирисы Фишера.

* `linear_model` из библиотеки `sklearn` — предоставляет набор моделей для линейной классификации. Кроме того в этом модуле реализован алгоритм обучения этих моделей методом [стохастического градиентного спуска](https://ru.wikipedia.org/wiki/Стохастический_градиентный_спуск).

* `pyplot` из библиотеки `matplotlib` — это интерфейс для построения графиков.

* `copy` — модуль для копирования объектов.

Скрипт начинается с загрузки набора данных ирисы Фишера. Эту загрузку выполняет функция `load_iris` из модуля `datasets`. Её результат сохраняется в переменную `iris`.

 Функция `load_iris` возвращает два массива: `data` и `target`. Элементы массива `data` состоят из четырёх чисел. Эти числа: длина и ширина чашелистника цветка, длина и ширина лепестка цветка. Второй массив `target` содержит коды видов ирисов: 0, 1, 2.

Элементы массивов `data` и `target` с одинаковым индексом дают полное описание конкретного растения. Например, первое растение в наборе данных имеет размеры цветка, описанные в нулевом элементе массива `data`. Вид этого растения соответствует коду в нулевом элементе массива `target`.

Далее скрипт берёт первое и второе число всех элементов массива `data`. Это выполняет следующая операция: `iris.data[:, :2]`. В результате получается массив, в котором есть только длина и ширина чашелистников цветков. Этот массив результат записывается в переменную `x`.

В переменную `y` записывается массив `target` без изменений.

На следующем шаге скрипт объединяет виды ирисов с номерами 1 и 2 в один. Это нужно, потому что по размерам чашелистника цветка можно отличить только вид 0 от видов 1 и 2. Но растение вида 1 от растения 2 по этим признакам не отличить. Для этого нужны размеры лепестка цветка. Наш пример упрощённый. В нём модель обучается только по двум признакам. Поэтому мы обучим модель отличать ирисы вида 0 под названием Iris Setosa от остальных видов.

Чтобы объединить виды ирисов 1 и 2, выполняются два действия:

1. Все элементы массива `y` копируются в массив `y_setosa` с помощью функции `copy` из модуля `copy`.

2. Всем элементам массива `y_setosa` со значением больше 0 присваивается значение 1.

Далее скрипт создаёт объект `sgdc` класса `SGDClassifier` из модуля `linear_model`. Конструктор класса получается два параметра:

1. `loss='log'` выбирает в качестве обучаемой модели логистическую регрессию.

2. `random_state=42` — параметр генератора случайных чисел. Если присвоить ему целое число, то алгоритм обучения будет выдавать одинаковый результат для одного и того же набора данных при перезапуске скрипта.

Когда объект `sgdc` создан, скрипт вызывает его метод `fit`. Этот метод реализует алгоритм обучения модели. Метод принимает в качестве входных параметров массивы `x` и `y_setosa`. Массив `x` содержит вектор входных значений, а массив `y_setosa` — вектор выходных значений для обучения модели.

После обучения модели скрипт выводит ошибку обучения. Эту ошибку возвращает метод `score` объекта `sgdc`. На вход метод принимает те же массивы `x` и `y_setosa`, что и алгоритм обучения `fit`.

Когда модель готова, скрипт строит график с результатом обучения. Для этого вызываются следующие функции из модуля `pyplot`:

1. `figure` — конструктор глобального объекта класса `Figure`. Он хранит все видимые графические элементы.

2. `xlabel` — указывает надпись для оси X.

3. `ylabel` — указывает надпись для оси Y.

4. `scatter` — рисует набор точек на плоскости.  Функция принимает следующие параметры:
   * Первый параметр — это массив с координатами точек по оси X.
   * Второй параметр — массив с координатами точек по оси Y.
   * `c` — массив со списком цветов для каждой точки.
   * `edgecolor` — цвет границы каждой точки.

5. `plot` — рисует линию по заданному набору точек. Функция принимает следующие параметры:
   * Первый параметр — это массив с координатами точек по оси X.
   * Второй параметр — массив с координатами точек по оси Y.
   * `ls` — стиль линии (сплошная, пунктирная и т.д.).
   * `color` — цвет линии.

6. `show` — выводит на экран всё содержимое всех объектов класса `Figure`.

Обученная модель на графике изображается в виде границы между классами. Для двумерного пространства признаков эта граница — прямая линия. Скрипт строит эту линию по двум точкам: крайняя левая и крайняя правая по оси X.

Координаты крайних точек по оси X возвращает функция `plt.xlim()`. Для каждой из них скрипт рассчитывает координату Y. Этот расчёт реализован в функции `calculate_y`. Для расчёта используются следующие параметры обучаемой модели:

* `coef_` — это двумерный массив с весами каждого признака. Первый индекс каждого элемента соответствует классу, а второй — номеру признака. Значение самого элемента равно весу соответствующего признака, который определил алгоритм обучения.

* `intercept_` — это массив с константами пороговой функции.

Для расчёта координаты Y скрипт использует следующую формулу:
{line-numbers: false, format: Python}
```
(-intercept[0] - (x1 * coef[0, 0])) / coef[0, 1]
```

Возникает вопрос: почему эта формула выглядит именно так? Формула границы разделения между классами выглядит так:
{width: "30%"}
![](images/Appendix/logreg-classes-border.png)

В ней используются следующие обозначения:

* z — выходное значение, которое определяет класс объекта. Если z > 0, то объект относится к классу над границей (Iris setosa). Если z < 0, объект относится к классу под границей (другой вид ириса). Если z = 0, то объект находится прямо на границе и модель не может определить его класс.

* θ~0~ — константное значение

* θ~1~ — вес признака ширина чашелистника

* x~1~ — длина чашелистника

* θ~2~ — вес признака длина чашелистника

* x~2~ — ширина чашелистника

Нам известна координата точки x~1~ по оси X. На оси X отложены длины чашелистников. Чтобы построить линию на графике, необходимо найти координату x~2~ по оси Y. На оси Y отложены значения ширины чашелистника. Для вычисления x~2~ допустим, что значение z = 0. Другими словами мы ищем именно точку на границе раздела классов. Тогда формула расчёта значения x~2~ по x~1~ выглядит так:
{width: "30%"}
![](images/Appendix/logreg-x2-calculation.png)

Именно эту формулу вычисления x~2~ использует функция `calculate_x2`.

### 4.1.2 Линейная регрессия цены на поддержанные автомобили

Скрипт `linear-regression.py` из листинга 5-2 демонстрирует обучение модели линейного регрессора на случайно сгенерированном наборе данных. После обучения модель прогнозирует стоимость поддержанных автомобилей в зависимости от их пробега. Для обучения линейного регрессора используется метод наименьших квадратов.

{caption: "Листинг 5-2. Скрипт обучения модели линейного регрессора", line-numbers: true, format: Python}
![`linear-regression.py`](code/ArtificialIntelligence/linear-regression.py)

Вот общий алгоритм работы скрипта:

1. Сгенерировать случайный набор точек в двумерном пространстве.

2. Разделить набор точек на обучающий и тестовый.

3. Обучить модель линейного регрессора на обучающем наборе точек.

4. Получить предсказания модели для тестового набора точек.

5. Вывести результаты предсказаний модели в виде графика.

Рассмотрим каждый шаг алгоритма подробнее.

Для работы скрипт импортирует следующие модули:

* `datasets` из библиотеки `sklearn` — предоставляет функции для генерации случайных наборов данных.

* `linear_model` — содержит набор моделей для линейной регрессии. Также в этом модуле реализованы алгоритмы обучения этих моделей.

* `model_selection` из библиотеки `sklearn` — предоставляет классы и функции для работы с набором данных.

* `pyplot` из библиотеки `matplotlib` — это интерфейс для построения графиков.

Первый шаг скрипта — генерация случайного набора точек с помощью функции `make_regression` из модуля `datasets`. Функция возвращает два массива: 

* Векторы независимых переменных X.
* Значения зависимой переменной Y.

В нашем случае каждый вектор из массива X состоит из единственного значения — величина пробега автомобиля. Каждому вектору соответствует конкретная цена автомобиля из массива Y.

На вход `make_regression` принимает следующие параметры:

* `n_samples` — количество генерируемых точек.

* `n_features` — количество признаков объектов. Размерность выходного массива X соответствует этому параметру.

* `noise` — случайное отклонение генерируемых точек от прямой линии.

* `random_state` — параметр генератора случайных чисел. Если присвоить ему целое число, то алгоритм обучения будет выдавать одинаковый результат для одного и того же набора данных при перезапуске скрипта.

Функция `make_regression` генерирует точки с координатами от -1.5 до 1.5 по оси X и от -100 до 100 по оси Y. Эти значения не похожи на возможные величины пробега автомобилей и их цены. Чтобы приблизить сгенерированные данные к условиям нашей задачи, скрипт приводит их к следующим диапазонам значений:

* Цены на автомобили по оси Y: от 18500$ до 21500$.
* Величины пробега автомобилей по оси X: от 0 км до 4000 км.

Кроме диапазонов значений, есть ещё одна проблема со сгенерированным набором точек. Он расположен так, что с ростом значений по оси X растут значения по оси Y. В контексте нашей задачи это означает, что автомобили с большим пробегом стоят дороже. Но на самом деле зависимость между значениями X и Y обратная: чем больше пробег, тем дешевле автомобиль. Чтобы решить эту проблему, необходимо развернуть значения по оси Y.

Подготовка сгенерированного набора точек выполняется в следующих двух строчках скрипта:
{line-numbers: false, format: Python}
```
x_aligned = [(e + 3) * 800 for e in x]
y_aligned = [23000 - (e + 150) * 23 for e in y]
```

Следующее действие скрипта — разделение всех сгенерированных точек на обучающий и тестовый наборы. Это выполняет функция `train_test_split` из модуля `model_selection`. В качестве параметров она принимает массивы значений X и Y. Кроме того параметр `test_size` определяет соотношение между обучающим и тестовым набором. В нашем случае `test_size` равен 0.15. Это означает, что 15% точек войдут в тестовый набор, а 85% — в обучающий. Значения X и Y обучающего набора сохраняются в переменных `x_train` и `y_train`, а тестового — в `x_test` и `y_test`.

После подготовки обучающего и тестового набора данных, скрипт создаёт модель линейного регрессора. Она реализована в классе `LinearRegression` из модуля `linear_model`. Скрипт создаёт объект этого класси и сохраняет его в переменной с именем `regr`.

Для обучения модели вызывается метод `fit` объекта `regr`. Этот метод принимает на вход значения X и Y из обучающего набора данных. Эти значения хранятся в переменных `x_train` и `y_train`.

Обучаемая модель готова к использованию. Теперь скрипт получает предсказания модели для значений X из тестового набора данных. Эти значения хранятся в переменной `x_test`. Для получения предсказаний вызывается метод `predict` объекта `regr`. Результат его работы сохраняется в переменной `y_pred`.

Благодаря предсказаниям модели, строится наглядный график прогнозируемых и реальных цен на автомобили с пробегом. Для этого скрипт вызывает следующие функции из модуля `pyplot`:

1. `figure` — конструктор глобального объекта класса `Figure`. Он хранит все видимые графические элементы.

2. `xlabel` — указывает надпись для оси X.

3. `ylabel` — указывает надпись для оси Y.

4. `scatter` — рисует набор точек на плоскости.

5. `plot` — рисует линию по заданному набору точек.

6. `show` — выводит на экран всё содержимое всех объектов класса `Figure`.

На графике предсказания модели изображаются синей линией. Чёрные точки соответствуют реальным ценам на автомобили с пробегом из тестового набора данных.

### 4.1.3 Кластеризация пользователей онлайн магазина методом k-средних

Скрипт `k-mean-clustering.py` из листинга 5-3 демонстрирует кластеризацию набора точек методом k-средних.

{caption: "Листинг 5-3. Скрипт кластеризации методом k-средних", line-numbers: true, format: Python}
![`k-mean-clustering.py`](code/ArtificialIntelligence/k-mean-clustering.py)

Общий алгоритм работы скрипта выглядит так:

1. Сгенерировать случайный набор точек в двумерном пространстве.

2. Кластеризовать точки методом k-средних.

3. Вывести результат кластеризации в виде графике.

Для работы скрипт импортирует следующие модули:

* `datasets` из библиотеки `sklearn` — содержит функции для генерации наборов данных. Кроме того в него входят методы загрузки эталонных наборов данных для тестирования новых алгоритмов обучения.

* `cluster` из библиотеки `sklearn` — в нём реализованы популярные алгоритмы обучения без учителя для задачи кластеризации.

* `pyplot` из библиотеки `matplotlib` — это интерфейс для построения графиков.

Скрипт начинается с вызова функции [`make_blobs`](https://scikit-learn.org/stable/datasets/sample_generators.html#sample-generators) из модуля `datasets`. Эта функция генерирует кластеры точек на двумерном пространстве признаков. Координаты центров кластеров выбираются случайно. Точки каждого кластера находятся на случайном расстоянии от его центра. Эти расстояния соответствуют [нормальному распределению вероятностей](https://ru.wikipedia.org/wiki/Нормальное_распределение).

Результат генерации кластеров точек сохраняется в переменной `X`. Эта переменная представляет собой массив. Каждый его элемент соответствует одной точке. Точка представляет собой пару чисел: координаты по оси X и Y.

Далее скрипт создаёт объект класса [`KMeans`](https://scikit-learn.org/stable/modules/clustering.html#k-means) из модуля `cluster`. Этот объект сохраняется в переменной `kmeans`. В классе `KMeans` реализован алгоритм обучения методом k-средних.

В нашем случае конструктор класса `KMeans` принимает только два входных параметра:

* `n_clusters` — число кластеров, которые должна найти обучаемая модель.

* `random_state` — параметр генератора случайных чисел. Если присвоить ему целое число, то алгоритм обучения будет выдавать одинаковый результат для одного и того же набора данных при перезапуске скрипта.

После создания объекта класса `KMeans` скрипт вызывает его метод `fit` с параметром `X`. Этот метод выполняет алгоритм обучения на наборе данных, который хранится в переменной `X`.

Далее скрипт строит график с результатами обучения. Для этого из модуля `pyplot` вызываются следующие функции:

1. `figure` — конструктор глобального объекта класса `Figure`. Он хранит все видимые графические элементы.

2. `xlabel` — указывает надпись для оси X.

3. `ylabel` — указывает надпись для оси Y.

4. `scatter` — рисует набор точек на плоскости.  Функция принимает следующие параметры:
   * Первый параметр — это массив с координатами точек по оси X.
   * Второй параметр — массив с координатами точек по оси Y.
   * `c` — массив со списком цветов для каждой точки.
   * `s` — размер точек.
   * `alpha` — уровень прозрачности от 0 (прозрачный) до 1 (непрозрачный).

5. `show` — выводит на экран всё содержимое всех объектов класса `Figure`.

Первый вызов функции `scatter` рисует все точки из сгенерированного набора. Функция принимает следующие параметры:

* `X[:,0]` — первые числа всех элементов массива `X`. Эти числа соответствуют координатам точек по оси X.

* `X[:,1]` — вторые числа всех элементов массива `X`. Эти числа соответствуют координатам точек по оси Y.

* `c=kmeans.labels_.astype(float)` — массив, каждый элемент которого соответствует точке из обучающего набора данных. Значение элемента — номер кластера к которому алгоритм обучения отнёс соответствующую точку.

Второй вызов функции `scatter` рисует центры кластеризации, которые нашёл алгоритм k-средних. Функция принимает следующие параметры:

* `centers[:, 0]` — координаты X центров всех кластеров, которые нашёл алгоритм обучения.

* `centers[:, 1]` — координаты Y центров всех кластеров, которые нашёл алгоритм обучения.

* `c='black'` — чёрный цвет, которым надо раскрасить центры кластеров.

* `s=200` — размер каждого центра кластера.

* `alpha=0.5` — полупрозрачность.

Иллюстрация 2-16 демонстрирует результат работы скрипта `k-mean-clustering.py`.

## 4.2 Современные шахматные движки

### 4.2.1 Применение фильтра для изображения

// TODO
