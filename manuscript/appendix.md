# 5 Приложение

## 5.1 Машинное обучение

### 5.1.1 Классификация набора ирисы Фишера

Скрипт `linear-classifier.py` из листинга 5-1 демонстрирует линейную классификацию точек из набора данных ирисы Фишера. Для этой классификации используется модель логистической регрессии.

{caption: "Листинг 5-1. Скрипт для линейной классификации", line-numbers: true, format: Python}
![`linear-classifier.py`](code/ArtificialIntelligence/linear-classifier.py)

Вот общий алгоритм работы скрипта:

1. Загрузить набор данных ирисы Фишера и объединить классы ирисов 1 и 2.

2. Обучить модель линейного классификатора.

3. Вывести результат классификации в виде графике.

Для работы скрипт импортирует следующие модули:

* `datasets` из библиотеки `sklearn` — содержит эталонный набор данных ирисы Фишера.

* `linear_model` из библиотеки `sklearn` — предоставляет набор моделей для линейной классификации. Кроме того в этом модуле реализован алгоритм обучения этих моделей методом [стохастического градиентного спуска](https://ru.wikipedia.org/wiki/Стохастический_градиентный_спуск).

* `pyplot` из библиотеки `matplotlib` — это интерфейс для построения графиков.

* `copy` — модуль для копирования объектов.

Скрипт начинается с загрузки набора данных ирисы Фишера. Эту загрузку выполняет функция `load_iris` из модуля `datasets`. Её результат сохраняется в переменную `iris`.

 Функция `load_iris` возвращает два массива: `data` и `target`. Элементы массива `data` состоят из четырёх чисел. Эти числа: длина и ширина чашелистика цветка, длина и ширина лепестка цветка. Второй массив `target` содержит коды видов ирисов: 0, 1, 2.

Элементы массивов `data` и `target` с одинаковым индексом дают полное описание конкретного растения. Например, первое растение в наборе данных имеет размеры цветка, описанные в нулевом элементе массива `data`. Вид этого растения соответствует коду в нулевом элементе массива `target`.

Далее скрипт берёт первое и второе число всех элементов массива `data`. Это выполняет следующая операция: `iris.data[:, :2]`. В результате получается массив, в котором есть только длина и ширина чашелистиков цветков. Этот массив результат записывается в переменную `x`.

В переменную `y` записывается массив `target` без изменений.

На следующем шаге скрипт объединяет виды ирисов с номерами 1 и 2 в один. Это нужно, потому что по размерам чашелистика цветка можно отличить только вид 0 от видов 1 и 2. Но растение вида 1 от растения 2 по этим признакам не отличить. Для этого нужны размеры лепестка цветка. Наш пример упрощённый. В нём модель обучается только по двум признакам. Поэтому мы обучим модель отличать ирисы вида 0 под названием Iris Setosa от остальных видов.

Чтобы объединить виды ирисов 1 и 2, выполняются два действия:

1. Все элементы массива `y` копируются в массив `y_setosa` с помощью функции `copy` из модуля `copy`.

2. Всем элементам массива `y_setosa` со значением больше 0 присваивается значение 1.

Далее скрипт создаёт объект `sgdc` класса `SGDClassifier` из модуля `linear_model`. Конструктор класса получается два параметра:

1. `loss='log_loss'` выбирает в качестве обучаемой модели логистическую регрессию.

2. `random_state=42` — параметр генератора случайных чисел. Если присвоить ему целое число, то алгоритм обучения будет выдавать одинаковый результат для одного и того же набора данных при перезапуске скрипта.

Когда объект `sgdc` создан, скрипт вызывает его метод `fit`. Этот метод реализует алгоритм обучения модели. Метод принимает в качестве входных параметров массивы `x` и `y_setosa`. Массив `x` содержит вектор входных значений, а массив `y_setosa` — вектор выходных значений для обучения модели.

После обучения модели скрипт выводит ошибку обучения. Эту ошибку возвращает метод `score` объекта `sgdc`. На вход метод принимает те же массивы `x` и `y_setosa`, что и алгоритм обучения `fit`.

Когда модель готова, скрипт строит график с результатом обучения. Для этого вызываются следующие функции из модуля `pyplot`:

1. `figure` — конструктор глобального объекта класса `Figure`. Он хранит все видимые графические элементы.

2. `xlabel` — указывает надпись для оси X.

3. `ylabel` — указывает надпись для оси Y.

4. `scatter` — рисует набор точек на плоскости.  Функция принимает следующие параметры:
   * Первый параметр — это массив с координатами точек по оси X.
   * Второй параметр — массив с координатами точек по оси Y.
   * `c` — массив со списком цветов для каждой точки.
   * `edgecolor` — цвет границы каждой точки.

5. `plot` — рисует линию по заданному набору точек. Функция принимает следующие параметры:
   * Первый параметр — это массив с координатами точек по оси X.
   * Второй параметр — массив с координатами точек по оси Y.
   * `ls` — стиль линии (сплошная, пунктирная и т.д.).
   * `color` — цвет линии.

6. `show` — выводит на экран всё содержимое всех объектов класса `Figure`.

Обученная модель на графике изображается в виде границы между классами. Для двумерного пространства признаков эта граница — прямая линия. Скрипт строит эту линию по двум точкам: крайняя левая и крайняя правая по оси X.

Координаты крайних точек по оси X возвращает функция `plt.xlim()`. Для каждой из них скрипт рассчитывает координату Y. Этот расчёт реализован в функции `calculate_y`. Для расчёта используются следующие параметры обучаемой модели:

* `coef_` — это двумерный массив с весами каждого признака. Первый индекс каждого элемента соответствует классу, а второй — номеру признака. Значение самого элемента равно весу соответствующего признака, который определил алгоритм обучения.

* `intercept_` — это массив с константами пороговой функции.

Для расчёта координаты Y скрипт использует следующую формулу:
{line-numbers: false, format: Python}
```
(-intercept[0] - (x1 * coef[0, 0])) / coef[0, 1]
```

Возникает вопрос: почему эта формула выглядит именно так? Формула границы разделения между классами выглядит так:
{width: "30%"}
![](images/Appendix/logreg-classes-border.png)

В ней используются следующие обозначения:

* z — выходное значение, которое определяет класс объекта. Если z > 0, то объект относится к классу над границей (Iris setosa). Если z < 0, объект относится к классу под границей (другой вид ириса). Если z = 0, то объект находится прямо на границе и модель не может определить его класс.

* θ~0~ — константное значение

* θ~1~ — вес признака ширина чашелистика

* x~1~ — длина чашелистика

* θ~2~ — вес признака длина чашелистика

* x~2~ — ширина чашелистика

Нам известна координата точки x~1~ по оси X. На оси X отложены длины чашелистиков. Чтобы построить линию на графике, необходимо найти координату x~2~ по оси Y. На оси Y отложены значения ширины чашелистика. Для вычисления x~2~ допустим, что значение z = 0. Другими словами мы ищем именно точку на границе раздела классов. Тогда формула расчёта значения x~2~ по x~1~ выглядит так:
{width: "30%"}
![](images/Appendix/logreg-x2-calculation.png)

Именно эту формулу вычисления x~2~ использует функция `calculate_x2`.

Иллюстрация 2-18 демонстрирует результат работы скрипта `linear-classifier.py`.

### 5.1.2 Линейная регрессия цены на поддержанные автомобили

Скрипт `linear-regression.py` из листинга 5-2 демонстрирует обучение модели линейного регрессора на случайно сгенерированном наборе данных. После обучения модель прогнозирует цену поддержанных автомобилей в зависимости от их пробега. Для обучения линейного регрессора используется метод наименьших квадратов.

{caption: "Листинг 5-2. Скрипт обучения модели линейного регрессора", line-numbers: true, format: Python}
![`linear-regression.py`](code/ArtificialIntelligence/linear-regression.py)

Вот общий алгоритм работы скрипта:

1. Сгенерировать случайный набор точек в двумерном пространстве.

2. Разделить набор точек на обучающий и тестовый.

3. Обучить модель линейного регрессора на обучающем наборе точек.

4. Получить предсказания модели для тестового набора точек.

5. Вывести результаты предсказаний модели в виде графика.

Рассмотрим каждый шаг алгоритма подробнее.

Для работы скрипт импортирует следующие модули:

* `datasets` из библиотеки `sklearn` — предоставляет функции для генерации случайных наборов данных.

* `linear_model` — содержит набор моделей для линейной регрессии. Также в этом модуле реализованы алгоритмы обучения этих моделей.

* `model_selection` из библиотеки `sklearn` — предоставляет классы и функции для работы с набором данных.

* `pyplot` из библиотеки `matplotlib` — это интерфейс для построения графиков.

Первый шаг скрипта — генерация случайного набора точек с помощью функции `make_regression` из модуля `datasets`. Функция возвращает два массива: 

* Векторы независимых переменных X.
* Значения зависимой переменной Y.

В нашем случае каждый вектор из массива X состоит из единственного значения — величина пробега автомобиля. Каждому вектору соответствует конкретная цена автомобиля из массива Y.

На вход `make_regression` принимает следующие параметры:

* `n_samples` — количество генерируемых точек.

* `n_features` — количество признаков объектов. Размерность выходного массива X соответствует этому параметру.

* `noise` — случайное отклонение генерируемых точек от прямой линии.

* `random_state` — параметр генератора случайных чисел. Если присвоить ему целое число, то алгоритм обучения будет выдавать одинаковый результат для одного и того же набора данных при перезапуске скрипта.

Функция `make_regression` генерирует точки с координатами от -1.5 до 1.5 по оси X и от -100 до 100 по оси Y. Эти значения не похожи на возможные величины пробега автомобилей и их цены. Чтобы приблизить сгенерированные данные к условиям нашей задачи, скрипт приводит их к следующим диапазонам значений:

* Цены на автомобили по оси Y: от 18500$ до 21500$.
* Величины пробега автомобилей по оси X: от 0 км до 4000 км.

Кроме диапазонов значений, есть ещё одна проблема со сгенерированным набором точек. Он расположен так, что с ростом значений по оси X растут значения по оси Y. В контексте нашей задачи это означает, что автомобили с большим пробегом стоят дороже. Но на самом деле зависимость между значениями X и Y обратная: чем больше пробег, тем дешевле автомобиль. Чтобы решить эту проблему, необходимо развернуть значения по оси Y.

Подготовка сгенерированного набора точек выполняется в следующих двух строчках скрипта:
{line-numbers: false, format: Python}
```
x_aligned = [(e + 3) * 800 for e in x]
y_aligned = [23000 - (e + 150) * 23 for e in y]
```

Следующее действие скрипта — разделение всех сгенерированных точек на обучающий и тестовый наборы. Это выполняет функция `train_test_split` из модуля `model_selection`. В качестве параметров она принимает массивы значений X и Y. Кроме того параметр `test_size` определяет соотношение между обучающим и тестовым набором. В нашем случае `test_size` равен 0.15. Это означает, что 15% точек войдут в тестовый набор, а 85% — в обучающий. Значения X и Y обучающего набора сохраняются в переменных `x_train` и `y_train`, а тестового — в `x_test` и `y_test`.

После подготовки обучающего и тестового набора данных, скрипт создаёт модель линейного регрессора. Она реализована в классе `LinearRegression` из модуля `linear_model`. Скрипт создаёт объект этого класси и сохраняет его в переменной с именем `regr`.

Для обучения модели вызывается метод `fit` объекта `regr`. Этот метод принимает на вход значения X и Y из обучающего набора данных. Эти значения хранятся в переменных `x_train` и `y_train`.

Обучаемая модель готова к использованию. Теперь скрипт получает предсказания модели для значений X из тестового набора данных. Эти значения хранятся в переменной `x_test`. Для получения предсказаний вызывается метод `predict` объекта `regr`. Результат его работы сохраняется в переменной `y_pred`.

Благодаря предсказаниям модели, строится наглядный график прогнозируемых и реальных цен на автомобили с пробегом. Для этого скрипт вызывает следующие функции из модуля `pyplot`:

1. `figure` — конструктор глобального объекта класса `Figure`. Он хранит все видимые графические элементы.

2. `xlabel` — указывает надпись для оси X.

3. `ylabel` — указывает надпись для оси Y.

4. `scatter` — рисует набор точек на плоскости.

5. `plot` — рисует линию по заданному набору точек.

6. `show` — выводит на экран всё содержимое всех объектов класса `Figure`.

На графике предсказания модели изображаются синей линией. Чёрные точки соответствуют реальным ценам на автомобили с пробегом из тестового набора данных.

Иллюстрация 2-19 демонстрирует результат работы скрипта `linear-regression.py`.

### 5.1.3 Кластеризация пользователей онлайн магазина методом k-средних

Скрипт `k-mean-clustering.py` из листинга 5-3 демонстрирует кластеризацию набора точек методом k-средних.

{caption: "Листинг 5-3. Скрипт кластеризации методом k-средних", line-numbers: true, format: Python}
![`k-mean-clustering.py`](code/ArtificialIntelligence/k-mean-clustering.py)

Общий алгоритм работы скрипта выглядит так:

1. Сгенерировать случайный набор точек в двумерном пространстве.

2. Кластеризовать точки методом k-средних.

3. Вывести результат кластеризации в виде графике.

Для работы скрипт импортирует следующие модули:

* `datasets` из библиотеки `sklearn` — содержит функции для генерации наборов данных. Кроме того в него входят методы загрузки эталонных наборов данных для тестирования новых алгоритмов обучения.

* `cluster` из библиотеки `sklearn` — в нём реализованы популярные алгоритмы обучения без учителя для задачи кластеризации.

* `pyplot` из библиотеки `matplotlib` — это интерфейс для построения графиков.

Скрипт начинается с вызова функции [`make_blobs`](https://scikit-learn.org/stable/datasets/sample_generators.html#sample-generators) из модуля `datasets`. Эта функция генерирует кластеры точек на двумерном пространстве признаков. Координаты центров кластеров выбираются случайно. Точки каждого кластера находятся на случайном расстоянии от его центра. Эти расстояния соответствуют [нормальному распределению вероятностей](https://ru.wikipedia.org/wiki/Нормальное_распределение).

Результат генерации кластеров точек сохраняется в переменной `X`. Эта переменная представляет собой массив. Каждый его элемент соответствует одной точке. Точка представляет собой пару чисел: координаты по оси X и Y.

Далее скрипт создаёт объект класса [`KMeans`](https://scikit-learn.org/stable/modules/clustering.html#k-means) из модуля `cluster`. Этот объект сохраняется в переменной `kmeans`. В классе `KMeans` реализован алгоритм обучения методом k-средних.

В нашем случае конструктор класса `KMeans` принимает только два входных параметра:

* `n_clusters` — число кластеров, которые должна найти обучаемая модель.

* `random_state` — параметр генератора случайных чисел. Если присвоить ему целое число, то алгоритм обучения будет выдавать одинаковый результат для одного и того же набора данных при перезапуске скрипта.

После создания объекта класса `KMeans` скрипт вызывает его метод `fit` с параметром `X`. Этот метод выполняет алгоритм обучения на наборе данных, который хранится в переменной `X`.

Далее скрипт строит график с результатами обучения. Для этого из модуля `pyplot` вызываются следующие функции:

1. `figure` — конструктор глобального объекта класса `Figure`. Он хранит все видимые графические элементы.

2. `xlabel` — указывает надпись для оси X.

3. `ylabel` — указывает надпись для оси Y.

4. `scatter` — рисует набор точек на плоскости.  Функция принимает следующие параметры:
   * Первый параметр — это массив с координатами точек по оси X.
   * Второй параметр — массив с координатами точек по оси Y.
   * `c` — массив со списком цветов для каждой точки.
   * `s` — размер точек.
   * `alpha` — уровень прозрачности от 0 (прозрачный) до 1 (непрозрачный).

5. `show` — выводит на экран всё содержимое всех объектов класса `Figure`.

Первый вызов функции `scatter` рисует все точки из сгенерированного набора. Функция принимает следующие параметры:

* `X[:,0]` — первые числа всех элементов массива `X`. Эти числа соответствуют координатам точек по оси X.

* `X[:,1]` — вторые числа всех элементов массива `X`. Эти числа соответствуют координатам точек по оси Y.

* `c=kmeans.labels_.astype(float)` — массив, каждый элемент которого соответствует точке из обучающего набора данных. Значение элемента — номер кластера к которому алгоритм обучения отнёс соответствующую точку.

Второй вызов функции `scatter` рисует центры кластеризации, которые нашёл алгоритм k-средних. Функция принимает следующие параметры:

* `centers[:, 0]` — координаты X центров всех кластеров, которые нашёл алгоритм обучения.

* `centers[:, 1]` — координаты Y центров всех кластеров, которые нашёл алгоритм обучения.

* `c='black'` — чёрный цвет, которым надо раскрасить центры кластеров.

* `s=200` — размер каждого центра кластера.

* `alpha=0.5` — полупрозрачность.

Иллюстрация 2-20 демонстрирует результат работы скрипта `k-mean-clustering.py`.

### 5.1.4 Обучение с подкреплением алгоритмом Q-learning

// TODO

## 5.2 Современные шахматные движки

### 5.2.1 Применение вертикального фильтра Собеля

Скрипт `sobel-vertical-filter.py` из листинга 5-4 демонстрирует применение вертикального фильтра Собеля к исходной фотографии. Чтобы запустить скрипт скачайте его и [фотографию Лены Сёдерберг](https://github.com/ellysh/ai-in-strategy-games/blob/master/manuscript/resources/code/Chess/lena.png) в один каталог. Пожалуйста, не меняйте имена файлов.

{caption: "Листинг 5-4. Скрипт для линейной классификации", line-numbers: true, format: Python}
![`sobel-vertical-filter.py`](code/Chess/sobel-vertical-filter.py)

Вот общий алгоритм работы скрипта:

1. Подготовка входных данных.

2. Применение фильтра к цветовым каналом фотографии.

3. Визуализация карт признаков в виде RGB изображения.

Для работы скрипт импортирует следующие модули и библиотеки:

* Библиотека `numpy` для работы с массивами.

* Модуль `pyplot` из библиотеки `matplotlib` предоставляет интерфейс для вывода изображений.

* Функция `convolve` из библиотеки `scipy` выполняет операцию свёртки.

В начале скрипта объявляется двумерный массив `sobel_vertical` размера 3x3 с вертикальным фильтром Собеля. Он сохраняется в объект `array` из библиотеки `numpy`. Объект предоставляет удобный интерфейс для работы с массивами.

На следующем шаге скрипт загружает фотографию из файла `lena.png`. Для загрузки вызывается функция `imread` из модуля `pyplot`. Она возвращает объект `array` с массивом пикселей загруженной фотографии. Для RGB изображений массив имеет размер `(M, N, 3)`. Где M — это ширина исходного изображения в пикселях, а N — его высота. Другими словами мы получили стек из трёх изображений: по одному для каждого цветового канала.

Далее скрипт применяет вертикальный фильтр Собеля к каждому из трёх цветовых каналов изображения. Для этого в цикле `for` с тремя итерациями вызывается функция `convolve` из библиотеки `scipy`. Функция принимает на воход два параметра:

1. `img[:,:,channel]` — массив пикселей исходного изображения из цветового канала с индексом `channel`.

2. `sobel_vertical` — массив с вертикальным фильтром Собеля.

Функция возвращает карту признаков с результатом операции свёртки. Она представляет собой объект `array`. Объект записывается во временную переменную с именем `result`. Эта временная переменная добавляется в список (объект `list`) с именем `channels`.

После окончания выполнения фильтра `for` мы получим список `channels` с тремя элементами. Каждый элемент — это объект `array` с картой признаков для соответствующего цветового канала исходно изображения.

На следующем шаге скрипт комбинирует все три элемента из списка `channels` в один массив. Для этого вызывается функция `dstack` из библиотеки `numpy`. Эта функция не меняет элементы входных массивов, а только упорядочивает их по третьему измерению. Таким образом из трёх массивов мы получаем изображение с тремя цветовыми каналами. Его мы сохраняем в виде объекта `array` в переменную `img`. 

I> Подробнее работа функции `dstack` описана в [статье](https://www.educative.io/answers/what-is-the-numpydstack-function-in-numpy).

Функция `dstack` вернула нам массив пикселей RGB изображения. Для его визуализации скрипт вызывает функцию `imshow` из библиотеки `matplotlib`. Эта функция принимает на вход объект `array` из переменной `img`.

Последнее действие скрипта — открыть окно с финальным RGB изображением. Для этого вызывается функция `show ` библиотеки `matplotlib`. Эта функция не имеет входных параметров.

Иллюстрация 3-41 демонстрирует результат работы скрипта `sobel-vertical-filter.py`.

### 5.2.2 Применение фильтра для изображения

Скрипт `apply-filter-manually.py` из листинга 5-5 демонстрирует выполнение операции свёртки без функции `convolve` из библиотеки `scipy`. Чтобы увидеть результаты скрипта, запустите его из интерпретатора командной строки. Это `cmd.exe` для Windows или Bash для Linux.

{caption: "Листинг 5-5. Скрипт для линейной классификации", line-numbers: true, format: Python}
![`apply-filter-manually.py`](code/Chess/apply-filter-manually.py)

Вот общий алгоритм работы скрипта:

1. Подготовка входных данных.

2. Выполнение произведения Адамара во вложенном цикле.

3. Вывод результата на консоль.

Для работы скрипт импортирует только библиотеку `numpy` для операций с массивами.

В начале скрипта объявляется двумерный массив `sobel_vertical` размера 3x3 с вертикальным фильтром Собеля. Он помещается в объект `array` из библиотеки `numpy`.

Далее объявляется массив `image` размера 5x5 c пикселями исходного чёрно-белого изображения. Он также помещается в объект `array`.

На следующем шаге объявляются три пустых массива:

1. `tmp` — временно хранит пиксели исходного изображения, которые на текущем шаге перекрыл фильтр. Размер этого двумерного массива 3x3 соответствует размеру фильтра.

2. `row` — временно хранит элементы одной строки карты признаков. Максимальный размер этого одномерного массива 3.

3. `result` хранит финальную карту признаков, которая получилась в результате операции свёртки. Размер этого массива 3x3.

После подготовки входных данных и временных массивов скрипт выполняет [**вложенный цикл**](https://education.yandex.ru/handbook/python/article/vlozhennye-cikly). Внешний цикл выполняет следующий оператор `for`:
{line-numbers: false, format: Python}
```
for i in range(1, 4):
```

Он проходит по строкам исходного изображения. Нумерация строк начинается с 0. Тогда в нашем случае последняя строка изображения имеет индекс 4. Функция `range(1, 4)` возвращает массив `[1, 2, 3]`. Цикл проходит по элементам этого массива. На каждой итерации очередной элемент записывается в переменную с именем `i`.

Внутренний цикл выполняет следующий оператор `for`:
{line-numbers: false, format: Python}
```
   for j in range(1, 4):
```

Он проходит по столбцам исходного изображения. На каждой из трёх итераций оператор `for` записывает очередной элемент массива `[1, 2, 3]` в переменную с именем `j`.

На каждой итерации внутреннего цикла `for` выполняются три действия:

1. Сохранить во временный массив `tmp` пиксели исходного изображения, которые перекрыл фильтр. Это три строки пикселей, которые начинаются с индекса `i-1` и заканчивая `i+1`. Ряды пикселей в этих строках начинаются с индекса `j-1` и заканчиваются `j+1`.

2. Выполнить произведение Адамара. Его результат представляет собой одно число, которое записывается в конец массива `row`. Произведение Адамара выполняется за два шага:

* Вызов функции `multiply` из библиотеки `numpy`. Она получает на вход два массива и перемножает их элементы с одинаковыми индексами. Это означает, что первый элемент умножается на первый, второй на второй и т.д. Результат функции возвращается в виде массива в `array` объекте.

* Вызов функции `sum` из библиотеки `numpy`. Она получает на вход один массив и скалывает все его элементы между собой.

3. Очистить временный массив `tmp` для подготовки к следующей итерации внутреннего цикла `for`.

На каждой итерации внешнего цикла `for` выполняются три действия:

1. Запустить внутренний цикл `for` с самого начала.

2. Записать результат выполнения внутреннего цикла `for` в конец массива `result`. Этот результат хранится во временном массиве `row`.

3. Очистить временный массив `row` для подготовки к следующей итерации внешнего цикла `for`.

После завершения внешнего цикла `for` результат работы скрипта хранится в массиве `result`. Он выводится на консоль с помощью функции `print`. Этот вывод выглядит следующим образом:
{line-numbers: false, format: Python}
```
[[-38, -190, -365], [-252, -204, -239], [37, 251, 429]]
```

{pagebreak}
